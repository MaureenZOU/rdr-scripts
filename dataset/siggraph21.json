[
  {
    "paper_id": "paperstog_123",
    "authors": "Bernhard Egger, William Smith, Ayush Tewari, Stefanie Wuhrer, Michael Zollhoefer, Thabo Beeler, Florian Bernard, Timo Bolkart, Adam Kortylewski, Sami Romdhani, Christian Theobalt, Volker Blanz, Thomas Vetter",
    "title": "3D Morphable Face Models — Past, Present, and Future",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3395208",
    "pdf_link": null,
    "abstract": "In this article, we provide a detailed survey of 3D Morphable Face Models over the 20 years since they were first proposed. The challenges in building and applying these models, namely, capture, modeling, image formation, and image analysis, are still active research topics, and we review the state-of-the-art in each of these areas. We also look ahead, identifying unsolved challenges, proposing directions for future research, and highlighting the broad range of current and future applications.",
    "scholar_publication": "ACM Transactions on …, 2020 - dl.acm.org"
  },
  {
    "paper_id": "papers_273",
    "authors": "Yingying Ren, Julian Panetta, Tian Chen, Florin Isvoranu, Samuel Poincloux, Christopher Brandt, Alison Martin, Mark Pauly",
    "title": "3D Weaving With Curved Ribbons",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459788",
    "pdf_link": null,
    "abstract": "… in the otherwise regular weaving pattern. However, shape … geometries by weaving carefully optimized curved ribbons. We … Our algorithm computes the ribbons' planar geometry such …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_122",
    "authors": "Sinan Sonlu, Ugur Gudukbay, Funda Durupinar",
    "title": "A Conversational Agent Framework With Multi-modal Personality Expression",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3439795",
    "pdf_link": null,
    "abstract": "Consistently exhibited personalities are crucial elements of realistic, engaging, and behavior-rich conversational virtual agents. Both nonverbal and verbal cues help convey these agents’ unseen psychological states, contributing to our effective communication with them. We introduce a comprehensive framework to design conversational agents that express personality through non-verbal behaviors like body movement and facial expressions, as well as verbal behaviors like dialogue selection and voice transformation. We use the OCEAN personality model, which defines personality as a combination of five orthogonal factors of openness, conscientiousness, extraversion, agreeableness, and neuroticism. The framework combines existing personality expression methods with novel ones such as new algorithms to convey Laban Shape and Effort qualities. We perform Amazon Mechanical Turk studies to analyze how different communication modalities influence our perception of virtual agent personalities and compare their individual and combined effects on each personality dimension. The results indicate that our personality-based modifications are perceived as natural, and each additional modality improves perception accuracy, with the best performance achieved when all the modalities are present. We also report some correlations for the perception of conscientiousness with neuroticism and openness with extraversion.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_179",
    "authors": "Alexander Wilkie, Petr Vevoda, Tom Bashford-Rogers, Lukáš Hošek, Tomáš Iser, Monika Kolářová, Tobias Rittig, Jaroslav Křivánek",
    "title": "A Fitted Radiance and Attenuation Model for Realistic Atmospheres",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459758",
    "pdf_link": null,
    "abstract": "We present a fitted model of sky dome radiance and attenuation for realistic terrestrial atmospheres. Using scatterer distribution data from atmospheric measurement data, our model considerably improves on the visual realism of existing analytical clear sky models, as well as of interactive methods that are based on approximating atmospheric light transport. We also provide features not found in fitted models so far: radiance patterns for post-sunset conditions, in-scattered radiance and attenuation values for finite viewing distances, an observer altitude resolved model that includes downward-looking viewing directions, as well as polarisation information. We introduce a fully spherical model for in-scattered radiance that replaces the family of hemispherical functions originally introduced by Perez et al., and which was extended for several subsequent analytical models: our model relies on reference image compression via tensor decomposition instead.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_280",
    "authors": "Shlomi Steinberg, Lingqi Yan",
    "title": "A Generic Framework for Physical Light Transport",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459791",
    "pdf_link": null,
    "abstract": "Physically accurate rendering often calls for taking the wave nature of light into consideration. In computer graphics, this is done almost exclusively locally, i.e. on a micrometre scale where the diffractive phenomena arise. However, the statistical properties of light, that dictate its coherence characteristics and its capacity to give rise to wave interference effects, evolve globally: these properties change on, e.g., interaction with a surface, diffusion by participating media and simply by propagation. In this paper, we derive the first global light transport framework that is able to account for these properties of light and, therefore, is fully consistent with Maxwell's electromagnetic theory. We show that our framework is a generalization of the classical, radiometry-based light transport---prominent in computer graphics---and retains some of its attractive properties. Finally, as a proof of concept, we apply the presented framework to a few practical problems in rendering and validate against well-studied methods in optics.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_412",
    "authors": "Thomas Klaus Nindel, Tomáš Iser, Tobias Rittig, Alexander Wilkie, Jaroslav Křivánek",
    "title": "A Gradient-based Framework for 3D Print Appearance Optimization",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459844",
    "pdf_link": null,
    "abstract": "In full-color inkjet 3D printing, a key problem is determining the material configuration for the millions of voxels that a printed object is made of. The goal is a configuration that minimises the difference between desired target appearance and the result of the printing process. So far, the techniques used to find such a configuration have relied on domain-specific methods or heuristic optimization, which allowed only a limited level of control over the resulting appearance. We propose to use differentiable volume rendering in a continuous material-mixture space, which leads to a framework that can be used as a general tool for optimising inkjet 3D printouts. We demonstrate the technical feasibility of this approach, and use it to attain fine control over the fabricated appearance, and high levels of faithfulness to the specified target.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_183",
    "authors": "Li Zhang, Weiping He, Huidong Bai, Jun He, Yiyue Qiao, Mark Billinghurst",
    "title": "A Hybrid 2D-3D Tangible Interface for Virtual Reality",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469166",
    "pdf_link": null,
    "abstract": "Virtual Reality (VR) controllers are widely used for easy object selection and manipulation as a primary 3D input method in the virtual environment. Mobile devices with touchscreens like smartphones or tablets provide precise 2D tangible inputs. This research combines a VR controller and a touch-based smartphone to create a novel hybrid 2D-3D interface for enhanced VR interaction. We present the interface design and its implementation and also demonstrate four featured scenarios with the hybrid interface.",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_466",
    "authors": "Mackenzie Leake, Gilbert Bernstein, Abe Davis, Maneesh Agrawala",
    "title": "A Mathematical Foundation for Foundation Paper Pieceable Quilts",
    "paper_url": "https://mackenzieleake.com/projects/paperpiecing/files/FPP_small.pdf",
    "pdf_link": null,
    "abstract": "Quiltmaking has become a popular craft, with 7-10 million quilters in the US alone [The Quilting Company 2017]. Foundation paper piecing is a common method for sewing the top layer of a quilt using a pattern printed on paper as a physical guide. Quilters sew pieces of fabric corresponding to each polygon in the pattern’s geometric design along the printed seam lines, directly to the paper and one another. The fabric pieces are sewn one at a time in the sewing order specified by the numbering of the polygons (Figure 1). After sewing all interior seams in the pattern, quilters remove the paper, resulting in a precise fabric patchwork quilt top ready to be layered atop batting material and backing fabric, and then sewn together into a finished quilt.The paper guide serves as a foundation for the construction process that provides stability and increases precision compared to traditional quilt piecing techniques that do not use paper [Alteneder 2020; Mahoney 2016; Sharp 2018]. Specifically, it provides a stable base for aligning the fabric pieces and holding them in place via pins during sewing. The printed seam lines serve as precise visual guides for sewing the seams accurately. Sewing a straight seam at a specific location is far more difficult when there is no printed line to follow along. These advantages of paper piecing have made it a widely used method for sewing quilt tops, especially among beginners, but also for many experienced quilters [Mahoney 2016].",
    "scholar_publication": "ACM Trans. Graph., 2021 - mackenzieleake.com"
  },
  {
    "paper_id": "papers_561",
    "authors": "Jingyu Chen, Victoria Kala, Alan Marquez-Razon, Elias Gueidon, David Andrew B. Hyde, Joseph Teran",
    "title": "A Momentum-conserving Implicit Material Point Method for Surface Tension With Contact Angles and Spatial Gradients",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459874",
    "pdf_link": null,
    "abstract": "We present a novel Material Point Method (MPM) discretization of surface tension forces that arise from spatially varying surface energies. These variations typically arise from surface energy dependence on temperature and/or concentration. Furthermore, since the surface energy is an interfacial property depending on the types of materials on either side of an interface, spatial variation is required for modeling the contact angle at the triple junction between a liquid, solid and surrounding air. Our discretization is based on the surface energy itself, rather than on the associated traction condition most commonly used for discretization with particle methods. Our energy based approach automatically captures surface gradients without the explicit need to resolve them as in traction condition based approaches. We include an implicit discretization of thermomechanical material coupling with a novel particle-based enforcement of Robin boundary conditions associated with convective heating. Lastly, we design a particle resampling approach needed to achieve perfect conservation of linear and angular momentum with Affine-Particle-In-Cell (APIC) [Jiang et al. 2015]. We show that our approach enables implicit time stepping for complex behaviors like the Marangoni effect and hydrophobicity/hydrophilicity. We demonstrate the robustness and utility of our method by simulating materials that exhibit highly diverse degrees of surface tension and thermomechanical effects, such as water, wine and wax.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_322",
    "authors": "Delio Vicini, Wenzel Jakob, Anton Kaplanyan",
    "title": "A Non-exponential Transmittance Model for Volumetric Scene Representations",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459815",
    "pdf_link": null,
    "abstract": "We introduce a novel transmittance model to improve the volumetric representation of 3D scenes. The model can represent opaque surfaces in the volumetric light transport framework. Volumetric representations are useful for complex scenes, and become increasingly popular for level of detail and scene reconstruction. The traditional exponential transmittance model found in volumetric light transport cannot capture correlations in visibility across volume elements. When representing opaque surfaces as volumetric density, this leads to both bloating of silhouettes and light leaking artifacts. By introducing a parametric non-exponential transmittance model, we are able to approximate these correlation effects and significantly improve the accuracy of volumetric appearance representation of opaque scenes. Our parametric transmittance model can represent a continuum between the linear transmittance that opaque surfaces exhibit and the traditional exponential transmittance encountered in participating media and unstructured geometries. This covers a large part of the spectrum of geometric structures encountered in complex scenes. In order to handle the spatially varying transmittance correlation effects, we further extend the theory of non-exponential participating media to a heterogeneous transmittance model. Our model is compact in storage and computationally efficient both for evaluation and for reverse-mode gradient computation. Applying our model to optimization algorithms yields significant improvements in volumetric scene appearance quality. We further show improvements for relevant applications, such as scene appearance prefiltering, image-based scene reconstruction using differentiable rendering, neural representations, and compare it to a conventional exponential model.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_255",
    "authors": "Brooke Krajancich, Petr Kellnhofer, Gordon Wetzstein",
    "title": "A Perceptual Model for Eccentricity-dependent Spatio-temporal Flicker Fusion and Its Applications to Foveated Graphics",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459784",
    "pdf_link": null,
    "abstract": "Virtual and augmented reality (VR/AR) displays strive to provide a resolution, framerate and field of view that matches the perceptual capabilities of the human visual system, all while constrained by limited compute budgets and transmission bandwidths of wearable computing systems. Foveated graphics techniques have emerged that could achieve these goals by exploiting the falloff of spatial acuity in the periphery of the visual field. However, considerably less attention has been given to temporal aspects of human vision, which also vary across the retina. This is in part due to limitations of current eccentricity-dependent models of the visual system. We introduce a new model, experimentally measuring and computationally fitting eccentricity-dependent critical flicker fusion thresholds jointly for both space and time. In this way, our model is unique in enabling the prediction of temporal information that is imperceptible for a certain spatial frequency, eccentricity, and range of luminance levels. We validate our model with an image quality user study, and use it to predict potential bandwidth savings 7X higher than those afforded by current spatial-only foveated models. As such, this work forms the enabling foundation for new temporally foveated graphics techniques.",
    "scholar_publication": "ACM transactions on graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_117",
    "authors": "Longhua Wu, Botao Wu, Yin Yang, Huamin Wang",
    "title": "A Safe and Fast Repulsion Method for GPU-based Cloth Self Collisions",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3430025",
    "pdf_link": null,
    "abstract": "Cloth dynamics and collision handling are the two most challenging topics in cloth simulation. While researchers have substantially improved the performances of cloth dynamics solvers recently, their success in fast collision detection and handling is rather limited. In this article, we focus our research on the safety, efficiency, and realism of the repulsion-based collision handling approach, which has demonstrated its potential in existing GPU-based simulators. Our first discovery is the necessary vertex distance conditions for cloth to enter self intersections, the negations of which can be viewed as vertex distance constraints continuous in time for sufficiently avoiding self collisions. Continuous constraints, however, cannot be enforced with ease. Our solution is to convert continuous constraints into three types of constraints: discrete edge length constraints, discrete vertex distance constraints, and vertex displacement constraints. Based on this solution, we develop a fast and safe collision handling process for enforcing constraints, a novel splitting method for integrating collision handling with dynamics solvers, and static and adaptive remeshing schemes to further improve the runtime performance. In summary, our cloth simulator is efficient, safe, robust, and parallelizable on a GPU. The experiment shows that it runs at least one order of magnitude faster than existing simulators.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2020 - dl.acm.org"
  },
  {
    "paper_id": "pos_158",
    "authors": "Koki Endo, Seung-Tak Noh, Kazutaka Nakashima, Xi Yang, Takeo Igarashi",
    "title": "A Suggestive Interface for Designing Dance Formations",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3450618.3469156",
    "pdf_link": null,
    "abstract": "In group dance performances, formations and transitions between them are one of the important components to attract an audience. Choreographers often design such formations and transitions using a pen and paper, but static diagrams on paper are unsuitable for understanding when and how each dancer moves. One possible approach to this problem is to make animations of the transitions. These animations are helpful in intuitively understanding the movements. Some applications and research have been undertaken to …",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_212",
    "authors": "Hsueh-Ti Derek Liu, Jiayi Eris Zhang, Mirela Ben-Chen, Alec Jacobson",
    "title": "A Surface Multigrid via Intrinsic Prolongation",
    "paper_url": "https://arxiv.org/abs/2104.13755",
    "pdf_link": null,
    "abstract": "This paper introduces a novel geometric multigrid solver for unstructured curved surfaces. Multigrid methods are highly efficient iterative methods for solving systems of linear equations. Despite the success in solving problems defined on structured domains, generalizing multigrid to unstructured curved domains remains a challenging problem. The critical missing ingredient is a prolongation operator to transfer functions across different multigrid levels. We propose a novel method for computing the prolongation for triangulated surfaces based on intrinsic geometry, enabling an efficient geometric multigrid solver for curved surfaces. Our surface multigrid solver achieves better convergence than existing multigrid methods. Compared to direct solvers, our solver is orders of magnitude faster. We evaluate our method on many geometry processing applications and a wide variety of complex shapes with and without boundaries. By simply replacing the direct solver, we upgrade existing algorithms to interactive frame rates, and shift the computational bottleneck away from solving linear systems.",
    "scholar_publication": "arXiv preprint arXiv …, 2021 - arxiv.org"
  },
  {
    "paper_id": "papers_591",
    "authors": "Camille Brunel, Pierre Bénard, Gaël Guennebaud",
    "title": "A Time-independent Deformer for Elastic Contacts",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459879",
    "pdf_link": null,
    "abstract": "We present a purely geometric, time-independent deformer resolving local contacts between elastic objects, including self-collisions between adjacent parts of the same object that often occur in character skinning animation. Starting from multiple meshes in intersection, our deformer first computes the parts of the surfaces remaining in contact, and then applies a procedural displacement with volume preservation. Although our deformer processes each frame independently, it achieves temporally continuous deformations with artistic control of the bulge through few pseudo-stiffness parameters. The plausibility of the deformation is further enhanced by anisotropically spreading the volume-preserving bulge. The result is a robust, real-time deformer that can handle complex geometric configurations such as a ball squashed by a hand, colliding lips, bending fingers, etc.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_333",
    "authors": "Haozhe Su, Tao Xue, Chengguizi Han, Chenfanfu Jiang, Mridul Aanjaneya",
    "title": "A Unified Second-order Accurate in Time MPM Formulation for Simulating Viscoelastic Liquids With Phase Change",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459820",
    "pdf_link": null,
    "abstract": "We assume that the viscous forces in any liquid are simultaneously local and non-local, and introduce the extended POM-POM model [McLeish and Larson 1998; Oishi et al. 2012; Verbeeten et al. 2001] to computer graphics to design a unified constitutive model for viscosity that generalizes prior models, such as Oldroyd-B, the Upper-convected Maxwell (UCM) model [Sadeghy et al. 2005], and classical Newtonian viscosity under one umbrella, recovering each of them with different parameter values. Implicit discretization of our model via backward Euler recovers the variational Stokes solver of [Larionov et al. 2017] for Newtonian viscosity. For greater accuracy, however, we introduce the second-order accurate Generalized Single Step Single Solve (GS4) scheme [Tamma et al. 2000; Zhou and Tamma 2004] to computer graphics, which recovers all prior second-order accurate time integration schemes to date. Using GS4 and our generalized constitutive model, we present a Material Point Method (MPM) for simulating various viscoelastic liquid behaviors, such as classical liquid rope coiling, buckling, folding, and shear thinning/thickening. In addition, we show how to couple our viscoelastic liquid simulator with the recently introduced non-Fourier heat diffusion solver [Xue et al. 2020] for simulating problems with phase change, such as melting chocolate and digital fabrication with 3D printing. While the discretization of heat diffusion is slightly different within GS4, we show that it can still be efficiently solved using an assembly-free Multigrid-preconditioned Conjugate Gradients solver. We present end-to-end 3D simulations to demonstrate the versatility of our framework.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_256",
    "authors": "Julien N. P. Martel, David B. Lindell, Connor Zhizhen Lin, Eric Ryan Chan, Marco Monteiro, Gordon Wetzstein",
    "title": "ACORN: Adaptive Coordinate Networks for Neural Scene Representation",
    "paper_url": "https://arxiv.org/abs/2105.02788",
    "pdf_link": null,
    "abstract": "Neural representations have emerged as a new paradigm for applications in rendering, imaging, geometric modeling, and simulation. Compared to traditional representations such as meshes, point clouds, or volumes they can be flexibly incorporated into differentiable learning-based pipelines. While recent improvements to neural representations now make it possible to represent signals with fine details at moderate resolutions (e.g., for images and 3D shapes), adequately representing large-scale or complex scenes has proven a challenge. Current neural representations fail to accurately represent images at resolutions greater than a megapixel or 3D scenes with more than a few hundred thousand polygons. Here, we introduce a new hybrid implicit-explicit network architecture and training strategy that adaptively allocates resources during training and inference based on the local complexity of a signal of interest. Our approach uses a multiscale block-coordinate decomposition, similar to a quadtree or octree, that is optimized during training. The network architecture operates in two stages: using the bulk of the network parameters, a coordinate encoder generates a feature grid in a single forward pass. Then, hundreds or thousands of samples within each block can be efficiently evaluated using a lightweight feature decoder. With this hybrid implicit-explicit network architecture, we demonstrate the first experiments that fit gigapixel images to nearly 40 dB peak signal-to-noise ratio. Notably this represents an increase in scale of over 1000x compared to the resolution of previously demonstrated image-fitting experiments. Moreover, our approach is able to represent 3D shapes significantly faster and better than previous techniques; it reduces training times from days to hours or minutes and memory requirements by over an order of magnitude.",
    "scholar_publication": "arXiv preprint arXiv …, 2021 - arxiv.org"
  },
  {
    "paper_id": "papers_104",
    "authors": "Xue Bin Peng, Ze Ma, Pieter Abbeel, Sergey Levine, Angjoo Kanazawa",
    "title": "AMP: Adversarial Motion Priors for Stylized Physics-based Character Control",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459670",
    "pdf_link": null,
    "abstract": "Synthesizing graceful and life-like behaviors for physically simulated characters has been a fundamental challenge in computer animation. Data-driven methods that leverage motion tracking are a prominent class of techniques for producing high fidelity motions for a wide range of behaviors. However, the effectiveness of these tracking-based methods often hinges on carefully designed objective functions, and when applied to large and diverse motion datasets, these methods require significant additional machinery to select the appropriate motion for the character to track in a given scenario. In this work, we propose to obviate the need to manually design imitation objectives and mechanisms for motion selection by utilizing a fully automated approach based on adversarial imitation learning. High-level task objectives that the character should perform can be specified by relatively simple reward functions, while the low-level style of the character's behaviors can be specified by a dataset of unstructured motion clips, without any explicit clip selection or sequencing. For example, a character traversing an obstacle course might utilize a task-reward that only considers forward progress, while the dataset contains clips of relevant behaviors such as running, jumping, and rolling. These motion clips are used to train an adversarial motion prior, which specifies style-rewards for training the character through reinforcement learning (RL). The adversarial RL procedure automatically selects which motion to perform, dynamically interpolating and generalizing from the dataset. Our system produces high-quality motions that are comparable to those achieved by state-of-the-art tracking-based techniques, while also being able to easily accommodate large datasets of unstructured motion clips. Composition of disparate skills emerges automatically from the motion prior, without requiring a high-level motion planner or other task-specific annotations of the motion clips. We demonstrate the effectiveness of our framework on a diverse cast of complex simulated characters and a challenging suite of motor control tasks.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_144",
    "authors": "Kazuma Yoshimura, Naoki Hashimoto",
    "title": "Adaptive Radiometric Compensation on Deforming Surfaces",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469150",
    "pdf_link": null,
    "abstract": "In this research, we propose an adaptive radiometric compensation method, which uses only a projector and a camera, on continuously deforming projection surfaces. Radiometric compensation has been widely studied as a technique for making various objects usable as screens, by canceling out the influence of the color and pattern of the projection target. However, since it is necessary to continuously maintain the inter-pixel correspondence between a projector and a camera, to date, the projection target has been limited to …",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_225",
    "authors": "Guoxian Song, Linjie Luo, Jing Liu, Wan Chun Ma, Chunpong Lai, Chuanxia Zheng, Tat Jen Cham",
    "title": "AgileGAN: Stylizing Portraits by Inversion-consistent Transfer Learning",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459771",
    "pdf_link": null,
    "abstract": "Portraiture as an art form has evolved from realistic depiction into a plethora of creative styles. While substantial progress has been made in automated stylization, generating high quality stylistic portraits is still a challenge, and even the recent popular Toonify suffers from several artifacts when used on real input images. Such StyleGAN-based methods have focused on finding the best latent inversion mapping for reconstructing input images; however, our key insight is that this does not lead to good generalization to different portrait styles. Hence we propose AgileGAN, a framework that can generate high quality stylistic portraits via inversion-consistent transfer learning. We introduce a novel hierarchical variational autoencoder to ensure the inverse mapped distribution conforms to the original latent Gaussian distribution, while augmenting the original space to a multi-resolution latent space so as to better encode different levels of detail. To better capture attribute-dependent stylization of facial features, we also present an attribute-aware generator and adopt an early stopping strategy to avoid overfitting small training datasets. Our approach provides greater agility in creating high quality and high resolution (1024×1024) portrait stylization models, requiring only a limited number of style exemplars (~100) and short training time (~1 hour). We collected several style datasets for evaluation including 3D cartoons, comics, oil paintings and celebrities. We show that we can achieve superior portrait stylization quality to previous state-of-the-art methods, with comparisons done qualitatively, quantitatively and through a perceptual user study. We also demonstrate two applications of our method, image editing and motion retargeting.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_178",
    "authors": "Seina Kobayashi, Kei Kanari, Mie Sato",
    "title": "An Examination of View-settings for Long Texts in VR Reading",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469164",
    "pdf_link": null,
    "abstract": "To reduce the burden from VR reading of long texts, this study finds the view-settings for better readability and less fatigue. As the view-settings, we focus on the font type, the font color, the font size, and the view-distance from the text. Our results show the relation among the view-settings, the readability, and the fatigue for long texts in VR reading.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_489",
    "authors": "Mégane Bati, Pascal Barla, Romain Pacanowski",
    "title": "An Inverse Method for the Exploration of Layered Material Appearance",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459857",
    "pdf_link": null,
    "abstract": "Layered materials exhibit a wide range of appearance, due to the combined effects of absorption and scattering at and between interfaces. Yet most existing approaches let users set the physical parameters of all layers by hand, a process of trial and error. We introduce an inverse method that provides control over BRDF lobe properties of layered materials, while automatically retrieving compatible physical parameters. Our method permits to explore the space of layered material appearance: it lets users find configurations with nearly indistinguishable appearance, isolate grazing angle effects, and give control over properties such as the color, blur or haze of reflections.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_369",
    "authors": "Markus Kettunen, Eugene d'Eon, Jacopo Pantaleoni, Jan Novák",
    "title": "An Unbiased Ray-marching Transmittance Estimator",
    "paper_url": "https://arxiv.org/abs/2102.10294",
    "pdf_link": null,
    "abstract": "We present an in-depth analysis of the sources of variance in state-of-the-art unbiased volumetric transmittance estimators, and propose several new methods for improving their efficiency. These combine to produce a single estimator that is universally optimal relative to prior work, with up to several orders of magnitude lower variance at the same cost, and has zero variance for any ray with non-varying extinction. We first reduce the variance of truncated power-series estimators using a novel efficient application of U-statistics. We then …",
    "scholar_publication": "arXiv preprint arXiv …, 2021 - arxiv.org"
  },
  {
    "paper_id": "pos_142",
    "authors": "Pablo Vielma, Ergun Akleman",
    "title": "Animated Futurist Sculpting as 4D Implicit Shapes Immersed in 3D",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469148",
    "pdf_link": null,
    "abstract": "… immersion of 4D structure into the 3D spatial domain provides us desired futurist sculpture … is the conversion of animated polygonal mesh into a 4D implicit shape. We first convert a …",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_251",
    "authors": "Cheng Zhang, Zhao Dong, Michael Doggett, Shuang Zhao",
    "title": "Antithetic Sampling for Monte Carlo Differentiable Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459783",
    "pdf_link": null,
    "abstract": "Stochastic sampling of light transport paths is key to Monte Carlo forward rendering, and previous studies have led to mature techniques capable of drawing high-contribution light paths in complex scenes. These sampling techniques have also been applied to differentiable rendering. In this paper, we demonstrate that path sampling techniques developed for forward rendering can become inefficient for differentiable rendering of glossy materials---especially when estimating derivatives with respect to global scene geometries. To address this problem, we introduce antithetic sampling of BSDFs and light-transport paths, allowing significantly faster convergence and can be easily integrated into existing differentiable rendering pipelines. We validate our method by comparing our derivative estimates to those generated with existing unbiased techniques. Further, we demonstrate the effectiveness of our technique by providing equal-quality and equal-time comparisons with existing sampling methods.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_234",
    "authors": "Alexander Neugebauer, Katarina Stingl, Iliya Ivanov, Siegfried Wahl",
    "title": "Applying Virtual Reality for Systematic Gaze Pattern Evaluation in Simulated Retinitis Pigmentosa Patients",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469178",
    "pdf_link": null,
    "abstract": "We apply virtual reality headsets with eye tracking capabilities to evaluate new training methods for patients living with loss of peripheral vision (“tunnel vision”). It can be shown that systematic gaze patterns, taught in a virtual reality environment, are able to significantly increase the effectively perceived visual area of the participants as well as reduce the number of obstacle collisions in navigation tasks.",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_110",
    "authors": "Christoph Peters",
    "title": "BRDF Importance Sampling for Polygonal Lights",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459672",
    "pdf_link": null,
    "abstract": "With the advent of real-time ray tracing, there is an increasing interest in GPU-friendly importance sampling techniques. We present such methods to sample convex polygonal lights approximately proportional to diffuse and specular BRDFs times the cosine term. For diffuse surfaces, we sample the polygons proportional to projected solid angle. Our algorithm partitions the polygon suitably and employs inverse function sampling for each part. Inversion of the distribution function is challenging. Using algebraic geometry, we develop a special iterative procedure and an initialization scheme. Together, they achieve high accuracy in all possible situations with only two iterations. Our implementation is numerically stable and fast. For specular BRDFs, this method enables us to sample the polygon proportional to a linearly transformed cosine. We combine these diffuse and specular sampling strategies through novel variants of optimal multiple importance sampling. Our techniques render direct lighting from Lambertian polygonal lights with almost no variance outside of penumbrae and support shadows and textured emission. Additionally, we propose an algorithm for solid angle sampling of polygons. It is faster and more stable than existing methods.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_138",
    "authors": "Masaharu Hirose, Masahiko Inami",
    "title": "Balanced Glass Design: A Flavor Perception Changing System by Controlling the Center of Gravity",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450550.3465344",
    "pdf_link": null,
    "abstract": "In this paper, we propose Balanced Glass Design, a system to change flavor perception. The system consists of glass-type device shifting its center of gravity in response to the user's motion which allows drinking a beverage with a virtual perception of weight through drinking motion. We thought It's possible to intervene in the user's perception of flavor by displaying virtual weight perception, and so conducted experiments on weight perception and demonstrations as a user study. This paper describes the system design, the result of …",
    "scholar_publication": "ACM SIGGRAPH 2021 Emerging Technologies, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_578",
    "authors": "David R. Walton, Rafael Kuffner dos Anjos, Sebastian Friston, David Swapp, Kaan Akşit, Anthony Steed, Tobias Ritschel",
    "title": "Beyond Blur: Real-time Ventral Metamers for Foveated Rendering",
    "paper_url": "https://eprints.whiterose.ac.uk/id/eprint/180009/",
    "pdf_link": null,
    "abstract": "To peripheral vision, a pair of physically different images can look the same. Such pairs are metamers relative to each other, just as physically-different spectra of light are perceived as the same color. We propose a real-time method to compute such ventral metamers for foveated rendering where, in particular for near-eye displays, the largest part of the framebuffer maps to the periphery. This improves in quality over state-of-the-art foveation methods which blur the periphery. Work in Vision Science has established how peripheral …",
    "scholar_publication": "ACM Transactions …, 2021 - eprints.whiterose.ac.uk"
  },
  {
    "paper_id": "papers_401",
    "authors": "Zhongshi Jiang, Ziyi Zhang, Yixin Hu, Teseo Schneider, Denis Zorin, Daniele Panozzo",
    "title": "Bijective and Coarse High-order Tetrahedral Meshes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459840",
    "pdf_link": null,
    "abstract": "We introduce a robust and automatic algorithm to convert linear triangle meshes with feature annotated into coarse tetrahedral meshes with curved elements. Our construction guarantees that the high-order meshes are free of element inversion or self-intersection. A user-specified maximal geometrical error from the input mesh controls the faithfulness of the curved approximation. The boundary of the output mesh is in bijective correspondence to the input, enabling attribute transfer between them, such as boundary conditions for simulations, making our curved mesh an ideal replacement or complement for the original input geometry. The availability of a bijective shell around the input surface is employed to ensure robust curving, prevent self-intersections, and compute a bijective map between the linear input and curved output surface. As necessary building blocks of our algorithm, we extend the bijective shell formulation to support features and propose a robust approach for boundary-preserving linear tetrahedral meshing. We demonstrate the robustness and effectiveness of our algorithm by generating high-order meshes for a large collection of complex 3D models.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_485",
    "authors": "Tian Chen, Julian Panetta, Max Schaubelt, Mark Pauly",
    "title": "Bistable Auxetic Surface Structures",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459940",
    "pdf_link": null,
    "abstract": "… of bistable auxetic cells to cover a range of in-plane expansion / contraction ratios, while maximizing the bistability … We then use metric distortion analysis of the target surface to compute …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_535",
    "authors": "Xingyi Du, Qingnan Zhou, Nathan Carr, Tao Ju",
    "title": "Boundary-sampled Halfspaces: A New Representation for Constructive Solid Modeling",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459870",
    "pdf_link": null,
    "abstract": "We present a novel representation of solid models for shape design. Like Constructive Solid Geometry (CSG), the solid shape is constructed from a set of halfspaces without the need for an explicit boundary structure. Instead of using Boolean expressions as in CSG, the shape is defined by sparsely placed samples on the boundary of each halfspace. This representation, called Boundary-Sampled Halfspaces (BSH), affords greater agility and expressiveness than CSG while simplifying the reverse engineering process. We discuss theoretical properties of the representation and present practical algorithms for boundary extraction and conversion from other representations. Our algorithms are demonstrated on both 2D and 3D examples.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_211",
    "authors": "Asuka Hirata, Keitaro Tanaka, Ryo Shimamura, Shigeo Morishima",
    "title": "Bowing-Net: Motion Generation for String Instruments Based on Bowing Information",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469170",
    "pdf_link": null,
    "abstract": "This paper presents a deep learning based method that generates body motion for string instrument performance from raw audio. In contrast to prior methods which aim to predict joint position from audio, we first estimate information that dictates the bowing dynamics, such as the bow direction and the played string. The final body motion is then determined from this information following a conversion rule. By adopting the bowing information as the target domain, not only is learning the mapping more feasible, but also the produced results …",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_283",
    "authors": "He Chen, Hyojoon Park, Kutay Macit, Ladislav Kavan",
    "title": "Capturing Detailed Deformations of Moving Human Bodies",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459792",
    "pdf_link": null,
    "abstract": "We present a new method to capture detailed human motion, sampling more than 1000 unique points on the body. Our method outputs highly accurate 4D (spatio-temporal) point coordinates and, crucially, automatically assigns a unique label to each of the points. The locations and unique labels of the points are inferred from individual 2D input images only, without relying on temporal tracking or any human body shape or skeletal kinematics models. Therefore, our captured point trajectories contain all of the details from the input images, including motion due to breathing, muscle contractions and flesh deformation, and are well suited to be used as training data to fit advanced models of the human body and its motion. The key idea behind our system is a new type of motion capture suit which contains a special pattern with checkerboard-like corners and two-letter codes. The images from our multi-camera system are processed by a sequence of neural networks which are trained to localize the corners and recognize the codes, while being robust to suit stretching and self-occlusions of the body. Our system relies only on standard RGB or monochrome sensors and fully passive lighting and the passive suit, making our method easy to replicate, deploy and use. Our experiments demonstrate highly accurate captures of a wide variety of human poses, including challenging motions such as yoga, gymnastics, or rolling on the ground.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_143",
    "authors": "Ergun Akleman, Tevfik Akgun",
    "title": "Caricature Creation With Conformal Mapping in Complex Domain",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469149",
    "pdf_link": null,
    "abstract": "Caricature is an art form of exaggeration of features [Akleman 1997; Akleman et al. 2000; Akleman and Reisch 2004; Brennan 1985; Klare et al. 2012; Liang et al. 2002]. An important property of feature exaggeration is that it is not deformation. By deforming features we can obtain funny looking portraits, however the resulting features will not look exaggerated. In this work, we present an approach for extreme exaggeration of facial features to obtain caricature effect. Our approach is based on the well-known conformal property of maps in complex domains. Namely, any map in a complex domain is angle preserving, which is crucial for caricature generation. Without angle preservation, the maps can result in deformations that look funny or grotesque, but not caricature. We have developed a particular mapping in a complex domain and show that we can obtain a wide variety of faces starting from any illustration (or photograph) of a human face.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_149",
    "authors": "Kang Chen, Zhipeng Tan, Jin Lei, Song-Hai Zhang, Yuan-Chen Guo, Weidong Zhang, Shi-Min Hu",
    "title": "ChoreoMaster: Choreography-oriented Music-driven Dance Synthesis",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459932",
    "pdf_link": null,
    "abstract": "Despite strong demand in the game and film industry, automatically synthesizing high-quality dance motions remains a challenging task. In this paper, we present ChoreoMaster, a production-ready music-driven dance motion synthesis system. Given a piece of music, ChoreoMaster can automatically generate a high-quality dance motion sequence to accompany the input music in terms of style, rhythm and structure. To achieve this goal, we introduce a novel choreography-oriented choreomusical embedding framework, which successfully constructs a unified choreomusical embedding space for both style and rhythm relationships between music and dance phrases. The learned choreomusical embedding is then incorporated into a novel choreography-oriented graph-based motion synthesis framework, which can robustly and efficiently generate high-quality dance motions following various choreographic rules. Moreover, as a production-ready system, ChoreoMaster is sufficiently controllable and comprehensive for users to produce desired results. Experimental results demonstrate that dance motions generated by ChoreoMaster are accepted by professional artists.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_520",
    "authors": "Shuqi Yang, Shiying Xiong, Yaorui Zhang, Fan Feng, Jinyuan Liu, Bo Zhu",
    "title": "Clebsch Gauge Fluid",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459866",
    "pdf_link": null,
    "abstract": "… a novel gauge fluid solver based on Clebsch wave functions to solve incompressible fluid … in our method that Clebsch wave functions can be used as a new type of gauge variables to …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_320",
    "authors": "Yiqian Wu, Yongliang Yang, Qinjie Xiao, Xiaogang Jin",
    "title": "Coarse-to-fine: Facial Structure Editing of Portrait Images via Latent Space Classifications",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459814",
    "pdf_link": null,
    "abstract": "Facial structure editing of portrait images is challenging given the facial variety, the lack of ground-truth, the necessity of jointly adjusting color and shape, and the requirement of no visual artifacts. In this paper, we investigate how to perform chin editing as a case study of editing facial structures. We present a novel method that can automatically remove the double chin effect in portrait images. Our core idea is to train a fine classification boundary in the latent space of the portrait images. This can be used to edit the chin appearance by manipulating the latent code of the input portrait image while preserving the original portrait features. To achieve such a fine separation boundary, we employ a carefully designed training stage based on latent codes of paired synthetic images with and without a double chin. In the testing stage, our method can automatically handle portrait images with only a refinement to subtle misalignment before and after double chin editing. Our model enables alteration to the neck region of the input portrait image while keeping other regions unchanged, and guarantees the rationality of neck structure and the consistency of facial characteristics. To the best of our knowledge, this presents the first effort towards an effective application for editing double chins. We validate the efficacy and efficiency of our approach through extensive experiments and user studies.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_210",
    "authors": "Minchen Li, Danny M. Kaufman, Chenfanfu Jiang",
    "title": "Codimensional Incremental Potential Contact",
    "paper_url": "https://arxiv.org/abs/2012.04457",
    "pdf_link": null,
    "abstract": "We extend the incremental potential contact (IPC) model for contacting elastodynamics to resolve systems composed of codimensional DOFs in arbitrary combination. This enables a unified, interpenetration-free, robust, and stable simulation framework that couples codimension-0,1,2, and 3 geometries seamlessly with frictional contact. Extending IPC to thin structures poses new challenges in computing strain, modeling thickness and determining collisions. To address these challenges we propose three corresponding contributions. First, we introduce a C2 constitutive barrier model that directly enforces strain limiting as an energy potential while preserving rest state. This provides energetically-consistent strain limiting models (both isotropic and anisotropic) for cloth that enable strict satisfaction of strain-limit inequalities with direct coupling to both elastodynamics and contact via minimization of the incremental potential. Second, to capture the geometric thickness of codimensional domains we extend the IPC model to directly enforce distance offsets. Our treatment imposes a strict guarantee that mid-surfaces (resp. mid-lines) of shells (resp. rods) will not move closer than applied thickness values. This enables us to account for thickness in the contact behavior of codimensional structures and so robustly capture challenging contacting geometries; a number of which, to our knowledge, have not been simulated before. Third, codimensional models, especially with modeled thickness, mandate strict accuracy requirements that pose a severe challenge to all existing continuous collision detection (CCD) methods. To address these limitations we develop a new, efficient, simple-to-implement additive CCD (ACCD) method that applies conservative advancement to iteratively refine a lower bound for deforming primitives, converging to time of impact.",
    "scholar_publication": "arXiv preprint arXiv:2012.04457, 2020 - arxiv.org"
  },
  {
    "paper_id": "papers_484",
    "authors": "Davide Pellis, Martin Killian, Helmut Pottmann, Mark Pauly",
    "title": "Computational Design of Weingarten Surfaces",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459939",
    "pdf_link": null,
    "abstract": "In this paper we study Weingarten surfaces and explore their potential for fabrication-aware design in freeform architecture. Weingarten surfaces are characterized by a functional relation between their principal curvatures that implicitly defines approximate local congruences on the surface. These symmetries can be exploited to simplify surface paneling of double-curved architectural skins through mold re-use. We present an optimization approach to find a Weingarten surface that is close to a given input design. Leveraging insights from differential geometry, our method aligns curvature isolines of the surface in order to contract the curvature diagram from a 2D region into a 1D curve. The unknown functional curvature relation then emerges as the result of the optimization. We show how a robust and efficient numerical shape approximation method can be implemented using a guided projection approach on a high-order B-spline representation. This algorithm is applied in several design studies to illustrate how Weingarten surfaces define a versatile shape space for fabrication-aware exploration in freeform architecture. Our optimization algorithm provides the first practical tool to compute general Weingarten surfaces with arbitrary curvature relation, thus enabling new investigations into a rich, but as of yet largely unexplored class of surfaces.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_274",
    "authors": "Julian Panetta, Florin Isvoranu, Tian Chen, Emmanuel Siefert, Benoit Roman, Mark Pauly",
    "title": "Computational Inverse Design of Surface-based Inflatables",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459789",
    "pdf_link": null,
    "abstract": "We present a computational inverse design method for a new class of surface-based inflatable structure. Our deployable structures are fabricated by fusing together two layers of inextensible sheet material along carefully selected curves. The fusing curves form a network of tubular channels that can be inflated with air or other fluids. When fully inflated, the initially flat surface assumes a programmed double-curved shape and becomes stiff and load-bearing. We present a method that solves for the layout of air channels that, when …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_247",
    "authors": "Stephanie Wang, Albert Chern",
    "title": "Computing Minimal Surfaces With Differential Forms",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459781",
    "pdf_link": null,
    "abstract": "We describe a new algorithm that solves a classical geometric problem: Find a surface of minimal area bordered by an arbitrarily prescribed boundary curve. Existing numerical methods face challenges due to the non-convexity of the problem. Using a representation of curves and surfaces via differential forms on the ambient space, we reformulate this problem as a convex optimization. This change of variables overcomes many difficulties in previous numerical attempts and allows us to find the global minimum across all possible surface topologies. The new algorithm is based on differential forms on the ambient space and does not require handling meshes. We adopt the Alternating Direction Method of Multiplier (ADMM) to find global minimal surfaces. The resulting algorithm is simple and efficient: it boils down to an alternation between a Fast Fourier Transform (FFT) and a pointwise shrinkage operation. We also show other applications of our solver in geometry processing such as surface reconstruction.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_542",
    "authors": "Zhoutong Zhang, Forrester Cole, Tali Dekel, Richard Tucker, William T. Freeman",
    "title": "Consistent Depth of Moving Objects in Video",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459871",
    "pdf_link": null,
    "abstract": "We present a method to estimate depth of a dynamic scene, containing arbitrary moving objects, from an ordinary video captured with a moving camera. We seek a geometrically and temporally consistent solution to this under-constrained problem: the depth predictions of corresponding points across frames should induce plausible, smooth motion in 3D. We formulate this objective in a new test-time training framework where a depth-prediction CNN is trained in tandem with an auxiliary scene-flow prediction MLP over the entire input video. By recursively unrolling the scene-flow prediction MLP over varying time steps, we compute both short-range scene flow to impose local smooth motion priors directly in 3D, and long-range scene flow to impose multi-view consistency constraints with wide baselines. We demonstrate accurate and temporally coherent results on a variety of challenging videos containing diverse moving objects (pets, people, cars), as well as camera motion. Our depth maps give rise to a number of depth-and-motion aware video editing effects such as object and lighting insertion.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_588",
    "authors": "Min Hyung Kee, Kiwon Um, WooSeok Jeong, JungHyun Han",
    "title": "Constrained Projective Dynamics: Real-time Simulation of Deformable Objects With Energy-momentum Conservation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459878",
    "pdf_link": null,
    "abstract": "This paper proposes a novel energy-momentum conserving integration method. Adopting Projective Dynamics, the proposed method extends its unconstrained minimization for time integration into the constrained form with the position-based energy-momentum constraints. This resolves the well-known problem of unwanted dissipation of energy and momenta without compromising the real-time performance and simulation stability. The proposed method also enables users to directly control the energy and momenta so as to easily create the vivid deformable and global motions they want, which is a fascinating feature for many real-time applications such as virtual/augmented reality and games.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_180",
    "authors": "Yousuf Soliman, Albert Chern, Olga Diamanti, Felix Knöppel, Ulrich Pinkall, Peter Schröder",
    "title": "Constrained Willmore Surfaces",
    "paper_url": "https://link.springer.com/article/10.1007/s00526-007-0142-5",
    "pdf_link": null,
    "abstract": "… constrained Willmore surfaces: an immersion f : M → R3 of a Riemann surface M is a constrained Willmore surface … This generalizes the notion of Willmore surfaces, the critical points of …",
    "scholar_publication": "Calculus of Variations and Partial …, 2008 - Springer"
  },
  {
    "paper_id": "papers_191",
    "authors": "Jungdam Won, Deepak Gopinath, Jessica Hodgins",
    "title": "Control Strategies for Physically Simulated Characters Performing Two-player Competitive Sports",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459761",
    "pdf_link": null,
    "abstract": "In two-player competitive sports, such as boxing and fencing, athletes often demonstrate efficient and tactical movements during a competition. In this paper, we develop a learning framework that generates control policies for physically simulated athletes who have many degrees-of-freedom. Our framework uses a two step-approach, learning basic skills and learning bout-level strategies, with deep reinforcement learning, which is inspired by the way that people how to learn competitive sports. We develop a policy model based on an encoder-decoder structure that incorporates an autoregressive latent variable, and a mixture-of-experts decoder. To show the effectiveness of our framework, we implemented two competitive sports, boxing and fencing, and demonstrate control policies learned by our framework that can generate both tactical and natural-looking behaviors. We also evaluate the control policies with comparisons to other learning configurations and with ablation studies.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_118",
    "authors": "Nathan Lindig",
    "title": "Creating Crowd Characters Through Procedural Deformation",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3450618.3469138",
    "pdf_link": null,
    "abstract": "Figure 1 Figure 1: A collection of the facial mesh results produced by the system implemented in this work. Each is a unique plot in the full 64 dimensional parametric space of the procedural deformation system. The framed face is the base facial mesh.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_206",
    "authors": "Jung Eun Lee, Seungkyu Lee",
    "title": "Cross Sample Similarity for Stable Training of GAN",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469169",
    "pdf_link": null,
    "abstract": "Recently attention network finding similarity in non-local area within a 2D image has shown outstanding improvement in multi-class generation task in GAN. However it frequently shows unstable training state sometimes falling in mode collapse. We propose cross sample similarity loss to penalize similar features of fake samples that are rarely observed in reals. Proposed method shows improved FID score compared to baseline methods on CelebA, LSUN, and decreased mode collapse on Cifar10[Krizhevsky 2009].",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_341",
    "authors": "Élie Michel, Tamy Boubekeur",
    "title": "DAG Amendment for Inverse Control of Parametric Shapes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459823",
    "pdf_link": null,
    "abstract": "Parametric shapes model objects as programs producing a geometry based on a few semantic degrees of freedom, called hyper-parameters. These shapes are the typical output of non-destructive modeling, CAD modeling or rigging. However they suffer from the core issue of being manipulated only indirectly, through a series of values rather than the geometry itself. In this paper, we introduce an amendment process of the underlying direct acyclic graph (DAG) of a parametric shape. This amendment enables a local differentiation of the shape w.r.t. its hyper-parameters that we leverage to provide interactive direct manipulation of the output. By acting on the shape synthesis process itself, our method is agnostic to the variations of the connectivity and topology that may occur in its output while changing the input hyper-parameters. Furthermore, our method is oblivious to the internal logic of the DAG nodes. We illustrate our approach on a collection of examples combining the typical nodes found in modern parametric modeling packages - such as deformation, booleans and surfacing operators - for which our method provides the user with inverse control over the hyper-parameters through a brush stroke metaphor.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_359",
    "authors": "Sai Bi, Stephen Lombardi, Shunsuke Saito, Tomas Simon, Shih-En Wei, Kevyn McPhail, Ravi Ramamoorthi, Yaser Sheikh, Jason Saragih",
    "title": "Deep Relightable Appearance Models for Animatable Faces",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459829",
    "pdf_link": null,
    "abstract": "We present a method for building high-fidelity animatable 3D face models that can be posed and rendered with novel lighting environments in real-time. Our main insight is that relightable models trained to produce an image lit from a single light direction can generalize to natural illumination conditions but are computationally expensive to render. On the other hand, efficient, high-fidelity face models trained with point-light data do not generalize to novel lighting conditions. We leverage the strengths of each of these two approaches. We first train an expensive but generalizable model on point-light illuminations, and use it to generate a training set of high-quality synthetic face images under natural illumination conditions. We then train an efficient model on this augmented dataset, reducing the generalization ability requirements. As the efficacy of this approach hinges on the quality of the synthetic data we can generate, we present a study of lighting pattern combinations for dynamic captures and evaluate their suitability for learning generalizable relightable models. Towards achieving the best possible quality, we present a novel approach for generating dynamic relightable faces that exceeds state-of-the-art performance. Our method is capable of capturing subtle lighting effects and can even generate compelling near-field relighting despite being trained exclusively with far-field lighting data. Finally, we motivate the utility of our model by animating it with images captured from VR-headset mounted cameras, demonstrating the first system for face-driven interactions in VR that uses a photorealistic relightable face model.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_188",
    "authors": "Shu-Yu Chen, Feng-Lin Liu, Yu-Kun Lai, Paul Rosin, Chun-Peng Li, Hongbo Fu, Lin Gao",
    "title": "DeepFaceEditing: Deep Face Generation and Editing With Disentangled Geometry and Appearance Control",
    "paper_url": "https://arxiv.org/abs/2105.08935",
    "pdf_link": null,
    "abstract": "Recent facial image synthesis methods have been mainly based on conditional generative models. Sketch-based conditions can effectively describe the geometry of faces, including the contours of facial components, hair structures, as well as salient edges (e.g., wrinkles) on face surfaces but lack effective control of appearance, which is influenced by color, material, lighting condition, etc. To have more control of generated results, one possible approach is to apply existing disentangling works to disentangle face images into geometry and appearance representations. However, existing disentangling methods are not optimized for human face editing, and cannot achieve fine control of facial details such as wrinkles. To address this issue, we propose DeepFaceEditing, a structured disentanglement framework specifically designed for face images to support face generation and editing with disentangled control of geometry and appearance. We adopt a local-to-global approach to incorporate the face domain knowledge: local component images are decomposed into geometry and appearance representations, which are fused consistently using a global fusion module to improve generation quality. We exploit sketches to assist in extracting a better geometry representation, which also supports intuitive geometry editing via sketching. The resulting method can either extract the geometry and appearance representations from face images, or directly extract the geometry representation from face sketches. Such representations allow users to easily edit and synthesize face images, with decoupled control of their geometry and appearance. Both qualitative and quantitative evaluations show the superior detail and appearance control abilities of our method compared to state-of-the-art methods.",
    "scholar_publication": "arXiv preprint arXiv …, 2021 - arxiv.org"
  },
  {
    "paper_id": "papers_194",
    "authors": "Mustafa B. Yaldiz, Andreas Meuleman, Hyeonjoong Jang, Hyunho Ha, Min H. Kim",
    "title": "DeepFormableTag: End-to-end Generation and Recognition of Deformable Fiducial Markers",
    "paper_url": "https://arxiv.org/abs/2206.08026",
    "pdf_link": null,
    "abstract": "Fiducial markers have been broadly used to identify objects or embed messages that can be detected by a camera. Primarily, existing detection methods assume that markers are printed on ideally planar surfaces. Markers often fail to be recognized due to various imaging artifacts of optical/perspective distortion and motion blur. To overcome these limitations, we propose a novel deformable fiducial marker system that consists of three main parts: First, a fiducial marker generator creates a set of free-form color patterns to encode significantly large-scale information in unique visual codes. Second, a differentiable image simulator creates a training dataset of photorealistic scene images with the deformed markers, being rendered during optimization in a differentiable manner. The rendered images include realistic shading with specular reflection, optical distortion, defocus and motion blur, color alteration, imaging noise, and shape deformation of markers. Lastly, a trained marker detector seeks the regions of interest and recognizes multiple marker patterns simultaneously via inverse deformation transformation. The deformable marker creator and detector networks are jointly optimized via the differentiable photorealistic renderer in an end-to-end manner, allowing us to robustly recognize a wide range of deformable markers with high accuracy. Our deformable marker system is capable of decoding 36-bit messages successfully at ~29 fps with severe shape deformation. Results validate that our system significantly outperforms the traditional and data-driven marker methods. Our learning-based marker system opens up new interesting applications of fiducial markers, including cost-effective motion capture of the human body, active 3D scanning using our fiducial markers' array as structured light patterns, and robust augmented reality rendering of virtual objects on dynamic surfaces.",
    "scholar_publication": "arXiv preprint arXiv …, 2022 - arxiv.org"
  },
  {
    "paper_id": "papers_524",
    "authors": "Simon Huber, Roi Poranne, Stelian Coros",
    "title": "Designing Actuation Systems for Animatronic Figures via Globally Optimal Discrete Search",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459867",
    "pdf_link": null,
    "abstract": "We present an algorithmic approach to designing animatronic figures - expressive robotic characters whose movements are driven by a large number of actuators. The input to our design system provides a high-level specification of the space of motions the character should be able to perform. The output consists of a fully functional mechatronic blueprint. We cast the design task as a search problem in a vast combinatorial space of possible solutions. To find an optimal design in this space, we propose an efficient best-first search algorithm that is guided by an admissible heuristic. The objectives guiding the search process demand that the design remains free of singularities and self-collisions at any point in the high-dimensional space of motions the character is expected to be able to execute. To identify worst-case self-collision scenarios for multi degree-of-freedom closed-loop mechanisms, we additionally develop an elegant technique inspired by the concept of adversarial attacks. We demonstrate the efficacy of our approach by creating designs for several animatronic figures of varying complexity.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_399",
    "authors": "Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, Daniel Cohen-Or",
    "title": "Designing an Encoder for StyleGAN Image Manipulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459838",
    "pdf_link": null,
    "abstract": "Recently, there has been a surge of diverse methods for performing image editing by employing pre-trained unconditional generators. Applying these methods on real images, however, remains a challenge, as it necessarily requires the inversion of the images into their latent space. To successfully invert a real image, one needs to find a latent code that reconstructs the input image accurately, and more importantly, allows for its meaningful manipulation. In this paper, we carefully study the latent space of StyleGAN, the state-of-the-art unconditional generator. We identify and analyze the existence of a distortion-editability tradeoff and a distortion-perception tradeoff within the StyleGAN latent space. We then suggest two principles for designing encoders in a manner that allows one to control the proximity of the inversions to regions that StyleGAN was originally trained on. We present an encoder based on our two principles that is specifically designed for facilitating editing on real images by balancing these tradeoffs. By evaluating its performance qualitatively and quantitatively on numerous challenging domains, including cars and horses, we show that our inversion method, followed by common editing techniques, achieves superior real-image editing quality, with only a small reconstruction accuracy drop.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_184",
    "authors": "Zheng Zeng, Xiaohong Jia, Liyong Shen, Pengbo Bo",
    "title": "Developable Surface Segmentation for CAD Models",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469167",
    "pdf_link": null,
    "abstract": "We present a novel method to segment CAD models into developable patches by detecting curve-like features on Gauss images of the corresponding patches. A region-growing approach is employed to detect planar and curved developable patches. The Gauss image of each segmented patch is constrained to be curve-like via principal component analysis and Pearson correlation analysis. Experimental results demonstrate that our approach generates nice results on CAD models with all kinds of developable surfaces.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_367",
    "authors": "Pingchuan Ma, Tao Du, John Z. Zhang, Kui Wu, Andrew Spielberg, Robert K. Katzschmann, Wojciech Matusik",
    "title": "DiffAqua: A Differentiable Computational Design Pipeline for Soft Underwater Swimmers with Shape Interpolation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459832",
    "pdf_link": null,
    "abstract": "The computational design of soft underwater swimmers is challenging because of the high degrees of freedom in soft-body modeling. In this paper, we present a differentiable pipeline for co-designing a soft swimmer's geometry and controller. Our pipeline unlocks gradient-based algorithms for discovering novel swimmer designs more efficiently than traditional gradient-free solutions. We propose Wasserstein barycenters as a basis for the geometric design of soft underwater swimmers since it is differentiable and can naturally interpolate between bio-inspired base shapes via optimal transport. By combining this design space with differentiable simulation and control, we can efficiently optimize a soft underwater swimmer's performance with fewer simulations than baseline methods. We demonstrate the efficacy of our method on various design problems such as fast, stable, and energy-efficient swimming and demonstrate applicability to multi-objective design.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_107",
    "authors": "Ethan Tseng, Ali Mosleh, Fahim Mannan, Karl St-Arnaud, Avinash Sharma, Yifan (Evan) Peng, Alexander Braun, Derek Nowrouzezahrai, Jean-Francois Lalonde, Felix Heide",
    "title": "Differentiable Compound Optics and Processing Pipeline Optimization for End-to-end Camera Design",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3446791",
    "pdf_link": null,
    "abstract": "Most modern commodity imaging systems we use directly for photography—or indirectly rely on for downstream applications—employ optical systems of multiple lenses that must balance deviations from perfect optics, manufacturing constraints, tolerances, cost, and footprint. Although optical designs often have complex interactions with downstream image processing or analysis tasks, today’s compound optics are designed in isolation from these interactions. Existing optical design tools aim to minimize optical aberrations, such as deviations from Gauss’ linear model of optics, instead of application-specific losses, precluding joint optimization with hardware image signal processing (ISP) and highly parameterized neural network processing. In this article, we propose an optimization method for compound optics that lifts these limitations. We optimize entire lens systems jointly with hardware and software image processing pipelines, downstream neural network processing, and application-specific end-to-end losses. To this end, we propose a learned, differentiable forward model for compound optics and an alternating proximal optimization method that handles function compositions with highly varying parameter dimensions for optics, hardware ISP, and neural nets. Our method integrates seamlessly atop existing optical design tools, such as Zemax. We can thus assess our method across many camera system designs and end-to-end applications. We validate our approach in an automotive camera optics setting—together with hardware ISP post processing and detection—outperforming classical optics designs for automotive object detection and traffic light state detection. For human viewing tasks, we optimize optics and processing pipelines for dynamic outdoor scenarios and dynamic low-light imaging. We outperform existing compartmentalized design or fine-tuning methods qualitatively and quantitatively, across all domain-specific applications tested.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_244",
    "authors": "Binh Huy Le, Keven Villeneuve, Carlos Gonzalez-Ochoa",
    "title": "Direct Delta Mush Skinning Compression With Continuous Examples",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459779",
    "pdf_link": null,
    "abstract": "Direct Delta Mush (DDM) is a high-quality, direct skinning method with a low setup cost. However, its storage and run-time computing cost are relatively high for two reasons: its skinning weights are 4 X 4 matrices instead of scalars like other direct skinning methods, and its computation requires one 3 X 3 Singular Value Decomposition per vertex. In this paper, we introduce a compression method that takes a DDM model and splits it into two layers: the first layer is a smaller DDM model that computes a set of virtual bone transformations and the second layer is a Linear Blend Skinning model that computes per-vertex transformations from the output of the first layer. The two-layer model can approximate the deformation of the original DDM model with significantly lower costs. Our main contribution is a novel problem formulation for the DDM compression based on a continuous example-based technique, in which we minimize the compression error on an uncountable set of example poses. This formulation provides an elegant metric for the compression error and simplifies the problem to the common linear matrix factorization. Our formulation also takes into account the skeleton hierarchy of the model, the bind pose, and the range of motions. In addition, we propose a new update rule to optimize DDM weights of the first layer and a modification to resolve the floating-point cancellation issue of DDM.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_112",
    "authors": "Steven Diamond, Vincent Sitzmann, Frank Julca-Aguilar, Stephen Boyd, Gordon Wetzstein, Felix Heide",
    "title": "Dirty Pixels: Towards End-to-end Image Processing and Perception",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3446918",
    "pdf_link": null,
    "abstract": "Real-world, imaging systems acquire measurements that are degraded by noise, optical aberrations, and other imperfections that make image processing for human viewing and higher-level perception tasks challenging. Conventional cameras address this problem by compartmentalizing imaging from high-level task processing. As such, conventional imaging involves processing the RAW sensor measurements in a sequential pipeline of steps, such as demosaicking, denoising, deblurring, tone-mapping, and compression. This pipeline is optimized to obtain a visually pleasing image. High-level processing, however, involves steps such as feature extraction, classification, tracking, and fusion. While this silo-ed design approach allows for efficient development, it also dictates compartmentalized performance metrics without knowledge of the higher-level task of the camera system. For example, today’s demosaicking and denoising algorithms are designed using perceptual image quality metrics but not with domain-specific tasks such as object detection in mind. We propose an end-to-end differentiable architecture that jointly performs demosaicking, denoising, deblurring, tone-mapping, and classification (see Figure 1). The architecture does not require any intermediate losses based on perceived image quality and learns processing pipelines whose outputs differ from those of existing ISPs optimized for perceptual quality, preserving fine detail at the cost of increased noise and artifacts. We show that state-of-the-art ISPs discard information that is essential in corner cases, such as extremely low-light conditions, where conventional imaging and perception stacks fail. We demonstrate on captured and simulated data that our model substantially improves perception in low light and other challenging conditions, which is imperative for real-world applications such as autonomous driving, robotics, and surveillance. Finally, we found that the proposed model also achieves state-of-the-art accuracy when optimized for image reconstruction in low-light conditions, validating the architecture itself as a potentially useful drop-in network for reconstruction and analysis tasks beyond the applications demonstrated in this work. Our proposed models, datasets, and calibration data are available at https://github.com/princeton-computational-imaging/DirtyPixels.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_330",
    "authors": "Zhiqi Yin, Zeshi Yang, Michiel van de Panne, KangKang Yin",
    "title": "Discovering Diverse Athletic Jumping Strategies",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459817",
    "pdf_link": null,
    "abstract": "We present a framework that enables the discovery of diverse and natural-looking motion strategies for athletic skills such as the high jump. The strategies are realized as control policies for physics-based characters. Given a task objective and an initial character configuration, the combination of physics simulation and deep reinforcement learning (DRL) provides a suitable starting point for automatic control policy training. To facilitate the learning of realistic human motions, we propose a Pose Variational Autoencoder (P-VAE) to constrain the actions to a subspace of natural poses. In contrast to motion imitation methods, a rich variety of novel strategies can naturally emerge by exploring initial character states through a sample-efficient Bayesian diversity search (BDS) algorithm. A second stage of optimization that encourages novel policies can further enrich the unique strategies discovered. Our method allows for the discovery of diverse and novel strategies for athletic jumping motions such as high jumps and obstacle jumps with no motion examples and less reward engineering than prior work.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_199",
    "authors": "Mark Gillespie, Boris Springborn, Keenan Crane",
    "title": "Discrete Conformal Equivalence of Polyhedral Surfaces",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459763",
    "pdf_link": null,
    "abstract": "This paper describes a numerical method for surface parameterization, yielding maps that are locally injective and discretely conformal in an exact sense. Unlike previous methods for discrete conformal parameterization, the method is guaranteed to work for any manifold triangle mesh, with no restrictions on triangulatiothat each task can be formulated as a convex problem where the triangulation is allowed to change---we complete the picture by introducing the machinery needed to actually construct a discrete conformal map. In particular, we introduce a new scheme for tracking correspondence between triangulations based on normal coordinates, and a new interpolation procedure based on layout in the light cone. Stress tests involving difficult cone configurations and near-degenerate triangulations indicate that the method is extremely robust in practice, and provides high-quality interpolation even on meshes with poor elements.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_356",
    "authors": "Alan Brunton, Lubna Abu Rmaileh",
    "title": "Displaced Signed Distance Fields for Additive Manufacturing",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459827",
    "pdf_link": null,
    "abstract": "We propose displaced signed distance fields, an implicit shape representation to accurately, efficiently and robustly 3D-print finely detailed and smoothly curved surfaces at native device resolution. As the resolution and accuracy of 3D printers increase, accurate reproduction of such surfaces becomes increasingly realizable from a hardware perspective. However, representing such surfaces with polygonal meshes requires high polygon counts, resulting in excessive storage, transmission and processing costs. These costs increase with print size, and can become exorbitant for large prints. Our implicit formulation simultaneously allows the augmentation of low-polygon meshes with compact meso-scale topographic information, such as displacement maps, and the realization of curved polygons, while leveraging efficient, streaming-compatible, discrete voxel-wise algorithms. Critical for this is careful treatment of the input primitives, their voxel approximation and the displacement to the true surface. We further propose a robust sign estimation to allow for incomplete, non-manifold input, whether human-made for onscreen rendering or directly out of a scanning pipeline. Our framework is efficient both in terms of time and space. The running time is independent of the number of input polygons, the amount of displacement, and is constant per voxel. The storage costs grow sub-linearly with the number of voxels, making our approach suitable for large prints. We evaluate our approach for efficiency and robustness, and show its advantages over standard techniques.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_448",
    "authors": "Timur Bagautdinov, Chenglei Wu, Tomas Simon, Takaaki Shiratori, Shih-En Wei, Fabian Andres Prada, Weipeng Xu, Yaser Sheikh, Jason Saragih",
    "title": "Driving-signal Aware Full-body Avatars",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459850",
    "pdf_link": null,
    "abstract": "We present a learning-based method for building driving-signal aware full-body avatars. Our model is a conditional variational autoencoder that can be animated with incomplete driving signals, such as human pose and facial keypoints, and produces a high-quality representation of human geometry and view-dependent appearance. The core intuition behind our method is that better drivability and generalization can be achieved by disentangling the driving signals and remaining generative factors, which are not available during animation. To this end, we explicitly account for information deficiency in the driving signal by introducing a latent space that exclusively captures the remaining information, thus enabling the imputation of the missing factors required during full-body animation, while remaining faithful to the driving signal. We also propose a learnable localized compression for the driving signal which promotes better generalization, and helps minimize the influence of global chance-correlations often found in real datasets. For a given driving signal, the resulting variational model produces a compact space of uncertainty for missing factors that allows for an imputation strategy best suited to a particular application. We demonstrate the efficacy of our approach on the challenging problem of full-body animation for virtual telepresence with driving signals acquired from minimal sensors placed in the environment and mounted on a VR-headset.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_239",
    "authors": "Suzi Kim, Sunghee Choi",
    "title": "Dynamic Closest Color Warping to Sort and Compare Palettes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459776",
    "pdf_link": null,
    "abstract": "A color palette is one of the simplest and most intuitive descriptors that can be extracted from images or videos. This paper proposes a method to assess the similarity between color palettes by sorting colors. While previous palette similarity measures compare only colors without considering the overall palette combination, we sort palettes to minimize the geometric distance between colors and align them to share a common color tendency. We propose dynamic closest color warping (DCCW) to calculate the minimum distance sum between colors and the graph connecting the colors in the other palette. We evaluate the proposed palette sorting and DCCW with several datasets and demonstrate that DCCW outperforms previous methods in terms of accuracy and computing time. We validate the effectiveness of the proposed sorting technique by conducting a perceptual study, which indicates a clear preference for the results of our approach. We also demonstrate useful applications enabled by DCCW, including palette interpolation, palette navigation, and image recoloring.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_154",
    "authors": "Mayu Arano, Yuki Morimoto",
    "title": "Dynamic Projection Mapping for Silkworms",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3450618.3469153",
    "pdf_link": null,
    "abstract": "Recently, there has been an increasing number of examples of dynamic projection mapping (DPM) applied to plants and animals. However, objects such as animals and plants are deformable, and it is difficult to obtain their shape or attach markers in advance; thus, these objects present a problem for DPM. Here, we propose an automatic generation method of DPM specially designed for silkworms. In addition, the system automatically generates visualeffect animations based on the shape of the projected object. Using this system, we conducted an experiment of projection on a real silkworm.Projections in the Forest [Schoor and Mawad 2014] is one example of a work in which PM is applied to plants and animals. In this previous work, static projection mapping was performed for plants and animals of the forest. Image registration for the mapping was performed manually by the artists, which required a substantial amount of time. For plant leaves with individual motion, a method of DPM that considers the occlusion of the projection area by the viewer has been proposed [Sueyoshi and Morimoto 2019]. This method automatically generates effects that match the shape of the plant. However, leaves exhibit small deformations, and it is difficult",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_121",
    "authors": "Kai Bai, Wei Li, Mathieu Desbrun, Xiaopei Liu",
    "title": "Dynamic Upsampling of Smoke Through Dictionary-based Learning",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3412360",
    "pdf_link": null,
    "abstract": "Simulating turbulent smoke flows with fine details is computationally intensive. For iterative editing or simply faster generation, efficiently upsampling a low-resolution numerical simulation is an attractive alternative. We propose a novel learning approach to the dynamic upsampling of smoke flows based on a training set of flows at coarse and fine resolutions. Our multiscale neural network turns an input coarse animation into a sparse linear combination of small velocity patches present in a precomputed over-complete dictionary. These sparse coefficients are then used to generate a high-resolution smoke animation sequence by blending the fine counterparts of the coarse patches. Our network is initially trained from a sequence of example simulations to both construct the dictionary of corresponding coarse and fine patches and allow for the fast evaluation of a sparse patch encoding of any coarse input. The resulting network provides an accurate upsampling when the coarse input simulation is well approximated by patches present in the training set (e.g., for re-simulation), or simply visually plausible upsampling when input and training sets differ significantly. We show a variety of examples to ascertain the strengths and limitations of our approach and offer comparisons to existing approaches to demonstrate its quality and effectiveness.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2020 - dl.acm.org"
  },
  {
    "paper_id": "papers_173",
    "authors": "Jiakai Zhang, Xinhang Liu, Xinyi Ye, Fuqiang Zhao, Yanshun Zhang, Minye Wu, Yingliang Zhang, Lan Xu, Jingyi Yu",
    "title": "Editable Free-viewpoint Video using a Layered Neural Representation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459756",
    "pdf_link": null,
    "abstract": "Generating free-viewpoint videos is critical for immersive VR/AR experience, but recent neural advances still lack the editing ability to manipulate the visual perception for large dynamic scenes. To fill this gap, in this paper, we propose the first approach for editable free-viewpoint video generation for large-scale view-dependent dynamic scenes using only 16 cameras. The core of our approach is a new layered neural representation, where each dynamic entity, including the environment itself, is formulated into a spatio-temporal …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_607",
    "authors": "Sitao Xiang",
    "title": "Eliminating Topological Errors in Neural Network Rotation Estimation Using Self-selecting Ensembles",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459882",
    "pdf_link": null,
    "abstract": "Many problems in computer graphics and computer vision applications involves inferring a rotation from a variety of different forms of inputs. With the increasing use of deep learning, neural networks have been employed to solve such problems. However, the traditional representations for 3D rotations, the quaternions and Euler angles, are found to be problematic for neural networks in practice, producing seemingly unavoidable large estimation errors. Previous researches has identified the discontinuity of the mapping from SO(3) to the quaternions or Euler angles as the source of such errors, and to solve it, embeddings of SO(3) have been proposed as the output representation of rotation estimation networks instead. In this paper, we argue that the argument against quaternions and Euler angles from local discontinuities of the mappings from SO(3) is flawed, and instead provide a different argument from the global topological properties of SO(3) that also establishes the lower bound of maximum error when using quaternions and Euler angles for rotation estimation networks. Extending from this view, we discover that rotation symmetries in the input object causes additional topological problems that even using embeddings of SO(3) as the output representation would not correctly handle. We propose the self-selecting ensemble, a topologically motivated approach, where the network makes multiple predictions and assigns weights to them. We show theoretically and with experiments that our methods can be combined with a wide range of different rotation representations and can handle all kinds of finite symmetries in 3D rotation estimation problems.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_232",
    "authors": "Aaron Demolder, Alfred Newman, Tom Durrant, Hammadi Nait-Charif, Valery Adzhiev, Andrzej Kaczorowski",
    "title": "Enabling Reflective and Refractive Depth Representation in Computer-generated Holography",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3450618.3469177",
    "pdf_link": null,
    "abstract": "Computer-Generated Holography (CGH) is a technique for the reconstruction and display of three-dimensional imagery through diffraction and interference of light. Holograms are generated digitally by calculating light propagation, and displayed on devices called Spatial Light Modulators (SLMs). When illuminated by coherent laser light, holograms then replay a full 3D scene. Recently, holography has received significant attention from industrial and academic communities, with neural holography [Peng et al. 2020][Shi et al. 2021] and numerous other techniques [Sahin et al. 2020]. Applications of holography include Augmented/Virtual Reality [Widjanarko et al. 2020], Head-Up Displays, and larger display devices [An et al. 2020]. In the real world, objects can be viewed in reflections (such as mirrors) and through refractions (such as glass or water); the depth at which these objects focus is defined by the focal power of the material. In computer graphics, realistic",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_118",
    "authors": "Qilin Sun, Congli Wang, Xiong Dun, Qiang Fu, Wolfgang Heidrich",
    "title": "End-to-end Complex Lens Design With Differentiable Ray Tracing",
    "paper_url": "https://vccimaging.org/Publications/Sun2021DiffLens/Sun2021DiffLens_small.pdf",
    "pdf_link": null,
    "abstract": "Cameras are designed with a complicated tradeoff between image quality (eg sharpness, contrast, color fidelity), and practical considerations such as cost, form factor, and weight. High-quality imaging systems require a stack of multiple optical elements to combat aberrations of all kinds. At the heart of the design process are tools like ZEMAX and Code V, which rely on merit functions to trade off the shape of the PSF over different image regions, depth, or zoom settings. Such a design process requires significant user knowledge",
    "scholar_publication": "ACM Trans. Graph, 2021 - vccimaging.org"
  },
  {
    "paper_id": "papers_316",
    "authors": "Tavi Halperin, Hanit Hakim, Orestis Vantzos, Gershon Hochman, Netai Benaim, Lior Sassy, Michael Kupchik, Ofir Bibi, Ohad Fried",
    "title": "Endless Loops: Detecting and Animating Periodic Patterns in Still Images",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459935",
    "pdf_link": null,
    "abstract": "We present an algorithm for producing a seamless animated loop from a single image. The algorithm detects periodic structures, such as the windows of a building or the steps of a staircase, and generates a non-trivial displacement vector field that maps each segment of the structure onto a neighboring segment along a user- or auto-selected main direction of motion. This displacement field is used, together with suitable temporal and spatial smoothing, to warp the image and produce the frames of a continuous animation loop. Our cinemagraphs are created in under a second on a mobile device. Over 140,000 users downloaded our app and exported over 350,000 cinemagraphs. Moreover, we conducted two user studies that show that users prefer our method for creating surreal and structured cinemagraphs compared to more manual approaches and compared to previous methods.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_158",
    "authors": "Carl Schissler, Gregor Mückl, Paul Calamia",
    "title": "Fast Diffraction Pathfinding for Dynamic Sound Propagation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459751",
    "pdf_link": null,
    "abstract": "In the context of geometric acoustic simulation, one of the more perceptually important yet difficult to simulate acoustic effects is diffraction, a phenomenon that allows sound to propagate around obstructions and corners. A significant bottleneck in real-time simulation of diffraction is the enumeration of high-order diffraction propagation paths in scenes with complex geometry (e.g. highly tessellated surfaces). To this end, we present a dynamic geometric diffraction approach that consists of an extensive mesh preprocessing pipeline and complementary runtime algorithm. The preprocessing module identifies a small subset of edges that are important for diffraction using a novel silhouette edge detection heuristic. It also extends these edges with planar diffraction geometry and precomputes a graph data structure encoding the visibility between the edges. The runtime module uses bidirectional path tracing against the diffraction geometry to probabilistically explore potential paths between sources and listeners, then evaluates the intensities for these paths using the Uniform Theory of Diffraction. It uses the edge visibility graph and the A* pathfinding algorithm to robustly and efficiently find additional high-order diffraction paths. We demonstrate how this technique can simulate 10th-order diffraction up to 568 times faster than the previous state of the art, and can efficiently handle large scenes with both high geometric complexity and high numbers of sources.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_243",
    "authors": "Ante Qu, Doug L. James",
    "title": "Fast Linking Numbers for Topology Verification of Loopy Structures",
    "paper_url": "https://graphics.stanford.edu/papers/fastlinkingnumbers/assets/QuJames2021FastLinkingNumbers_Optimized400dpi.pdf",
    "pdf_link": null,
    "abstract": "It is increasingly common to model, simulate, and process complex materials based on loopy structures, such as in knitted yarnlevel cloth garments, which possess topological constraints between inter-looping curves. In contrast to a solid or continuum model, the integrity of a loopy material depends on the preservation of its loop–loop topology. A failure to preserve these links, or an illegal creation of new links between unlinked loops, can result in an incorrect representation of the loopy material.",
    "scholar_publication": "ACM Trans. Graph., 2021 - graphics.stanford.edu"
  },
  {
    "paper_id": "papers_231",
    "authors": "Andrew B. Adams",
    "title": "Fast Median Filters Using Separable Sorting Networks",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459773",
    "pdf_link": null,
    "abstract": "Median filters are a widely-used tool in graphics, imaging, machine learning, visual effects, and even audio processing. Currently, very-small-support median filters are performed using sorting networks, and large-support median filters are handled by O(1) histogram-based methods. However, the constant factor on these O(1) algorithms is large, and they scale poorly to data types above 8-bit integers. On the other hand, good sorting networks have not been described above the 7 X 7 case, leaving us with no fast way to compute integer median filters of modest size, and no fast way to compute floating point median filters for any size above 7 X 7. This paper describes new sorting networks that efficiently compute median filters of arbitrary size. The key idea is that these networks can be factored to exploit the separability of the sorting problem - they share common work across scanlines, and within small tiles of output. We also describe new ways to run sorting networks efficiently, using a sorting-specific instruction set, compiler, and interpreter. The speed-up over prior work is more than an order of magnitude for a wide range of data types and filter sizes. For 8-bit integers, we describe the fastest median filters for all sizes up to 25 X 25 on CPU, and up to 33 X 33 on GPU. For higher-precision types, we describe the fastest median filters at all sizes tested on both CPU and GPU.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_295",
    "authors": "Yu Wang, Justin Solomon",
    "title": "Fast Quasi-harmonic Weights for Geometric Data Interpolation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459801",
    "pdf_link": null,
    "abstract": "We propose quasi-harmonic weights for interpolating geometric data, which are orders of magnitude faster to compute than state-of-the-art. Currently, interpolation (or, skinning) weights are obtained by solving large-scale constrained optimization problems with explicit constraints to suppress oscillative patterns, yielding smooth weights only after a substantial amount of computation time. As an alternative, our weights are obtained as minima of an unconstrained problem that can be optimized quickly using straightforward numerical techniques. We consider weights that can be obtained as solutions to a parameterized family of second-order elliptic partial differential equations. By leveraging the maximum principle and careful parameterization, we pose weight computation as an inverse problem of recovering optimal anisotropic diffusivity tensors. In addition, we provide a customized ADAM solver that significantly reduces the number of gradient steps; our solver only requires inverting tens of linear systems that share the same sparsity pattern. Overall, our approach achieves orders of magnitude acceleration compared to previous methods, allowing weight computation in near real-time.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_156",
    "authors": "Vibol Yem, Tsubasa Morita, Tomohiro Amemiya, Michiteru Kitazaki, Yasushi Ikei",
    "title": "Feedback of Rotational Sensation Experienced by Body for Immersive Telepresence",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469154",
    "pdf_link": null,
    "abstract": "In our previous study, we proposed a telepresence system that can transfer the riding sensation of a vehicle (Segway) for assisting collaborative task. The system could provide a local expert who remotely attend the task not only the view of a remote environment that is captured by a camera but also the vestibular perception during the movement of the camera. In this study, we examined the rotation feedback by the rotary seat when the camera is rotated. The measured intensity adjustment showed that the angular acceleration of the rotary seat was about half that of the camera rotation. Further, the result of the simulator sickness questionnaire scores showed that the inphase rotation of the seat with the camera is appropriate for suppressing virtual reality sickness, indicating that the requirement of vestibular intensity is quite low compared with the visual cue showed on the head mounted display, which allows a designer to develop a sensation feedback device that has an actuator of low strength.",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_404",
    "authors": "Torsten Hädrich, Daniel T. Banuti, Wojtek Palubicki, Sören Pirk, Dominik L. Michels",
    "title": "Fire in Paradise: Mesoscale Simulation of Wildfires",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459954",
    "pdf_link": null,
    "abstract": "Resulting from changing climatic conditions, wildfires have become an existential threat across various countries around the world. The complex dynamics paired with their often rapid progression renders wildfires an often disastrous natural phenomenon that is difficult to predict and to counteract. In this paper we present a novel method for simulating wildfires with the goal to realistically capture the combustion process of individual trees and the resulting propagation of fires at the scale of forests. We rely on a state-of-the-art modeling approach for large-scale ecosystems that enables us to represent each plant as a detailed 3D geometric model. We introduce a novel mathematical formulation for the combustion process of plants - also considering effects such as heat transfer, char insulation, and mass loss - as well as for the propagation of fire through the entire ecosystem. Compared to other wildfire simulations which employ geometric representations of plants such as cones or cylinders, our detailed 3D tree models enable us to simulate the interplay of geometric variations of branching structures and the dynamics of fire and wood combustion. Our simulation runs at interactive rates and thereby provides a convenient way to explore different conditions that affect wildfires, ranging from terrain elevation profiles and ecosystem compositions to various measures against wildfires, such as cutting down trees as firebreaks, the application of fire retardant, or the simulation of rain.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_437",
    "authors": "Vladimir Garanzha, Igor Kaporin, Liudmila Kudryavtseva, François Protais, Nicolas Ray, Dmitry Sokolov",
    "title": "Foldover-free Maps in 50 Lines of Code",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459847",
    "pdf_link": null,
    "abstract": "Mapping a triangulated surface to 2D space (or a tetrahedral mesh to 3D space) is an important problem in geometry processing. In computational physics, untangling plays an important role in mesh generation: it takes a mesh as an input, and moves the vertices to get rid of foldovers. In fact, mesh untangling can be considered as a special case of mapping where the geometry of the object is to be defined in the map space and the geometric domain is not explicit, supposing that each element is regular. In this paper, we propose a mapping method inspired by the untangling problem and compare its performance to the state of the art. The main advantage of our method is that the untangling aims at producing locally injective maps, which is the major challenge of mapping. In practice, our method produces locally injective maps in very difficult settings, both in 2D and 3D. We demonstrate it on a large reference database as well as on more difficult stress tests. For a better reproducibility, we publish the code in Python for a basic evaluation, and in C++ for more advanced applications.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_364",
    "authors": "Rafal Mantiuk, Gyorgy Denes, Alexandre Chapiro, Anton Kaplanyan, Gizem Rufo, Romain Bachy, Trisha Lian, Anjul Patney",
    "title": "FovVideoVDP: A Visible Difference Predictor for Wide Field-of-view Video",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459831",
    "pdf_link": null,
    "abstract": "FovVideoVDP is a video difference metric that models the spatial, temporal, and peripheral aspects of perception. While many other metrics are available, our work provides the first practical treatment of these three central aspects of vision simultaneously. The complex interplay between spatial and temporal sensitivity across retinal locations is especially important for displays that cover a large field-of-view, such as Virtual and Augmented Reality displays, and associated methods, such as foveated rendering. Our metric is derived from psychophysical studies of the early visual system, which model spatio-temporal contrast sensitivity, cortical magnification and contrast masking. It accounts for physical specification of the display (luminance, size, resolution) and viewing distance. To validate the metric, we collected a novel foveated rendering dataset which captures quality degradation due to sampling and reconstruction. To demonstrate our algorithm's generality, we test it on 3 independent foveated video datasets, and on a large image quality dataset, achieving the best performance across all datasets when compared to the state-of-the-art.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_120",
    "authors": "Nicholas Milef, Nima Kalantari",
    "title": "Foveated Monte-Carlo Denoising",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469140",
    "pdf_link": null,
    "abstract": "… to use foveation to speed up Monte-Carlo denoising? … -learning approach that supports foveated denoising. Inspired by … to perform foveated denoising by producing denoised images for …",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_143",
    "authors": "Xiaohe Ma, Kaizhang Kang, Ruisheng Zhu, Hongzhi Wu, Kun Zhou",
    "title": "Free-form Scanning of Non-planar Appearance With Neural Trace Photography",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459679",
    "pdf_link": null,
    "abstract": "We propose neural trace photography, a novel framework to automatically learn high-quality scanning of non-planar, complex anisotropic appearance. Our key insight is that free-form appearance scanning can be cast as a geometry learning problem on unstructured point clouds, each of which represents an image measurement and the corresponding acquisition condition. Based on this connection, we carefully design a neural network, to jointly optimize the lighting conditions to be used in acquisition, as well as the spatially independent reconstruction of reflectance from corresponding measurements. Our framework is not tied to a specific setup, and can adapt to various factors in a data-driven manner. We demonstrate the effectiveness of our framework on a number of physical objects with a wide variation in appearance. The objects are captured with a light-weight mobile device, consisting of a single camera and an RGB LED array. We also generalize the framework to other common types of light sources, including a point, a linear and an area light.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_114",
    "authors": "Egor Larionov, Ye Fan, Dinesh K. Pai",
    "title": "Frictional Contact on Smooth Elastic Solids",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3446663",
    "pdf_link": null,
    "abstract": "Frictional contact between deformable elastic objects remains a difficult simulation problem in computer graphics. Traditionally, contact has been resolved using sophisticated collision detection schemes and methods that build on the assumption that contact happens between polygons. While polygonal surfaces are an efficient representation for solids, they lack some intrinsic properties that are important for contact resolution. Generally, polygonal surfaces are not equipped with an intrinsic inside and outside partitioning or a smooth distance field close to the surface. Here we propose a new method for resolving frictional contacts against deforming implicit surface representations that addresses these problems. We augment a moving least squares (MLS) implicit surface formulation with a local kernel for resolving contacts, and develop a simple parallel transport approximation to enable transfer of frictional impulses. Our variational formulation of dynamics and elasticity enables us to naturally include contact constraints, which are resolved as one Newton-Raphson solve with linear inequality constraints. We extend this formulation by forwarding friction impulses from one time step to the next, used as external forces in the elasticity solve. This maintains the decoupling of friction from elasticity thus allowing for different solvers to be used in each step. In addition, we develop a variation of staggered projections, that relies solely on a non-linear optimization without constraints and does not require a discretization of the friction cone. Our results compare favorably to a popular industrial elasticity solver (used for visual effects), as well as recent academic work in frictional contact, both of which rely on polygons for contact resolution. We present examples of coupling between rigid bodies, cloth and elastic solids.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_331",
    "authors": "Karl D.D. Willis, Yewen Pu, Jieliang Luo, Hang Chu, Tao Du, Joseph G. Lambourne, Armando Solar-Lezama, Wojciech Matusik",
    "title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Construction From Human Design Sequences",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459818",
    "pdf_link": null,
    "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used to design manufactured objects, where a 3D shape is represented as a program supported by the CAD software. Despite the pervasiveness of parametric CAD and a growing interest from the research community, currently there does not exist a dataset of realistic CAD models in a concise programmatic form. In this paper we present the Fusion 360 Gallery, consisting of a simple language with just the sketch and extrude modeling operations, and a dataset of 8,625 human design sequences expressed in this language. We also present an interactive environment called the Fusion 360 Gym, which exposes the sequential construction of a CAD program as a Markov decision process, making it amendable to machine learning approaches. As a use case for our dataset and environment, we define the CAD reconstruction task of recovering a CAD program from a target geometry. We report results of applying state-of-the-art methods of program synthesis with neurally guided search on this task.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_133",
    "authors": "Daniel Bird, Stephen Laycock",
    "title": "GPGPU Accelerated Flow Diagrams",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3450618.3469143",
    "pdf_link": null,
    "abstract": "… utilising the massively parallel processing of the GPU, without the need for networked clusters. Here we present a GPGPU accelerated aggregate flow method, used to aggregate the …",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_105",
    "authors": "Milan Jaros, Lubomir Riha, Petr Strakos, Matej Spetko",
    "title": "GPU Accelerated Path Tracing of Massive Scenes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3447807",
    "pdf_link": null,
    "abstract": "This article presents a solution to path tracing of massive scenes on multiple GPUs. Our approach analyzes the memory access pattern of a path tracer and defines how the scene data should be distributed across up to 16 GPUs with minimal effect on performance. The key concept is that the parts of the scene that have the highest amount of memory accesses are replicated on all GPUs. We propose two methods for maximizing the performance of path tracing when working with partially distributed scene data. Both methods work on the memory management level and therefore path tracer data structures do not have to be redesigned, making our approach applicable to other path tracers with only minor changes in their code. As a proof of concept, we have enhanced the open-source Blender Cycles path tracer. The approach was validated on scenes of sizes up to 169 GB. We show that only 1–5% of the scene data needs to be replicated to all machines for such large scenes. On smaller scenes we have verified that the performance is very close to rendering a fully replicated scene. In terms of scalability we have achieved a parallel efficiency of over 94% using up to 16 GPUs.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_271",
    "authors": "Huamin Wang",
    "title": "GPU-based Simulation of Cloth Wrinkles at Submillimeter Levels",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459787",
    "pdf_link": null,
    "abstract": "In this paper, we study physics-based cloth simulation in a very high resolution setting, presumably at submillimeter levels with millions of vertices, to meet perceptual precision of our human eyes. State-of-the-art simulation techniques, mostly developed for unstructured triangular meshes, can hardly meet this demand due to their large computational costs and memory footprints. We argue that in a very high resolution, it is more plausible to use regular meshes with an underlying grid structure, which can be highly compatible with GPU acceleration like high-resolution images. Based on this idea, we formulate and solve the nonlinear optimization problem for simulating high-resolution wrinkles, by a fast block-based descent method with reduced memory accesses. We also investigate the development of the collision handling component in our system, whose performance benefits greatly from the grid structure. Finally, we explore various issues related to the applications of our system, including initialization for fast convergence and temporal coherence, gathering effects, inflation and stuffing models, and mesh simplification. We can treat our system as a quasistatic wrinkle synthesis tool, run it as a standalone dynamic simulator, or integrate it into a multi-resolution solver as an additional component. The experiment demonstrates the capability, efficiency and flexibility of our system in producing a variety of high-resolution wrinkles effects.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_368",
    "authors": "Haoran Mo, Edgar Simo-Serra, Chengying Gao, Changqing Zou, Ruomei Wang",
    "title": "General Virtual Sketching Framework for Vector Line Art",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459833",
    "pdf_link": null,
    "abstract": "Vector line art plays an important role in graphic design, however, it is tedious to manually create. We introduce a general framework to produce line drawings from a wide variety of images, by learning a mapping from raster image space to vector image space. Our approach is based on a recurrent neural network that draws the lines one by one. A differentiable rasterization module allows for training with only supervised raster data. We use a dynamic window around a virtual pen while drawing lines, implemented with a proposed aligned cropping and differentiable pasting modules. Furthermore, we develop a stroke regularization loss that encourages the model to use fewer and longer strokes to simplify the resulting vector image. Ablation studies and comparisons with existing methods corroborate the efficiency of our approach which is able to generate visually better results in less computation time, while generalizing better to a diversity of images and applications.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_396",
    "authors": "Michael Barton, Michal Bizzarri, Florian Rist, Oleksii Sliusarenko, Helmut Pottmann",
    "title": "Geometry and Tool Motion Planning for Curvature Adapted CNC Machining",
    "paper_url": "https://repository.kaust.edu.sa/handle/10754/669057",
    "pdf_link": null,
    "abstract": "CNC machining is the leading subtractive manufacturing technology. Although it is in use since decades, it is far from fully solved and still a rich source for challenging problems in geometric computing. We demonstrate this at hand of 5-axis machining of freeform surfaces, where the degrees of freedom in selecting and moving the cutting tool allow one to adapt the tool motion optimally to the surface to be produced. We aim at a high-quality surface finish, thereby reducing the need for hard-to-control post-machining processes such as grinding and polishing. Our work is based on a careful geometric analysis of curvature-adapted machining via so-called second order line contact between tool and target surface. On the geometric side, this leads to a new continuous transition between “dual” classical results in surface theory concerning osculating circles of surface curves and osculating cones of tangentially circumscribed developable surfaces. Practically, it serves as an effective basis for tool motion planning. Unlike previous approaches to curvature-adapted machining, we solve locally optimal tool positioning and motion planning within a single optimization framework and achieve curvature adaptation even for convex surfaces. This is possible with a toroidal cutter that contains a negatively curved cutting area. The effectiveness of our approach is verified at hand of digital models, simulations and machined parts, including a comparison to results generated with commercial software.",
    "scholar_publication": "2021 - repository.kaust.edu.sa"
  },
  {
    "paper_id": "pos_181",
    "authors": "Kohei Doi, Yuki Morimoto, Reiji Tsuruno",
    "title": "Global Illumination-Aware Color Remapping with Fidelity for Texture Values",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469165",
    "pdf_link": null,
    "abstract": "Our aim is to convert an object’s appearance to an arbitrary color considering the light scattering in the entire scene, which is often called the global illumination. Existing stylization methods convert the color of an object with a 1-dimensional texture for 3-dimensional computer graphics to reproduce a typical style used in illustrations and cel animations. However, they cannot express global illumination effects such as color bleedings and soft shadows. We propose a method to compute the global illumination and convert the shading to an arbitrary color. It consists of subpath tracing from the eye to the object, and radiance estimation on the object. The radiance is stored and used later to convert its color. The method reproduces reflections in other objects with the converted color. As a result, we can convert the color of illumination effects such as soft shadows and refractions.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_167",
    "authors": "Shuma Shimizu, Tatsuya Minagawa, James Harry Morris, Xanat Vargas Meza, Yoichi Ochiai",
    "title": "Goshuin 2.0: Construction of the World's Largest Goshuin Dataset and Automatic Generation System of Goshuin by Neural Style Transfer",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469160",
    "pdf_link": null,
    "abstract": "… AUTOMATIC GENERATION SYSTEM We created a system that allows users to generate goshuin … We used neural style transfer to generate characters. This is a mechanism that inputs …",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_178",
    "authors": "Yu Fang, Minchen Li, Chenfanfu Jiang, Danny M. Kaufman",
    "title": "Guaranteed Globally Injective 3D Deformation Processing",
    "paper_url": "https://par.nsf.gov/servlets/purl/10290706",
    "pdf_link": null,
    "abstract": "A wide array of geometry processing and animation tasks boil down to minimizing a deformation objective while seeking to achieve both targeted boundary conditions and injectivity. If we loosen our requirements to satisfying just local injectivity, or else to focus solely on 2D problems, then recent advances in distortion optimization offer many promising solutions [Jiang et al. 2017; Kovalsky et al. 2016; Schüller et al. 2013; Smith and Schaefer 2015; Su et al. 2020; Zhu et al. 2018].However, when it comes to optimizing 3D mesh deformations with global injectivity, very few options are available. At the same time, existing methods come with strong limitations on performance and, perhaps even more restrictive, significant modes of failure. In summary (we detail the work in Section 3), there is currently an undesirable trade-off between reliability and expressiveness in computing globally injective deformations in 3D. On the one hand, many methods apply iterative contact-processing modules from physics-based animation [Bridson et al. 2002] to resolve intersections in geometry processing. These methods are efficient and easily",
    "scholar_publication": "ACM Transactions on Graphics, 2021 - par.nsf.gov"
  },
  {
    "paper_id": "papers_115",
    "authors": "Manish Mandad, Marcel Campen",
    "title": "Guaranteed-Quality Higher-Order Triangular Meshing of 2D Domains",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459673",
    "pdf_link": null,
    "abstract": "We present a guaranteed quality mesh generation algorithm for the curvilinear triangulation of planar domains with piecewise polynomial boundary. The resulting mesh consists of higher-order triangular elements which are not only regular (i.e., with injective geometric map) but respect strict bounds on quality measures like scaled Jacobian and MIPS distortion. This also implies that the curved triangles' inner angles are bounded from above and below. These are key quality criteria, for instance, in the field of finite element analysis. The domain boundary is reproduced exactly, without geometric approximation error. The central idea is to transform the curvilinear meshing problem into a linear meshing problem via a carefully constructed transformation of bounded distortion, enabling us to leverage key results on guaranteed-quality straight-edge triangulation. The transformation is based on a simple yet general construction and observations about convergence properties of curves under subdivision. Our algorithm can handle arbitrary polynomial order, arbitrarily sharp corners, feature and interface curves, and can be executed using rational arithmetic for strict reliability.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_315",
    "authors": "Shilin Zhu, Zexiang Xu, Tiancheng Sun, Alexandr Kuznetsov, Mark Meyer, Henrik Wann Jensen, Hao Su, Ravi Ramamoorthi",
    "title": "Hierarchical Neural Reconstruction for Path Guiding Using Hybrid Path and Photon Samples",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459810",
    "pdf_link": null,
    "abstract": "Path guiding is a promising technique to reduce the variance of path tracing. Although existing online path guiding algorithms can eventually learn good sampling distributions given a large amount of time and samples, the speed of learning becomes a major bottleneck. In this paper, we accelerate the learning of sampling distributions by training a light-weight neural network offline to reconstruct from sparse samples. Uniquely, we design our neural network to directly operate convolutions on a sparse quadtree, which regresses a high-quality hierarchical sampling distribution. Our approach can reconstruct reasonably accurate sampling distributions faster, allowing for efficient path guiding and rendering. In contrast to the recent offline neural path guiding techniques that reconstruct low-resolution 2D images for sampling, our novel hierarchical framework enables more fine-grained directional sampling with less memory usage, effectively advancing the practicality and efficiency of neural path guiding. In addition, we take advantage of hybrid bidirectional samples including both path samples and photons, as we have found this more robust to different light transport scenarios compared to using only one type of sample as in previous work. Experiments on diverse testing scenes demonstrate that our approach often improves rendering results with better visual quality and lower errors. Our framework can also provide the proper balance of speed, memory cost, and robustness.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_168",
    "authors": "Siyuan Shen, Yin Yang, Tianjia Shao, He Wang, Chenfanfu Jiang, Lei Lan, Kun Zhou",
    "title": "High-order Differentiable Autoencoder for Nonlinear Model Reduction",
    "paper_url": "https://arxiv.org/abs/2102.11026",
    "pdf_link": null,
    "abstract": "This paper provides a new avenue for exploiting deep neural networks to improve physics-based simulation. Specifically, we integrate the classic Lagrangian mechanics with a deep autoencoder to accelerate elastic simulation of deformable solids. Due to the inertia effect, the dynamic equilibrium cannot be established without evaluating the second-order derivatives of the deep autoencoder network. This is beyond the capability of off-the-shelf automatic differentiation packages and algorithms, which mainly focus on the gradient evaluation. Solving the nonlinear force equilibrium is even more challenging if the standard Newton's method is to be used. This is because we need to compute a third-order derivative of the network to obtain the variational Hessian. We attack those difficulties by exploiting complex-step finite difference, coupled with reverse automatic differentiation. This strategy allows us to enjoy the convenience and accuracy of complex-step finite difference and in the meantime, to deploy complex-value perturbations as collectively as possible to save excessive network passes. With a GPU-based implementation, we are able to wield deep autoencoders (e.g., layers) with a relatively high-dimension latent space in real-time. Along this pipeline, we also design a sampling network and a weighting network to enable \\emph{weight-varying} Cubature integration in order to incorporate nonlinearity in the model reduction. We believe this work will inspire and benefit future research efforts in nonlinearly reduced physical simulation problems.",
    "scholar_publication": "arXiv preprint arXiv …, 2021 - arxiv.org"
  },
  {
    "paper_id": "papers_477",
    "authors": "Jie Guo, Shuichang Lai, Chengzhi Tao, Yuelong Cai, Lei Wang, Yanwen Guo, Ling-Qi Yan",
    "title": "Highlight-aware Two-stream Network for Single-image SVBRDF Acquisition",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459854",
    "pdf_link": null,
    "abstract": "This paper addresses the task of estimating spatially-varying reflectance (i.e., SVBRDF) from a single, casually captured image. Central to our method is a highlight-aware (HA) convolution operation and a two-stream neural network equipped with proper training losses. Our HA convolution, as a novel variant of standard (ST) convolution, directly modulates convolution kernels under the guidance of automatically learned masks representing potentially overexposed highlight regions. It helps to reduce the impact of strong specular highlights on diffuse components and at the same time, hallucinates plausible contents in saturated regions. Considering that variation of saturated pixels also contains important cues for inferring surface bumpiness and specular components, we design a two-stream network to extract features from two different branches stacked by HA convolutions and ST convolutions, respectively. These two groups of features are further fused in an attention-based manner to facilitate feature selection of each SVBRDF map. The whole network is trained end to end with a new perceptual adversarial loss which is particularly useful for enhancing the texture details. Such a design also allows the recovered material maps to be disentangled. We demonstrate through quantitative analysis and qualitative visualization that the proposed method is effective to recover clear SVBRDFs from a single casually captured image, and performs favorably against state-of-the-arts. Since we impose very few constraints on the capture process, even a non-expert user can create high-quality SVBRDFs that cater to many graphical applications.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_290",
    "authors": "Dmitriy Smirnov, Justin Solomon",
    "title": "HodgeNet: Learning Spectral Geometry on Triangle Meshes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459797",
    "pdf_link": null,
    "abstract": "Constrained by the limitations of learning toolkits engineered for other applications, such as those in image processing, many mesh-based learning algorithms employ data flows that would be atypical from the perspective of conventional geometry processing. As an alternative, we present a technique for learning from meshes built from standard geometry processing modules and operations. We show that low-order eigenvalue/eigenvector computation from operators parameterized using discrete exterior calculus is amenable to efficient approximate backpropagation, yielding spectral per-element or per-mesh features with similar formulas to classical descriptors like the heat/wave kernel signatures. Our model uses few parameters, generalizes to high-resolution meshes, and exhibits performance and time complexity on par with past work.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_229",
    "authors": "Grigoris Daskalogrigorakis, Ann McNamara, Katerina Mania",
    "title": "Holo-Box: Level-of-detail Glanceable Interfaces for Augmented Reality",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469175",
    "pdf_link": null,
    "abstract": "Glanceable interfaces are Augmented Reality (AR) User Interfaces (UIs) for information retrieval ”at a glance” relying on eye gaze for implicit input. While they provide rapid information retrieval, they often occlude a large part of the real-world. This is compounded as the amount of virtual information increases. Interacting with complex glanceable interfaces often results in unintentional eye gaze interaction and selections due to the Midas Touch problem. In this work, we present Holo-box, an innovative AR UI design that combines 2D compact glanceable interfaces with 3D virtual ”Holo-boxes”. We can utilize the glanceable 2D interface to provide compact information at a glance while using Holo-box for explicit input such as hand tracking activated when necessary, surpassing the Midas Touch problem and resulting in Level-of-Detail(LOD) for AR glanceable UIs. We test our proposed system inside a real-world machine shop to provide on-demand virtual information while minimizing unintentional real-world occlusion.",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_102",
    "authors": "Marina Alterman, Chen Bar, Ioannis Gkioulekas, Anat Levin",
    "title": "Imaging With Local Speckle Intensity Correlations: Theory and Practice",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3447392",
    "pdf_link": null,
    "abstract": "Recent advances in computational imaging have significantly expanded our ability to image through scattering layers such as biological tissues by exploiting the auto-correlation properties of captured speckle intensity patterns. However, most experimental demonstrations of this capability focus on the far-field imaging setting, where obscured light sources are very far from the scattering layer. By contrast, medical imaging applications such as fluorescent imaging operate in the near-field imaging setting, where sources are inside the scattering layer. We provide a theoretical and experimental study of the similarities and differences between the two settings, highlighting the increased challenges posed by the near-fieldsetting. We then draw insights from this analysis to develop a new algorithm for imaging through scattering that is tailored to the near-field setting by taking advantage of unique properties of speckle patterns formed under this setting, such as their local support. We present a theoretical analysis of the advantages of our algorithm and perform real experiments in both far-field and near-field configurations, showing an order-of magnitude expansion in both the range and the density of the obscured patterns that can be recovered.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_518",
    "authors": "Shiying Xiong, Rui Tao, Yaorui Zhang, Fan Feng, Bo Zhu",
    "title": "Incompressible Flow Simulation on Vortex Segment Clouds",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459865",
    "pdf_link": null,
    "abstract": "We propose a novel Lagrangian geometric representation using segment clouds to simulate incompressible fluid exhibiting strong anisotropic vortical features. The central component of our approach is a cloud of discrete segments enhanced by a set of local segment reseeding operations to facilitate both the geometrical evolution and the topological updates of vortical flow. We build a vortex dynamics solver with the support for dynamic solid boundaries based on discrete segment primitives. We demonstrate the efficacy of our approach by simulating a broad range of challenging flow phenomena, such as reconnection of non-closed vortex tubes and vortex shedding behind a rotating object.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_222",
    "authors": "Ashley Cornall, Rehan Zia",
    "title": "Integrating Abstract Expressionism With 3D Lighting Within the Light-in-space Movement",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3450618.3469172",
    "pdf_link": null,
    "abstract": "The research objective of this project was to create a unique pipeline for integrating 3D lighting with Abstract Expressionistic painting (TATE, no date b) that served the artistic goals and creative intent of the artist. The final result is a critical creative practice pipeline to that allows the artist to unpack the effects of a year-long lockdown on creativity and growth. Inspired by the Light-in-Space movement (The Art Story, no date), a combination of computer graphics (CG) lighting and painting techniques are used to create custom shadow casters from painting scans, and, manipulation of scanning technology to render a final abstract effect. The completed pipeline serves as a framework for creating a unified body of work.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_145",
    "authors": "Tomoki Sueyoshi, Yuki Morimoto",
    "title": "Interactive DPM for Thin Plants With the Latency Measurement",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3450618.3469151",
    "pdf_link": null,
    "abstract": "2 METHODOur system consists of a ProCam (projector and camera) system (Sec 2.1) that acquires target surfaces using the camera as candidate projection areas and projects images applied to these surfaces via the projector. In our system, points of each contour of the specified projection area in the previous frame are first tracked on every frame (Sec 2.2) to map the effects. Second, a capacitive sensor detects touch events on target objects for interactive effects generation (Sec 2.3). These effects are generated using our concept. Finally, these effects are projected onto real-world plants.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_213",
    "authors": "Rinat Abdrashitov, Seungbae Bang, David Levin, Karan Singh, Alec Jacobson",
    "title": "Interactive Modelling of Volumetric Musculoskeletal Anatomy",
    "paper_url": "https://arxiv.org/abs/2106.05161",
    "pdf_link": null,
    "abstract": "We present a new approach for modelling musculoskeletal anatomy. Unlike previous methods, we do not model individual muscle shapes as geometric primitives (polygonal meshes, NURBS etc.). Instead, we adopt a volumetric segmentation approach where every point in our volume is assigned to a muscle, fat, or bone tissue. We provide an interactive modelling tool where the user controls the segmentation via muscle curves and we visualize the muscle shapes using volumetric rendering. Muscle curves enable intuitive yet powerful control over the muscle shapes. This representation allows us to automatically handle intersections between different tissues (musclemuscle, muscle-bone, and muscle-skin) during the modelling and automates computation of muscle fiber fields. We further introduce a novel algorithm for converting the volumetric muscle representation into tetrahedral or surface geometry for use in downstream tasks. Additionally, we introduce an interactive skeleton authoring tool that allows the users to create skeletal anatomy starting from only a skin mesh using a library of bone parts.",
    "scholar_publication": "arXiv preprint arXiv …, 2021 - arxiv.org"
  },
  {
    "paper_id": "papers_284",
    "authors": "Mustafa Işık, Krishna Mullia, Matthew Fisher, Jonathan Eisenmann, Michaël Gharbi",
    "title": "Interactive Monte Carlo Denoising Using Affinity of Neural Features",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459793",
    "pdf_link": null,
    "abstract": "High-quality denoising of Monte Carlo low-sample renderings remains a critical challenge for practical interactive ray tracing. We present a new learning-based denoiser that achieves state-of-the-art quality and runs at interactive rates. Our model processes individual path-traced samples with a lightweight neural network to extract per-pixel feature vectors. The rest of our pipeline operates in pixel space. We define a novel pairwise affinity over the features in a pixel neighborhood, from which we assemble dilated spatial kernels to filter the noisy radiance. Our denoiser is temporally stable thanks to two mechanisms. First, we keep a running average of the noisy radiance and intermediate features, using a per-pixel recursive filter with learned weights. Second, we use a small temporal kernel based on the pairwise affinity between features of consecutive frames. Our experiments show our new affinities lead to higher quality outputs than techniques with comparable computational costs, and better high-frequency details than kernel-predicting approaches. Our model matches or outperfoms state-of-the-art offline denoisers in the low-sample count regime (2--8 samples per pixel), and runs at interactive frame rates at 1080p resolution.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_296",
    "authors": "Zachary Ferguson, Minchen Li, Teseo Schneider, Francisca Gil-Ureta, Timothy Langlois, Chenfanfu Jiang, Denis Zorin, Danny M. Kaufman, Daniele Panozzo",
    "title": "Intersection-free Rigid Body Dynamics",
    "paper_url": "https://par.nsf.gov/servlets/purl/10285667",
    "pdf_link": null,
    "abstract": "Simulations of rigid objects with contact resolution and friction are ubiquitous in computer graphics and robotics. Rigid body models do not deform. Equipped with just rotational and translational degrees of freedom (DOF) they are a critical simplification enabling simulations with orders of magnitude less DOF when material deformation effects are either not significant or can be safely ignored. An ideal rigid body simulator should take a scene description, initial conditions, and a set of (possibly time-dependent) boundary conditions, and integrate the system through time. This is unfortunately not the case with existing algorithms, which require extensive parameter tuning to produce sensible results (Section 6). In this work, we revisit the problem with a very different focus: automation and robustness. We propose an algorithm that does not require per-scene parameter tuning and can timestep large scenes",
    "scholar_publication": "ACM Transactions on …, 2021 - par.nsf.gov"
  },
  {
    "paper_id": "paperstog_116",
    "authors": "Xinwei Yao, Ohad Fried, Kayvon Fatahalian, Maneesh Agrawala",
    "title": "Iterative Text-based Editing of Talking-heads Using Neural Retargeting",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3449063",
    "pdf_link": null,
    "abstract": "We present a text-based tool for editing talking-head video that enables an iterative editing workflow. On each iteration users can edit the wording of the speech, further refine mouth motions if necessary to reduce artifacts, and manipulate non-verbal aspects of the performance by inserting mouth gestures (e.g., a smile) or changing the overall performance style (e.g., energetic, mumble). Our tool requires only 2 to 3 minutes of the target actor video and it synthesizes the video for each iteration in about 40 seconds, allowing users to quickly explore many editing possibilities as they iterate. Our approach is based on two key ideas. (1) We develop a fast phoneme search algorithm that can quickly identify phoneme-level subsequences of the source repository video that best match a desired edit. This enables our fast iteration loop. (2) We leverage a large repository of video of a source actor and develop a new self-supervised neural retargeting technique for transferring the mouth motions of the source actor to the target actor. This allows us to work with relatively short target actor videos, making our approach applicable in many real-world editing scenarios. Finally, our, refinement and performance controls give users the ability to further fine-tune the synthesized results.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_311",
    "authors": "Mohammad Sina Nabizadeh, Ravi Ramamoorthi, Albert Chern",
    "title": "Kelvin Transformations for Simulations on Infinite Domains",
    "paper_url": "https://mathweb.ucsd.edu/~b3tran/cgm/Chern_KelvinTransform_2021.pdf",
    "pdf_link": null,
    "abstract": "97: 2• Mohammad Sina Nabizadeh, Ravi Ramamoorthi, and Albert Chern the space require the domain to be truncated into a nite size, introducing arti cial boundaries [Tsynkov 1998]. These boundaries are imposed with conditions that either approximate the behavior of the solution at in nity, or match an outer regime simulation [Stomakhin and Selle 2017] or analytic model (including absorbing layers)[Bojsen-Hansen and Wojtan 2016]. Mesh-free methods may also require special treatments in in nite domains. For example, Monte-Carlo-based PDE solvers [Sawhney and Crane 2020] for the direct evaluation of the solution usually involve a random walk in the domain, which converges much more slowly as the walker likely wanders to in nity.In this paper, we introduce a technique to rewrite a PDE on an in nite domain as a PDE on a compact domain. After such a transformation, standard numerical methods on compact domains apply. We refer to this transformation as the Kelvin transform, since it agrees with the historical Kelvin transform in the case of the Laplace and Poisson equations [Kellogg 1953]. We demonstrate the Kelvin transform for the Laplace and Poisson equations on in nite domains, as these problems underpin the fundamental building blocks in 3D data processing and many physical simulations such as uids, electromagnetism, thermostatics and gravitation. We also include examples of a generalized Kelvin transform applied to the Helmholtz equation (Figure 1), which is the basis for acoustic simulation. This demonstrates the possibility to compute such oscillatory elds on an outer domain without requiring any arti cial wave-absorbing boundary. This paper contributes the following novel concepts and applications:",
    "scholar_publication": "ACM Trans. Graph., 2021 - mathweb.ucsd.edu"
  },
  {
    "paper_id": "papers_160",
    "authors": "Alexandre Kaspar, Kui Wu, Yiyue Luo, Liane Makatura, Wojciech Matusik",
    "title": "Knit Sketching: from Cut and Sew Patterns to Machine-Knit Garments",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459752",
    "pdf_link": null,
    "abstract": "We present a novel workflow to design and program knitted garments for industrial whole-garment knitting machines. Inspired by traditional garment making based on cutting and sewing, we propose a sketch representation with additional annotations necessary to model the knitting process. Our system bypasses complex editing operations in 3D space, which allows us to achieve interactive editing of both the garment shape and its underlying time process. We provide control of the local knitting direction, the location of important course interfaces, as well as the placement of stitch irregularities that form seams in the final garment. After solving for the constrained knitting time process, the garment sketches are automatically segmented into a minimal set of simple regions that can be knitted using simple knitting procedures. Finally, our system optimizes a stitch graph hierarchically while providing control over the tradeoff between accuracy and simplicity. We showcase different garments created with our web interface.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_279",
    "authors": "Georges Nader, Yu Han Quek, Pei Zhi Chia, Oliver Weeger, Sai-Kit Yeung",
    "title": "KnitKit: A Flexible System for Machine Knitting of Customizable Textiles",
    "paper_url": "https://hal.science/hal-03214570/",
    "pdf_link": null,
    "abstract": "In this work, we introduce KnitKit, a flexible and customizable system for the computational design and production of functional, multi-material, and three-dimensional knitted textiles. Our system greatly simplifies the knitting of 3D objects with complex, varying patterns that use multiple yarns and stitch patterns by separating the high-level design specification in terms of geometry, stitch patterns, materials, or colors from the low-level, machine specific knitting instruction generation. Starting from a triangular 3D mesh and a 2D texture that specifies knitting patterns on top of the geometry, our system generates the required machine instructions in three major steps. First, the input is processed and the KnitNet data structure is generated. This graph structure serves as an abstract interface between the high-level geometric and knitting configuration and the low-level, machine-specific knitting instructions. Second, a graph rewriting procedure is applied on the KnitNet that produces a sequence of abstract machine actions. Finally, the low-level machine instructions are generated by adapting those abstract actions to a specific machine context. We showcase the potential of this computational approach by designing and fabricating a variety of objects with complex geometries, multiple yarns, and multiple stitch patterns.",
    "scholar_publication": "ACM Transactions on …, 2021 - hal.science"
  },
  {
    "paper_id": "papers_526",
    "authors": "Zishun Liu, Xingjian Han, Yuchen Zhang, Xiangjia Chen, Yukun Lai, Eugeni L. Doubrovski, Emily Whiting, Charlie C. L. Wang",
    "title": "Knitting 4D Garments With Elasticity Controlled for Body Motion",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459868",
    "pdf_link": null,
    "abstract": "In this paper, we present a new computational pipeline for designing and fabricating 4D garments as knitwear that considers comfort during body movement. This is achieved by careful control of elasticity distribution to reduce uncomfortable pressure and unwanted sliding caused by body motion. We exploit the ability to knit patterns in different elastic levels by single-jersey jacquard (SJJ) with two yarns. We design the distribution of elasticity for a garment by physics-based computation, the optimized elasticity on the garment is then converted into instructions for a digital knitting machine by two algorithms proposed in this paper. Specifically, a graph-based algorithm is proposed to generate knittable stitch meshes that can accurately capture the 3D shape of a garment, and a tiling algorithm is employed to assign SJJ patterns on the stitch mesh to realize the designed distribution of elasticity. The effectiveness of our approach is verified on simulation results and on specimens physically fabricated by knitting machines.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_614",
    "authors": "Sangeetha Grama Srinivasan, Qisi Wang, Junior Rojas, Gergely Klar, Ladislav Kavan, Eftychios Sifakis",
    "title": "Learning Active Quasistatic Physics-based Models From Data",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459883",
    "pdf_link": null,
    "abstract": "Humans and animals can control their bodies to generate a wide range of motions via low-dimensional action signals representing high-level goals. As such, human bodies and faces are prime examples of active objects, which can affect their shape via an internal actuation mechanism. This paper explores the following proposition: given a training set of example poses of an active deformable object, can we learn a low-dimensional control space that could reproduce the training set and generalize to new poses? In contrast to popular machine learning methods for dimensionality reduction such as auto-encoders, we model our active objects in a physics-based way. We utilize a differentiable, quasistatic, physics-based simulation layer and combine it with a decoder-type neural network. Our differentiable physics layer naturally fits into deep learning frameworks and allows the decoder network to learn actuations that reach the desired poses after physics-based simulation. In contrast to modeling approaches where users build anatomical models from first principles, medical literature or medical imaging, we do not presume knowledge of the underlying musculature, but learn the structure and control of the actuation mechanism directly from the input data. We present a training paradigm and several scalability-oriented enhancements that allow us to train effectively while accommodating high-resolution volumetric models, with as many as a quarter million simulation elements. The prime demonstration of the efficacy of our example-driven modeling framework targets facial animation, where we train on a collection of input expressions while generalizing to unseen poses, drive detailed facial animation from sparse motion capture input, and facilitate expression sculpting via direct manipulation.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_566",
    "authors": "Cristian Romero, Dan Casas, Jesús Pérez, Miguel A. Otaduy",
    "title": "Learning Contact Corrections for Handle-based Subspace Dynamics",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459875",
    "pdf_link": null,
    "abstract": "This paper introduces a novel subspace method for the simulation of dynamic deformations. The method augments existing linear handle-based subspace formulations with nonlinear learning-based corrections parameterized by the same subspace. Together, they produce a compact nonlinear model that combines the fast dynamics and overall contact-based interaction of subspace methods, with the highly detailed deformations of learning-based methods. We propose a formulation of the model with nonlinear corrections applied on the …",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_414",
    "authors": "Mengyu Chu, Nils Thuerey, Hans-Peter Seidel, Christian Theobalt, Rhaleb Zayer",
    "title": "Learning Meaningful Controls for Fluids",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459845",
    "pdf_link": null,
    "abstract": "While modern fluid simulation methods achieve high-quality simulation results, it is still a big challenge to interpret and control motion from visual quantities, such as the advected marker density. These visual quantities play an important role in user interactions: Being familiar and meaningful to humans, these quantities have a strong correlation with the underlying motion. We propose a novel data-driven conditional adversarial model that solves the challenging and theoretically ill-posed problem of deriving plausible velocity fields from a single frame of a density field. Besides density modifications, our generative model is the first to enable the control of the results using all of the following control modalities: obstacles, physical parameters, kinetic energy, and vorticity. Our method is based on a new conditional generative adversarial neural network that explicitly embeds physical quantities into the learned latent space, and a new cyclic adversarial network design for control disentanglement. We show the high quality and versatile controllability of our results for density-based inference, realistic obstacle interaction, and sensitive responses to modifications of physical parameters, kinetic energy, and vorticity. Code, models, and results can be found at https://github.com/RachelCmy/den2vel.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_118",
    "authors": "Or Perel, Oron Anschel, Omri Ben-Eliezer, Shai Mazor, Hadar Averbuch-Elor",
    "title": "Learning Multimodal Affinities for Textual Editing in Images",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3451340",
    "pdf_link": null,
    "abstract": "Nowadays, as cameras are rapidly adopted in our daily routine, images of documents are becoming both abundant and prevalent. Unlike natural images that capture physical objects, document-images contain a significant amount of text with critical semantics and complicated layouts. In this work, we devise a generic unsupervised technique to learn multimodal affinities between textual entities in a document-image, considering their visual style, the content of their underlying text, and their geometric context within the image. We then use these learned affinities to automaticallycluster the textual entities in the image into different semantic groups. The core of our approach is a deep optimization scheme dedicated for an image provided by the user that detects and leverages reliable pairwise connections in the multimodal representation of the textual elements to properly learn the affinities. We show that our technique can operate on highly varying images spanning a wide range of documents and demonstrate its applicability for various editing operations manipulating the content, appearance, and geometry of the image.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_463",
    "authors": "Peizhuo Li, Kfir Aberman, Rana Hanocka, Libin Liu, Olga Sorkine-Hornung, Baoquan Chen",
    "title": "Learning Skeletal Articulations With Neural Blend Shapes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459852",
    "pdf_link": null,
    "abstract": "Animating a newly designed character using motion capture (mocap) data is a long standing problem in computer animation. A key consideration is the skeletal structure that should correspond to the available mocap data, and the shape deformation in the joint regions, which often requires a tailored, pose-specific refinement. In this work, we develop a neural technique for articulating 3D characters using enveloping with a pre-defined skeletal structure which produces high quality pose dependent deformations. Our framework learns to rig and skin characters with the same articulation structure (e.g., bipeds or quadrupeds), and builds the desired skeleton hierarchy into the network architecture. Furthermore, we propose neural blend shapes - a set of corrective pose-dependent shapes which improve the deformation quality in the joint regions in order to address the notorious artifacts resulting from standard rigging and skinning. Our system estimates neural blend shapes for input meshes with arbitrary connectivity, as well as weighting coefficients which are conditioned on the input joint rotations. Unlike recent deep learning techniques which supervise the network with ground-truth rigging and skinning parameters, our approach does not assume that the training data has a specific underlying deformation model. Instead, during training, the network observes deformed shapes and learns to infer the corresponding rig, skin and blend shapes using indirect supervision. During inference, we demonstrate that our network generalizes to unseen characters with arbitrary mesh connectivity, including unrigged characters built by 3D artists. Conforming to standard skeletal animation models enables direct plug-and-play in standard animation software, as well as game engines.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_355",
    "authors": "Kyungho Lee, Sehee Min, Sunmin Lee, Jehee Lee",
    "title": "Learning Time-critical Responses for Interactive Character Control",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459826",
    "pdf_link": null,
    "abstract": "Creating agile and responsive characters from a collection of unorganized human motion has been an important problem of constructing interactive virtual environments. Recently, learning-based approaches have successfully been exploited to learn deep network policies for the control of interactive characters. The agility and responsiveness of deep network policies are influenced by many factors, such as the composition of training datasets, the architecture of network models, and learning algorithms that involve many threshold values, weights, and hyper-parameters. In this paper, we present a novel teacher-student framework to learn time-critically responsive policies, which guarantee the time-to-completion between user inputs and their associated responses regardless of the size and composition of the motion databases. We demonstrate the effectiveness of our approach with interactive characters that can respond to the user's control quickly while performing agile, highly dynamic movements.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_235",
    "authors": "Seyoung Lee, Sunmin Lee, Yongwoo Lee, Jehee Lee",
    "title": "Learning a Family of Motor Skills From a Single Motion Clip",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459774",
    "pdf_link": null,
    "abstract": "We present a new algorithm that learns a parameterized family of motor skills from a single motion clip. The motor skills are represented by a deep policy network, which produces a stream of motions in physics simulation in response to user input and environment interaction by navigating continuous action space. Three novel technical components play an important role in the success of our algorithm. First, it explicitly constructs motion parameterization that maps action parameters to their corresponding motions. Simultaneous learning of motion parameterization and motor skills significantly improves the performance and visual quality of learned motor skills. Second, continuous-time reinforcement learning is adopted to explore temporal variations as well as spatial variations in motion parameterization. Lastly, we present a new automatic curriculum generation method that explores continuous action space more efficiently. We demonstrate the flexibility and versatility of our algorithm with highly dynamic motor skills that can be parameterized by task goals, body proportions, physical measurements, and environmental conditions.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_357",
    "authors": "Yao Feng, Haiwen Feng, Michael J. Black, Timo Bolkart",
    "title": "Learning an Animatable Detailed 3D Face Model From In-the-wild Images",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459936",
    "pdf_link": null,
    "abstract": "While current monocular 3D face reconstruction methods can recover fine geometric details, they suffer several limitations. Some methods produce faces that cannot be realistically animated because they do not model how wrinkles vary with expression. Other methods are trained on high-quality face scans and do not generalize well to in-the-wild images. We present the first approach that regresses 3D face shape and animatable details that are specific to an individual but change with expression. Our model, DECA (Detailed Expression Capture and Animation), is trained to robustly produce a UV displacement map from a low-dimensional latent representation that consists of person-specific detail parameters and generic expression parameters, while a regressor is trained to predict detail, shape, albedo, expression, pose and illumination parameters from a single image. To enable this, we introduce a novel detail-consistency loss that disentangles person-specific details from expression-dependent wrinkles. This disentanglement allows us to synthesize realistic person-specific wrinkles by controlling expression parameters while keeping person-specific details unchanged. DECA is learned from in-the-wild images with no paired 3D supervision and achieves state-of-the-art shape reconstruction accuracy on two benchmarks. Qualitative results on in-the-wild data demonstrate DECA's robustness and its ability to disentangle identity- and expression-dependent details enabling animation of reconstructed faces. The model and code are publicly available at https://deca.is.tue.mpg.de.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_122",
    "authors": "Taichi Watanabe, Naoki Hashimoto",
    "title": "Light Field Projection for Tangible Projection Mapping",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469142",
    "pdf_link": null,
    "abstract": "In the present study, we propose a novel projection mapping using a 3D light-field image as a light source. In recent years, spatial augmented reality has evolved into dynamic projection mapping that extends the target to moving objects. However, spatial augmented reality causes multiplexing of projection and measurement equipment, which causes various problems, such as increased psychological pressure on users and a reduced production effect. Therefore, based on the concept of stealth projection, which hides the projection device using aerial imaging technology, we propose a dynamic projection mapping method using a 3D light-field image generated in real time according to the position and orientation of the target object. As a result, a simple light-field projector consisting of an LCD panel and a lenticular lens provides projection mapping for moving objects while visually hiding the projection devices.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_344",
    "authors": "Clara Callenberg, Zheng Shi, Felix Heide, Matthias B. Hullin",
    "title": "Low-cost SPAD Sensing for Non-line-of-sight Tracking, Material Classification, and Depth Imaging",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459824",
    "pdf_link": null,
    "abstract": "Time-correlated imaging is an emerging sensing modality that has been shown to enable promising application scenarios, including lidar ranging, fluorescence lifetime imaging, and even non-line-of-sight sensing. A leading technology for obtaining time-correlated light measurements are single-photon avalanche diodes (SPADs), which are extremely sensitive and capable of temporal resolution on the order of tens of picoseconds. However, the rare and expensive optical setups used by researchers have so far prohibited these novel sensing techniques from entering the mass market. Fortunately, SPADs also exist in a radically cheaper and more power-efficient version that has been widely deployed as proximity sensors in mobile devices for almost a decade. These commodity SPAD sensors can be obtained at a mere few cents per detector pixel. However, their inferior data quality and severe technical drawbacks compared to their high-end counterparts necessitate the use of additional optics and suitable processing algorithms. In this paper, we adopt an existing evaluation platform for commodity SPAD sensors, and modify it to unlock time-of-flight (ToF) histogramming and hence computational imaging. Based on this platform, we develop and demonstrate a family of hardware/software systems that, for the first time, implement applications that had so far been limited to significantly more advanced, higher-priced setups: direct ToF depth imaging, non-line-of-sight object tracking, and material classification.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_146",
    "authors": "Ziqi Wang, Peng Song, Mark Pauly",
    "title": "MOCCA: Modeling and Optimizing Cone-joints for Complex Assemblies",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459680",
    "pdf_link": null,
    "abstract": "We present a computational framework for modeling and optimizing complex assemblies using cone joints. Cone joints are integral joints that generalize traditional single-direction joints such as mortise and tenon joints to support a general cone of directions for assembly. This additional motion flexibility not just reduces the risk of deadlocking for complex joint arrangements, but also simplifies the assembly process, in particular for automatic assembly by robots. On the other hand, compared to planar contacts, cone joints restrict relative part movement for improved structural stability. Cone joints can be realized in the form of curved contacts between associated parts, which have demonstrated good mechanical properties such as reduced stress concentration. To find the best trade-off between assemblability and stability, we propose an optimization approach that first determines the optimal motion cone for each part contact and subsequently derives a geometric realization of each joint to match this motion cone. We demonstrate that our approach can optimize cone joints for assemblies with a variety of geometric forms, and highlight several application examples.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_362",
    "authors": "He Zhang, Yuting Ye, Takaaki Shiratori, Taku Komura",
    "title": "ManipNet: Neural Manipulation Synthesis With a Hand-object Spatial Representation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459830",
    "pdf_link": null,
    "abstract": "Natural hand manipulations exhibit complex finger maneuvers adaptive to object shapes and the tasks at hand. Learning dexterous manipulation from data in a brute force way would require a prohibitive amount of examples to effectively cover the combinatorial space of 3D shapes and activities. In this paper, we propose a hand-object spatial representation that can achieve generalization from limited data. Our representation combines the global object shape as voxel occupancies with local geometric details as samples of closest distances. This representation is used by a neural network to regress finger motions from input trajectories of wrists and objects. Specifically, we provide the network with the current finger pose, past and future trajectories, and the spatial representations extracted from these trajectories. The network then predicts a new finger pose for the next frame as an autoregressive model. With a carefully chosen hand-centric coordinate system, we can handle single-handed and two-handed motions in a unified framework. Learning from a small number of primitive shapes and kitchenware objects, the network is able to synthesize a variety of finger gaits for grasping, in-hand manipulation, and bimanual object handling on a rich set of novel shapes and functional tasks. We also demonstrate a live demo of manipulating virtual objects in real-time using a simple physical prop. Our system is useful for offline animation or real-time applications forgiving to a small delay.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_324",
    "authors": "Georg Sperl, Rahul Narain, Chris Wojtan",
    "title": "Mechanics-aware Deformation of Yarn Pattern Geometry",
    "paper_url": "https://pub.ista.ac.at/group_wojtan/projects/2021_Sperl_MADYPG/2021_MADYPG_paper_lowres.pdf",
    "pdf_link": null,
    "abstract": "… Naive texturing approaches do not consider yarn-level physics, while full yarn-level simulations may become prohibitively expensive for large garments. We propose a method to animate yarn-level cloth geometry on top of an underlying deforming mesh in a mechanics-aware fashion. Using triangle strains to interpolate precomputed yarn geometry, we are able to reproduce effects such as knit loops tightening under stretching. In combination with precomputed mesh animation or real-time mesh simulation, our method is able to animate …",
    "scholar_publication": "ACM Trans. Graph., 2021 - pub.ista.ac.at"
  },
  {
    "paper_id": "papers_166",
    "authors": "Lei Lan, Yin Yang, Danny Kaufman, Junfeng Yao, Minchen Li, Chenfanfu Jiang",
    "title": "Medial IPC: Accelerated Incremental Potential Contact With Medial Elastics",
    "paper_url": "https://par.nsf.gov/biblio/10290709",
    "pdf_link": null,
    "abstract": "Recently proposed as a stable means of evaluating geometric compactness, theisoperimetric profileof a planar domain measures the minimum perimeter needed to inscribe a shape with prescribed area varying from 0 to the area of the domain. While this profile has proven valuable for evaluating properties of geographic partitions, existing algorithms for its computation rely on aggressive approximations and are still computationally expensive. In this paper, we propose a practical means of approximating the isoperimetric profile and show that for domains satisfying a “thick neck” condition, our approximation is exact. For more general domains, we show that our bound is still exact within a conservative regime and is otherwise an upper bound. Our method is based on a traversal of the medial axis which produces efficient and robust results. We compare our technique with the state‐of‐the‐art approximation to the isoperimetric profile on a variety of domains and show significantly tighter bounds than were previously achievable.",
    "scholar_publication": "ACM Transactions on …, 2021 - par.nsf.gov"
  },
  {
    "paper_id": "paperstog_129",
    "authors": "Rahul Arora, Karan Singh",
    "title": "Mid-air Drawing of Curves on 3D Surfaces in Virtual Reality",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3459090",
    "pdf_link": null,
    "abstract": "Complex 3D curves can be created by directly drawing mid-air in immersive environments (Augmented and Virtual Realities). Drawing mid-air strokes precisely on the surface of a 3D virtual object, however, is difficult, necessitating a projection of the mid-air stroke onto the user “intended” surface curve. We present the first detailed investigation of the fundamental problem of 3D stroke projection in VR. An assessment of the design requirements of real-time drawing of curves on 3D objects in VR is followed by the definition and classification of multiple techniques for 3D stroke projection. We analyze the advantages and shortcomings of these approaches both theoretically and via practical pilot testing. We then formally evaluate the two most promising techniques spraycan and mimicry with 20 users in VR. The study shows a strong qualitative and quantitative user preference for our novel stroke mimicry projection algorithm. We further illustrate the effectiveness andutility of stroke mimicry to draw complex 3D curves on surfaces for various artistic and functional design applications.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_511",
    "authors": "Stephen Lombardi, Tomas Simon, Gabriel Schwartz, Michael Zollhoefer, Yaser Sheikh, Jason Saragih",
    "title": "Mixture of Volumetric Primitives for Efficient Neural Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459863",
    "pdf_link": null,
    "abstract": "Real-time rendering and animation of humans is a core function in games, movies, and telepresence applications. Existing methods have a number of drawbacks we aim to address with our work. Triangle meshes have difficulty modeling thin structures like hair, volumetric representations like Neural Volumes are too low-resolution given a reasonable memory budget, and high-resolution implicit representations like Neural Radiance Fields are too slow for use in real-time applications. We present Mixture of Volumetric Primitives …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_148",
    "authors": "Kang Chen, Yupan Wang, Song-Hai Zhang, Sen-Zhe Xu, Weidong Zhang, Shi-Min Hu",
    "title": "MoCap-Solver: A Neural Solver for Optical Motion Capture Data",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459681",
    "pdf_link": null,
    "abstract": "In a conventional optical motion capture (MoCap) workflow, two processes are needed to turn captured raw marker sequences into correct skeletal animation sequences. Firstly, various tracking errors present in the markers must be fixed (cleaning or refining). Secondly, an agent skeletal mesh must be prepared for the actor/actress, and used to determine skeleton information from the markers (re-targeting or solving). The whole process, normally referred to as solving MoCap data, is extremely time-consuming, labor-intensive, and usually the most costly part of animation production. Hence, there is a great demand for automated tools in industry. In this work, we present MoCap-Solver, a production-ready neural solver for optical MoCap data. It can directly produce skeleton sequences and clean marker sequences from raw MoCap markers, without any tedious manual operations. To achieve this goal, our key idea is to make use of neural encoders concerning three key intrinsic components: the template skeleton, marker configuration and motion, and to learn to predict these latent vectors from imperfect marker sequences containing noise and errors. By decoding these components from latent vectors, sequences of clean markers and skeletons can be directly recovered. Moreover, we also provide a novel normalization strategy based on learning a pose-dependent marker reliability function, which greatly improves system robustness. Experimental results demonstrate that our algorithm consistently outperforms the state-of-the-art on both synthetic and real-world datasets.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_408",
    "authors": "Zhong-Yuan Liu, Zhan Zhang, Di Zhang, Chunyang Ye, Ligang Liu, Xiao-Ming Fu",
    "title": "Modeling and Fabrication With Specified Discrete Equivalence Classes",
    "paper_url": "https://zhanzhangzz.com/publication/discrete-equivalences/discrete-equivalences-Supp.pdf",
    "pdf_link": null,
    "abstract": "Prop. 1. The shape of△ u0u1u2 is independent of the translation b, and so do 𝐶. Given any 𝑅, the best b minimizing∥ 𝜉 (𝑅)∥∞ is the vector from the origin o to the center c of 𝐶, and the minimum∥ 𝜉 (𝑅)∥∞ is the radius 𝑟𝑐 of 𝐶.",
    "scholar_publication": "ACM Trans. Graph., 2021 - zhanzhangzz.com"
  },
  {
    "paper_id": "paperstog_104",
    "authors": "Bohan Wang, George Matcuk, Jernej Barbic",
    "title": "Modeling of Personalized Anatomy Using Plastic Strains",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3443703",
    "pdf_link": null,
    "abstract": "We present a method for modeling solid objects undergoing large spatially varying and/or anisotropic strains, and use it to reconstruct human anatomy from medical images. Our novel shape deformation method uses plastic strains and the finite element method to successfully model shapes undergoing large and/or anisotropic strains, specified by sparse point constraints on the boundary of the object. We extensively compare our method to standard second-order shape deformation methods, variational methods, and surface-based methods, and demonstrate that our method avoids the spikiness, wiggliness, and other artifacts of previous methods. We demonstrate how to perform such shape deformation both for attached and un-attached (“free flying”) objects, using a novel method to solve linear systems with singular matrices with a known nullspace. Although our method is applicable to general large-strain shape deformation modeling, we use it to create personalized 3D triangle and volumetric meshes of human organs, based on magnetic resonance imaging or computed tomography scans. Given a medically accurate anatomy template of a generic individual, we optimize the geometry of the organ to match the magnetic resonance imaging or computed tomography scan of a specific individual. Our examples include human hand muscles, a liver, a hip bone, and a gluteus medius muscle (“hip abductor”).",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_309",
    "authors": "Tizian Zeltner, Sébastien Speierer, Iliyan Georgiev, Wenzel Jakob",
    "title": "Monte Carlo Estimators for Differential Light Transport",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459807",
    "pdf_link": null,
    "abstract": "Physically based differentiable rendering algorithms propagate derivatives through realistic light transport simulations and have applications in diverse areas including inverse reconstruction and machine learning. Recent progress has led to unbiased methods that can simultaneously compute derivatives with respect to millions of parameters. At the same time, elementary properties of these methods remain poorly understood. Current algorithms for differentiable rendering are constructed by mechanically differentiating a given primal algorithm. While convenient, such an approach is simplistic because it leaves no room for improvement. Differentiation produces major changes in the integrals that occur throughout the rendering process, which indicates that the primal and differential algorithms should be decoupled so that the latter can suitably adapt. This leads to a large space of possibilities: consider that even the most basic Monte Carlo path tracer already involves several design choices concerning the techniques for sampling materials and emitters, and their combination, e.g. via multiple importance sampling (MIS). Differentiation causes a veritable explosion of this decision tree: should we differentiate only the estimator, or also the sampling technique? Should MIS be applied before or after differentiation? Are specialized derivative sampling strategies of any use? How should visibility-related discontinuities be handled when millions of parameters are differentiated simultaneously? In this paper, we provide a taxonomy and analysis of different estimators for differential light transport to provide intuition about these and related questions.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_237",
    "authors": "Wei Sen Loi, Kenneth Chau",
    "title": "Multi-scale Computational Visualization of Angle-dependent and Roughness-sensitive Plasmonic Structural Coloration",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3450618.3469179",
    "pdf_link": null,
    "abstract": "Structural coloration can be achieved through plasmonic nanostructures tailored on size scales below the wavelength of light. The perceived colors of these structures are highly sensitive to surface geometry and are generally angle-and frequency-dependent [Song et al. 2019]. Fabricated plasmonic nanostructures exhibit roughness which can lead to deviations in its performance compared to those predicted from simulations [Rodríguez-Fernández et al. 2009]. Roughness occurring at nanometer size scales can perturb surface plasmon resonances and, in turn, affect both the far-and near-field electromagnetic field patterns associated with the plasmonic structure [Ge et al. 2018]. Despite considerable progress in coloration technology using plasmonic structures [Lee et al. 2018], there is limited understanding on the impacts of surface roughness on the resulting color produced from plasmonic structures. Physically based rendering (PBR) has enable computational visualization of the visual appearance of complex materials. PBR has been successfully applied to visualize iridescence of Morpho butterfly wings [Musbach et al. 2013], Elaphe snake skin [Dhillon et al. 2014], and soap bubbles [Huang et al. 2020]. State-of-the-art computational visualization cannot be readily applied to investigate structural color from plasmonic nanostructures, as their color is governed by electromagnetic interactions occurring on size scales (10s of nanometers) that cannot be captured by traditional PBR. Adaption",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_453",
    "authors": "Jiong Chen, Florian Schäfer, Jin Huang, Mathieu Desbrun",
    "title": "Multiscale Cholesky Preconditioning for Ill-conditioned Problems",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459851",
    "pdf_link": null,
    "abstract": "Many computer graphics applications boil down to solving sparse systems of linear equations. While the current arsenal of numerical solvers available in various specialized libraries and for different computer architectures often allow efficient and scalable solutions to image processing, modeling and simulation applications, an increasing number of graphics problems face large-scale and ill-conditioned sparse linear systems --- a numerical challenge which typically chokes both direct factorizations (due to high memory requirements) and iterative solvers (because of slow convergence). We propose a novel approach to the efficient preconditioning of such problems which often emerge from the discretization over unstructured meshes of partial differential equations with heterogeneous and anisotropic coefficients. Our numerical approach consists in simply performing a fine-to-coarse ordering and a multiscale sparsity pattern of the degrees of freedom, using which we apply an incomplete Cholesky factorization. By further leveraging supernodes for cache coherence, graph coloring to improve parallelism and partial diagonal shifting to remedy negative pivots, we obtain a preconditioner which, combined with a conjugate gradient solver, far exceeds the performance of existing carefully-engineered libraries for graphics problems involving bad mesh elements and/or high contrast of coefficients. We also back the core concepts behind our simple solver with theoretical foundations linking the recent method of operator-adapted wavelets used in numerical homogenization to the traditional Cholesky factorization of a matrix, providing us with a clear bridge between incomplete Cholesky factorization and multiscale analysis that we leverage numerically.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_287",
    "authors": "Alexandr Kuznetsov, Krishna Mullia, Zexiang Xu, Miloš Hašan, Ravi Ramamoorthi",
    "title": "NeuMIP: Multi-resolution Neural Materials",
    "paper_url": "https://par.nsf.gov/servlets/purl/10322825",
    "pdf_link": null,
    "abstract": "The world is full of materials with interesting small-scale structure: a green pasture consisting of millions of individual blades of grass, a scratched and partially rusted metallic paint on a car, a knitted sweater or a velvet dress. The underlying mesostructure and microstructure phenomena are wildly variable: complex surface height profiles, fibers and yarns, self-shadowing, multiple reflections and refractions, and subsurface scattering. Many of these effects vary at different levels of detail: for example, we can see individual fibers of a fabric when we zoom in, but they morph into yarns and eventually disappear when we zoom out.While computer graphics has made great strides in modeling these phenomena, this is usually at the cost of large computational expense and/or loss of generality. Many previous approaches were designed for a specific material at a particular level of detail, and evaluating those methods over a large patch becomes either slow or results in artifacts. In essence, when we zoom out, we integrate over a given patch. Theoretically, this can be achieved using Monte Carlo integration techniques by evaluating a large number of samples of the patch. However, the variance of such an estimator grows with the size of the patch, and the method quickly becomes impractical, requiring large effort to compute a function that typically becomes simpler under zoomed-out viewing conditions. Traditional mipmap techniques [Williams 1983] can erroneously average parameters such as normals that influence the final appearance non-linearly. A universal method for prefiltering a material (that is, finding the integral of the patch of material microstructure covered by a pixel) has remained a challenge, despite some methods that address this problem for specific kinds of specular surfaces [Dupuy et al. 2013; Jakob et al. 2014] and fabrics [Zhao et al. 2016]. Our goal is to develop a neural method to accurately represent a variety of complex materials at different scales, train such a method on synthetic and real data, and integrate it into a standard pathtracing system. Our neural architecture learns a continuous variant of a bidirectional texture function (BTF)[Dana et al. 1999], which we term multi-scale BTF (MBTF). This is a 7-dimensional function, with two dimensions each for the query location, incoming and outgoing direction, and one extra dimension for the filter kernel size. This framework can represent a complex material (with self-shadowing, inter-reflections, displacements, fibers or other structure) at very different scales and can smoothly transition between them. Inspired by the mipmapping technique, we propose NeuMIP, a method that uses a set of learned power-of-2 feature textures to represent the material at different levels, combined with a fixed per-material fully connected neural network. The network takes as input the trilinearly interpolated feature vector queried from the texture pyramid, along with incoming and outgoing directions, and outputs a reflectance value.",
    "scholar_publication": "ACM Transactions on Graphics (ToG), 2021 - par.nsf.gov"
  },
  {
    "paper_id": "papers_604",
    "authors": "Sebastian Starke, Yiwei Zhao, Fabio Zinno, Taku Komura",
    "title": "Neural Animation Layering for Synthesizing Martial Arts Movements",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459881",
    "pdf_link": null,
    "abstract": "Interactively synthesizing novel combinations and variations of character movements from different motion skills is a key problem in computer animation. In this paper, we propose a deep learning framework to produce a large variety of martial arts movements in a controllable manner from raw motion capture data. Our method imitates animation layering using neural networks with the aim to overcome typical challenges when mixing, blending and editing movements from unaligned motion sources. The framework can synthesize …",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_291",
    "authors": "Junqiu Zhu, Yaoyi Bai, Zilin Xu, Steve Bako, Edgar Velázquez-Armendáriz, Lu Wang, Pradeep Sen, Miloš Hašan, Ling-Qi Yan",
    "title": "Neural Complex Luminaires: Representation and Rendering",
    "paper_url": "https://slides.games-cn.org/pdf/Games2021208%E6%9C%B1%E5%90%9B%E7%A7%8B.pdf",
    "pdf_link": null,
    "abstract": "… Complex geometries Complex light transport … Blend the luminaire and background … A neural method which represent complex luminaires as “black boxes” …",
    "scholar_publication": "ACM Trans …, 2021 - slides.games-cn.org"
  },
  {
    "paper_id": "paperstog_110",
    "authors": "Xiuming Zhang, Sean Fanello, Yun-Ta Tsai, Tiancheng Sun, Tianfan Xue, Rohit Pandey, Sergio Orts-Escolano, Philip Davidson, Christoph Rhemann, Paul Debevec‎, Jonathan T. Barron, Ravi Ramamoorthi, William Freeman",
    "title": "Neural Light Transport for Relighting and View Synthesis",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3446328",
    "pdf_link": null,
    "abstract": "The light transport (LT) of a scene describes how it appears under different lighting conditions from different viewing directions, and complete knowledge of a scene’s LT enables the synthesis of novel views under arbitrary lighting. In this article, we focus on image-based LT acquisition, primarily for human bodies within a light stage setup. We propose a semi-parametric approach for learning a neural representation of the LT that is embedded in a texture atlas of known but possibly rough geometry. We model all non-diffuse and global LT as residuals added to a physically based diffuse base rendering. In particular, we show how to fuse previously seen observations of illuminants and views to synthesize a new image of the same scene under a desired lighting condition from a chosen viewpoint. This strategy allows the network to learn complex material effects (such as subsurface scattering) and global illumination (such as diffuse interreflection), while guaranteeing the physical correctness of the diffuse LT (such as hard shadows). With this learned LT, one can relight the scene photorealistically with a directional light or an HDRI map, synthesize novel views with view-dependent effects, or do both simultaneously, all in a unified framework using a set of sparse observations. Qualitative and quantitative experiments demonstrate that our Neural Light Transport (NLT) outperforms state-of-the-art solutions for relighting and view synthesis, without requiring separate treatments for both problems that prior work requires. The code and data are available at http://nlt.csail.mit.edu.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_345",
    "authors": "Soshi Shimada, Vladislav Golyanik, Weipeng Xu, Patrick Pérez, Christian Theobalt",
    "title": "Neural Monocular 3D Human Motion Capture With Physical Awareness",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459825",
    "pdf_link": null,
    "abstract": "We present a new trainable system for physically plausible markerless 3D human motion capture, which achieves state-of-the-art results in a broad range of challenging scenarios. Unlike most neural methods for human motion capture, our approach, which we dub\" physionical\", is aware of physical and environmental constraints. It combines in a fully-differentiable way several key innovations, ie, 1) a proportional-derivative controller, with gains predicted by a neural network, that reduces delays even in the presence of fast …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_443",
    "authors": "Jonathan Granskog, Till Schnabel, Fabrice Rousselle, Jan Novák",
    "title": "Neural Scene Graph Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459848",
    "pdf_link": null,
    "abstract": "… , and the transformation matrices, into a neural scene graph: the vectors are stored in leaf nodes, … to render the scene graph using a streaming neural renderer. The renderer processes …",
    "scholar_publication": "… Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_226",
    "authors": "Nicholas Moon, Megan Reddy, Luther Tychonievich",
    "title": "Non-photorealistic Ray Tracing With Paint and Toon Shading",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469173",
    "pdf_link": null,
    "abstract": "We present a modification to traditional ray tracing that stylistically renders a scene with cartoon and painterly styles. Previous methods rely on post-processing, materials, or textures to achieve a non-photorealistic look. Our method uses a ray tracer to combine cel animation art styles with complex lighting effects, such as reflections, refractions, and global illumination. The ray tracer collects information about objects and their properties to dynamically switch between cartoon and painterly rendering styles. The renderer generates the styles by shooting additional rays for each pixel and collecting information such as normals, distance, slope, object identifiers, and light gradients from neighboring areas of the image. The resulting algorithm produces images with visual and artistic characteristics that allow artists to take advantage of rendering techniques that are not commonly supported in production ray tracers.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_119",
    "authors": "Nakamura Toshikatsu, Ryusuke Miyazaki, Kouga Yoshida, Toshiki Sato",
    "title": "Omnidirectional display that presents information to the ambient environment with optical transparency",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3450618.3469139",
    "pdf_link": null,
    "abstract": "Projection mapping is an information presentation method (called omnidirectional display) in which images are projected on the entire surface (all sides) of a three-dimensional structure (screen). Using this method, users can browse the projected images on the threedimensional shape from various angles. Omnidirectional display has the advantage that multiple people can simultaneously browse the highly immersive images projected onto a real three-dimensional shape in front of them without the need for HMDs or similar …",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_307",
    "authors": "Yuval Alaluf, Or Patashnik, Daniel Cohen-Or",
    "title": "Only a Matter of Style: Age Transformation Using a Style-based Regression Model",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459805",
    "pdf_link": null,
    "abstract": "The task of age transformation illustrates the change of an individual's appearance over time. Accurately modeling this complex transformation over an input facial image is extremely challenging as it requires making convincing, possibly large changes to facial features and head shape, while still preserving the input identity. In this work, we present an image-to-image translation method that learns to directly encode real facial images into the latent space of a pre-trained unconditional GAN (e.g., StyleGAN) subject to a given aging shift. We employ a pre-trained age regression network to explicitly guide the encoder in generating the latent codes corresponding to the desired age. In this formulation, our method approaches the continuous aging process as a regression task between the input age and desired target age, providing fine-grained control over the generated image. Moreover, unlike approaches that operate solely in the latent space using a prior on the path controlling age, our method learns a more disentangled, non-linear path. Finally, we demonstrate that the end-to-end nature of our approach, coupled with the rich semantic latent space of StyleGAN, allows for further editing of the generated images. Qualitative and quantitative evaluations show the advantages of our method compared to state-of-the-art approaches. Code is available at our project page: https://yuval-alaluf.github.io/SAM.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_190",
    "authors": "Élie Michel",
    "title": "OpenMfx: An API for Cross-software Non-destructible Mesh Effects",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469168",
    "pdf_link": null,
    "abstract": "Non-destructive operations are widely used in mesh-based 3D modeling to add procedural effects on top a coarse geometry while allowing it to remain editable. Common such operations include surface subdivision, beveling, repetition, boolean operations. Combined together as a stack or even as a direct acyclic graph, they are a very powerful tool to build parametric assets. Although this mechanism is present in many different 3D modeling suites (Maya, Houdini, Blender, Cinema4D, 3ds Max, etc.), it is not easy to share a parametric asset across them. Indeed, they do not all implement the",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_126",
    "authors": "Rene Winchenbach, Andreas Kolb",
    "title": "Optimized Refinement for Spatially Adaptive SPH",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3363555",
    "pdf_link": null,
    "abstract": "In this article, we propose an improved refinement process for the simulation of incompressible low-viscosity turbulent flows using Smoothed Particle Hydrodynamics, under adaptive volume ratios of up to 1 : 1, 000, 000. We derive a discretized objective function, which allows us to generate ideal refinement patterns for any kernel function and any number of particles a priori without requiring intuitive initial user-input. We also demonstrate how this objective function can be optimized online to further improve the refinement process during simulations by utilizing a gradient descent and a modified evolutionary optimization. Our investigation reveals an inherent residual refinement error term, which we smooth out using improved and novel methods. Our improved adaptive method is able to simulate adaptive volume ratios of 1 : 1, 000, 000 and higher, even under highly turbulent flows, only being limited by memory consumption. In general, we achieve more than an order of magnitude greater adaptive volume ratios than prior work.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_593",
    "authors": "Abdalla G. M. Ahmed, Peter Wonka",
    "title": "Optimizing Dyadic Nets",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459880",
    "pdf_link": null,
    "abstract": "… that we use to produce nets with high-quality … nets that we use to show that the space of dyadic sequences is significantly smaller than that of nets, reducing the possibility of optimizing …",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_407",
    "authors": "Joonho Kim, Karan Singh",
    "title": "Optimizing UI Layouts for Deformable Face-rig Manipulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459842",
    "pdf_link": null,
    "abstract": "Complex deformable face-rigs have many independent parameters that control the shape of the object. A human face has upwards of 50 parameters (FACS Action Units), making conventional UI controls hard to find and operate. Animators address this problem by tediously hand-crafting in-situ layouts of UI controls that serve as visual deformation proxies, and facilitate rapid shape exploration. We propose the automatic creation of such in-situ UI control layouts. We distill the design choices made by animators into mathematical objectives that we optimize as the solution to an integer quadratic programming problem. Our evaluation is three-fold: we show the impact of our design principles on the resulting layouts; we show automated UI layouts for complex and diverse face rigs, comparable to animator handcrafted layouts; and we conduct a user study showing our UI layout to be an effective approach to face-rig manipulation, preferable to a baseline slider interface.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_385",
    "authors": "Gal Metzer, Rana Hanocka, Denis Zorin, Raja Giryes, Daniele Panozzo, Daniel Cohen-Or",
    "title": "Orienting Point Clouds With Dipole Propagation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459835",
    "pdf_link": null,
    "abstract": "Establishing a consistent normal orientation for point clouds is a notoriously difficult problem in geometry processing, requiring attention to both local and global shape characteristics. The normal direction of a point is a function of the local surface neighborhood; yet, point clouds do not disclose the full underlying surface structure. Even assuming known geodesic proximity, calculating a consistent normal orientation requires the global context. In this work, we introduce a novel approach for establishing a globally consistent normal orientation for point clouds. Our solution separates the local and global components into two different sub-problems. In the local phase, we train a neural network to learn a coherent normal direction per patch (i.e., consistently oriented normals within a single patch). In the global phase, we propagate the orientation across all coherent patches using a dipole propagation. Our dipole propagation decides to orient each patch using the electric field defined by all previously orientated patches. This gives rise to a global propagation that is stable, as well as being robust to nearby surfaces, holes, sharp features and noise.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_220",
    "authors": "Kacper Pluta, Michal Edelstein, Amir Vaxman, Mirela Ben Chen",
    "title": "PH-CPF: Planar Hexagonal Meshing Using Coordinate Power Fields",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459770",
    "pdf_link": null,
    "abstract": "We present a new approach for computing planar hexagonal meshes that approximate a given surface, represented as a triangle mesh. Our method is based on two novel technical contributions. First, we introduce Coordinate Power Fields, which are a pair of tangent vector fields on the surface that fulfill a certain continuity constraint. We prove that the fulfillment of this constraint guarantees the existence of a seamless parameterization with quantized rotational jumps, which we then use to regularly remesh the surface. We additionally …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_120",
    "authors": "Yupan Wang, Guiqing Li, Huiqian Zhang, Xinyi Zou, Yuxin Liu, Yongwei Nie",
    "title": "PanoMan: Sparse Localized Components Based Model for Full Human Motions",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3447244",
    "pdf_link": null,
    "abstract": "Parameterizing Variations of human shapes and motions is a long-standing problem in computer graphics and vision. Most of the existing methods only deal with a specific kind of motion, such as body poses, facial expressions, or hand gestures. We propose PanoMan (sParse locAlized compoNents based mOdel for full huMAn motioNs) to handle shape variation and full-motion across body, face, and hand in a unified framework. Like previous approaches, we factor shape variation into principal components to obtain a human shape space that approximates the shape of arbitrary identity. We then analyze sparse localized components in terms of relative edge length and dihedral angle to capture full motions of body poses, facial expressions, and hand gestures. The final piece of our model is a multilayer perceptron (MLP) that fits the residual between the ground truth and the aforementioned two-level approximation. As an application, we employ the discrete-shell deformation to drive the model to fit sparse constraints such as joint positions and surface feature points. We thoroughly evaluate PanoMan on body, face, and hand motion benchmarks as well as scanned data. The existing skinning-based techniques suffer from joint collapsing when encountering twisting motion of joints. Experiments show that PanoMan can capture all kinds of full human motions with high quality and is easier than the state-of-the-art models in recovering poses with wide joint twisting and complex hand gestures.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_137",
    "authors": "Richa Gadgil, Reesa John, Stefanie Zollmann, Jonathan Ventura",
    "title": "PanoSynthVR: View Synthesis From a Single Input Panorama With Multi-cylinder Images",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469144",
    "pdf_link": null,
    "abstract": "We introduce a method to automatically convert a single panoramic input into a multi-cylinder image representation that supports real-time, free-viewpoint view synthesis for virtual reality. We apply an existing convolutional neural network trained on pinhole images to a cylindrical panorama with wrap padding to ensure agreement between the left and right edges. The network outputs a stack of semi-transparent panoramas at varying depths which can be easily rendered and composited with over blending. Initial experiments show that the …",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_153",
    "authors": "Liane Makatura, Minghao Guo, Adriana Schulz, Justin Solomon, Wojciech Matusik",
    "title": "Pareto Gamuts: Exploring Optimal Designs Across Varying Contexts",
    "paper_url": "http://oastats.mit.edu/handle/1721.1/129366",
    "pdf_link": null,
    "abstract": "Manufactured parts are meticulously engineered to perform well with respect to several conflicting metrics, like weight, stress, and cost. The best achievable trade-offs reside on the Pareto front, which can be discovered via performance-driven optimization. Objective functions used to define the Pareto front often incorporate assumptions about the context in which a part will be used, including loading conditions, environmental influences, material properties, or regions that must be preserved to interface with a surrounding assembly. Existing multi-objective optimization tools are only equipped to study one context at a time, so engineers must run independent optimizations for each context of interest. However, engineered parts frequently appear in many contexts: wind turbines must perform well in many wind speeds, and a bracket might be optimized several times with its bolt-holes fixed in different locations on each run. In this paper, we formulate a framework for variable-context multi-objective optimization. We introduce the Pareto gamut, which captures Pareto fronts over a range of contexts. We develop a global-local optimization algorithm to discover the Pareto gamut directly, rather than discovering a single fixed-context \"slice\" at a time. To validate our method, we adapt existing multi-objective optimization benchmarks to contextual scenarios. We also demonstrate the practical utility of Pareto gamut exploration for several engineering design problems.",
    "scholar_publication": "2020 - oastats.mit.edu"
  },
  {
    "paper_id": "papers_305",
    "authors": "Delio Vicini, Sébastien Speierer, Wenzel Jakob",
    "title": "Path Replay Backpropagation: Differentiating Light Paths Using Constant Memory and Linear Time",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459804",
    "pdf_link": null,
    "abstract": "Differentiable physically-based rendering has become an indispensable tool for solving inverse problems involving light. Most applications in this area jointly optimize a large set of scene parameters to minimize an objective function, in which case reverse-mode differentiation is the method of choice for obtaining parameter gradients. However, existing techniques that perform the necessary differentiation step suffer from either statistical bias or a prohibitive cost in terms of memory and computation time. For example, standard techniques for automatic differentiation based on program transformation or Wengert tapes lead to impracticably large memory usage when applied to physically-based rendering algorithms. A recently proposed adjoint method by Nimier-David et al. [2020] reduces this to a constant memory footprint, but the computation time for unbiased gradient estimates then becomes quadratic in the number of scattering events along a light path. This is problematic when the scene contains highly scattering materials like participating media. In this paper, we propose a new unbiased backpropagation algorithm for rendering that only requires constant memory, and whose computation time is linear in the number of scattering events (i.e., just like path tracing). Our approach builds on the invertibility of the local Jacobian at scattering interactions to recover the various quantities needed for reverse-mode differentiation. Our method also extends to specular materials such as smooth dielectrics and conductors that cannot be handled by prior work.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_250",
    "authors": "Cheng Zhang, Zihan Yu, Shuang Zhao",
    "title": "Path-space Differentiable Rendering of Participating Media",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459782",
    "pdf_link": null,
    "abstract": "Physics-based differentiable rendering---which focuses on estimating derivatives of radiometric detector responses with respect to arbitrary scene parameters---has a diverse array of applications from solving analysis-by-synthesis problems to training machine-learning pipelines incorporating forward-rendering processes. Unfortunately, existing general-purpose differentiable rendering techniques lack either the generality to handle volumetric light transport or the flexibility to devise Monte Carlo estimators capable of handling complex geometries and light transport effects. In this paper, we bridge this gap by showing how generalized path integrals can be differentiated with respect to arbitrary scene parameters. Specifically, we establish the mathematical formulation of generalized differential path integrals that capture both interfacial and volumetric light transport. Our formulation allows the development of advanced differentiable rendering algorithms capable of efficiently handling challenging geometric discontinuities and light transport phenomena such as volumetric caustics. We validate our method by comparing our derivative estimates to those generated using the finite differences. Further, to demonstrate the effectiveness of our technique, we compare both differentiable rendering and inverse rendering performance with state-of-the-art methods.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_207",
    "authors": "Mallikarjun B R, Ayush Tewari, Abdallah Dib, Tim Weyrich, Bernd Bickel, Hans-Peter Seidel, Hanspeter Pfister, Wojciech Matusik, Louis Chevalier, Mohamed Elgharib, Christian Theobalt",
    "title": "PhotoApp: Photorealistic Appearance Editing of Head Portraits",
    "paper_url": "https://discovery.ucl.ac.uk/id/eprint/10143517/",
    "pdf_link": null,
    "abstract": "… Photorealistic editing of head portraits is a challenging task as humans are … editing of the camera viewpoint and scene illumination (parameterised with an environment map) in a portrait …",
    "scholar_publication": "ACM Transactions …, 2021 - discovery.ucl.ac.uk"
  },
  {
    "paper_id": "papers_134",
    "authors": "Victor Romero, Mickaël Ly, Abdullah Haroon Rasheed, Raphaël Charrondière, Arnaud Lazarus, Sébastien Neukirch, Florence Bertails-Descoubes",
    "title": "Physical Validation of Simulators in Computer Graphics: A New Framework Dedicated to Slender Elastic Structures and Frictional Contact",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459931",
    "pdf_link": null,
    "abstract": "We introduce a selected set of protocols inspired from the Soft Matter Physics community in order to validate Computer Graphics simulators of slender elastic structures possibly subject to dry frictional contact. Although these simulators were primarily intended for feature film animation and visual effects, they are more and more used as virtual design tools for predicting the shape and deformation of real objects; hence the need for a careful, quantitative validation. Our tests, experimentally verified, are designed to evaluate carefully the predictability of these simulators on various aspects, such as bending elasticity, bend-twist coupling, and frictional contact. We have passed a number of popular codes of Computer Graphics through our benchmarks by defining a rigorous, consistent, and as fair as possible methodology. Our results show that while some popular simulators for plates/shells and frictional contact fail even on the simplest scenarios, more recent ones, as well as well-known codes for rods, generally perform well and sometimes even better than some reference commercial tools of Mechanical Engineering. To make our validation protocols easily applicable to any simulator, we provide an extensive description of our methodology, and we shall distribute all the necessary model data to be compared against.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_227",
    "authors": "Aubrey Simonson",
    "title": "Pockets: User-assigned Menus Based on Physical Buttons for Virtual Environments",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469174",
    "pdf_link": null,
    "abstract": "We present Pockets, a simple means of organizing and carrying 3D tools and other objects in virtual environments. Previous examples exist of using 3D tools with visually obvious affordances in virtual immersive environments instead of more traditional menus, however, in these applications a 2D menu is still necessary to select 3D tools from. Pockets make use of a belt with physical buttons, that objects can be assigned to. The Pockets design not only enables users to use their muscle memory to store and retrieve objects, thereby making tool use more efficient, but also solves the occlusion problem associated with state of the art approaches such as 2D menus tied to the body or to world space.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_108",
    "authors": "Miguel Crespo, Adrian Jarabo, Adolfo Muñoz",
    "title": "Primary-space Adaptive Control Variates Using Piecewise-polynomial Approximations",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450627",
    "pdf_link": null,
    "abstract": "We present an unbiased numerical integration algorithm that handles both low-frequency regions and high-frequency details of multidimensional integrals. It combines quadrature and Monte Carlo integration by using a quadrature-based approximation as a control variate of the signal. We adaptively build the control variate constructed as a piecewise polynomial, which can be analytically integrated, and accurately reconstructs the low-frequency regions of the integrand. We then recover the high-frequency details missed by the control variate by using Monte Carlo integration of the residual. Our work leverages importance sampling techniques by working in primary space, allowing the combination of multiple mappings; this enables multiple importance sampling in quadrature-based integration. Our algorithm is generic and can be applied to any complex multidimensional integral. We demonstrate its effectiveness with four applications with low dimensionality: transmittance estimation in heterogeneous participating media, low-order scattering in homogeneous media, direct illumination computation, and rendering of distribution effects. Finally, we show how our technique is extensible to integrands of higher dimensionality by computing the control variate on Monte Carlo estimates of the high-dimensional signal, and accounting for such additional dimensionality on the residual as well. In all cases, we show accurate results and faster convergence compared to previous approaches.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_121",
    "authors": "Alain Lioret, Sofiane Ben Embareck, Julien Boutet, Félix Cantet",
    "title": "Procedural Real-Time Live Drawing Animation",
    "paper_url": "https://arxiv.org/abs/2105.09153",
    "pdf_link": null,
    "abstract": "… 6,000 to 15,000 ANSI lumens are used to render real-time animations in 8K quality [5]. The … a real-time render dissipates the flower [video 1]. Such animations use generated animation …",
    "scholar_publication": "arXiv preprint arXiv:2105.09153, 2021 - arxiv.org"
  },
  {
    "paper_id": "pos_169",
    "authors": "Jessica Baron, Daljit Singh Dhillon, Eric Patterson",
    "title": "Procedural Shading for Rendering the Appearance of Feathers",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469161",
    "pdf_link": null,
    "abstract": "The appearance of a real-world feather is the result of light interactions with complex, patterned structures of varying scale; however, these have not yet been modeled for accurate rendering of feathers in computer graphics. Previously published works have presented simplified curve models for feather appearance. Using imaging from real feathers, we suggest why these approaches are not sufficient and provide motivation for building an appearance model specific to feathers. In that vein we demonstrate a new technique that takes into account the substructures of feathers during shading calculations to produce a more accurate far-field appearance.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_163",
    "authors": "Jana Hoffard, Takuto Nakamura, Erwin Wu, Hideki Koike",
    "title": "PushToSki — An Indoor Ski Training System Using Haptic Feedback",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469158",
    "pdf_link": null,
    "abstract": "Haptic feedback is an intuitive way of improving required postures in sports without having the trainee change their head-pose towards visual cues and therefore possibly worsening their overall body-pose. However, this feedback is not possible in a dynamic sport like alpine skiing which is why we propose a virtual reality ski training system that uses vibration as a haptic feedback method. Our system uses a commercially available indoor ski simulator and several trackers to capture the user’s motion together with a set of vibration motors which will provide direct, haptic feedback to the user. Our system therefore allows giving haptic feedback even while the trainee is moving on the simulator.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_108",
    "authors": "Yuanming Hu, Jiafeng Liu, Xuanda Yang, Mingkuan Xu, Ye Kuang, Weiwei Xu, Qiang Dai, William T. Freeman, Fredo Durand",
    "title": "QuanTaichi: A Compiler for Quantized Simulations",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459671",
    "pdf_link": null,
    "abstract": "High-resolution simulations can deliver great visual quality, but they are often limited by available memory, especially on GPUs. We present a compiler for physical simulation that can achieve both high performance and significantly reduced memory costs, by enabling flexible and aggressive quantization. Low-precision (\"quantized\") numerical data types are used and packed to represent simulation states, leading to reduced memory space and bandwidth consumption. Quantized simulation allows higher resolution simulation with less memory, which is especially attractive on GPUs. Implementing a quantized simulator that has high performance and packs the data tightly for aggressive storage reduction would be extremely labor-intensive and error-prone using a traditional programming language. To make the creation of quantized simulation practical, we have developed a new set of language abstractions and a compilation system. A suite of tailored domain-specific optimizations ensure quantized simulators often run as fast as the full-precision simulators, despite the overhead of encoding-decoding the packed quantized data types. Our programming language and compiler, based on Taichi, allow developers to effortlessly switch between different full-precision and quantized simulators, to explore the full design space of quantization schemes, and ultimately to achieve a good balance between space and precision. The creation of quantized simulation with our system has large benefits in terms of memory consumption and performance, on a variety of hardware, from mobile devices to workstations with high-end GPUs. We can simulate with levels of resolution that were previously only achievable on systems with much more memory, such as multiple GPUs. For example, on a single GPU, we can simulate a Game of Life with 20 billion cells (8× compression per pixel), an Eulerian fluid system with 421 million active voxels (1.6× compression per voxel), and a hybrid Eulerian-Lagrangian elastic object simulation with 235 million particles (1.7× compression per particle). At the same time, quantized simulations create physically plausible results. Our quantization techniques are complementary to existing acceleration approaches of physical simulation: they can be used in combination with these existing approaches, such as sparse data structures, for even higher scalability and performance.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_157",
    "authors": "Félix Olart, Eloïse Tassin, Laurine Capdeville, Luc Pinguet, Théo Gautier, Alain Lioret",
    "title": "Quantum Nodes: Quantum Computing Applied to 3D Modeling",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469155",
    "pdf_link": null,
    "abstract": "Quantum Nodes is a Blender add-on that introduces the integration of quantum algorithms into the 3D creation process. Our work focuses on allowing users to experiment both new forms of creation and approaching the concepts of quantum computing through 3D creation.",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_126",
    "authors": "Jiazhao Zhang, Chenyang Zhu, Lintao Zheng, Kai Xu",
    "title": "ROSEFusion: Random Optimization for Online Dense Reconstruction Under Fast Camera Motion",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459676",
    "pdf_link": null,
    "abstract": "Online reconstruction based on RGB-D sequences has thus far been restrained to relatively slow camera motions (<1m/s). Under very fast camera motion (e.g., 3m/s), the reconstruction can easily crumble even for the state-of-the-art methods. Fast motion brings two challenges to depth fusion: 1) the high nonlinearity of camera pose optimization due to large inter-frame rotations and 2) the lack of reliably trackable features due to motion blur. We propose to tackle the difficulties of fast-motion camera tracking in the absence of inertial measurements using random optimization, in particular, the Particle Filter Optimization (PFO). To surmount the computation-intensive particle sampling and update in standard PFO, we propose to accelerate the randomized search via updating a particle swarm template (PST). PST is a set of particles pre-sampled uniformly within the unit sphere in the 6D space of camera pose. Through moving and rescaling the pre-sampled PST guided by swarm intelligence, our method is able to drive tens of thousands of particles to locate and cover a good local optimum extremely fast and robustly. The particles, representing candidate poses, are evaluated with a fitness function defined based on depth-model conformance. Therefore, our method, being depth-only and correspondence-free, mitigates the motion blur impediment as (ToF-based) depths are often resilient to motion blur. Thanks to the efficient template-based particle set evolution and the effective fitness function, our method attains good quality pose tracking under fast camera motion (up to 4m/s) in a realtime framerate without including loop closure or global pose optimization. Through extensive evaluations on public datasets of RGB-D sequences, especially on a newly proposed benchmark of fast camera motion, we demonstrate the significant advantage of our method over the state of the arts.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_150",
    "authors": "Ahmed Mahmoud, Serban D. Porumbescu, John D. Owens",
    "title": "RXMesh: A GPU Mesh Data Structure",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459748",
    "pdf_link": null,
    "abstract": "… the high performance of the GPU. We present RXMesh, a GPU triangle mesh data structure that captures locality by partitioning the input mesh into small patches that fit in the GPU’s …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_308",
    "authors": "Chen Cao, Vasu Agrawal, Fernando De la Torre, Lele Chen, Jason Saragih, Tomas Simon, Yaser Sheikh",
    "title": "Real-time 3D Neural Facial Animation From Binocular Video",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459806",
    "pdf_link": null,
    "abstract": "We present a method for performing real-time facial animation of a 3D avatar from binocular video. Existing facial animation methods fail to automatically capture precise and subtle facial motions for driving a photo-realistic 3D avatar \"in-the-wild\" (i.e., variability in illumination, camera noise). The novelty of our approach lies in a light-weight process for specializing a personalized face model to new environments that enables extremely accurate real-time face tracking anywhere. Our method uses a pre-trained high-fidelity personalized model of the face that we complement with a novel illumination model to account for variations due to lighting and other factors often encountered in-the-wild (e.g., facial hair growth, makeup, skin blemishes). Our approach comprises two steps. First, we solve for our illumination model's parameters by applying analysis-by-synthesis on a short video recording. Using the pairs of model parameters (rigid, non-rigid) and the original images, we learn a regression for real-time inference from the image space to the 3D shape and texture of the avatar. Second, given a new video, we fine-tune the real-time regression model with a few-shot learning strategy to adapt the regression model to the new environment. We demonstrate our system's ability to precisely capture subtle facial motions in unconstrained scenarios, in comparison to competing methods, on a diverse collection of identities, expressions, and real-world environments.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_152",
    "authors": "Marc Habermann, Lingjie Liu, Weipeng Xu, Michael Zollhoefer, Gerard Pons-Moll, Christian Theobalt",
    "title": "Real-time Deep Dynamic Characters",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459749",
    "pdf_link": null,
    "abstract": "… deep videorealistic 3D human character model displaying highly realistic shape, motion, and dynamic … In contrast to previous work, our controllable 3D character displays dynamics, eg, …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_127",
    "authors": "Abhimitra Meka, Mohammad Shafiei, Michael Zollhöfer, Christian Richardt, Christian Theobalt",
    "title": "Real-time Global Illumination Decomposition of Videos",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3374753",
    "pdf_link": null,
    "abstract": "We propose the first approach for the decomposition of a monocular color video into direct and indirect illumination components in real time. We retrieve, in separate layers, the contribution made to the scene appearance by the scene reflectance, the light sources, and the reflections from various coherent scene regions to one another. Existing techniques that invert global light transport require image capture under multiplexed controlled lighting or only enable the decomposition of a single image at slow off-line frame rates. In contrast, our approach works for regular videos and produces temporally coherent decomposition layers at real-time frame rates. At the core of our approach are several sparsity priors that enable the estimation of the per-pixel direct and indirect illumination layers based on a small set of jointly estimated base reflectance colors. The resulting variational decomposition problem uses a new formulation based on sparse and dense sets of non-linear equations that we solve efficiently using a novel alternating data-parallel optimization strategy. We evaluate our approach qualitatively and quantitatively and show improvements over the state-of-the-art in this field, in both quality and runtime. In addition, we demonstrate various real-time appearance editing applications for videos with consistent illumination.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_285",
    "authors": "Wentao Liao, Renjie Chen, Yuchen Hua, Ligang Liu, Ofir Weber",
    "title": "Real-time Locally Injective Volumetric Deformation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459794",
    "pdf_link": null,
    "abstract": "We present a highly efficient method for interactive volumetric meshless shape deformation. Our method operates within a low dimensional sub-space of shape-aware C∞ harmonic maps, and is the first method that is guaranteed to produce a smooth locally injective deformation in 3D. Unlike mesh-based methods in which local injectivity is enforced on tetrahedral elements, our method enforces injectivity on a sparse set of domain samples. The main difficulty is then to certify the map as locally injective throughout the entire domain. This is done by utilizing the Lipschitz continuity property of the harmonic basis functions. We show a surprising relation between the Lipschitz constant of the smallest singular value of the map Jacobian and the norm of the Hessian. We further carefully derive a Lipschitz constant for the Hessian, and develop a sufficient condition for the injectivity certification. This is done by utilizing the special structure of the harmonic basis functions combined with a novel regularization term that pushes the Lipschitz constants further down. As a result, the injectivity analysis can be performed on a relatively sparse set of samples. Combined with a parallel GPU-based implementation, our method can produce superior deformations with unique quality guarantees at real-time rates which were possible only in 2D so far.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_317",
    "authors": "Thomas Müller, Fabrice Rousselle, Jan Novák, Alex Keller",
    "title": "Real-time Neural Radiance Caching for Path Tracing",
    "paper_url": "https://arxiv.org/abs/2106.12372",
    "pdf_link": null,
    "abstract": "We present a real-time neural radiance caching method for path-traced global illumination. Our system is designed to handle fully dynamic scenes, and makes no assumptions about the lighting, geometry, and materials. The data-driven nature of our approach sidesteps many difficulties of caching algorithms, such as locating, interpolating, and updating cache points. Since pretraining neural networks to handle novel, dynamic scenes is a formidable generalization challenge, we do away with pretraining and instead achieve generalization via adaptation, i.e. we opt for training the radiance cache while rendering. We employ self-training to provide low-noise training targets and simulate infinite-bounce transport by merely iterating few-bounce training updates. The updates and cache queries incur a mild overhead -- about 2.6ms on full HD resolution -- thanks to a streaming implementation of the neural network that fully exploits modern hardware. We demonstrate significant noise reduction at the cost of little induced bias, and report state-of-the-art, real-time performance on a number of challenging scenarios.",
    "scholar_publication": "arXiv preprint arXiv:2106.12372, 2021 - arxiv.org"
  },
  {
    "paper_id": "pos_220",
    "authors": "Luna Takagi, Toshiki Sato, Shio Miyafuji, Hideki Koike",
    "title": "Real-time Projection of Lip Animation Onto Face Masks Using OmniProcam",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469171",
    "pdf_link": null,
    "abstract": "This paper describes an OmniProcam system, which enables 360 degree horizontal projection by a fisheye lens with a coaxial procam in which the optical axes of the camera and projector are exactly matched. Combined with 2D marker recognition, the OmniProcam can display images onto screens at arbitrary positions in 3D space. As an example application, we developed a system which projects lip animation onto the user’s face masks for better communication at the physical meeting in current COVID-19 situation. The system recognizes the user’s speech, generates the lip animation using Lipsync, and projects the animation onto the user’s face masks.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_103",
    "authors": "Masaki Takahashi, Makiko Azuma, Takuya Handa, Taichi Ishiwatari, Masanori Sano, Yuko Yamanouchi",
    "title": "Real-time Sports Video Analysis for Video Content Viewing With Haptic Information",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3450618.3469135",
    "pdf_link": null,
    "abstract": "Video content mainly conveys visual and audio information, but it would be more immersive by adding haptic information. The sense of presence when watching video could be enhanced through tactile stimuli from haptic devices, enabling video content to provide immersive experiences. We developed a haptic perception system that can be used at public sports viewing events. The live sports broadcast video is displayed on a large screen in front of audiences, and haptic stimuli that are synchronized with the video are supplied to …",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_119",
    "authors": "Hyeongseok Son, Junyong Lee, Jonghyeop Lee, Sunghyun Cho, Seungyong Lee",
    "title": "Recurrent Video Deblurring With Blur-invariant Motion Estimation and Pixel Volumes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3453720",
    "pdf_link": null,
    "abstract": "For the success of video deblurring, it is essential to utilize information from neighboring frames. Most state-of-the-art video deblurring methods adopt motion compensation between video frames to aggregate information from multiple frames that can help deblur a target frame. However, the motion compensation methods adopted by previous deblurring methods are not blur-invariant, and consequently, their accuracy is limited for blurry frames with different blur amounts. To alleviate this problem, we propose two novel approaches to …",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_139",
    "authors": "George Ash, Juraj Tomori, Mike Pelton, Charles Dupont",
    "title": "Reflectance Estimation for Free-viewpoint Video",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469146",
    "pdf_link": null,
    "abstract": "We present a method to infer physically-based material properties for free-viewpoint video. Given a multi-camera image feed and reconstructed geometry, our method infers material properties, such as albedo, surface normal, metallic and roughness maps. We use a physically based, differentiable renderer to generate candidate images which are compared against the image feed. Our method searches for material textures which minimise an image-space loss metric between candidate renders and the ground truth image feed. Our method produces results that approximate state of the art reflectance capture, and produces texture maps that are compatible with common real-time and offline shading models.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_491",
    "authors": "Nico Pietroni, Stefano Nuvoli, Thomas Alderighi, Paolo Cignoni, Marco Tarini",
    "title": "Reliable Feature-line Driven Quad-remeshing",
    "paper_url": "https://air.unimi.it/handle/2434/869863",
    "pdf_link": null,
    "abstract": "We present a new algorithm for the semi-regular quadrangulation of an input surface, driven by its line features, such as sharp creases. We define a perfectly feature-aligned cross-field and a coarse layout of polygonal-shaped patches where we strictly ensure that all the feature-lines are represented as patch boundaries. To be able to consistently do so, we allow non-quadrilateral patches and T-junctions in the layout; the key is the ability to constrain the layout so that it still admits a globally consistent, T-junction-free, and pure-quad internal tessellation of its patches. This requires the insertion of additional irregular-vertices inside patches, but the regularity of the final-mesh is safeguarded by optimizing for both their number and for their reciprocal alignment. In total, our method guarantees the reproduction of feature-lines by construction, while still producing good quality, isometric, pure-quad, conforming meshes, making it an ideal candidate for CAD models. Moreover, the method is fully automatic, requiring no user intervention, and remarkably reliable, requiring little assumptions on the input mesh, as we demonstrate by batch processing the entire Thingi10K repository, with less than 0.5% of the attempted cases failing to produce a usable mesh.",
    "scholar_publication": "ACM Transactions on …, 2021 - air.unimi.it"
  },
  {
    "paper_id": "papers_138",
    "authors": "Yun (Raymond) Fei, Qi Guo, Rundong Wu, Li Huang, Ming Gao",
    "title": "Revisiting Integration in the Material Point Method: A Scheme for Easier Separation and Less Dissipation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459678",
    "pdf_link": null,
    "abstract": "The material point method (MPM) recently demonstrated its efficacy at simulating many materials and the coupling between them on a massive scale. However, in scenarios containing debris, MPM manifests more dissipation and numerical viscosity than traditional Lagrangian methods. We have two observations from carefully revisiting existing integration methods used in MPM. First, nearby particles would end up with smoothed velocities without recovering momentum for each particle during the particle-grid-particle transfers. Second, most existing integrators assume continuity in the entire domain and advect particles by directly interpolating the positions from deformed nodal positions, which would trap the particles and make them harder to separate. We propose an integration scheme that corrects particle positions at each time step. We demonstrate our method's effectiveness with several large-scale simulations involving brittle materials. Our approach effectively reduces diffusion and unphysical viscosity compared to traditional integrators.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_169",
    "authors": "Kai Jia",
    "title": "SANM: A Symbolic Asymptotic Numerical Solver With Applications in Mesh Deformation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459755",
    "pdf_link": null,
    "abstract": "Solving nonlinear systems is an important problem. Numerical continuation methods efficiently solve certain nonlinear systems. The Asymptotic Numerical Method (ANM) is a powerful continuation method that usually converges faster than Newtonian methods. ANM explores the landscape of the function by following a parameterized solution curve approximated with a high-order power series. Although ANM has successfully solved a few graphics and engineering problems, prior to our work, applying ANM to new problems required significant effort because the standard ANM assumes quadratic functions, while manually deriving the power series expansion for nonquadratic systems is a tedious and challenging task. This paper presents a novel solver, SANM, that applies ANM to solve symbolically represented nonlinear systems. SANM solves such systems in a fully automated manner. SANM also extends ANM to support many nonquadratic operators, including intricate ones such as singular value decomposition. Furthermore, SANM generalizes ANM to support the implicit homotopy form. Moreover, SANM achieves high computing performance via optimized system design and implementation. We deploy SANM to solve forward and inverse elastic force equilibrium problems and controlled mesh deformation problems with a few constitutive models. Our results show that SANM converges faster than Newtonian solvers, requires little programming effort for new problems, and delivers comparable or better performance than a hand-coded, specialized ANM solver. While we demonstrate on mesh deformation problems, SANM is generic and potentially applicable to many tasks.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_124",
    "authors": "Yu Ju Chen, Seung Heon Sheen, Uri Ascher, Dinesh K. Pai",
    "title": "SIERE: A Hybrid Semi-implicit Exponential Integrator for Efficiently Simulating Stiff Deformable Objects",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/2019406.2019440",
    "pdf_link": null,
    "abstract": "… For each element in the mesh, we build the local stiffness … nodes which cannot be simulated stably, because they are … characteristics of the explicit semi-implicit Euler method and the …",
    "scholar_publication": "Proceedings of the 2011 ACM …, 2011 - dl.acm.org"
  },
  {
    "paper_id": "papers_208",
    "authors": "Ruihui Li, Xianzhi Li, Ka-Hei Hui, Chi-Wing Fu",
    "title": "SP-GAN: Sphere-guided 3D Shape Generation and Manipulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459766",
    "pdf_link": null,
    "abstract": "We present SP-GAN, a new unsupervised sphere-guided generative model for direct synthesis of 3D shapes in the form of point clouds. Compared with existing models, SP-GAN is able to synthesize diverse and high-quality shapes with fine details and promote controllability for part-aware shape generation and manipulation, yet trainable without any parts annotations. In SP-GAN, we incorporate a global prior (uniform points on a sphere) to spatially guide the generative process and attach a local prior (a random latent code) to each sphere point to provide local details. The key insight in our design is to disentangle the complex 3D shape generation task into a global shape modeling and a local structure adjustment, to ease the learning process and enhance the shape generation quality. Also, our model forms an implicit dense correspondence between the sphere points and points in every generated shape, enabling various forms of structure-aware shape manipulations such as part editing, part-wise shape interpolation, and multi-shape part composition, etc., beyond the existing generative models. Experimental results, which include both visual and quantitative evaluations, demonstrate that our model is able to synthesize diverse point clouds with fine details and less noise, as compared with the state-of-the-art models.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_393",
    "authors": "Rinon Gal, Dana Cohen Hochberg, Amit Bermano, Daniel Cohen-Or",
    "title": "SWAGAN: A Style-based Wavelet-driven Generative Model",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459836",
    "pdf_link": null,
    "abstract": "In recent years, considerable progress has been made in the visual quality of Generative Adversarial Networks (GANs). Even so, these networks still suffer from degradation in quality for high-frequency content, stemming from a spectrally biased architecture, and similarly unfavorable loss functions. To address this issue, we present a novel general-purpose Style and WAvelet based GAN (SWAGAN) that implements progressive generation in the frequency domain. SWAGAN incorporates wavelets throughout its generator and discriminator architectures, enforcing a frequency-aware latent representation at every step of the way. This approach, designed to directly tackle the spectral bias of neural networks, yields an improvement in the ability to generate medium and high frequency content, including structures which other networks fail to learn. We demonstrate the advantage of our method by integrating it into the SyleGAN2 framework, and verifying that content generation in the wavelet domain leads to more realistic high-frequency content, even when trained for fewer iterations. Furthermore, we verify that our model's latent space retains the qualities that allow StyleGAN to serve as a basis for a multitude of editing tasks, and show that our frequency-aware approach also induces improved high-frequency performance in downstream tasks.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_445",
    "authors": "Jiamin Xu, Xiuchao Wu, Zihan Zhu, Weiwei Xu, Yin Yang, Hujun Bao, Qixing Huang",
    "title": "Scalable Image-based Indoor Scene Rendering With Reflections",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459849",
    "pdf_link": null,
    "abstract": "This paper proposes a novel scalable image-based rendering (IBR) pipeline for indoor scenes with reflections. We make substantial progress towards three sub-problems in IBR, namely, depth and reflection reconstruction, view selection for temporally coherent view-warping, and smooth rendering refinements. First, we introduce a global-mesh-guided alternating optimization algorithm that robustly extracts a two-layer geometric representation. The front and back layers encode the RGB-D reconstruction and the reflection reconstruction, respectively. This representation minimizes the image composition error under novel views, enabling accurate renderings of reflections. Second, we introduce a novel approach to select adjacent views and compute blending weights for smooth and temporal coherent renderings. The third contribution is a supersampling network with a motion vector rectification module that refines the rendering results to improve the final output's temporal coherence. These three contributions together lead to a novel system that produces highly realistic rendering results with various reflections. The rendering quality outperforms state-of-the-art IBR or neural rendering algorithms considerably.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_149",
    "authors": "Avirup Mandal, Parag Chaudhuri, Subhasis Chaudhuri",
    "title": "Scalable Visual Simulation of Ductile and Brittle Fracture",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469152",
    "pdf_link": null,
    "abstract": "Fracture of solid objects produces debris. Modelling the physics that produces the broken fragments from the original solid requires an increase in the number of degrees of freedom. This causes a huge increase in computational cost for FEM based methods used to model such phenomena. We present a graph-based FEM method that tackles this issue by relabeling the edges of the graph induced in a volumetric mesh, using a damage variable. We reformulate the system dynamics for this relabelled graph in order to simulate the fracture mechanics using FEM without an explosion in the computation cost. Our method therefore requires no remeshing of the volumetric mesh used for computation and this makes it very scalable to high-resolution meshes. We demonstrate that the method can simulate both brittle and ductile fracture.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_108",
    "authors": "Lvmin Zhang, Chengze Li",
    "title": "Screenshots From Screen Photography",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469136",
    "pdf_link": null,
    "abstract": "… This allows direct sharing of the screen content, but the … screenshots. Might we be able to achieve a computer graphic solution to directly convert a screen photography to a screenshot, …",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_337",
    "authors": "Minshan Xie, Menghan Xia, Xueting Liu, Chengze Li, Tien-Tsin Wong",
    "title": "Seamless Manga Inpainting With Semantics Awareness",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459822",
    "pdf_link": null,
    "abstract": "Manga inpainting fills up the disoccluded pixels due to the removal of dialogue balloons or \"sound effect\" text. This process is long needed by the industry for the language localization and the conversion to animated manga. It is mostly done manually, as existing methods (mostly for natural image inpainting) cannot produce satisfying results. Manga inpainting is more tricky than natural image inpainting because its highly abstract illustration using structural lines and screentone patterns, which confuses the semantic interpretation and visual content synthesis. In this paper, we present the first manga inpainting method, a deep learning model, that generates high-quality results. Instead of direct inpainting, we propose to separate the complicated inpainting into two major phases, semantic inpainting and appearance synthesis. This separation eases both the feature understanding and hence the training of the learning model. A key idea is to disentangle the structural line and screentone, that helps the network to better distinguish the structural line and the screentone features for semantic interpretation. Both the visual comparison and the quantitative experiments evidence the effectiveness of our method and justify its superiority over existing state-of-the-art methods in the application of manga inpainting.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_115",
    "authors": "Nanxuan Zhao, Quanlong Zheng, Jing Liao, Ying Cao, Hanspeter Pfister, Rynson W.H. Lau",
    "title": "Selective Region-based Photo Color Adjustment for Graphic Designs",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3447647",
    "pdf_link": null,
    "abstract": "When adding a photo onto a graphic design, professional graphic designers often adjust its colors based on some target colors obtained from the brand or product to make the entire design more memorable to audiences and establish a consistent brand identity. However, adjusting the colors of a photo in the context of a graphic design is a difficult task, with two major challenges: (1) Locality: The color is often adjusted locally to preserve the semantics and atmosphere of the original image; and (2) Naturalness: The modified region needs to be carefully chosen and recolored to obtain a semantically valid and visually natural result. To address these challenges, we propose a learning-based approach to photo color adjustment for graphic designs, which maps an input photo along with the target colors to a recolored result. Our method decomposes the color adjustment process into two successive stages: modifiable region selection and target color propagation. The first stage aims to solve the core, challenging problem of which local image region(s) should be adjusted, which requires not only a common sense of colors appearing in our visual world but also understanding of subtle visual design heuristics. To this end, we capitalize on both natural photos and graphic designs to train a region selection network, which detects the most likely regions to be adjusted to the target colors. The second stage trains a recoloring network to naturally propagate the target colors in the detected regions. Through extensive experiments and a user study, we demonstrate the effectiveness of our selective region-based photo recoloring framework.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_128",
    "authors": "Peichang Ouyang, Kwok-Wai Chung, Alain Nicolas, Krzysztof Gdawiec",
    "title": "Self-similar Fractal Drawings Inspired by M.C. Escher's Print Square Limit",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3456298",
    "pdf_link": null,
    "abstract": "A fractal tiling (f-tiling) is a kind of rarely explored tiling by similar polygonal tiles which possesses self-similarity and the boundary of which is a fractal. Based on a tiling by similar isosceles right triangles, Dutch graphic artist M. C. Escher created an ingenious print Square Limit in which fish are uniformly reduced in size as they approach the boundaries of the tiling. In this article, we present four families of f-tilings and propose an easy-to-implement method to achieve similar Escher-like drawings. By systematically investigating the local star-shaped structure of f-tilings, we first enumerate four families of f-tilings admitted by kite-shaped or dart-shaped prototiles. Then, we establish a fast binning algorithm for visualising f-tilings. To facilitate the creation of Escher-like drawings on the reported f-tilings, we next introduce one-to-one mappings between the square, and kite and dart, respectively. This treatment allows a pre-designed square template to be deformed into all prototiles considered in the article. Finally, we specify some technical implementations and present a gallery of the resulting Escher-like drawings. The method established in this article is thus able to generate a great variety of exotic Escher-like drawings.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_335",
    "authors": "R. Kenny Jones, David Charatan, Paul Guerrero, Niloy Mitra, Daniel Ritchie",
    "title": "ShapeMOD: Macro Operation Discovery for 3D Shape Programs",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459821",
    "pdf_link": null,
    "abstract": "A popular way to create detailed yet easily controllable 3D shapes is via procedural modeling, i.e. generating geometry using programs. Such programs consist of a series of instructions along with their associated parameter values. To fully realize the benefits of this representation, a shape program should be compact and only expose degrees of freedom that allow for meaningful manipulation of output geometry. One way to achieve this goal is to design higher-level macro operators that, when executed, expand into a series of commands from the base shape modeling language. However, manually authoring such macros, much like shape programs themselves, is difficult and largely restricted to domain experts. In this paper, we present ShapeMOD, an algorithm for automatically discovering macros that are useful across large datasets of 3D shape programs. ShapeMOD operates on shape programs expressed in an imperative, statement-based language. It is designed to discover macros that make programs more compact by minimizing the number of function calls and free parameters required to represent an input shape collection. We run ShapeMOD on multiple collections of programs expressed in a domain-specific language for 3D shape structures. We show that it automatically discovers a concise set of macros that abstract out common structural and parametric patterns that generalize over large shape collections. We also demonstrate that the macros found by ShapeMOD improve performance on downstream tasks including shape generative modeling and inferring programs from point clouds. Finally, we conduct a user study that indicates that ShapeMOD's discovered macros make interactive shape editing more efficient.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_231",
    "authors": "Laxmi Pandey, Ahmed Sabbir Arif",
    "title": "Silent Speech and Emotion Recognition From Vocal Tract Shape Dynamics in Real-time MRI",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469176",
    "pdf_link": null,
    "abstract": "We propose a novel deep neural network-based learning framework that understands acoustic information in the variable-length sequence of vocal tract shaping during speech production, captured by real-time magnetic resonance imaging (rtMRI), and translate it into text. In an experiment, it achieved a 40.6% PER at sentence-level, much better compared to the existing models. We also performed an analysis of variations in the geometry of articulation in each sub-regions of the vocal tract with respect to different emotions and genders. Results suggest that each sub-regions distortion is affected by both emotion and gender.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_103",
    "authors": "Hao Zhang, Yuxiao Zhou, Yifei Tian, Jun-Hai Yong, Feng Xu",
    "title": "Single Depth View Based Real-time Reconstruction of Hand-object Interactions",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3451341",
    "pdf_link": null,
    "abstract": "Reconstructing hand-object interactions is a challenging task due to strong occlusions and complex motions. This article proposes a real-time system that uses a single depth stream to simultaneously reconstruct hand poses, object shape, and rigid/non-rigid motions. To achieve this, we first train a joint learning network to segment the hand and object in a depth image, and to predict the 3D keypoints of the hand. With most layers shared by the two tasks, computation cost is saved for the real-time performance. A hybrid dataset is constructed here to train the network with real data (to learn real-world distributions) and synthetic data (to cover variations of objects, motions, and viewpoints). Next, the depth of the two targets and the keypoints are used in a uniform optimization to reconstruct the interacting motions. Benefitting from a novel tangential contact constraint, the system not only solves the remaining ambiguities but also keeps the real-time performance. Experiments show that our system handles different hand and object shapes, various interactive motions, and moving cameras.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_508",
    "authors": "Liangwang Ruan, Jinyuan Liu, Bo Zhu, Shinjiro Sueda, Bin Wang, Baoquan Chen",
    "title": "Solid-fluid Interaction With Surface-tension-dominant Contact",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459862",
    "pdf_link": null,
    "abstract": "We propose a novel three-way coupling method to model the contact interaction between solid and fluid driven by strong surface tension. At the heart of our physical model is a thin liquid membrane that simultaneously couples to both the liquid volume and the rigid objects, facilitating accurate momentum transfer, collision processing, and surface tension calculation. This model is implemented numerically under a hybrid Eulerian-Lagrangian framework where the membrane is modelled as a simplicial mesh and the liquid volume is simulated on a background Cartesian grid. We devise a monolithic solver to solve the interactions among the three systems of liquid, solid, and membrane. We demonstrate the efficacy of our method through an array of rigid-fluid contact simulations dominated by strong surface tension, which enables the faithful modeling of a host of new surface-tension-dominant phenomena including: objects with higher density than water that remains afloat; 'Cheerios effect' where floating objects attract one another; and surface tension weakening effect caused by surface-active constituents.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_429",
    "authors": "Syuhei Sato, Yoshinori Dobashi, Theodore Kim",
    "title": "Stream-guided Smoke Simulations",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459846",
    "pdf_link": null,
    "abstract": "… the smoke, this resulted in an average of 10% reduction in computation time. Since a sudden change in 𝛼 at the boundary of the smoke … We show smoke computed by our method with …",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_240",
    "authors": "Dave Pagurek van Mossel, Chenxi Liu, Nicholas Vining, Mikhail Bessmeltsev, Alla Sheffer",
    "title": "StrokeStrip: Joint Parameterization and Fitting of Stroke Clusters",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459777",
    "pdf_link": null,
    "abstract": "When creating freeform drawings, artists routinely employ clusters of overdrawn strokes to convey intended, aggregate curves. The ability to algorithmically fit these intended curves to their corresponding clusters is central to many applications that use artist drawings as inputs. However, while human observers effortlessly envision the intended curves given stroke clusters as input, existing fitting algorithms lack robustness and frequently fail when presented with input stroke clusters with non-trivial geometry or topology. We present StrokeStrip, a new and robust method for fitting intended curves to vector-format stroke clusters. Our method generates fitting outputs consistent with viewer expectations across a vast range of input stroke cluster configurations. We observe that viewers perceive stroke clusters as continuous, varying-width strips whose paths are described by the intended curves. An arc length parameterization of these strips defines a natural mapping from a strip to its path. We recast the curve fitting problem as one of parameterizing the cluster strokes using a joint 1D parameterization that is the restriction of the natural arc length parameterization of this strip to the strokes in the cluster. We simultaneously compute the joint cluster parameterization and implicitly reconstruct the a priori unknown strip geometry by solving a variational problem using a discrete-continuous optimization framework. We use this parameterization to compute parametric aggregate curves whose shape reflects the geometric properties of the cluster strokes at the corresponding isovalues. We demonstrate StrokeStrip outputs to be significantly better aligned with observer preferences compared to those of prior art; in a perceptual study, viewers preferred our fitting outputs by a factor of 12:1 compared to alternatives. We further validate our algorithmic choices via a range of ablation studies; extend our framework to raster data; and illustrate applications that benefit from the parameterizations produced.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_503",
    "authors": "Wonjong Jang, Gwangjin Ju, Yucheol Jung, Jiaolong Yang, Xin Tong, Seungyong Lee",
    "title": "StyleCariGAN: Caricature Generation via StyleGAN Feature Map Modulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459860",
    "pdf_link": null,
    "abstract": "We present a caricature generation framework based on shape and style manipulation using StyleGAN. Our framework, dubbed StyleCariGAN, automatically creates a realistic and detailed caricature from an input photo with optional controls on shape exaggeration degree and color stylization type. The key component of our method is shape exaggeration blocks that are used for modulating coarse layer feature maps of StyleGAN to produce desirable caricature shape exaggerations. We first build a layer-mixed StyleGAN for photo-to-caricature style conversion by swapping fine layers of the StyleGAN for photos to the corresponding layers of the StyleGAN trained to generate caricatures. Given an input photo, the layer-mixed model produces detailed color stylization for a caricature but without shape exaggerations. We then append shape exaggeration blocks to the coarse layers of the layer-mixed model and train the blocks to create shape exaggerations while preserving the characteristic appearances of the input. Experimental results show that our StyleCariGAN generates realistic and detailed caricatures compared to the current state-of-the-art methods. We demonstrate StyleCariGAN also supports other StyleGAN-based image manipulations, such as facial expression control.",
    "scholar_publication": "ACM Transactions On …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_106",
    "authors": "Rameen Abdal, Peihao Zhu, Niloy Mitra, Peter Wonka",
    "title": "StyleFlow: Attribute-conditioned Exploration of StyleGAN-generated Images Using Conditional Continuous Normalizing Flows",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3447648",
    "pdf_link": null,
    "abstract": "High-quality, diverse, and photorealistic images can now be generated by unconditional GANs (e.g., StyleGAN). However, limited options exist to control the generation process using (semantic) attributes while stillpreserving the quality of the output. Further, due to the entangled nature of the GAN latent space, performing edits along one attribute can easily result in unwanted changes along other attributes. In this article, in the context of conditional exploration of entangled latent spaces, we investigate the two sub-problems of attribute-conditioned sampling and attribute-controlled editing. We present StyleFlow as a simple, effective, and robust solution to both the sub-problems by formulating conditional exploration as an instance of conditional continuous normalizing flows in the GAN latent space conditioned by attribute features. We evaluate our method using the face and the car latent space of StyleGAN, and demonstrate fine-grained disentangled edits along various attributes on both real photographs and StyleGAN generated images. For example, for faces, we vary camera pose, illumination variation, expression, facial hair, gender, and age. Finally, via extensive qualitative and quantitative comparisons, we demonstrate the superiority of StyleFlow over prior and several concurrent works. Project Page and Video: https://rameenabdal.github.io/StyleFlow.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_246",
    "authors": "Silvia Sellán, Noam Aigerman, Alec Jacobson",
    "title": "Swept Volumes via Spacetime Numerical Continuation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459780",
    "pdf_link": null,
    "abstract": "Given a solid 3D shape and a trajectory of it over time, we compute its swept volume - the union of all points contained within the shape at some moment in time. We consider the representation of the input and output as implicit functions, and lift the problem to 4D spacetime, where we show the problem gains a continuous structure which avoids expensive global searches. We exploit this structure via a continuation method which marches and reconstructs the zero level set of the swept volume, using the temporal dimension to avoid erroneous solutions. We show that, compared to other methods, our approach is not restricted to a limited class of shapes or trajectories, is extremely robust, and its asymptotic complexity is an order lower than standards used in the industry, enabling its use in applications such as modeling, constructive solid geometry, and path planning.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_238",
    "authors": "Sai Praveen Bangaru, Jesse Michel, Kevin Mu, Gilbert Bernstein, Tzu-Mao Li, Jonathan Ragan-Kelley",
    "title": "Systematically Differentiating Parametric Discontinuities",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459775",
    "pdf_link": null,
    "abstract": "Emerging research in computer graphics, inverse problems, and machine learning requires us to differentiate and optimize parametric discontinuities. These discontinuities appear in object boundaries, occlusion, contact, and sudden change over time. In many domains, such as rendering and physics simulation, we differentiate the parameters of models that are expressed as integrals over discontinuous functions. Ignoring the discontinuities during differentiation often has a significant impact on the optimization process. Previous approaches either apply specialized hand-derived solutions, smooth out the discontinuities, or rely on incorrect automatic differentiation. We propose a systematic approach to differentiating integrals with discontinuous integrands, by developing a new differentiable programming language. We introduce integration as a language primitive and account for the Dirac delta contribution from differentiating parametric discontinuities in the integrand. We formally define the language semantics and prove the correctness and closure under the differentiation, allowing the generation of gradients and higher-order derivatives. We also build a system, Teg, implementing these semantics. Our approach is widely applicable to a variety of tasks, including image stylization, fitting shader parameters, trajectory optimization, and optimizing physical designs.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_109",
    "authors": "Joerg H. Mueller, Thomas Neff, Philip Voglreiter, Markus Steinberger, Dieter Schmalstieg",
    "title": "Temporally Adaptive Shading Reuse for Real-time Rendering and Virtual Reality",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3446790",
    "pdf_link": null,
    "abstract": "Temporal coherence has the potential to enable a huge reduction of shading costs in rendering. Existing techniques focus either only on spatial shading reuse or cannot adaptively choose temporal shading frequencies. We find that temporal shading reuse is possible for extended periods of time for a majority of samples, and we show under which circumstances users perceive temporal artifacts. Our analysis implies that we can approximate shading gradients to efficiently determine when and how long shading can be reused. Whereas visibility usually stays temporally coherent from frame to frame for more than 90%, we find that even in heavily animated game scenes with advanced shading, typically more than 50% of shading is also temporally coherent. To exploit this potential, we introduce a temporally adaptive shading framework and apply it to two real-time methods. Its application saves more than 57% of the shader invocations, reducing overall rendering times up to <?TeX $5\\times$?> in virtual reality applications without a noticeable loss in visual quality. Overall, our work shows that there is significantly more potential for shading reuse than currently exploited.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_162",
    "authors": "Kenta Yamamoto, Kosaku Namikawa, Yoichi Ochiai",
    "title": "TeraFoils: Design and Rapid Fabrication Techniques for Binary Holographic Structures in the Terahertz Region",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469157",
    "pdf_link": null,
    "abstract": "In this paper, we introduce TeraFoils, a method for designing and fabricating material-based structures using binary holograms in the terahertz region. We outline the design, fabrication, imaging, and data processing steps for embedding information inside physical objects and exploring a method to create holographic structures with silver-foiled paper. This paper is a sheet on which silver foil is pasted where the ink is printed, using a home-use laser printer and an electric iron. Wave propagation calculations were performed to design a binary …",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_177",
    "authors": "Anindita Ghosh, Noshaba Cheema, Cennet Oguz, Christian Theobalt, Philipp Slusallek",
    "title": "Text-based Motion Synthesis With a Hierarchical Two-stream RNN",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469163",
    "pdf_link": null,
    "abstract": "We present a learning-based method for generating animated 3D pose sequences depicting multiple sequential or superimposed actions provided in long, compositional sentences. We propose a hierarchical two-stream sequential model to explore a finer joint-level mapping between natural language sentences and the corresponding 3D pose sequences of the motions. We learn two manifold representations of the motion –- one each for the upper body and the lower body movements. We evaluate our proposed model on the publicly available KIT Motion-Language Dataset containing 3D pose data with human-annotated sentences. Experimental results show that our model advances the state-of-the-art on text-based motion synthesis in objective evaluations by a margin of 50%.",
    "scholar_publication": "ACM SIGGRAPH 2021 …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_113",
    "authors": "Michael Mara, Felix Heide, Michael Zollhoefer, Matthias Nießner, Pat Hanrahan",
    "title": "Thallo - Scheduling for High-performance Large-scale Non-linear Least-squares Solvers",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3453986",
    "pdf_link": null,
    "abstract": "Large-scale optimization problems at the core of many graphics, vision, and imaging applications are often implemented by hand in tedious and error-prone processes in order to achieve high performance (in particular on GPUs), despite recent developments in libraries and DSLs. At the same time, these hand-crafted solver implementations reveal that the key for high performance is a problem-specific schedule that enables efficient usage of the underlying hardware. In this work, we incorporate this insight into Thallo, a domain-specific language for large-scale non-linear least squares optimization problems. We observe various code reorganizations performed by implementers of high-performance solvers in the literature, and then define a set of basic operations that span these scheduling choices, thereby defining a large scheduling space. Users can either specify code transformations in a scheduling language or use an autoscheduler. Thallo takes as input a compact, shader-like representation of an energy function and a (potentially auto-generated) schedule, translating the combination into high-performance GPU solvers. Since Thallo can generate solvers from a large scheduling space, it can handle a large set of large-scale non-linear and non-smooth problems with various degrees of non-locality and compute-to-memory ratios, including diverse applications such as bundle adjustment, face blendshape fitting, and spatially-varying Poisson deconvolution, as seen in Figure 1. Abstracting schedules from the optimization, we outperform state-of-the-art GPU-based optimization DSLs by an average of 16× across all applications introduced in this work, and even some published hand-written GPU solvers by 30%+.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_294",
    "authors": "Christian Hafner, Bernd Bickel",
    "title": "The Design Space of Plane Elastic Curves",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459800",
    "pdf_link": null,
    "abstract": "Elastic bending of initially flat slender elements allows the realization and economic fabrication of intriguing curved shapes. In this work, we derive an intuitive but rigorous geometric characterization of the design space of plane elastic rods with variable stiffness. It enables designers to determine which shapes are physically viable with active bending by visual inspection alone. Building on these insights, we propose a method for efficiently designing the geometry of a flat elastic rod that realizes a target equilibrium curve, which only requires solving a linear program. We implement this method in an interactive computational design tool that gives feedback about the feasibility of a design, and computes the geometry of the structural elements necessary to realize it within an instant. The tool also offers an iterative optimization routine that improves the fabricability of a model while modifying it as little as possible. In addition, we use our geometric characterization to derive an algorithm for analyzing and recovering the stability of elastic curves that would otherwise snap out of their unstable equilibrium shapes by buckling. We show the efficacy of our approach by designing and manufacturing several physical models that are assembled from flat elements.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_319",
    "authors": "Ana Serrano, Bin Chen, Chao Wang, Michal Piovarči, Hans-Peter Seidel, Piotr Didyk, Karol Myszkowski",
    "title": "The Effect of Shape and Illumination on Material Perception: Model and Applications",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459813",
    "pdf_link": null,
    "abstract": "Material appearance hinges on material reflectance properties but also surface geometry and illumination. The unlimited number of potential combinations between these factors makes understanding and predicting material appearance a very challenging task. In this work, we collect a large-scale dataset of perceptual ratings of appearance attributes with more than 215,680 responses for 42,120 distinct combinations of material, shape, and illumination. The goal of this dataset is twofold. First, we analyze for the first time the effects of illumination and geometry in material perception across such a large collection of varied appearances. We connect our findings to those of the literature, discussing how previous knowledge generalizes across very diverse materials, shapes, and illuminations. Second, we use the collected dataset to train a deep learning architecture for predicting perceptual attributes that correlate with human judgments. We demonstrate the consistent and robust behavior of our predictor in various challenging scenarios, which, for the first time, enables estimating perceived material attributes from general 2D images. Since our predictor relies on the final appearance in an image, it can compare appearance properties across different geometries and illumination conditions. Finally, we demonstrate several applications that use our predictor, including appearance reproduction using 3D printing, BRDF editing by integrating our predictor in a differentiable renderer, illumination design, or material recommendations for scene design.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_230",
    "authors": "Ty M. Trusty, Honglin Chen, David I.W. Levin",
    "title": "The Shape Matching Element Method: Direct Animation of Curved Surface Models",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459772",
    "pdf_link": null,
    "abstract": "We introduce a new method for direct physics-based animation of volumetric curved models, represented using NURBS surfaces. Our technical contribution is the Shape Matching Element Method (SEM). SEM is a completely meshless algorithm, the first to simultaneously be robust to gaps and overlaps in geometry, be compatible with standard constitutive models and time integration schemes, support contact and frictional interactions and to preserve feature correspondence during simulation which enables editable simulated output. We demonstrate the efficacy of our algorithm by producing compelling physics-based animations from a variety of curved input models.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_514",
    "authors": "Mengdi Wang, Yitong Deng, Xiangxin Kong, Aditya Prasad, Shiying Xiong, Bo Zhu",
    "title": "Thin-film Smoothed Particle Hydrodynamics Fluid",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459864",
    "pdf_link": null,
    "abstract": "We propose a particle-based method to simulate thin-film fluid that jointly facilitates aggressive surface deformation and vigorous tangential flows. We build our dynamics model from the surface tension driven Navier-Stokes equation with the dimensionality reduced using the asymptotic lubrication theory and customize a set of differential operators based on the weakly compressible Smoothed Particle Hydrodynamics (SPH) for evolving pointset surfaces. The key insight is that the compressible nature of SPH, which is unfavorable in its typical usage, is helpful in our application to co-evolve the thickness, calculate the surface tension, and enforce the fluid incompressibility on a thin film. In this way, we are able to two-way couple the surface deformation with the in-plane flows in a physically based manner. We can simulate complex vortical swirls, fingering effects due to Rayleigh-Taylor instability, capillary waves, Newton's interference fringes, and the Marangoni effect on liberally deforming surfaces by presenting both realistic visual results and numerical validations. The particle-based nature of our system also enables it to conveniently handle topology changes and codimension transitions, allowing us to marry the thin-film simulation with a wide gamut of 3D phenomena, such as pinch-off of unstable catenoids, dripping under gravity, merging of droplets, as well as bubble rupture.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_543",
    "authors": "Rohit Pandey, Sergio Orts Escolano, Chloe LeGendre, Christian Haene, Sofien Bouaziz, Christoph Rhemann, Paul Debevec, Sean Fanello",
    "title": "Total Relighting: Learning to Relight Portraits for Background Replacement",
    "paper_url": "https://3dvar.com/Pandey2021Total.pdf",
    "pdf_link": null,
    "abstract": "Compositing a person into a scene to look like they are really there is a fundamental technique in visual effects, with many other applications such as smartphone photography [Tsai and Pandey 2020] and video conferencing [Hou and Mullen 2020]. The most common practice in film-making has been to record an actor in front of green or blue screen and use chroma-keying [Wright 2013] to derive an alpha matte and then change the background to a new one. However, this does nothing to ensure that the lighting on the subject appears consistent with the lighting in the new background environment, which must be solved with laborious lighting placement or elaborate LED lighting reproduction systems [Bluff et al. 2020; Debevec et al. 2002; Hamon et al. 2014]. Our goal is to design a system that allows for automated portrait relighting and background replacement. There is a significant body of work both in relighting, eg [Barron and Malik 2015; Debevec et al. 2000; Nestmeyer et al. 2020; Sun et al. 2019; Wang et al. 2020; Zhou et al. 2019], and in determining alpha mattes and foreground colors, eg [Cai et al. 2019; Forte and Pitié 2020; Hou and Liu 2019; Lutz et al. 2018; Xu et al. 2017]. A few techniques simultaneously consider foreground estimation and compositing in a unified framework [Wang and Cohen 2006; Zhang et al. 2020b] and produce convincing composites when the input and target lighting conditions are similar. However, the absence of an explicit relighting step limits realism when the input and target illumination conditions are different. To generate convincing relit composites, Einarsson et al.[2006] and Wenger et al.[2005] captured reflectance field basis images using time-multiplexed lighting conditions played back at very high frame rates (∼ 1000 Hz) in a computational illumination system, leveraging image-based relighting [Debevec et al. 2000] to match the lighting of the subject to the target background. Both methods also employed a simple ratio matting technique [Debevec et al. 2002] used to derive the alpha channel, based on infrared or time-multiplexed mattes and recording a “clean plate”. These hardware-based systems produced realistic composites by handling matting, relighting, and compositing in one complete system. However, their specialized hardware makes these techniques impractical in casual settings, such as for mobile phone photography and video conferencing. Inspired by these approaches, we propose a system for realistic portrait relighting and background replacement, starting from just a single RGB image and a desired target high dynamic range (HDR) lighting environment [Debevec 1998]. Our approach relies on multiple deep learning modules trained to accurately detect the foreground and alpha matte from portraits and to perform foreground relighting and compositing under a target illumination condition. We train our models using data from a light stage computational illumination system [Guo et al. 2019] to record reflectance fields and alpha mattes of 70 diverse individuals in various poses and expressions. We process the data to estimate useful photometric information such as per-pixel surface normals and surface albedo, which we leverage to help supervise the training of the relighting model. We extrapolate the recorded alpha mattes to all of the camera viewpoints using a deep learning framework that leverages clean plates of the light stage background, extending ratio matting to unconstrained backgrounds without the need for specialized lighting. With these reflectance fields, alpha mattes, and a database of high resolution HDR lighting environments, we use image-based relighting [Debevec et al …",
    "scholar_publication": "ACM Trans …, 2021 - 3dvar.com"
  },
  {
    "paper_id": "papers_332",
    "authors": "Zeyu Wang, Sherry Qiu, Nicole Feng, Holly Rushmeier, Leonard McMillan, Julie Dorsey",
    "title": "Tracing Versus Freehand for Evaluating Computer-Generated Drawings",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459819",
    "pdf_link": null,
    "abstract": "Non-photorealistic rendering (NPR) and image processing algorithms are widely assumed as a proxy for drawing. However, this assumption is not well assessed due to the difficulty in collecting and registering freehand drawings. Alternatively, tracings are easier to collect and register, but there is no quantitative evaluation of tracing as a proxy for freehand drawing. In this paper, we compare tracing, freehand drawing, and computer-generated drawing approximation (CGDA) to understand their similarities and differences. We collected a dataset of 1,498 tracings and freehand drawings by 110 participants for 100 image prompts. Our drawings are registered to the prompts and include vector-based timestamped strokes collected via stylus input. Comparing tracing and freehand drawing, we found a high degree of similarity in stroke placement and types of strokes used over time. We show that tracing can serve as a viable proxy for freehand drawing because of similar correlations between spatio-temporal stroke features and labeled stroke types. Comparing hand-drawn content and current CGDA output, we found that 60% of drawn pixels corresponded to computer-generated pixels on average. The overlap tended to be commonly drawn content, but people's artistic choices and temporal tendencies remained largely uncaptured. We present an initial analysis to inform new CGDA algorithms and drawing applications, and provide the dataset for use by the community.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_263",
    "authors": "Xinyu Yi, Yuxiao Zhou, Feng Xu",
    "title": "TransPose: Real-time 3D Human Translation and Pose Estimation With Six Inertial Sensors",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459786",
    "pdf_link": null,
    "abstract": "Motion capture is facing some new possibilities brought by the inertial sensing technologies which do not suffer from occlusion or wide-range recordings as vision-based solutions do. However, as the recorded signals are sparse and quite noisy, online performance and global translation estimation turn out to be two key difficulties. In this paper, we present TransPose, a DNN-based approach to perform full motion capture (with both global translations and body poses) from only 6 Inertial Measurement Units (IMUs) at over 90 fps. For body pose estimation, we propose a multi-stage network that estimates leaf-to-full joint positions as intermediate results. This design makes the pose estimation much easier, and thus achieves both better accuracy and lower computation cost. For global translation estimation, we propose a supporting-foot-based method and an RNN-based method to robustly solve for the global translations with a confidence-based fusion technique. Quantitative and qualitative comparisons show that our method outperforms the state-of-the-art learning- and optimization-based methods with a large margin in both accuracy and efficiency. As a purely inertial sensor-based approach, our method is not limited by environmental settings (e.g., fixed cameras), making the capture free from common difficulties such as wide-range motion space and strong occlusion.",
    "scholar_publication": "ACM Transactions On Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_496",
    "authors": "Joël Randrianandrasana, Patrick Callet, Laurent Lucas",
    "title": "Transfer Matrix Based Layered Materials Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459859",
    "pdf_link": null,
    "abstract": "A statistical multi-lobe approach was recently introduced in order to efficiently handle layered materials rendering as an alternative to expensive general-purpose approaches. However, this approach poorly supports scattering volumes as the method does not account for back-scattering and resorts to single scattering approximations. In this paper, we address these limitations with an efficient solution based upon a transfer matrix approach which leverages the properties of the Henyey-Greenstein phase function. Under this formalism, each scattering component of the stack is described through a lightweight matrix, layering operations are reduced to simple matrix products and the statistics of each BSDF lobe accounting for multiple scattering effects are obtained through matrix operators. Based on this representation, we leverage the versatility of the transfer matrix approach to efficiently handle forward and backward scattering which occurs in arbitrary layered materials. The resulting model enables the reproduction of a wide range of layered structures embedding scattering volumes of arbitrary depth, in constant computation time and with low variance.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_631",
    "authors": "Kathleen M. Lewis, Srivatsan Varadharajan, Ira Kemelmacher-Shlizerman",
    "title": "TryOnGAN: Body-aware Try-on via Layered Interpolation",
    "paper_url": "",
    "pdf_link": null,
    "abstract": null,
    "scholar_publication": null
  },
  {
    "paper_id": "papers_297",
    "authors": "Merel Meekes, Amir Vaxman",
    "title": "Unconventional Patterns on Surfaces",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459933",
    "pdf_link": null,
    "abstract": "… We present a unified method to meshing surfaces with unconventional patterns, both periodic and aperiodic. These patterns, which have so far been studied on the plane, are patterns …",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_201",
    "authors": "Bo Ren, Ben Xu, Chenfeng Li",
    "title": "Unified Particle System for Multiple-fluid Flow and Porous Material",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459764",
    "pdf_link": null,
    "abstract": "Porous materials are common in daily life. They include granular material (e.g. sand) that behaves like liquid flow when mixed with fluid and foam material (e.g. sponge) that deforms like solid when interacting with liquid. The underlying physics is further complicated when multiple fluids interact with porous materials involving coupling between rigid and fluid bodies, which may follow different physics models such as the Darcy's law and the multiple-fluid Navier-Stokes equations. We propose a unified particle framework for the simulation of multiple-fluid flows and porous materials. A novel virtual phase concept is introduced to avoid explicit particle state tracking and runtime particle deletion/insertion. Our unified model is flexible and stable to cope with multiple fluid interacting with porous materials, and it can ensure consistent mass and momentum transport over the whole simulation space.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_554",
    "authors": "Kaizhi Yang, Xuejin Chen",
    "title": "Unsupervised Learning for Cuboid Shape Abstraction via Joint Segmentation From Point Clouds",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459873",
    "pdf_link": null,
    "abstract": "Representing complex 3D objects as simple geometric primitives, known as shape abstraction, is important for geometric modeling, structural analysis, and shape synthesis. In this paper, we propose an unsupervised shape abstraction method to map a point cloud into a compact cuboid representation. We jointly predict cuboid allocation as part segmentation and cuboid shapes and enforce the consistency between the segmentation and shape abstraction for self-learning. For the cuboid abstraction task, we transform the input point cloud into a set of parametric cuboids using a variational auto-encoder network. The segmentation network allocates each point into a cuboid considering the point-cuboid affinity. Without manual annotations of parts in point clouds, we design four novel losses to jointly supervise the two branches in terms of geometric similarity and cuboid compactness. We evaluate our method on multiple shape collections and demonstrate its superiority over existing shape abstraction methods. Moreover, based on our network architecture and learned representations, our approach supports various applications including structured shape generation, shape interpolation, and structural shape clustering.",
    "scholar_publication": "ACM Transactions On Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_400",
    "authors": "Caigui Jiang, Hui Wang, Victor Ceballos Inza, Felix Dellinger, Florian Rist, Johannes Wallner, Helmut Pottmann",
    "title": "Using Isometries for Computational Design and Fabrication",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459839",
    "pdf_link": null,
    "abstract": "We solve the task of representing free forms by an arrangement of panels that are manufacturable by precise isometric bending of surfaces made from a small number of molds. In fact we manage to solve the paneling task with surfaces of constant Gaussian curvature alone. This includes the case of developable surfaces which exhibit zero curvature. Our computations are based on an existing discrete model of isometric mappings between surfaces which for this occasion has been refined to obtain higher numerical accuracy. Further topics are interesting connections of the paneling problem with the geometry of Killing vector fields, designing and actuating isometries, curved folding in the double-curved case, and quad meshes with rigid faces that are nevertheless flexible.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_101",
    "authors": "Yang Zhou, Lifan Wu, Ravi Ramamoorthi, Lingqi Yan",
    "title": "Vectorization for Fast, Analytic, and Differentiable Visibility",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3452097",
    "pdf_link": null,
    "abstract": "In Computer Graphics, the two main approaches to rendering and visibility involve ray tracing and rasterization. However, a limitation of both approaches is that they essentially use point sampling. This is the source of noise and aliasing, and also leads to significant difficulties for differentiable rendering. In this work, we present a new rendering method, which we call vectorization, that computes 2D point-to-region integrals analytically, thus eliminating point sampling in the 2D integration domain such as for pixel footprints and area lights. Our vectorization revisits the concept of beam tracing, and handles the hidden surface removal problem robustly and accurately. That is, for each intersecting triangle inserted into the viewport of a beam in an arbitrary order, we are able to maintain all the visible regions formed by intersections and occlusions, thanks to our Visibility Bounding Volume Hierarchy structure. As a result, our vectorization produces perfectly anti-aliased visibility, accurate and analytic shading and shadows, and most important, fast and noise-free gradients with Automatic Differentiation or Finite Differences that directly enables differentiable rendering without any changes to our rendering pipeline. Our results are inherently high-quality and noise-free, and our gradients are one to two orders of magnitude faster than those computed with existing differentiable rendering methods.",
    "scholar_publication": "ACM Transactions on Graphics …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_111",
    "authors": "Haotian Zhang, Cristobal Sciutto, Maneesh Agrawala, Kayvon Fatahalian",
    "title": "Vid2Player: Controllable Video Sprites That Behave and Appear Like Professional Tennis Players",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3448978",
    "pdf_link": null,
    "abstract": "We present a system that converts annotated broadcast video of tennis matches into interactively controllable video sprites that behave and appear like professional tennis players. Our approach is based on controllable video textures and utilizes domain knowledge of the cyclic structure of tennis rallies to place clip transitions and accept control inputs at key decision-making moments of point play. Most importantly, we use points from the video collection to model a player’s court positioning and shot selection decisions during points. We use these behavioral models to select video clips that reflect actions the real-life player is likely to take in a given match-play situation, yielding sprites that behave realistically at the macro level of full points, not just individual tennis motions. Our system can generate novel points between professional tennis players that resemble Wimbledon broadcasts, enabling new experiences, such as the creation of matchups between players that have not competed in real life or interactive control of players in the Wimbledon final. According to expert tennis players, the rallies generated using our approach are significantly more realistic in terms of player behavior than video sprite methods that only consider the quality of motion transitions during video synthesis. The supplementary material/video are available at our https://cs.stanford.edu/~haotianz/research/vid2player/ project website.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_119",
    "authors": "Zheng-Jun Du, Kai-Xiang Lei, Kun Xu, Jianchao Tan, Yotam Gingold",
    "title": "Video Recoloring via Spatial-temporal Geometric Palettes",
    "paper_url": "https://cragl.cs.gmu.edu/videopalette/Video%20Recoloring%20via%20Spatial-Temporal%20Geometric%20Palettes%20(Zheng-Jun%20Du,%20Kai-Xiang%20Lei,%20Kun%20Xu,%20Jianchao%20Tan,%20Yotam%20Gingold%202021%20SIGGRAPH%20Asia)%20presentation%2017-minutes.pdf",
    "pdf_link": null,
    "abstract": "… • Our work is based on RGB convex hull-based palette recoloring … 2) Recoloring • Our work is based on RGB convex hull-based palette recoloring …",
    "scholar_publication": "ACM Trans. Graph., 2021 - cragl.cs.gmu.edu"
  },
  {
    "paper_id": "pos_141",
    "authors": "Wesley Khademi, Jonathan Ventura",
    "title": "View Synthesis in Casually Captured Scenes Using a Cylindrical Neural Radiance Field With Exposure Compensation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469147",
    "pdf_link": null,
    "abstract": "We extend Neural Radiance Fields (NeRF) with a cylindrical parameterization that enables rendering photorealistic novel views of 360° outward facing scenes. We further introduce a learned exposure compensation parameter to account for the varying exposure in training images that may occur from casually capturing a scene. We evaluate our method on a variety of 360° casually captured scenes.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_292",
    "authors": "Jie Guo, Mengtian Li, Zijing Zong, Yuntao Liu, Jingwu He, Yanwen Guo, Ling-Qi Yan",
    "title": "Volumetric Appearance Stylization With Stylizing Kernel Prediction Network",
    "paper_url": "https://slides.games-cn.org/pdf/Games2021206MengtianLi.pdf",
    "pdf_link": null,
    "abstract": "… Stylizing kernel & Its predictor • … We propose the first feed-forward neural network that enables efficient artistic volumetric appearance stylization … Can not guarantee consistency between color and structural features if adopt SKPN and TNST independently to stylize both density and albedo …",
    "scholar_publication": "ACM Trans …, 2021 - slides.games-cn.org"
  },
  {
    "paper_id": "papers_529",
    "authors": "George E. Brown, Rahul Narain",
    "title": "WRAPD: Weighted Rotation-aware ADMM for Parameterization and Deformation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459942",
    "pdf_link": null,
    "abstract": "Local-global solvers such as ADMM for elastic simulation and geometry optimization struggle to resolve large rotations such as bending and twisting modes, and large distortions in the presence of barrier energies. We propose two improvements to address these challenges. First, we introduce a novel local-global splitting based on the polar decomposition that separates the geometric nonlinearity of rotations from the material nonlinearity of the deformation energy. The resulting ADMM-based algorithm is a combination of an L-BFGS solve in the global step and proximal updates of element stretches in the local step. We also introduce a novel method for dynamic reweighting that is used to adjust element weights at runtime for improved convergence. With both improved rotation handling and element weighting, our algorithm is considerably faster than state-of-the-art approaches for quasi-static simulations. It is also much faster at making early progress in parameterization problems, making it valuable as an initializer to jump-start second-order algorithms.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_570",
    "authors": "In-young Cho, Yuchi Huo, Sung-eui Yoon",
    "title": "Weakly Supervised Contrastive Learning in Path Manifold for Monte Carlo Image Reconstruction",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459876",
    "pdf_link": null,
    "abstract": "Image-space auxiliary features such as surface normal have significantly contributed to the recent success of Monte Carlo (MC) reconstruction networks. However, path-space features, another essential piece of light propagation, have not yet been sufficiently explored. Due to the curse of dimensionality, information flow between a regression loss and high-dimensional path-space features is sparse, leading to difficult training and inefficient usage of path-space features in a typical reconstruction framework. This paper introduces a contrastive manifold learning framework to utilize path-space features effectively. The proposed framework employs weakly-supervised learning that converts reference pixel colors to dense pseudo labels for light paths. A convolutional path-embedding network then induces a low-dimensional manifold of paths by iteratively clustering intra-class embeddings, while discriminating inter-class embeddings using gradient descent. The proposed framework facilitates path-space exploration of reconstruction networks by extracting low-dimensional yet meaningful embeddings within the features. We apply our framework to the recent image- and sample-space models and demonstrate considerable improvements, especially on the sample space. The source code is available at https://github.com/Mephisto405/WCMC.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_164",
    "authors": "Rao Xu, Lingze Wu, Qin Wu",
    "title": "WhiteStone: A Tangible Interactive Device for Revitalizing Qiang Language and Culture",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469159",
    "pdf_link": null,
    "abstract": "The Qiang is an ancient minority in western China. However, the number of people who can speak the Qiang language is decreasing due to a lack of written text. Although the protection of intangible cultural heritage has been widely discussed, there is still a dearth of interactive design for the Qiang people’s language and culture. This research aims to determine the efficacy of tangible interactive games to encourage Qiang people’s interest in learning the Qiang language and increase their cultural awareness. To better understand the current state and challenges of Qiang language and culture, we conducted a three-day field investigation in the Qiang villages. Based on the field study’s key findings, we created ”WhiteStone,” a tangible interactive projection device based on the heroic epic of Qiang. This poster examines the design opportunities for tangible interactive games to revitalize the Qiang language and culture.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_172",
    "authors": "Sehee Min, Jehee Lee",
    "title": "Why You Walk Like That: Inferring Body Conditions From Single Gait Cycle",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469162",
    "pdf_link": null,
    "abstract": "Gait is a key barometer to analyze human body conditions. We propose a personalized gait analysis framework which can diagnose a possible muscularskeletal disorders with a single gait cycle. Our framework built over a gait manifold which reveals the principle kinematic characteristics in the temporal pose sequence. Body parameters such as muscle, skeleton, and joint limits for an arbitrary gait cycle can be approximated by measuring similarity in the small latent space. We present a physical gait simulator to enrich the gait space paired with the body conditions.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_112",
    "authors": "Shino Higuchi, Hiromasa Oku",
    "title": "Wide Angular Range Dynamic Projection Mapping Method Applied to the Projection on a Flying Drone",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450618.3469137",
    "pdf_link": null,
    "abstract": "In this study, we proposed a method to realize dynamic projection mapping on a target moving at high speed in a wide angular range around the projection equipment using a high-speed gaze control system, and actually implemented and evaluated it. We also combined the proposed system with a teleconferencing system, and conducted an experiment in which a drone was used as an avatar robot for communication with remote locations.",
    "scholar_publication": "ACM SIGGRAPH 2021 Posters, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_289",
    "authors": "Zhijin Yang, Pengfei Xu, Hongbo Fu, Hui Huang",
    "title": "WireRoom: Model-guided Explorative Design of Abstract Wire Art",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3450626.3459796",
    "pdf_link": null,
    "abstract": "We present WireRoom, a computational framework for the intelligent design of abstract 3D wire art to depict a given 3D model. Our algorithm generates a set of 3D wire shapes from the 3D model with informative, visually pleasing, and concise structures. It is achieved by solving a dynamic travelling salesman problem on the surface of the 3D model with a multi-path expansion approach. We introduce a novel explorative computational design procedure by taking the generated wire shapes as candidates, avoiding manual design of the wire shape structure. We compare our algorithm with a baseline method and conduct a user study to investigate the usability of the framework and the quality of the produced wire shapes. The results of the comparison and user study confirm that our framework is effective for producing informative, visually pleasing, and concise wire shapes.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  }
]