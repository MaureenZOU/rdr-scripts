[
  {
    "paper_no": "54",
    "authors": "Liu, Qing; su, hu; LIU, Song",
    "title": "Binary Amplitude-Only Hologram Design for Acoustic End-Effector Construction by Physics-based deep learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "56",
    "authors": "Zhang, Chong; Rudin, Nikita; Hoeller, David; Hutter, Marco",
    "title": "Learning Agile Locomotion on Risky Terrains",
    "arxiv_pdf": "http://arxiv.org/pdf/2311.10484v2",
    "arxiv_abstract": "Quadruped robots have shown remarkable mobility on various terrains through\nreinforcement learning. Yet, in the presence of sparse footholds and risky\nterrains such as stepping stones and balance beams, which require precise foot\nplacement to avoid falls, model-based approaches are often used. In this paper,\nwe show that end-to-end reinforcement learning can also enable the robot to\ntraverse risky terrains with dynamic motions. To this end, our approach\ninvolves training a generalist policy for agile locomotion on disorderly and\nsparse stepping stones before transferring its reusable knowledge to various\nmore challenging terrains by finetuning specialist policies from it. Given that\nthe robot needs to rapidly adapt its velocity on these terrains, we formulate\nthe task as a navigation task instead of the commonly used velocity tracking\nwhich constrains the robot's behavior and propose an exploration strategy to\novercome sparse rewards and achieve high robustness. We validate our proposed\nmethod through simulation and real-world experiments on an ANYmal-D robot\nachieving peak forward velocity of >= 2.5 m/s on sparse stepping stones and\nnarrow balance beams. Video: youtu.be/Z5X0J8OH6z4"
  },
  {
    "paper_no": "68",
    "authors": "Zhang, Tianyu; Chang, Yong; Wang, Hongguang; Wang, Tianlong",
    "title": "Kinetic-Energy-Optimal and Safety-Guaranteed Trajectory Planning for Bridge Inspection Robot Manipulator",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "77",
    "authors": "Latif, Ehsan; Parasuraman, Ramviyas",
    "title": "HGP-RL: Distributed Hierarchical Gaussian Processes for Wi-Fi-based Relative Localization in Multi-Robot Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "78",
    "authors": "Ravipati, Siva Krishna; Latif, Ehsan; Bhandarkar, Suchendra; Parasuraman, Ramviyas",
    "title": "Object-Oriented Material Classification and 3D Clustering for Improved Semantic Perception and Mapping in Mobile Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.06077v1",
    "arxiv_abstract": "Classification of different object surface material types can play a\nsignificant role in the decision-making algorithms for mobile robots and\nautonomous vehicles. RGB-based scene-level semantic segmentation has been\nwell-addressed in the literature. However, improving material recognition using\nthe depth modality and its integration with SLAM algorithms for 3D semantic\nmapping could unlock new potential benefits in the robotics perception\npipeline. To this end, we propose a complementarity-aware deep learning\napproach for RGB-D-based material classification built on top of an\nobject-oriented pipeline. The approach further integrates the ORB-SLAM2 method\nfor 3D scene mapping with multiscale clustering of the detected material\nsemantics in the point cloud map generated by the visual SLAM algorithm.\nExtensive experimental results with existing public datasets and newly\ncontributed real-world robot datasets demonstrate a significant improvement in\nmaterial classification and 3D clustering accuracy compared to state-of-the-art\napproaches for 3D semantic scene mapping."
  },
  {
    "paper_no": "88",
    "authors": "Meyer, Lukas; Erich, Floris Marc Arden; Yoshiyasu, Yusuke; Stamminger, Marc; Ando, Noriaki; Domae, Yukiyasu",
    "title": "PEGASUS: Physically Enhanced Gaussian Splatting Simulation System for 6DOF Object Pose Dataset Generation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "94",
    "authors": "Liu, Zhongyan; Lu, Biao; Xing, Xinghai; Mao, Dun; Fang, Yongchun",
    "title": "Multi-target Tracking with Occlusion Resistance for Mobile Robots in Dynamic Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "99",
    "authors": "Su, Yao; Jiao, Ziyuan; Zhang, Zeyu; Zhang, Jingwen; Li, Hang; Wang, Meng; Liu, Hangxin",
    "title": "Flight Structure Optimization of Modular Reconfigurable UAVs",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.03724v1",
    "arxiv_abstract": "This paper presents a Genetic Algorithm (GA) designed to reconfigure a large\ngroup of modular Unmanned Aerial Vehicles (UAVs), each with different weights\nand inertia parameters, into an over-actuated flight structure with improved\ndynamic properties. Previous research efforts either utilized expert knowledge\nto design flight structures for a specific task or relied on enumeration-based\nalgorithms that required extensive computation to find an optimal one. However,\nboth approaches encounter challenges in accommodating the heterogeneity among\nmodules. Our GA addresses these challenges by incorporating the complexities of\nover-actuation and dynamic properties into its formulation. Additionally, we\nemploy a tree representation and a vector representation to describe flight\nstructures, facilitating efficient crossover operations and fitness evaluations\nwithin the GA framework, respectively. Using cubic modular quadcopters capable\nof functioning as omni-directional thrust generators, we validate that the\nproposed approach can (i) adeptly identify suboptimal configurations ensuring\nover-actuation while ensuring trajectory tracking accuracy and (ii)\nsignificantly reduce computational costs compared to traditional\nenumeration-based methods."
  },
  {
    "paper_no": "101",
    "authors": "Filotheou, Alexandros",
    "title": "CBGL: Fast Monte Carlo Passive Global Localisation of 2D LIDAR Sensor",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "103",
    "authors": "Georgiev, Nikola",
    "title": "Understanding Strain Wave Gear Directional Efficiency in the Context of Robotic Actuation and Overcoming the Corresponding Performance Limitations Through Direct Torque Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "105",
    "authors": "Zeng, Jianxin; Wang, Yaonan; Miao, Zhiqiang; He, Wei; Wang, Hesheng",
    "title": "Decentralized Trajectory Planning for Formation Flight in Unknown and Dense Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "110",
    "authors": "Wang, Meng; Li, Wanlin; Liang, Hao; Li, Boren; Althoefer, Kaspar; Su, Yao; Liu, Hangxin",
    "title": "Large-scale Deployment of Vision-based Tactile Sensors on Multi-fingered Grippers",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.02206v1",
    "arxiv_abstract": "Vision-based Tactile Sensors (VBTSs) show significant promise in that they\ncan leverage image measurements to provide high-spatial-resolution human-like\nperformance. However, current VBTS designs, typically confined to the\nfingertips of robotic grippers, prove somewhat inadequate, as many grasping and\nmanipulation tasks require multiple contact points with the object. With an end\ngoal of enabling large-scale, multi-surface tactile sensing via VBTSs, our\nresearch (i) develops a synchronized image acquisition system with minimal\nlatency,(ii) proposes a modularized VBTS design for easy integration into\nfinger phalanges, and (iii) devises a zero-shot calibration approach to improve\ndata efficiency in the simultaneous calibration of multiple VBTSs. In\nvalidating the system within a miniature 3-fingered robotic gripper equipped\nwith 7 VBTSs we demonstrate improved tactile perception performance by covering\nthe contact surfaces of both gripper fingers and palm. Additionally, we show\nthat our VBTS design can be seamlessly integrated into various end-effector\nmorphologies significantly reducing the data requirements for calibration."
  },
  {
    "paper_no": "115",
    "authors": "Bilal, Muhammad; Lipovetzky, Nir; Oetomo, Denny; Johal, Wafa",
    "title": "Beyond Success: Quantifying Quality of Task Execution for Improved Learning from Demonstration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "120",
    "authors": "Przystupa, Michael; Gidel, Gauthier; Taylor, Matthew; Jagersand, Martin; Piater, Justus; Tosatto, Samuele",
    "title": "Local Linearity is All You Need (in Data Driven Teleoperation)",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "125",
    "authors": "Lezcano, Dimitri A.; Iordachita, Ioan Iulian; Kim, Jin Seob",
    "title": "FBG-based Shape-Sensing to Enable Lateral Deflection Methods of Autonomous Needle Insertion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "132",
    "authors": "Williams, Henry; Smith, David Anthony James; Shahabi, Jalil; Gee, Trevor; Qureshi, Ans; McGuinness, Benjamin John; Harvey, Scott; Downes, Catherine; Jangali, Rahul; Black, Kale; Lim, Shen Hin; Duke, Mike; MacDonald, Bruce",
    "title": "Archie Jnr: A Robotic Platform for Autonomous Cane Pruning of Grapevines",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "135",
    "authors": "Paramonov, Kirill; Zhong, Jia-Xing; Michieli, Umberto; Moon, Jijoong; Ozay, Mete",
    "title": "Swiss DINO: Efficient and Versatile Vision Framework for On-Device Personal Object Search",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.07541v1",
    "arxiv_abstract": "In this paper, we address a recent trend in robotic home appliances to\ninclude vision systems on personal devices, capable of personalizing the\nappliances on the fly. In particular, we formulate and address an important\ntechnical task of personal object search, which involves localization and\nidentification of personal items of interest on images captured by robotic\nappliances, with each item referenced only by a few annotated images. The task\nis crucial for robotic home appliances and mobile systems, which need to\nprocess personal visual scenes or to operate with particular personal objects\n(e.g., for grasping or navigation). In practice, personal object search\npresents two main technical challenges. First, a robot vision system needs to\nbe able to distinguish between many fine-grained classes, in the presence of\nocclusions and clutter. Second, the strict resource requirements for the\non-device system restrict the usage of most state-of-the-art methods for\nfew-shot learning and often prevent on-device adaptation. In this work, we\npropose Swiss DINO: a simple yet effective framework for one-shot personal\nobject search based on the recent DINOv2 transformer model, which was shown to\nhave strong zero-shot generalization properties. Swiss DINO handles challenging\non-device personalized scene understanding requirements and does not require\nany adaptation training. We show significant improvement (up to 55%) in\nsegmentation and recognition accuracy compared to the common lightweight\nsolutions, and significant footprint reduction of backbone inference time (up\nto 100x) and GPU consumption (up to 10x) compared to the heavy\ntransformer-based solutions."
  },
  {
    "paper_no": "136",
    "authors": "Barbato, Francesco; Michieli, Umberto; Moon, Jijoong; Zanuttigh, Pietro; Ozay, Mete",
    "title": "Cross-Architecture Auxiliary Feature Space Translation for Efficient Few-Shot Personalized Object Detection",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.01193v1",
    "arxiv_abstract": "Recent years have seen object detection robotic systems deployed in several\npersonal devices (e.g., home robots and appliances). This has highlighted a\nchallenge in their design, i.e., they cannot efficiently update their knowledge\nto distinguish between general classes and user-specific instances (e.g., a dog\nvs. user's dog). We refer to this challenging task as Instance-level\nPersonalized Object Detection (IPOD). The personalization task requires many\nsamples for model tuning and optimization in a centralized server, raising\nprivacy concerns. An alternative is provided by approaches based on recent\nlarge-scale Foundation Models, but their compute costs preclude on-device\napplications.\n  In our work we tackle both problems at the same time, designing a Few-Shot\nIPOD strategy called AuXFT. We introduce a conditional coarse-to-fine few-shot\nlearner to refine the coarse predictions made by an efficient object detector,\nshowing that using an off-the-shelf model leads to poor personalization due to\nneural collapse. Therefore, we introduce a Translator block that generates an\nauxiliary feature space where features generated by a self-supervised model\n(e.g., DINOv2) are distilled without impacting the performance of the detector.\nWe validate AuXFT on three publicly available datasets and one in-house\nbenchmark designed for the IPOD task, achieving remarkable gains in all\nconsidered scenarios with excellent time-complexity trade-off: AuXFT reaches a\nperformance of 80% its upper bound at just 32% of the inference time, 13% of\nVRAM and 19% of the model size."
  },
  {
    "paper_no": "137",
    "authors": "Camuffo, Elena; Michieli, Umberto; Milani, Simone; Moon, Jijoong; Ozay, Mete",
    "title": "Enhanced Model Robustness to Input Corruptions by Per-Corruption Adaptation of Normalization Statistics",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.06450v1",
    "arxiv_abstract": "Developing a reliable vision system is a fundamental challenge for robotic\ntechnologies (e.g., indoor service robots and outdoor autonomous robots) which\ncan ensure reliable navigation even in challenging environments such as adverse\nweather conditions (e.g., fog, rain), poor lighting conditions (e.g.,\nover/under exposure), or sensor degradation (e.g., blurring, noise), and can\nguarantee high performance in safety-critical functions. Current solutions\nproposed to improve model robustness usually rely on generic data augmentation\ntechniques or employ costly test-time adaptation methods. In addition, most\napproaches focus on addressing a single vision task (typically, image\nrecognition) utilising synthetic data. In this paper, we introduce\nPer-corruption Adaptation of Normalization statistics (PAN) to enhance the\nmodel robustness of vision systems. Our approach entails three key components:\n(i) a corruption type identification module, (ii) dynamic adjustment of\nnormalization layer statistics based on identified corruption type, and (iii)\nreal-time update of these statistics according to input data. PAN can integrate\nseamlessly with any convolutional model for enhanced accuracy in several robot\nvision tasks. In our experiments, PAN obtains robust performance improvement on\nchallenging real-world corrupted image datasets (e.g., OpenLoris, ExDark,\nACDC), where most of the current solutions tend to fail. Moreover, PAN\noutperforms the baseline models by 20-30% on synthetic benchmarks in object\nrecognition tasks."
  },
  {
    "paper_no": "139",
    "authors": "Liu, Hsu-Shen; Kuroki, So; Kozuno, Tadashi; Sun, Wei-Fang; Lee, Chun-Yi",
    "title": "Language-Guided Pattern Formation for Swarm Robotics with Multi-Agent Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "143",
    "authors": "Hilger, Maximilian; Mandischer, Nils; Corves, Burkhard",
    "title": "RaNDT SLAM: Radar SLAM Based on Intensity-Augmented Normal Distributions Transform",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.11576v1",
    "arxiv_abstract": "Rescue robotics sets high requirements to perception algorithms due to the\nunstructured and potentially vision-denied environments. Pivoting\nFrequency-Modulated Continuous Wave radars are an emerging sensing modality for\nSLAM in this kind of environment. However, the complex noise characteristics of\nradar SLAM makes, particularly indoor, applications computationally demanding\nand slow. In this work, we introduce a novel radar SLAM framework, RaNDT SLAM,\nthat operates fast and generates accurate robot trajectories. The method is\nbased on the Normal Distributions Transform augmented by radar intensity\nmeasures. Motion estimation is based on fusion of motion model, IMU data, and\nregistration of the intensity-augmented Normal Distributions Transform. We\nevaluate RaNDT SLAM in a new benchmark dataset and the Oxford Radar RobotCar\ndataset. The new dataset contains indoor and outdoor environments besides\nmultiple sensing modalities (LiDAR, radar, and IMU)."
  },
  {
    "paper_no": "156",
    "authors": "Makino, Hiroya; Ito, Seigo",
    "title": "Online Multi-Agent Pickup and Delivery with Task Deadlines",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12377v3",
    "arxiv_abstract": "Managing delivery deadlines in automated warehouses and factories is crucial\nfor maintaining customer satisfaction and ensuring seamless production. This\nstudy introduces the problem of online multi-agent pickup and delivery with\ntask deadlines (MAPD-D), an advanced variant of the online MAPD problem\nincorporating delivery deadlines. In the MAPD problem, agents must manage a\ncontinuous stream of delivery tasks online. Tasks are added at any time. Agents\nmust complete their tasks while avoiding collisions with each other. MAPD-D\nintroduces a dynamic, deadline-driven approach that incorporates task\ndeadlines, challenging the conventional MAPD frameworks. To tackle MAPD-D, we\npropose a novel algorithm named deadline-aware token passing (D-TP). The D-TP\nalgorithm calculates pickup deadlines and assigns tasks while balancing\nexecution cost and deadline proximity. Additionally, we introduce the D-TP with\ntask swaps (D-TPTS) method to further reduce task tardiness, enhancing\nflexibility and efficiency through task-swapping strategies. Numerical\nexperiments were conducted in simulated warehouse environments to showcase the\neffectiveness of the proposed methods. Both D-TP and D-TPTS demonstrated\nsignificant reductions in task tardiness compared to existing methods. Our\nmethods contribute to efficient operations in automated warehouses and\nfactories with delivery deadlines."
  },
  {
    "paper_no": "159",
    "authors": "Makino, Hiroya; Ohama, Yoshihiro; Ito, Seigo",
    "title": "MARPF: Multi-Agent and Multi-Rack Path Finding",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "160",
    "authors": "ALJaber, Faisal; Hassan, Ahmed; Vitanov, Ivan; Almeadadi, Noora; ALHAJRI, HIND; AlEnazi, Sara; Al-Marri, Rashid; Choe, Pilsung",
    "title": "Optimal Sensing in Soft Pneumatic Actuators via Stretchable Optical Waveguides",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "161",
    "authors": "Xiao, YuanZheng; Gao, YangQing; Wu, Haoran; Huang, Bo; Lv, Jianyong",
    "title": "A Fast Heuristic Scheduling Search for Robotic Cellular Manufacturing Systems with Generalized and Timed Petri Nets",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "162",
    "authors": "Duque Domingo, Jaime; García-Gómez, Miguel; Zalama, Eduardo; Gomez Garcia Bermejo, Jaime",
    "title": "Continuous Rapid Learning by Human Imitation using Audio Prompts and One-Shot Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "167",
    "authors": "Guan, Runwei; Yao, Shanliang; Man, Ka Lok; Zhu, Xiaohui; Yue, Yong; Smith, Jeremy; Yue, Yutao; Lim, Eng Gee",
    "title": "ASY-VRNet: Waterway Panoptic Driving Perception Model based on Asymmetric Fair Fusion of Vision and 4D mmWave Radar",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "169",
    "authors": "Hua, Minh Tuan; Sveen, Emil Mühlbradt; Schlanbusch, Siri Marte; Sanfilippo, Filippo",
    "title": "Robust-Adaptive Two-Loop Control for Robots with Mixed Rigid-Elastic Joints",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "170",
    "authors": "Williams, Henry; Qureshi, Ans; Smith, David Anthony James; Gee, Trevor; McGuinness, Benjamin John; Jangali, Rahul; Black, Kale; Harvey, Scott; Downes, Catherine; Lim, Shen Hin; Oliver, Richard; Duke, Mike; MacDonald, Bruce",
    "title": "Archie Snr: A Robotic Platform for Autonomous Apple Fruitlet Thinning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "174",
    "authors": "Selvamuthu, Moses Gladson; Tadakuma, Riichiro",
    "title": "Development of a Bendable and Extendable Soft Gripper Driven by Differential Worm Gear Mechanism",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "177",
    "authors": "Luo, Chuanyu; Cheng, Nuo; Zhong, Ren; Jiang, Haipeng; Chen, Wenyu; Wang, Aoli; Li, Pu",
    "title": "3D Object Visibility Prediction in Autonomous Driving",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.03681v1",
    "arxiv_abstract": "With the rapid advancement of hardware and software technologies, research in\nautonomous driving has seen significant growth. The prevailing framework for\nmulti-sensor autonomous driving encompasses sensor installation, perception,\npath planning, decision-making, and motion control. At the perception phase, a\ncommon approach involves utilizing neural networks to infer 3D bounding box\n(Bbox) attributes from raw sensor data, including classification, size, and\norientation. In this paper, we present a novel attribute and its corresponding\nalgorithm: 3D object visibility. By incorporating multi-task learning, the\nintroduction of this attribute, visibility, negligibly affects the model's\neffectiveness and efficiency. Our proposal of this attribute and its\ncomputational strategy aims to expand the capabilities for downstream tasks,\nthereby enhancing the safety and reliability of real-time autonomous driving in\nreal-world scenarios."
  },
  {
    "paper_no": "184",
    "authors": "Kim, Junghyun; Kang, Gi-Cheon; Kim, Jaein; Yang, Seoyun; Jung, Minjoon; Zhang, Byoung-Tak",
    "title": "PGA: Personalizing Grasping Agents with Single Human-Robot Interaction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "186",
    "authors": "Miao, Yang; Armeni, Iro; Pollefeys, Marc; Barath, Daniel",
    "title": "Volumetric Semantically Consistent 3D Panoptic Mapping",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.14737v3",
    "arxiv_abstract": "We introduce an online 2D-to-3D semantic instance mapping algorithm aimed at\ngenerating comprehensive, accurate, and efficient semantic 3D maps suitable for\nautonomous agents in unstructured environments. The proposed approach is based\non a Voxel-TSDF representation used in recent algorithms. It introduces novel\nways of integrating semantic prediction confidence during mapping, producing\nsemantic and instance-consistent 3D regions. Further improvements are achieved\nby graph optimization-based semantic labeling and instance refinement. The\nproposed method achieves accuracy superior to the state of the art on public\nlarge-scale datasets, improving on a number of widely used metrics. We also\nhighlight a downfall in the evaluation of recent studies: using the ground\ntruth trajectory as input instead of a SLAM-estimated one substantially affects\nthe accuracy, creating a large gap between the reported results and the actual\nperformance on real-world data."
  },
  {
    "paper_no": "187",
    "authors": "Guo, Shih-Wei; Hsiao, Tsu-Ching; Liu, Yu-Lun; Lee, Chun-Yi",
    "title": "Precise Pick-and-Place using Score-Based Diffusion Networks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "188",
    "authors": "Staderini, Vanessa; Glück, Tobias; Schneider, Philipp; Kugi, Andreas",
    "title": "Visual Quality Inspection Planning: A Model-Based Framework for Generating Optimal and Feasible Inspection Poses",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "190",
    "authors": "Pang, Xincheng; Xia, Wenke; Wang, Zhigang; Zhao, Bin; Hu, Di; Wang, Dong; Li, Xuelong",
    "title": "Depth Helps: Improving Pre-trained RGB-based Policy with Depth Information Injection",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.05107v1",
    "arxiv_abstract": "3D perception ability is crucial for generalizable robotic manipulation.\nWhile recent foundation models have made significant strides in perception and\ndecision-making with RGB-based input, their lack of 3D perception limits their\neffectiveness in fine-grained robotic manipulation tasks. To address these\nlimitations, we propose a Depth Information Injection ($\\bold{DI}^{\\bold{2}}$)\nframework that leverages the RGB-Depth modality for policy fine-tuning, while\nrelying solely on RGB images for robust and efficient deployment. Concretely,\nwe introduce the Depth Completion Module (DCM) to extract the spatial prior\nknowledge related to depth information and generate virtual depth information\nfrom RGB inputs to aid policy deployment. Further, we propose the Depth-Aware\nCodebook (DAC) to eliminate noise and reduce the cumulative error from the\ndepth prediction. In the inference phase, this framework employs RGB inputs and\naccurately predicted depth data to generate the manipulation action. We conduct\nexperiments on simulated LIBERO environments and real-world scenarios, and the\nexperiment results prove that our method could effectively enhance the\npre-trained RGB-based policy with 3D perception ability for robotic\nmanipulation. The website is released at\nhttps://gewu-lab.github.io/DepthHelps-IROS2024."
  },
  {
    "paper_no": "192",
    "authors": "Xia, Jun; Wang, Ting; Ni, Huanqi; Li, Yanlin; Chen, Ruoxi; Nasseri, M. Ali; Lin, Haotian; Huang, Kai",
    "title": "An Online RCM Adjusting System for Robot-Assisted Retinal Surgeries",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "193",
    "authors": "Zobeidi, Ehsan; Atanasov, Nikolay",
    "title": "A Deep Signed Directional Distance Function for Shape Representation",
    "arxiv_pdf": "http://arxiv.org/pdf/2107.11024v2",
    "arxiv_abstract": "Neural networks that map 3D coordinates to signed distance function (SDF) or\noccupancy values have enabled high-fidelity implicit representations of object\nshape. This paper develops a new shape model that allows synthesizing novel\ndistance views by optimizing a continuous signed directional distance function\n(SDDF). Similar to deep SDF models, our SDDF formulation can represent whole\ncategories of shapes and complete or interpolate across shapes from partial\ninput data. Unlike an SDF, which measures distance to the nearest surface in\nany direction, an SDDF measures distance in a given direction. This allows\ntraining an SDDF model without 3D shape supervision, using only distance\nmeasurements, readily available from depth camera or Lidar sensors. Our model\nalso removes post-processing steps like surface extraction or rendering by\ndirectly predicting distance at arbitrary locations and viewing directions.\nUnlike deep view-synthesis techniques, such as Neural Radiance Fields, which\ntrain high-capacity black-box models, our model encodes by construction the\nproperty that SDDF values decrease linearly along the viewing direction. This\nstructure constraint not only results in dimensionality reduction but also\nprovides analytical confidence about the accuracy of SDDF predictions,\nregardless of the distance to the object surface."
  },
  {
    "paper_no": "196",
    "authors": "Choi, Dooseop; Kang, Jungyu; An, Taeg-Hyun; An, Kyounghwan; KyoungWook, MIN",
    "title": "Progressive Query Refinement Framework for Bird's-Eye-View Semantic Segmentation from Surrounding Images",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.17003v1",
    "arxiv_abstract": "Expressing images with Multi-Resolution (MR) features has been widely adopted\nin many computer vision tasks. In this paper, we introduce the MR concept into\nBird's-Eye-View (BEV) semantic segmentation for autonomous driving. This\nintroduction enhances our model's ability to capture both global and local\ncharacteristics of driving scenes through our proposed residual learning.\nSpecifically, given a set of MR BEV query maps, the lowest resolution query map\nis initially updated using a View Transformation (VT) encoder. This updated\nquery map is then upscaled and merged with a higher resolution query map to\nundergo further updates in a subsequent VT encoder. This process is repeated\nuntil the resolution of the updated query map reaches the target. Finally, the\nlowest resolution map is added to the target resolution to generate the final\nquery map. During training, we enforce both the lowest and final query maps to\nalign with the ground-truth BEV semantic map to help our model effectively\ncapture the global and local characteristics. We also propose a visual feature\ninteraction network that promotes interactions between features across images\nand across feature levels, thus highly contributing to the performance\nimprovement. We evaluate our model on a large-scale real-world dataset. The\nexperimental results show that our model outperforms the SOTA models in terms\nof IoU metric. Codes are available at\nhttps://github.com/d1024choi/ProgressiveQueryRefineNet"
  },
  {
    "paper_no": "198",
    "authors": "Ishida, Yutaro; Noguchi, Yuki; Kanai, Takayuki; Shintani, Kazuhiro; Bitoh, Hiroshi",
    "title": "Robust Imitation Learning for Mobile Manipulator Focusing on Task-Related Viewpoints and Regions",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.01292v1",
    "arxiv_abstract": "We study how to generalize the visuomotor policy of a mobile manipulator from\nthe perspective of visual observations. The mobile manipulator is prone to\nocclusion owing to its own body when only a single viewpoint is employed and a\nsignificant domain shift when deployed in diverse situations. However, to the\nbest of the authors' knowledge, no study has been able to solve occlusion and\ndomain shift simultaneously and propose a robust policy. In this paper, we\npropose a robust imitation learning method for mobile manipulators that focuses\non task-related viewpoints and their spatial regions when observing multiple\nviewpoints. The multiple viewpoint policy includes attention mechanism, which\nis learned with an augmented dataset, and brings optimal viewpoints and robust\nvisual embedding against occlusion and domain shift. Comparison of our results\nfor different tasks and environments with those of previous studies revealed\nthat our proposed method improves the success rate by up to 29.3 points. We\nalso conduct ablation studies using our proposed method. Learning task-related\nviewpoints from the multiple viewpoints dataset increases robustness to\nocclusion than using a uniquely defined viewpoint. Focusing on task-related\nregions contributes to up to a 33.3-point improvement in the success rate\nagainst domain shift."
  },
  {
    "paper_no": "199",
    "authors": "Ding, Hao; Zeng, Yiming; Wan, Zhaoliang; Cheng, Hui",
    "title": "OPG-Policy: Occluded Push-Grasp Policy Learning with Amodal Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "205",
    "authors": "Dosunmu-Ogunbi, Oluwami; Shrivastava, Aayushi; Grizzle, J.W",
    "title": "Demonstrating a Robust Walking Algorithm for Underactuated Bipedal Robots in Non-flat, Non-stationary Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.02486v2",
    "arxiv_abstract": "This work explores an innovative algorithm designed to enhance the mobility\nof underactuated bipedal robots across challenging terrains, especially when\nnavigating through spaces with constrained opportunities for foot support, like\nsteps or stairs. By combining ankle torque with a refined angular\nmomentum-based linear inverted pendulum model (ALIP), our method allows\nvariability in the robot's center of mass height. We employ a dual-strategy\ncontroller that merges virtual constraints for precise motion regulation across\nessential degrees of freedom with an ALIP-centric model predictive control\n(MPC) framework, aimed at enforcing gait stability. The effectiveness of our\nfeedback design is demonstrated through its application on the Cassie bipedal\nrobot, which features 20 degrees of freedom. Key to our implementation is the\ndevelopment of tailored nominal trajectories and an optimized MPC that reduces\nthe execution time to under 500 microseconds--and, hence, is compatible with\nCassie's controller update frequency. This paper not only showcases the\nsuccessful hardware deployment but also demonstrates a new capability, a\nbipedal robot using a moving walkway."
  },
  {
    "paper_no": "209",
    "authors": "Hu, Haotian; Wang, Fanyi; Zhang, Zhiwang",
    "title": "IC-FPS: Instance-Centroid Faster Point Sampling Framework for 3D Point-based Object Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "210",
    "authors": "Li, Kunyi; Niemeyer, Michael; Navab, Nassir; Tombari, Federico",
    "title": "DNS-SLAM: Dense Neural Semantic-Informed SLAM",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "211",
    "authors": "Yang, Yifan; Cui, Zhihao; Zhang, Qianyi; Liu, Jingtai",
    "title": "PS6D: Point Cloud Based Symmetry-Aware 6D Object Pose Estimation in Robot Bin-Picking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "214",
    "authors": "Aygul, Cem; Pandey, Ritwik; Kothimbakam, Krishram; Yilmaz Akkaya, Ceren; Rao, Pratap; Nemitz, Markus",
    "title": "Integrated Electronic Circuitry for Soft Robots using Multi-Material FDM Printing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "215",
    "authors": "Liu, Min; Yang, Gang; Luo, Siyuan; Shao, Lin",
    "title": "SoftMAC: Differentiable Soft Body Simulation with Forecast-based Contact Model and Two-way Coupling with Articulated Rigid Bodies and Clothes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "217",
    "authors": "He, Zewen; Ishigaki, Taiki; Yamamoto, Ko",
    "title": "Compliance Optimization Control for Rigid-Soft Hybrid System and its Application in Humanoid Robot Motion Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "218",
    "authors": "Huang, Shuangyao; Zhang, Haibo; Huang, Zhiyi",
    "title": "CoDe: A Cooperative and Decentralized Collision Avoidance Algorithm for Small-Scale UAV Swarms Considering Energy Efficiency",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "219",
    "authors": "Valencia Redrovan, David Patricio; Williams, Henry; Xing, Yuning; Gee, Trevor; Liarokapis, Minas; MacDonald, Bruce",
    "title": "Image-Based Deep Reinforcement Learning with Intrinsically Motivated Stimuli: On the Execution of Complex Robotic Tasks",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.21338v1",
    "arxiv_abstract": "Reinforcement Learning (RL) has been widely used to solve tasks where the\nenvironment consistently provides a dense reward value. However, in real-world\nscenarios, rewards can often be poorly defined or sparse. Auxiliary signals are\nindispensable for discovering efficient exploration strategies and aiding the\nlearning process. In this work, inspired by intrinsic motivation theory, we\npostulate that the intrinsic stimuli of novelty and surprise can assist in\nimproving exploration in complex, sparsely rewarded environments. We introduce\na novel sample-efficient method able to learn directly from pixels, an\nimage-based extension of TD3 with an autoencoder called \\textit{NaSA-TD3}. The\nexperiments demonstrate that NaSA-TD3 is easy to train and an efficient method\nfor tackling complex continuous-control robotic tasks, both in simulated\nenvironments and real-world settings. NaSA-TD3 outperforms existing\nstate-of-the-art RL image-based methods in terms of final performance without\nrequiring pre-trained models or human demonstrations."
  },
  {
    "paper_no": "221",
    "authors": "Kim, Heecheol; Ohmura, Yoshiyuki; Kuniyoshi, Yasuo",
    "title": "Multi-task real-robot data with gaze attention for dual-arm fine manipulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2401.07603v3",
    "arxiv_abstract": "In the field of robotic manipulation, deep imitation learning is recognized\nas a promising approach for acquiring manipulation skills. Additionally,\nlearning from diverse robot datasets is considered a viable method to achieve\nversatility and adaptability. In such research, by learning various tasks,\nrobots achieved generality across multiple objects. However, such multi-task\nrobot datasets have mainly focused on single-arm tasks that are relatively\nimprecise, not addressing the fine-grained object manipulation that robots are\nexpected to perform in the real world. This paper introduces a dataset of\ndiverse object manipulations that includes dual-arm tasks and/or tasks\nrequiring fine manipulation. To this end, we have generated dataset with 224k\nepisodes (150 hours, 1,104 language instructions) which includes dual-arm fine\ntasks such as bowl-moving, pencil-case opening or banana-peeling, and this data\nis publicly available. Additionally, this dataset includes visual attention\nsignals as well as dual-action labels, a signal that separates actions into a\nrobust reaching trajectory and precise interaction with objects, and language\ninstructions to achieve robust and precise object manipulation. We applied the\ndataset to our Dual-Action and Attention (DAA), a model designed for\nfine-grained dual arm manipulation tasks and robust against covariate shifts.\nThe model was tested with over 7k total trials in real robot manipulation\ntasks, demonstrating its capability in fine manipulation."
  },
  {
    "paper_no": "224",
    "authors": "YANG, Guidong; Zhang, Jihan; ZHAO, Benyun; GAO, CHUANXIANG; HUANG, Yijun; Wen, Junjie; Li, Qingxiang; Chen, Xi; Chen, Ben M.",
    "title": "Det-Recon-Reg: An Intelligent Framework Towards Automated Large-Scale Infrastructure Inspection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "226",
    "authors": "Tsakmakopoulou, Dimitra; Moustakas, Konstantinos",
    "title": "Perception for Connected Autonomous Vehicles under Adverse Weather Conditions",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "227",
    "authors": "Flögel, Daniel; Fischer, Lars; Rudolf, Thomas; Schürmann, Tobias; Hohmann, Sören",
    "title": "Socially Integrated Navigation: A Social Acting Robot with Deep Reinforcement Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.09793v3",
    "arxiv_abstract": "Mobile robots are being used on a large scale in various crowded situations\nand become part of our society. The socially acceptable navigation behavior of\na mobile robot with individual human consideration is an essential requirement\nfor scalable applications and human acceptance. Deep Reinforcement Learning\n(DRL) approaches are recently used to learn a robot's navigation policy and to\nmodel the complex interactions between robots and humans. We propose to divide\nexisting DRL-based navigation approaches based on the robot's exhibited social\nbehavior and distinguish between social collision avoidance with a lack of\nsocial behavior and socially aware approaches with explicit predefined social\nbehavior. In addition, we propose a novel socially integrated navigation\napproach where the robot's social behavior is adaptive and emerges from the\ninteraction with humans. The formulation of our approach is derived from a\nsociological definition, which states that social acting is oriented toward the\nacting of others. The DRL policy is trained in an environment where other\nagents interact socially integrated and reward the robot's behavior\nindividually. The simulation results indicate that the proposed socially\nintegrated navigation approach outperforms a socially aware approach in terms\nof ego navigation performance while significantly reducing the negative impact\non all agents within the environment."
  },
  {
    "paper_no": "234",
    "authors": "Luo, Chuanyu; Cheng, Nuo; Ma, Sikun; Xiang, Jun; Li, Xiaohan; Lei, Shengguang; Li, Pu",
    "title": "mini-PointNetPlus: A Local Feature Descriptor in Deep Learning Model for Real-time 3D Environment Perception",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "236",
    "authors": "NATE, Issei; Hirai, Shinichi",
    "title": "Passive Underwater Robot Hand Utilizing Water Resistance",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "241",
    "authors": "Arai, Ryo; Sakai, Satoru; Ono, Kazuki",
    "title": "Response Improvement of Hydraulic Robotic Joints via New Force Servo and Inverted Pendulum Demo",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "243",
    "authors": "Xiang, Yu; Allu, Sai Haneesh; Peddi, Rohith; Summers, Tyler; GOGATE, VIBHAV",
    "title": "Grasping Trajectory Optimization with Point Clouds",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.05466v2",
    "arxiv_abstract": "We introduce a new trajectory optimization method for robotic grasping based\non a point-cloud representation of robots and task spaces. In our method,\nrobots are represented by 3D points on their link surfaces. The task space of a\nrobot is represented by a point cloud that can be obtained from depth sensors.\nUsing the point-cloud representation, goal reaching in grasping can be\nformulated as point matching, while collision avoidance can be efficiently\nachieved by querying the signed distance values of the robot points in the\nsigned distance field of the scene points. Consequently, a constrained\nnonlinear optimization problem is formulated to solve the joint motion and\ngrasp planning problem. The advantage of our method is that the point-cloud\nrepresentation is general to be used with any robot in any environment. We\ndemonstrate the effectiveness of our method by performing experiments on a\ntabletop scene and a shelf scene for grasping with a Fetch mobile manipulator\nand a Franka Panda arm. The project page is available at\n\\url{https://irvlutd.github.io/GraspTrajOpt}"
  },
  {
    "paper_no": "246",
    "authors": "Dang, Tuan; Nguyen, Khang; Huber, Manfred",
    "title": "V3D-SLAM: Robust RGB-D SLAM in Dynamic Environments with 3D Semantic Geometry Voting",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "250",
    "authors": "Xu, Shaohang; Zhang, Wentao; Zhu, Lijun",
    "title": "KLILO: Kalman Filter based LiDAR-Inertial-Leg Odometry for Legged Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "253",
    "authors": "Taylor, Annalisa; Landis, Malachi; Wang, Yaoke; Murphey, Todd; Guo, Ping",
    "title": "Image to Patterning: Density-specified Patterning of Micro-structured Surfaces with a Mobile Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "254",
    "authors": "Cao, Hu; li, Yanpeng; Liu, Yinlong; Li, Xinyi; Chen, Guang; Knoll, Alois",
    "title": "Lightweight Fisheye Object Detection Network with Transformer-based Feature Enhancement for Autonomous Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "255",
    "authors": "Asano, Fumihiko; Komori, Mikito; Sedoguchi, Taiki; Zheng, Yanqiu",
    "title": "Stable Wheel Gait Generation for Planar X-shaped Walker with Telescopic Legs Based on Asymmetric Impact Posture",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "261",
    "authors": "Jiang, Wenyi; Xv, Baowei; Cui, Zhihao",
    "title": "Behavior-Actor: Behavioral Decomposition and Efficient-Training for Robotic Manipulation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "262",
    "authors": "REN, Tianyu; Chalvatzaki, Georgia; Peters, Jan",
    "title": "Extended Tree Search for Robot Task and Motion Planning",
    "arxiv_pdf": "http://arxiv.org/pdf/2103.05456v3",
    "arxiv_abstract": "Integrated task and motion planning (TAMP) is desirable for generalized\nautonomy robots but it is challenging at the same time. TAMP requires the\nplanner to not only search in both the large symbolic task space and the\nhigh-dimension motion space but also deal with the infeasible task actions due\nto its intrinsic hierarchical process. We propose a novel decision-making\nframework for TAMP by constructing an extended decision tree for both symbolic\ntask planning and high-dimension motion variable binding. We integrate top-k\nplanning for generating explicitly a skeleton space where a variety of\ncandidate skeleton plans are at disposal. Moreover, we effectively combine this\nskeleton space with the resultant motion variable spaces into a single extended\ndecision space. Accordingly, we use Monte-Carlo Tree Search (MCTS) to ensure an\nexploration-exploitation balance at each decision node and optimize globally to\nproduce optimal solutions. The proposed seamless combination of symbolic top-k\nplanning with streams, with the proved optimality of MCTS, leads to a powerful\nplanning algorithm that can handle the combinatorial complexity of long-horizon\nmanipulation tasks. We empirically evaluate our proposed algorithm in\nchallenging robot tasks with different domains that require multi-stage\ndecisions and show how our method can overcome the large task space and motion\nspace through its effective tree search compared to its most competitive\nbaseline method."
  },
  {
    "paper_no": "271",
    "authors": "Sun, Wei; Qiu, Lili",
    "title": "Visual Timing For Sound Source Depth Estimation in the Wild",
    "arxiv_pdf": "http://arxiv.org/pdf/2207.03074v2",
    "arxiv_abstract": "Depth estimation enables a wide variety of 3D applications, such as robotics,\nautonomous driving, and virtual reality. Despite significant work in this area,\nit remains open how to enable accurate, low-cost, high-resolution, and\nlarge-range depth estimation. Inspired by the flash-to-bang phenomenon (i.e.\nhearing the thunder after seeing the lightning), this paper develops FBDepth,\nthe first audio-visual depth estimation framework. It takes the difference\nbetween the time-of-flight (ToF) of the light and the sound to infer the sound\nsource depth. FBDepth is the first to incorporate video and audio with both\nsemantic features and spatial hints for range estimation. It first aligns\ncorrespondence between the video track and audio track to locate the target\nobject and target sound in a coarse granularity. Based on the observation of\nmoving objects' trajectories, FBDepth proposes to estimate the intersection of\noptical flow before and after the sound production to locate video events in\ntime. FBDepth feeds the estimated timestamp of the video event and the audio\nclip for the final depth estimation. We use a mobile phone to collect 3000+\nvideo clips with 20 different objects at up to $50m$. FBDepth decreases the\nAbsolute Relative error (AbsRel) by 55\\% compared to RGB-based methods."
  },
  {
    "paper_no": "272",
    "authors": "zhang, zhentong; liu, juan; li, xinde; Hu, Chuanfei; Dunkin, Fir; zhang, shaokun",
    "title": "A Novel Framework for Structure Descriptors-Guided Hand-drawn Floor Plan Reconstruction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "273",
    "authors": "Van Vo, Tuan; Vu, Minh Nhat; Huang, Baoru; Vuong, An Dinh; Le, Ngan; Vo, Thieu; Nguyen, Anh",
    "title": "Language-driven Grasp Detection with Mask-guided Attention",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.19877v1",
    "arxiv_abstract": "Grasp detection is an essential task in robotics with various industrial\napplications. However, traditional methods often struggle with occlusions and\ndo not utilize language for grasping. Incorporating natural language into grasp\ndetection remains a challenging task and largely unexplored. To address this\ngap, we propose a new method for language-driven grasp detection with\nmask-guided attention by utilizing the transformer attention mechanism with\nsemantic segmentation features. Our approach integrates visual data,\nsegmentation mask features, and natural language instructions, significantly\nimproving grasp detection accuracy. Our work introduces a new framework for\nlanguage-driven grasp detection, paving the way for language-driven robotic\napplications. Intensive experiments show that our method outperforms other\nrecent baselines by a clear margin, with a 10.0% success score improvement. We\nfurther validate our method in real-world robotic experiments, confirming the\neffectiveness of our approach."
  },
  {
    "paper_no": "274",
    "authors": "Tan, Zhen; Zhou, Zongtan; Ge, Yangbing; Wang, Zi; Chen, Xieyuanli; Hu, Dewen",
    "title": "TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "275",
    "authors": "OBrien, Reuben; Lambrechtse-Reid, Martin; Liarokapis, Minas",
    "title": "An Autonomous, 3D Printed, Waterjet-Powered, Open-Source Robotic Trimaran for Environmental Inspection and Monitoring",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "278",
    "authors": "Munir, Aiman; Latif, Ehsan; Parasuraman, Ramviyas",
    "title": "Anchor-Oriented Localized Voronoi Partitioning for GPS-denied Multi-Robot Coverage",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.06296v1",
    "arxiv_abstract": "Multi-robot coverage is crucial in numerous applications, including\nenvironmental monitoring, search and rescue operations, and precision\nagriculture. In modern applications, a multi-robot team must collaboratively\nexplore unknown spatial fields in GPS-denied and extreme environments where\nglobal localization is unavailable. Coverage algorithms typically assume that\nthe robot positions and the coverage environment are defined in a global\nreference frame. However, coordinating robot motion and ensuring coverage of\nthe shared convex workspace without global localization is challenging. This\npaper proposes a novel anchor-oriented coverage (AOC) approach to generate\ndynamic localized Voronoi partitions based around a common anchor position. We\nfurther propose a consensus-based coordination algorithm that achieves\nagreement on the coverage workspace around the anchor in the robots' relative\nframes of reference. Through extensive simulations and real-world experiments,\nwe demonstrate that the proposed anchor-oriented approach using localized\nVoronoi partitioning performs as well as the state-of-the-art coverage\ncontroller using GPS."
  },
  {
    "paper_no": "281",
    "authors": "Koda, Yuta; Osawa, Hiroshi; Nagatsuka, Norio; Kariya, Shinichi; Inagawa, Taeko; Ishizuka, Kensaku",
    "title": "Development of Bidirectional Series Elastic Actuator with Torsion Coil Spring and Implementation to the Legged Robot",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.15791v1",
    "arxiv_abstract": "Many studies have been conducted on Series Elastic Actuators (SEA) for robot\njoints because they are effective in terms of flexibility, safety, and energy\nefficiency. The ability of SEA to robustly handle unexpected disturbances has\nraised expectations for practical applications in environments where robots\ninteract with humans. On the other hand, the development and commercialization\nof small robots for indoor entertainment applications is also actively\nunderway, and it is thought that by using SEA in these robots, dynamic\nmovements such as jumping and running can be realized. In this work, we\ndeveloped a small and lightweight SEA using coil springs as elastic elements.\nBy devising a method for fixing the coil spring, it is possible to absorb shock\nand perform highly accurate force measurement in both rotational directions\nwith a simple structure. In addition, to verify the effectiveness of the\ndeveloped SEA, we created a small single-legged robot with SEA implemented in\nthe three joints of the hip, knee, and ankle, and we conducted a drop test. By\nadjusting the initial posture and control gain of each joint, we confirmed that\nflexible landing and continuous hopping are possible with simple PD position\ncontrol. The measurement results showed that SEA is effective in terms of shock\nabsorption and energy reuse. This work was performed for research purposes\nonly."
  },
  {
    "paper_no": "282",
    "authors": "Shi, Shuohao; fang, qiang; Zhao, Tong; Xu, Xin",
    "title": "Similarity Distance-Based Label Assignment for Tiny Object Detection",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.02394v3",
    "arxiv_abstract": "Tiny object detection is becoming one of the most challenging tasks in\ncomputer vision because of the limited object size and lack of information. The\nlabel assignment strategy is a key factor affecting the accuracy of object\ndetection. Although there are some effective label assignment strategies for\ntiny objects, most of them focus on reducing the sensitivity to the bounding\nboxes to increase the number of positive samples and have some fixed\nhyperparameters need to set. However, more positive samples may not necessarily\nlead to better detection results, in fact, excessive positive samples may lead\nto more false positives. In this paper, we introduce a simple but effective\nstrategy named the Similarity Distance (SimD) to evaluate the similarity\nbetween bounding boxes. This proposed strategy not only considers both location\nand shape similarity but also learns hyperparameters adaptively, ensuring that\nit can adapt to different datasets and various object sizes in a dataset. Our\napproach can be simply applied in common anchor-based detectors in place of the\nIoU for label assignment and Non Maximum Suppression (NMS). Extensive\nexperiments on four mainstream tiny object detection datasets demonstrate\nsuperior performance of our method, especially, 1.8 AP points and 4.1 AP points\nof very tiny higher than the state-of-the-art competitors on AI-TOD. Code is\navailable at: \\url{https://github.com/cszzshi/SimD}."
  },
  {
    "paper_no": "283",
    "authors": "Liu, Han; Liu, Tian; Cui, Mingyue; Shan, Yunxiao; Zhao, Shuai; Huang, Kai",
    "title": "An Efficient Position Reconfiguration Approach for Maximizing Lifetime of Fixed-wing Swarm Drones",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "285",
    "authors": "Nguyen, Nghia; Vu, Minh Nhat; Huang, Baoru; Vuong, An Dinh; Le, Ngan; Vo, Thieu; Nguyen, Anh",
    "title": "Lightweight Language-driven Grasp Detection using Conditional Consistency Model",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.17967v1",
    "arxiv_abstract": "Language-driven grasp detection is a fundamental yet challenging task in\nrobotics with various industrial applications. In this work, we present a new\napproach for language-driven grasp detection that leverages the concept of\nlightweight diffusion models to achieve fast inference time. By integrating\ndiffusion processes with grasping prompts in natural language, our method can\neffectively encode visual and textual information, enabling more accurate and\nversatile grasp positioning that aligns well with the text query. To overcome\nthe long inference time problem in diffusion models, we leverage the image and\ntext features as the condition in the consistency model to reduce the number of\ndenoising timesteps during inference. The intensive experimental results show\nthat our method outperforms other recent grasp detection methods and\nlightweight diffusion models by a clear margin. We further validate our method\nin real-world robotic experiments to demonstrate its fast inference time\ncapability."
  },
  {
    "paper_no": "286",
    "authors": "Yin, Jie; Luo, Andrew; Du, Yilun; Cherian, Anoop; Marks, Tim K.; Le Roux, Jonathan; Gan, Chuang",
    "title": "Disentangled Acoustic Fields For Multimodal Physical Scene Understanding",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.11333v1",
    "arxiv_abstract": "We study the problem of multimodal physical scene understanding, where an\nembodied agent needs to find fallen objects by inferring object properties,\ndirection, and distance of an impact sound source. Previous works adopt\nfeed-forward neural networks to directly regress the variables from sound,\nleading to poor generalization and domain adaptation issues. In this paper, we\nillustrate that learning a disentangled model of acoustic formation, referred\nto as disentangled acoustic field (DAF), to capture the sound generation and\npropagation process, enables the embodied agent to construct a spatial\nuncertainty map over where the objects may have fallen. We demonstrate that our\nanalysis-by-synthesis framework can jointly infer sound properties by\nexplicitly decomposing and factorizing the latent space of the disentangled\nmodel. We further show that the spatial uncertainty map can significantly\nimprove the success rate for the localization of fallen objects by proposing\nmultiple plausible exploration locations."
  },
  {
    "paper_no": "289",
    "authors": "Wu, Qianliang; Ding, Yaqing; Luo, Lei; Jiang, Haobo; Gu, Shuo; Zhou, Chuanwei; Xie, Jin; YANG, JIAN",
    "title": "SGNet: Salient Geometric Network for Point Cloud Registration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "290",
    "authors": "Li, Leheng; Lian, Qing; Chen, Yingcong",
    "title": "Adv3D: Generating 3D Adversarial Examples for 3D Object Detection in Driving Scenarios with NeRF",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "291",
    "authors": "Ko, Tianyi; Ikeda, Takuya; Stewart, Thomas; Lee, Robert; Nishiwaki, Koichi",
    "title": "Gravity-aware Grasp Generation with Implicit Grasp Mode Selection for Underactuated Hands",
    "arxiv_pdf": "http://arxiv.org/pdf/2312.11804v3",
    "arxiv_abstract": "Learning-based grasp detectors typically assume a precision grasp, where each\nfinger only has one contact point, and estimate the grasp probability. In this\nwork, we propose a data generation and learning pipeline that can leverage\npower grasping, which has more contact points with an enveloping configuration\nand is robust against both positioning error and force disturbance. To train a\ngrasp detector to prioritize power grasping while still keeping precision\ngrasping as the secondary choice, we propose to train the network against the\nmagnitude of disturbance in the gravity direction a grasp can resist\n(gravity-rejection score) rather than the binary classification of success. We\nalso provide an efficient data generation pipeline for a dataset with\ngravity-rejection score annotation. In addition to thorough ablation studies,\nquantitative evaluation in both simulation and real-robot clarifies the\nsignificant improvement in our approach, especially when the objects are heavy."
  },
  {
    "paper_no": "293",
    "authors": "Sha, Hao; Cui, Yuxiang; Lu, Wangtao; Zhang, Dongkun; Wang, Chaoqun; Wu, Jun; Xiong, Rong; Wang, Yue",
    "title": "Efficient Global Trajectory Planning for Multi-robot System with Affinely Deformable Formation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "294",
    "authors": "Jiang, Yuxuan; Yang, Yujie; Lan, Zhiqian; Zhan, Guojian; Li, Shengbo Eben; Sun, Qi; Ma, Jian; Yu, Tianwen; Zhang, Changwu",
    "title": "Rocket Landing Control with Random Annealing Jump Start Reinforcement Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.15083v1",
    "arxiv_abstract": "Rocket recycling is a crucial pursuit in aerospace technology, aimed at\nreducing costs and environmental impact in space exploration. The primary focus\ncenters on rocket landing control, involving the guidance of a nonlinear\nunderactuated rocket with limited fuel in real-time. This challenging task\nprompts the application of reinforcement learning (RL), yet goal-oriented\nnature of the problem poses difficulties for standard RL algorithms due to the\nabsence of intermediate reward signals. This paper, for the first time,\nsignificantly elevates the success rate of rocket landing control from 8% with\na baseline controller to 97% on a high-fidelity rocket model using RL. Our\napproach, called Random Annealing Jump Start (RAJS), is tailored for real-world\ngoal-oriented problems by leveraging prior feedback controllers as guide policy\nto facilitate environmental exploration and policy learning in RL. In each\nepisode, the guide policy navigates the environment for the guide horizon,\nfollowed by the exploration policy taking charge to complete remaining steps.\nThis jump-start strategy prunes exploration space, rendering the problem more\ntractable to RL algorithms. The guide horizon is sampled from a uniform\ndistribution, with its upper bound annealing to zero based on performance\nmetrics, mitigating distribution shift and mismatch issues in existing methods.\nAdditional enhancements, including cascading jump start, refined reward and\nterminal condition, and action smoothness regulation, further improve policy\nperformance and practical applicability. The proposed method is validated\nthrough extensive evaluation and Hardware-in-the-Loop testing, affirming the\neffectiveness, real-time feasibility, and smoothness of the proposed\ncontroller."
  },
  {
    "paper_no": "295",
    "authors": "Luu, Tung; Nguyen, Thanh; Tee, Joshua Tian Jin; Kim, Sungwoong; Yoo, Chang D.",
    "title": "Mitigating Adversarial Perturbations for Deep Reinforcement Learning via Vector Quantization",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.03376v1",
    "arxiv_abstract": "Recent studies reveal that well-performing reinforcement learning (RL) agents\nin training often lack resilience against adversarial perturbations during\ndeployment. This highlights the importance of building a robust agent before\ndeploying it in the real world. Most prior works focus on developing robust\ntraining-based procedures to tackle this problem, including enhancing the\nrobustness of the deep neural network component itself or adversarially\ntraining the agent on strong attacks. In this work, we instead study an input\ntransformation-based defense for RL. Specifically, we propose using a variant\nof vector quantization (VQ) as a transformation for input observations, which\nis then used to reduce the space of adversarial attacks during testing,\nresulting in the transformed observations being less affected by attacks. Our\nmethod is computationally efficient and seamlessly integrates with adversarial\ntraining, further enhancing the robustness of RL agents against adversarial\nattacks. Through extensive experiments in multiple environments, we demonstrate\nthat using VQ as the input transformation effectively defends against\nadversarial attacks on the agent's observations."
  },
  {
    "paper_no": "304",
    "authors": "Mahuttanatan, Suksakaow; Asawalertsak, Naris; Paripurana, Jinjuta; Tarapongnivat, Kanut; Chuthong, Thirawat; Manoonpong, Poramate",
    "title": "S-BUN: Soft Bifunctional Utility Module for Robot Sensing and Signaling",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "309",
    "authors": "Liao, Lizhou; Yan, Wenlei; Sun, Li; Bai, Xinhui; You, Zhenxing; Yuan, Hongyuan; Fu, Chunyun",
    "title": "NDT-Map-Code: A 3D global descriptor for real-time loop closure detection in lidar SLAM",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "312",
    "authors": "Verdoja, Francesco; Kucner, Tomasz Piotr; Kyrki, Ville",
    "title": "Bayesian Floor Field: Transferring people flow predictions across environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2208.10851v2",
    "arxiv_abstract": "Mapping people dynamics is a crucial skill for robots, because it enables\nthem to coexist in human-inhabited environments. However, learning a model of\npeople dynamics is a time consuming process which requires observation of large\namount of people moving in an environment. Moreover, approaches for mapping\ndynamics are unable to transfer the learned models across environments: each\nmodel is only able to describe the dynamics of the environment it has been\nbuilt in. However, the impact of architectural geometry on people's movement\ncan be used to anticipate their patterns of dynamics, and recent work has\nlooked into learning maps of dynamics from occupancy. So far however,\napproaches based on trajectories and those based on geometry have not been\ncombined. In this work we propose a novel Bayesian approach to learn people\ndynamics able to combine knowledge about the environment geometry with\nobservations from human trajectories. An occupancy-based deep prior is used to\nbuild an initial transition model without requiring any observations of\npedestrian; the model is then updated when observations become available using\nBayesian inference. We demonstrate the ability of our model to increase data\nefficiency and to generalize across real large-scale environments, which is\nunprecedented for maps of dynamics."
  },
  {
    "paper_no": "313",
    "authors": "Zimmerman, Nicky; Giusti, Alessandro; Guzzi, Jerome",
    "title": "Resource-Aware Collaborative Monte Carlo Localization with Distribution Compression",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.02010v1",
    "arxiv_abstract": "Global localization is essential in enabling robot autonomy, and\ncollaborative localization is key for multi-robot systems. In this paper, we\naddress the task of collaborative global localization under computational and\ncommunication constraints. We propose a method which reduces the amount of\ninformation exchanged and the computational cost. We also analyze, implement\nand open-source seminal approaches, which we believe to be a valuable\ncontribution to the community. We exploit techniques for distribution\ncompression in near-linear time, with error guarantees. We evaluate our\napproach and the implemented baselines on multiple challenging scenarios,\nsimulated and real-world. Our approach can run online on an onboard computer.\nWe release an open-source C++/ROS2 implementation of our approach, as well as\nthe baselines"
  },
  {
    "paper_no": "315",
    "authors": "Zhang, Yu; Tian, Guangyao; Wen, Long; Yao, Xiangtong; Zhang, Liding; Bing, Zhenshan; He, Wei; Knoll, Alois",
    "title": "Online Efficient Safety-Critical Control for Mobile Robots in Unknown Dynamic Multi-Obstacle Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.16449v1",
    "arxiv_abstract": "This paper proposes a LiDAR-based goal-seeking and exploration framework,\naddressing the efficiency of online obstacle avoidance in unstructured\nenvironments populated with static and moving obstacles. This framework\naddresses two significant challenges associated with traditional dynamic\ncontrol barrier functions (D-CBFs): their online construction and the\ndiminished real-time performance caused by utilizing multiple D-CBFs. To tackle\nthe first challenge, the framework's perception component begins with\nclustering point clouds via the DBSCAN algorithm, followed by encapsulating\nthese clusters with the minimum bounding ellipses (MBEs) algorithm to create\nelliptical representations. By comparing the current state of MBEs with those\nstored from previous moments, the differentiation between static and dynamic\nobstacles is realized, and the Kalman filter is utilized to predict the\nmovements of the latter. Such analysis facilitates the D-CBF's online\nconstruction for each MBE. To tackle the second challenge, we introduce buffer\nzones, generating Type-II D-CBFs online for each identified obstacle. Utilizing\nthese buffer zones as activation areas substantially reduces the number of\nD-CBFs that need to be activated. Upon entering these buffer zones, the system\nprioritizes safety, autonomously navigating safe paths, and hence referred to\nas the exploration mode. Exiting these buffer zones triggers the system's\ntransition to goal-seeking mode. We demonstrate that the system's states under\nthis framework achieve safety and asymptotic stabilization. Experimental\nresults in simulated and real-world environments have validated our framework's\ncapability, allowing a LiDAR-equipped mobile robot to efficiently and safely\nreach the desired location within dynamic environments containing multiple\nobstacles."
  },
  {
    "paper_no": "316",
    "authors": "Tadeja, Slawomir Konrad; Zhou, Tianye; Capponi, Matteo; Walas, Krzysztof, Tadeusz; Bohné, Thomas; Forni, Fulvio",
    "title": "Using Augmented Reality in Human-Robot Assembly: A Comparative Study of Eye-Gaze and Hand-Ray Pointing Methods",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "319",
    "authors": "Fan, Songyuan; Piao, Haiyin; Hu, Yi; Jiang, Feng; Yang, Roushu",
    "title": "Deep Ad-hoc Sub-Team Partition Learning for Multi-Agent Air Combat Cooperation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "320",
    "authors": "Theunissen, Mathilde; Fantoni, Isabelle; Malis, Ezio; Martinet, Philippe",
    "title": "Robustness Study of Optimal Geometries for Cooperative Multi-Robot Localization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "321",
    "authors": "Chen, Jiaxing; Yuan, Weilin; Chen, Shaofei; liu, furong; MA, AO; Hu, Zhenzhen; Li, Peng",
    "title": "Offline Meta-Reinforcement Learning with Evolving Gradient Agreement",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "322",
    "authors": "Li, Yi; Cao, Hoang-Giang; Dao, Cong-Tinh; Chen, Yu-Cheng; Wu, I-Chen",
    "title": "Gradient-based Regularization for Action Smoothness in Robotic Control with Reinforcement Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.04315v1",
    "arxiv_abstract": "Deep Reinforcement Learning (DRL) has achieved remarkable success, ranging\nfrom complex computer games to real-world applications, showing the potential\nfor intelligent agents capable of learning in dynamic environments. However,\nits application in real-world scenarios presents challenges, including the\njerky problem, in which jerky trajectories not only compromise system safety\nbut also increase power consumption and shorten the service life of robotic and\nautonomous systems. To address jerky actions, a method called conditioning for\naction policy smoothness (CAPS) was proposed by adding regularization terms to\nreduce the action changes. This paper further proposes a novel method, named\nGradient-based CAPS (Grad-CAPS), that modifies CAPS by reducing the difference\nin the gradient of action and then uses displacement normalization to enable\nthe agent to adapt to invariant action scales. Consequently, our method\neffectively reduces zigzagging action sequences while enhancing policy\nexpressiveness and the adaptability of our method across diverse scenarios and\nenvironments. In the experiments, we integrated Grad-CAPS with different\nreinforcement learning algorithms and evaluated its performance on various\nrobotic-related tasks in DeepMind Control Suite and OpenAI Gym environments.\nThe results demonstrate that Grad-CAPS effectively improves performance while\nmaintaining a comparable level of smoothness compared to CAPS and Vanilla\nagents."
  },
  {
    "paper_no": "323",
    "authors": "Zhang, Qiang; Cui, Peter; Yan, David; SUN, Jingkai; DUAN, YIQUN; Han, Gang; Zhao, Wen; ZHANG, Weining; Guo, Yijie; Zhang, Arthur; Xu, Renjing",
    "title": "Whole-body Humanoid Robot Locomotion with Human Reference",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.18294v4",
    "arxiv_abstract": "Recently, humanoid robots have made significant advances in their ability to\nperform challenging tasks due to the deployment of Reinforcement Learning (RL),\nhowever, the inherent complexity of humanoid robots, including the difficulty\nof designing complicated reward functions and training entire sophisticated\nsystems, still poses a notable challenge. To conquer these challenges, after\nmany iterations and in-depth investigations, we have meticulously developed a\nfull-size humanoid robot, \"Adam\", whose innovative structural design greatly\nimproves the efficiency and effectiveness of the imitation learning process. In\naddition, we have developed a novel imitation learning framework based on an\nadversarial motion prior, which applies not only to Adam but also to humanoid\nrobots in general. Using the framework, Adam can exhibit unprecedented\nhuman-like characteristics in locomotion tasks. Our experimental results\ndemonstrate that the proposed framework enables Adam to achieve\nhuman-comparable performance in complex locomotion tasks, marking the first\ntime that human locomotion data has been used for imitation learning in a\nfull-size humanoid robot."
  },
  {
    "paper_no": "324",
    "authors": "Reichardt, Laurenz; Uhr, Luca; Wasenmüller, Oliver",
    "title": "Text3DAug  Prompted Instance Augmentation for LiDAR Perception",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.14253v2",
    "arxiv_abstract": "LiDAR data of urban scenarios poses unique challenges, such as heterogeneous\ncharacteristics and inherent class imbalance. Therefore, large-scale datasets\nare necessary to apply deep learning methods. Instance augmentation has emerged\nas an efficient method to increase dataset diversity. However, current methods\nrequire the time-consuming curation of 3D models or costly manual data\nannotation. To overcome these limitations, we propose Text3DAug, a novel\napproach leveraging generative models for instance augmentation. Text3DAug does\nnot depend on labeled data and is the first of its kind to generate instances\nand annotations from text. This allows for a fully automated pipeline,\neliminating the need for manual effort in practical applications. Additionally,\nText3DAug is sensor agnostic and can be applied regardless of the LiDAR sensor\nused. Comprehensive experimental analysis on LiDAR segmentation, detection and\nnovel class discovery demonstrates that Text3DAug is effective in supplementing\nexisting methods or as a standalone method, performing on par or better than\nestablished methods, however while overcoming their specific drawbacks. The\ncode is publicly available."
  },
  {
    "paper_no": "325",
    "authors": "Limoyo, Oliver; Li, Jimmy; Rivkin, Dmitriy; Kelly, Jonathan; Dudek, Gregory",
    "title": "PhotoBot: Reference-Guided Interactive Photography via Natural Language",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "326",
    "authors": "Negi, Shubham; Sharma, Deepika; Kosta, Adarsh Kumar; Roy, Kaushik",
    "title": "Best of Both Worlds: Hybrid SNN-ANN Architecture for Event-based Optical Flow Estimation",
    "arxiv_pdf": "http://arxiv.org/pdf/2306.02960v2",
    "arxiv_abstract": "In the field of robotics, event-based cameras are emerging as a promising\nlow-power alternative to traditional frame-based cameras for capturing\nhigh-speed motion and high dynamic range scenes. This is due to their sparse\nand asynchronous event outputs. Spiking Neural Networks (SNNs) with their\nasynchronous event-driven compute, show great potential for extracting the\nspatio-temporal features from these event streams. In contrast, the standard\nAnalog Neural Networks (ANNs) fail to process event data effectively. However,\ntraining SNNs is difficult due to additional trainable parameters (thresholds\nand leaks), vanishing spikes at deeper layers, and a non-differentiable binary\nactivation function. Furthermore, an additional data structure, membrane\npotential, responsible for keeping track of temporal information, must be\nfetched and updated at every timestep in SNNs. To overcome these challenges, we\npropose a novel SNN-ANN hybrid architecture that combines the strengths of\nboth. Specifically, we leverage the asynchronous compute capabilities of SNN\nlayers to effectively extract the input temporal information. Concurrently, the\nANN layers facilitate training and efficient hardware deployment on traditional\nmachine learning hardware such as GPUs. We provide extensive experimental\nanalysis for assigning each layer to be spiking or analog, leading to a network\nconfiguration optimized for performance and ease of training. We evaluate our\nhybrid architecture for optical flow estimation on DSEC-flow and Multi-Vehicle\nStereo Event-Camera (MVSEC) datasets. On the DSEC-flow dataset, the hybrid\nSNN-ANN architecture achieves a 40% reduction in average endpoint error (AEE)\nwith 22% lower energy consumption compared to Full-SNN, and 48% lower AEE\ncompared to Full-ANN, while maintaining comparable energy usage."
  },
  {
    "paper_no": "327",
    "authors": "Nah, Moses; Lachner, Johannes; Tessari, Federico; Hogan, Neville",
    "title": "On the Modularity of Elementary Dynamic Actions",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.15271v2",
    "arxiv_abstract": "In this paper, a kinematically modular approach to robot control is\npresented. The method involves structures called Elementary Dynamic Actions and\na network model combining these elements. With this control framework, a rich\nrepertoire of movements can be generated by combination of basic modules. The\nproblems of solving inverse kinematics, managing kinematic singularity and\nkinematic redundancy are avoided. The modular approach is robust against\ncontact and physical interaction, which makes it particularly effective for\ncontact-rich manipulation. Each kinematic module can be learned by Imitation\nLearning, thereby resulting in a modular learning strategy for robot control.\nThe theoretical foundations and their real robot implementation are presented.\nUsing a KUKA LBR iiwa14 robot, three tasks were considered: (1) generating a\nsequence of discrete movements, (2) generating a combination of discrete and\nrhythmic movements, and (3) a drawing and erasing task. The results obtained\nindicate that this modular approach has the potential to simplify the\ngeneration of a diverse range of robot actions."
  },
  {
    "paper_no": "329",
    "authors": "Ikeda, Takuya; Zakharov, Sergey; Ko, Tianyi; Irshad, Muhammad Zubair; Lee, Robert; Liu, Katherine; Ambrus, Rares; Nishiwaki, Koichi",
    "title": "DiffusionNOCS: Managing Symmetry and Uncertainty in Sim2Real Multi-Modal Category-level Pose Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "330",
    "authors": "Yang, Rui; Gupta, Rajiv",
    "title": "P4: Pruning and Prediction-Based Priority Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "332",
    "authors": "Xie, Guoqiang; Chen, Jie; Tang, Tianhang; Chen, Zeyu; Lei, Ling; Liu, Yiguang",
    "title": "A Point-Line Features Fusion Method for Fast and Robust Monocular Visual-Inertial Initialization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "333",
    "authors": "Yun, Yeoil; Oh, DongJun; Song, Eun Jeong; Choi, Hyouk Ryeol; Moon, Hyungpil; Koo, Ja Choon",
    "title": "Adaptive Passivation of Admittance Controllers by Bypassing Power to Null Space on Redundant Manipulators",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "334",
    "authors": "Chen, Linghao; Zheng, Kangfu; Hong, Zhengdong; Zhou, Xiaowei; Su, Hao",
    "title": "EasyHeC++: Fully Automatic Hand-Eye Calibration with Pretrained Image Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "335",
    "authors": "Wang, Liuyi; Tang, Jiagui; He, Zongtao; Dang, Ronghao; Liu, Chengju; Chen, Qijun",
    "title": "Enhanced Language-guided Robot Navigation with Panoramic Semantic Depth Perception and Cross-modal Fusion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "336",
    "authors": "Arnob, Raihan Islam; Stein, Gregory",
    "title": "Active Information Gathering for Long-Horizon Navigation Under Uncertainty by Predicting the Value of Information",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.03269v1",
    "arxiv_abstract": "We address the task of long-horizon navigation in partially mapped\nenvironments for which active gathering of information about faraway unseen\nspace is essential for good behavior. We present a novel planning strategy\nthat, at training time, affords tractable computation of the value of\ninformation associated with revealing potentially informative regions of unseen\nspace, data used to train a graph neural network to predict the goodness of\ntemporally-extended exploratory actions. Our learning-augmented model-based\nplanning approach predicts the expected value of information of revealing\nunseen space and is capable of using these predictions to actively seek\ninformation and so improve long-horizon navigation. Across two simulated\noffice-like environments, our planner outperforms competitive learned and\nnon-learned baseline navigation strategies, achieving improvements of up to\n63.76% and 36.68%, demonstrating its capacity to actively seek\nperformance-critical information."
  },
  {
    "paper_no": "337",
    "authors": "Li, Yinghui; Wu, Jinze; Liu, Xin; Guo, Weizhong; Xue, Yufei",
    "title": "Experience-Learning Inspired Two-Step Reward Method for Efficient Legged Locomotion Learning Towards Natural and Robust Gaits",
    "arxiv_pdf": "http://arxiv.org/pdf/2401.12389v1",
    "arxiv_abstract": "Multi-legged robots offer enhanced stability in complex terrains, yet\nautonomously learning natural and robust motions in such environments remains\nchallenging. Drawing inspiration from animals' progressive learning patterns,\nfrom simple to complex tasks, we introduce a universal two-stage learning\nframework with two-step reward setting based on self-acquired experience, which\nefficiently enables legged robots to incrementally learn natural and robust\nmovements. In the first stage, robots learn through gait-related rewards to\ntrack velocity on flat terrain, acquiring natural, robust movements and\ngenerating effective motion experience data. In the second stage, mirroring\nanimal learning from existing experiences, robots learn to navigate challenging\nterrains with natural and robust movements using adversarial imitation\nlearning. To demonstrate our method's efficacy, we trained both quadruped\nrobots and a hexapod robot, and the policy were successfully transferred to a\nphysical quadruped robot GO1, which exhibited natural gait patterns and\nremarkable robustness in various terrains."
  },
  {
    "paper_no": "341",
    "authors": "Ren, Zhongqiang; Cai, Yilin; Wang, Hesheng",
    "title": "Multi-Agent Teamwise Cooperative Path Finding and Traffic Intersection Coordination",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "347",
    "authors": "Khindkar, Vaishnavi; Balasubramanian, Vineeth; Arora, Chetan; Subramanian, Anbumani; Jawahar, C.V.",
    "title": "Can Reasons Help Improve Pedestrian Intent Estimation? A Cross-Modal Approach",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.13302v1",
    "arxiv_abstract": "With the increased importance of autonomous navigation systems has come an\nincreasing need to protect the safety of Vulnerable Road Users (VRUs) such as\npedestrians. Predicting pedestrian intent is one such challenging task, where\nprior work predicts the binary cross/no-cross intention with a fusion of visual\nand motion features. However, there has been no effort so far to hedge such\npredictions with human-understandable reasons. We address this issue by\nintroducing a novel problem setting of exploring the intuitive reasoning behind\na pedestrian's intent. In particular, we show that predicting the 'WHY' can be\nvery useful in understanding the 'WHAT'. To this end, we propose a novel,\nreason-enriched PIE++ dataset consisting of multi-label textual\nexplanations/reasons for pedestrian intent. We also introduce a novel\nmulti-task learning framework called MINDREAD, which leverages a cross-modal\nrepresentation learning framework for predicting pedestrian intent as well as\nthe reason behind the intent. Our comprehensive experiments show significant\nimprovement of 5.6% and 7% in accuracy and F1-score for the task of intent\nprediction on the PIE++ dataset using MINDREAD. We also achieved a 4.4%\nimprovement in accuracy on a commonly used JAAD dataset. Extensive evaluation\nusing quantitative/qualitative metrics and user studies shows the effectiveness\nof our approach."
  },
  {
    "paper_no": "350",
    "authors": "Bui, Bach-Thuan; Bui, Huy Hoang; Tran, Dinh Tuan; Lee, Joo-Ho",
    "title": "Representing 3D sparse map points and lines for camera relocalization",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.18011v1",
    "arxiv_abstract": "Recent advancements in visual localization and mapping have demonstrated\nconsiderable success in integrating point and line features. However, expanding\nthe localization framework to include additional mapping components frequently\nresults in increased demand for memory and computational resources dedicated to\nmatching tasks. In this study, we show how a lightweight neural network can\nlearn to represent both 3D point and line features, and exhibit leading pose\naccuracy by harnessing the power of multiple learned mappings. Specifically, we\nutilize a single transformer block to encode line features, effectively\ntransforming them into distinctive point-like descriptors. Subsequently, we\ntreat these point and line descriptor sets as distinct yet interconnected\nfeature sets. Through the integration of self- and cross-attention within\nseveral graph layers, our method effectively refines each feature before\nregressing 3D maps using two simple MLPs. In comprehensive experiments, our\nindoor localization findings surpass those of Hloc and Limap across both\npoint-based and line-assisted configurations. Moreover, in outdoor scenarios,\nour method secures a significant lead, marking the most considerable\nenhancement over state-of-the-art learning-based methodologies. The source code\nand demo videos of this work are publicly available at:\nhttps://thpjp.github.io/pl2map/"
  },
  {
    "paper_no": "354",
    "authors": "Serussi, Gabriele; Shor, Tamir; Hirshberg, Tom; Baskin, Chaim; Bronstein, Alexander",
    "title": "Active propulsion noise shaping for multi-rotor aircraft localization",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.17289v2",
    "arxiv_abstract": "Multi-rotor aerial autonomous vehicles (MAVs) primarily rely on vision for\nnavigation purposes. However, visual localization and odometry techniques\nsuffer from poor performance in low or direct sunlight, a limited field of\nview, and vulnerability to occlusions. Acoustic sensing can serve as a\ncomplementary or even alternative modality for vision in many situations, and\nit also has the added benefits of lower system cost and energy footprint, which\nis especially important for micro aircraft. This paper proposes actively\ncontrolling and shaping the aircraft propulsion noise generated by the rotors\nto benefit localization tasks, rather than considering it a harmful nuisance.\nWe present a neural network architecture for selfnoise-based localization in a\nknown environment. We show that training it simultaneously with learning\ntime-varying rotor phase modulation achieves accurate and robust localization.\nThe proposed methods are evaluated using a computationally affordable\nsimulation of MAV rotor noise in 2D acoustic environments that is fitted to\nreal recordings of rotor pressure fields."
  },
  {
    "paper_no": "356",
    "authors": "Long, Shijun; Li, Ying; Wu, Chenming; Xu, Bin; Fan, Wei",
    "title": "HPHS: Hierarchical Planning based on Hybrid Frontier Sampling for Unknown Environments Exploration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "358",
    "authors": "Dio, Maximilian; Graichen, Knut; Völz, Andreas",
    "title": "Time-Optimal Path Parameterization for Cooperative Multi-Arm Robotic Systems with Third-Order Constraints",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "359",
    "authors": "Lai, Qianhua; Zhao, Enhao; Fan, Shicai; Zou, Jianxiao",
    "title": "MERSYS: A Collaborative Estimation and Dense Mapping System for Multi-Agent Generic SLAM",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "364",
    "authors": "Shienman, Moshe; Levy-Or, Ohad; Kaess, Michael; Indelman, Vadim",
    "title": "A Slices Perspective for Incremental Nonparametric Inference in High Dimensional State Spaces",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.16453v1",
    "arxiv_abstract": "We introduce an innovative method for incremental nonparametric probabilistic\ninference in high-dimensional state spaces. Our approach leverages \\slices from\nhigh-dimensional surfaces to efficiently approximate posterior distributions of\nany shape. Unlike many existing graph-based methods, our \\slices perspective\neliminates the need for additional intermediate reconstructions, maintaining a\nmore accurate representation of posterior distributions. Additionally, we\npropose a novel heuristic to balance between accuracy and efficiency, enabling\nreal-time operation in nonparametric scenarios. In empirical evaluations on\nsynthetic and real-world datasets, our \\slices approach consistently\noutperforms other state-of-the-art methods. It demonstrates superior accuracy\nand achieves a significant reduction in computational complexity, often by an\norder of magnitude."
  },
  {
    "paper_no": "365",
    "authors": "Wu, Yuankai; Messaoud, Rayene; Hildebrandt, Arne-Christoph; Baldini, Marco; Salihu, Driton; Patsch, Constantin; Steinbach, Eckehard",
    "title": "Enhanced Robotic Assistance for Human Activities through Human-Object Interaction Segment Prediction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "366",
    "authors": "Yang, Chenhongyi; Lin, Tianwei; Huang, Lichao; Crowley, Elliot J.",
    "title": "WidthFormer: Toward Efficient Transformer-based BEV View Transformation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "370",
    "authors": "Nishimura, Takayuki; Kuyo, Katsuyuki; Kambara, Motonari; Sugiura, Komei",
    "title": "Object Segmentation from Open-Vocabulary Manipulation Instructions Based on Optimal Transport Polygon Matching with Multimodal Foundation Models",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.00985v1",
    "arxiv_abstract": "We consider the task of generating segmentation masks for the target object\nfrom an object manipulation instruction, which allows users to give open\nvocabulary instructions to domestic service robots. Conventional segmentation\ngeneration approaches often fail to account for objects outside the camera's\nfield of view and cases in which the order of vertices differs but still\nrepresents the same polygon, which leads to erroneous mask generation. In this\nstudy, we propose a novel method that generates segmentation masks from open\nvocabulary instructions. We implement a novel loss function using optimal\ntransport to prevent significant loss where the order of vertices differs but\nstill represents the same polygon. To evaluate our approach, we constructed a\nnew dataset based on the REVERIE dataset and Matterport3D dataset. The results\ndemonstrated the effectiveness of the proposed method compared with existing\nmask generation methods. Remarkably, our best model achieved a +16.32%\nimprovement on the dataset compared with a representative polygon-based method."
  },
  {
    "paper_no": "371",
    "authors": "Meyer, Lukas; Gilson, Andreas; Schmid, Ute; Stamminger, Marc",
    "title": "FruitNeRF: A Unified Neural Radiance Field based Fruit Counting Framework",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "376",
    "authors": "Wu, Rui; Mintchev, Stefano",
    "title": "Vine Robots That Evert through Bending",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "379",
    "authors": "Pan, Xianghui; Du, Jiayuan; Liu, Chengju; Chen, Qijun; Su, Shuai; Zong, Wenhao; Wang, Xiao",
    "title": "GenerOcc: Self-supervised Framework of Real-time 3D Occupancy Prediction for Monocular Generic Cameras",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "380",
    "authors": "Guadarrama-Olvera, J. Rogelio; Kajita, Shuuji; Kanehiro, Fumio; Cheng, Gordon",
    "title": "Contact Stability Control of Stepping Over Partial Footholds Using Plantar Tactile Feedback",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "383",
    "authors": "Liu, Yuezhen; Zeng, Guangjun; Du, Xingzhou; Fang, Kaiwen; Yu, Jiangfan",
    "title": "Navigated Locomotion and Controllable Splitting of a Microswarm in a Complex Environment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "386",
    "authors": "Lee, Sibaek; Kang, Kyeongsu; Yu, Hyeonwoo",
    "title": "Just Flip: Flipped Observation Generation and Optimization for Neural Radiance Fields to Cover Unobserved View",
    "arxiv_pdf": "http://arxiv.org/pdf/2303.06335v3",
    "arxiv_abstract": "With the advent of Neural Radiance Field (NeRF), representing 3D scenes\nthrough multiple observations has shown remarkable improvements in performance.\nSince this cutting-edge technique is able to obtain high-resolution renderings\nby interpolating dense 3D environments, various approaches have been proposed\nto apply NeRF for the spatial understanding of robot perception. However,\nprevious works are challenging to represent unobserved scenes or views on the\nunexplored robot trajectory, as these works do not take into account 3D\nreconstruction without observation information. To overcome this problem, we\npropose a method to generate flipped observation in order to cover unexisting\nobservation for unexplored robot trajectory. To achieve this, we propose a data\naugmentation method for 3D reconstruction using NeRF by flipping observed\nimages, and estimating flipped camera 6DOF poses. Our technique exploits the\nproperty of objects being geometrically symmetric, making it simple but fast\nand powerful, thereby making it suitable for robotic applications where\nreal-time performance is important. We demonstrate that our method\nsignificantly improves three representative perceptual quality measures on the\nNeRF synthetic dataset."
  },
  {
    "paper_no": "387",
    "authors": "Wang, Yibin; Xiong, Yiting; Fang, Kaiwen; Yu, Jiangfan",
    "title": "Millipede-Inspired Multi-legged Magnetic Soft Robots for Targeted Locomotion in Tortuous Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "389",
    "authors": "YU, Zihan; Tang, Yuqing",
    "title": "Neural Trajectory Model: Implicit Neural Trajectory Representation for Trajectories Generation",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.01254v2",
    "arxiv_abstract": "Trajectory planning is a fundamental problem in robotics. It facilitates a\nwide range of applications in navigation and motion planning, control, and\nmulti-agent coordination. Trajectory planning is a difficult problem due to its\ncomputational complexity and real-world environment complexity with\nuncertainty, non-linearity, and real-time requirements. The multi-agent\ntrajectory planning problem adds another dimension of difficulty due to\ninter-agent interaction. Existing solutions are either search-based or\noptimization-based approaches with simplified assumptions of environment,\nlimited planning speed, and limited scalability in the number of agents. In\nthis work, we make the first attempt to reformulate single agent and\nmulti-agent trajectory planning problem as query problems over an implicit\nneural representation of trajectories. We formulate such implicit\nrepresentation as Neural Trajectory Models (NTM) which can be queried to\ngenerate nearly optimal trajectory in complex environments. We conduct\nexperiments in simulation environments and demonstrate that NTM can solve\nsingle-agent and multi-agent trajectory planning problems. In the experiments,\nNTMs achieve (1) sub-millisecond panning time using GPUs, (2) almost avoiding\nall environment collision, (3) almost avoiding all inter-agent collision, and\n(4) generating almost shortest paths. We also demonstrate that the same NTM\nframework can also be used for trajectories correction and multi-trajectory\nconflict resolution refining low quality and conflicting multi-agent\ntrajectories into nearly optimal solutions efficiently. (Open source code will\nbe available at https://github.com/laser2099/neural-trajectory-model)"
  },
  {
    "paper_no": "396",
    "authors": "Peng, Yanlong; Wang, Zhigang; Zhang, Yisheng; Zhang, Shengmin; cai, nan; Wu, Fan; Chen, Ming",
    "title": "Revolutionizing Battery Disassembly: The Design and Implementation of a Battery Disassembly Autonomous Mobile Manipulator Robot(BEAM-1)",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.06590v1",
    "arxiv_abstract": "The efficient disassembly of end-of-life electric vehicle batteries(EOL-EVBs)\nis crucial for green manufacturing and sustainable development. The current\npre-programmed disassembly conducted by the Autonomous Mobile Manipulator\nRobot(AMMR) struggles to meet the disassembly requirements in dynamic\nenvironments, complex scenarios, and unstructured processes. In this paper, we\npropose a Battery Disassembly AMMR(BEAM-1) system based on NeuralSymbolic AI.\nIt detects the environmental state by leveraging a combination of multi-sensors\nand neural predicates and then translates this information into a\nquasi-symbolic space. In real-time, it identifies the optimal sequence of\naction primitives through LLM-heuristic tree search, ensuring high-precision\nexecution of these primitives. Additionally, it employs positional speculative\nsampling using intuitive networks and achieves the disassembly of various bolt\ntypes with a meticulously designed end-effector. Importantly, BEAM-1 is a\ncontinuously learning embodied intelligence system capable of subjective\nreasoning like a human, and possessing intuition. A large number of real scene\nexperiments have proved that it can autonomously perceive, decide, and execute\nto complete the continuous disassembly of bolts in multiple, multi-category,\nand complex situations, with a success rate of 98.78%. This research attempts\nto use NeuroSymbolic AI to give robots real autonomous reasoning, planning, and\nlearning capabilities. BEAM-1 realizes the revolution of battery disassembly.\nIts framework can be easily ported to any robotic system to realize different\napplication scenarios, which provides a ground-breaking idea for the design and\nimplementation of future embodied intelligent robotic systems."
  },
  {
    "paper_no": "398",
    "authors": "Zhang, Liding; Bing, Zhenshan; Chen, Kejia; Chen, Lingyun; Cai, Kuanqi; Zhang, Yu; Wu, Fan; Krumbholz, Peter; Yuan, Zhilin; Haddadin, Sami; Knoll, Alois",
    "title": "Flexible Informed Trees (FIT*): Adaptive Batch-Size Approach in Informed Sampling-Based Path Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "401",
    "authors": "Sun, Lei",
    "title": "Outlier-Robust Geometric Perception: A Novel Thresholding-Based Estimator with Intra-Class Variance Maximization",
    "arxiv_pdf": "http://arxiv.org/pdf/2204.01324v2",
    "arxiv_abstract": "Geometric perception problems are fundamental tasks in robotics and computer\nvision. In real-world applications, they often encounter the inevitable issue\nof outliers, preventing traditional algorithms from making correct estimates.\nIn this paper, we present a novel general-purpose robust estimator TIVM\n(Thresholding with Intra-class Variance Maximization) that can collaborate with\nstandard non-minimal solvers to efficiently reject outliers for geometric\nperception problems. First, we introduce the technique of intra-class variance\nmaximization to design a dynamic 2-group thresholding method on the measurement\nresiduals, aiming to distinctively separate inliers from outliers. Then, we\ndevelop an iterative framework that robustly optimizes the model by approaching\nthe pure-inlier group using a multi-layered dynamic thresholding strategy as\nsubroutine, in which a self-adaptive mechanism for layer-number tuning is\nfurther employed to minimize the user-defined parameters. We validate the\nproposed estimator on 3 classic geometric perception problems: rotation\naveraging, point cloud registration and category-level perception, and\nexperiments show that it is robust against 70--90\\% of outliers and can\nconverge typically in only 3--15 iterations, much faster than state-of-the-art\nrobust solvers such as RANSAC, GNC and ADAPT. Furthermore, another highlight is\nthat: our estimator can retain approximately the same level of robustness even\nwhen the inlier-noise statistics of the problem are fully unknown."
  },
  {
    "paper_no": "403",
    "authors": "Jiao, Ruochen; Wang, Yixuan; Liu, Xiangguo; Zhan, Sinong; Huang, Chao; Zhu, Qi",
    "title": "Kinematics-aware Trajectory Generation and Prediction with Latent Stochastic Differential Modeling",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.09317v2",
    "arxiv_abstract": "Trajectory generation and trajectory prediction are two critical tasks in\nautonomous driving, which generate various trajectories for testing during\ndevelopment and predict the trajectories of surrounding vehicles during\noperation, respectively. In recent years, emerging data-driven deep\nlearning-based methods have shown great promise for these two tasks in learning\nvarious traffic scenarios and improving average performance without assuming\nphysical models. However, it remains a challenging problem for these methods to\nensure that the generated/predicted trajectories are physically realistic. This\nchallenge arises because learning-based approaches often function as opaque\nblack boxes and do not adhere to physical laws. Conversely, existing\nmodel-based methods provide physically feasible results but are constrained by\npredefined model structures, limiting their capabilities to address complex\nscenarios. To address the limitations of these two types of approaches, we\npropose a new method that integrates kinematic knowledge into neural stochastic\ndifferential equations (SDE) and designs a variational autoencoder based on\nthis latent kinematics-aware SDE (LK-SDE) to generate vehicle motions.\nExperimental results demonstrate that our method significantly outperforms both\nmodel-based and learning-based baselines in producing physically realistic and\nprecisely controllable vehicle trajectories. Additionally, it performs well in\npredicting unobservable physical variables in the latent space."
  },
  {
    "paper_no": "404",
    "authors": "Eum, Sungmin; Lee, Hyungtae; Kwon, Heesung; Osteen, Philip; Harrison, Andre",
    "title": "Two Teachers Are Better Than One: Leveraging Depth In Training Only For Unsupervised Obstacle Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "405",
    "authors": "Kundu, Tanmoy; Rafaeli, Moshe; Indelman, Vadim",
    "title": "Multi-Robot Communication-Aware Cooperative Belief Space Planning with Inconsistent Beliefs: An Action-Consistent Approach",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.05962v1",
    "arxiv_abstract": "Multi-robot belief space planning (MR-BSP) is essential for reliable and safe\nautonomy. While planning, each robot maintains a belief over the state of the\nenvironment and reasons how the belief would evolve in the future for different\ncandidate actions. Yet, existing MR-BSP works have a common assumption that the\nbeliefs of different robots are consistent at planning time. Such an assumption\nis often highly unrealistic, as it requires prohibitively extensive and\nfrequent communication capabilities. In practice, each robot may have a\ndifferent belief about the state of the environment. Crucially, when the\nbeliefs of different robots are inconsistent, state-of-the-art MR-BSP\napproaches could result in a lack of coordination between the robots, and in\ngeneral, could yield dangerous, unsafe and sub-optimal decisions. In this\npaper, we tackle this crucial gap. We develop a novel decentralized algorithm\nthat is guaranteed to find a consistent joint action. For a given robot, our\nalgorithm reasons for action preferences about 1) its local information, 2)\nwhat it perceives about the reasoning of the other robot, and 3) what it\nperceives about the reasoning of itself perceived by the other robot. This\nalgorithm finds a consistent joint action whenever these steps yield the same\nbest joint action obtained by reasoning about action preferences; otherwise, it\nself-triggers communication between the robots. Experimental results show\nefficacy of our algorithm in comparison with two baseline algorithms."
  },
  {
    "paper_no": "406",
    "authors": "Shi, Yucheng; wang, wenlong; Tao, Xiaowen; Dusparic, Ivana; Cahill, Vinny",
    "title": "Applying Neural Monte Carlo Tree Search to Unsignalized Multi-Intersection Scheduling for Autonomous Vehicles",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.18786v1",
    "arxiv_abstract": "Dynamic scheduling of access to shared resources by autonomous systems is a\nchallenging problem, characterized as being NP-hard. The complexity of this\ntask leads to a combinatorial explosion of possibilities in highly dynamic\nsystems where arriving requests must be continuously scheduled subject to\nstrong safety and time constraints. An example of such a system is an\nunsignalized intersection, where automated vehicles' access to potential\nconflict zones must be dynamically scheduled. In this paper, we apply Neural\nMonte Carlo Tree Search (NMCTS) to the challenging task of scheduling platoons\nof vehicles crossing unsignalized intersections. Crucially, we introduce a\ntransformation model that maps successive sequences of potentially conflicting\nroad-space reservation requests from platoons of vehicles into a series of\nboard-game-like problems and use NMCTS to search for solutions representing\noptimal road-space allocation schedules in the context of past allocations. To\noptimize search, we incorporate a prioritized re-sampling method with parallel\nNMCTS (PNMCTS) to improve the quality of training data. To optimize training, a\ncurriculum learning strategy is used to train the agent to schedule\nprogressively more complex boards culminating in overlapping boards that\nrepresent busy intersections. In a busy single four-way unsignalized\nintersection simulation, PNMCTS solved 95\\% of unseen scenarios, reducing\ncrossing time by 43\\% in light and 52\\% in heavy traffic versus first-in,\nfirst-out control. In a 3x3 multi-intersection network, the proposed method\nmaintained free-flow in light traffic when all intersections are under control\nof PNMCTS and outperformed state-of-the-art RL-based traffic-light controllers\nin average travel time by 74.5\\% and total throughput by 16\\% in heavy traffic."
  },
  {
    "paper_no": "407",
    "authors": "Xia, Youya; Nino, Jose; Han, Yutao; Campbell, Mark",
    "title": "SWIFT: Strategic Weather-informed Image-based Forecasting for Trajectories",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "409",
    "authors": "Yao, ZhuTao; Huang, Bo; Lv, Jianyong; Lu, Xiaoyu",
    "title": "Scheduling of Robotic Cellular Manufacturing Systems with Timed Petri Nets and Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "412",
    "authors": "Qian, Yilue; Yu, Peiyu; Wu, Ying Nian; Su, Yao; Wang, Wei; Fan, Lifeng",
    "title": "Learning Concept-Based Causal Transition and Symbolic Reasoning for Visual Planning",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.03325v2",
    "arxiv_abstract": "Visual planning simulates how humans make decisions to achieve desired goals\nin the form of searching for visual causal transitions between an initial\nvisual state and a final visual goal state. It has become increasingly\nimportant in egocentric vision with its advantages in guiding agents to perform\ndaily tasks in complex environments. In this paper, we propose an interpretable\nand generalizable visual planning framework consisting of i) a novel\nSubstitution-based Concept Learner (SCL) that abstracts visual inputs into\ndisentangled concept representations, ii) symbol abstraction and reasoning that\nperforms task planning via the self-learned symbols, and iii) a Visual Causal\nTransition model (ViCT) that grounds visual causal transitions to semantically\nsimilar real-world actions. Given an initial state, we perform goal-conditioned\nvisual planning with a symbolic reasoning method fueled by the learned\nrepresentations and causal transitions to reach the goal state. To verify the\neffectiveness of the proposed model, we collect a large-scale visual planning\ndataset based on AI2-THOR, dubbed as CCTP. Extensive experiments on this\nchallenging dataset demonstrate the superior performance of our method in\nvisual task planning. Empirically, we show that our framework can generalize to\nunseen task trajectories, unseen object categories, and real-world data.\nFurther details of this work are provided at\nhttps://fqyqc.github.io/ConTranPlan/."
  },
  {
    "paper_no": "413",
    "authors": "Shin, Yeongha; Kim, Hanguen; Kim, Jinwhan",
    "title": "AnytimeFusion: Parameter-free RGB Camera-Radar Sensor Fusion Algorithm in Complex Maritime Situations",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "417",
    "authors": "Liu, Zihao; Liu, Xing; Liu, Zhengxiong; Zhang, Yizhai; Huang, Panfeng",
    "title": "Tactile Active Inference Reinforcement Learning for Efficient Robotic Manipulation Skill Acquisition",
    "arxiv_pdf": "http://arxiv.org/pdf/2311.11287v1",
    "arxiv_abstract": "Robotic manipulation holds the potential to replace humans in the execution\nof tedious or dangerous tasks. However, control-based approaches are not\nsuitable due to the difficulty of formally describing open-world manipulation\nin reality, and the inefficiency of existing learning methods. Thus, applying\nmanipulation in a wide range of scenarios presents significant challenges. In\nthis study, we propose a novel method for skill learning in robotic\nmanipulation called Tactile Active Inference Reinforcement Learning\n(Tactile-AIRL), aimed at achieving efficient training. To enhance the\nperformance of reinforcement learning (RL), we introduce active inference,\nwhich integrates model-based techniques and intrinsic curiosity into the RL\nprocess. This integration improves the algorithm's training efficiency and\nadaptability to sparse rewards. Additionally, we utilize a vision-based tactile\nsensor to provide detailed perception for manipulation tasks. Finally, we\nemploy a model-based approach to imagine and plan appropriate actions through\nfree energy minimization. Simulation results demonstrate that our method\nachieves significantly high training efficiency in non-prehensile objects\npushing tasks. It enables agents to excel in both dense and sparse reward tasks\nwith just a few interaction episodes, surpassing the SAC baseline. Furthermore,\nwe conduct physical experiments on a gripper screwing task using our method,\nwhich showcases the algorithm's rapid learning capability and its potential for\npractical applications."
  },
  {
    "paper_no": "418",
    "authors": "Li, Xiangjie; Xie, Shuxiang; Sakurada, Ken; Sagawa, Ryusuke; Oishi, Takeshi",
    "title": "Implicit Neural Fusion of RGB and Far-Infrared 3D Imagery for Invisible Scenes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "419",
    "authors": "Kariyawasam Thanthrige, Yasas Mahima; Perera, Asanka; Anavatti, Sreenatha; Garratt, Matthew",
    "title": "3DR-DIFF: Blind Diffusion Inpainting for 3D Point Cloud Reconstruction and Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "425",
    "authors": "Chen, Yifei; Arturo, Gamboa-Gonzalez; Wehner, Michael; Xiong, Xiaobin",
    "title": "Explosive Legged Robotic Hopping: Energy Accumulation and Power Amplification via Pneumatic Augmentation",
    "arxiv_pdf": "http://arxiv.org/pdf/2312.05773v1",
    "arxiv_abstract": "We present a novel pneumatic augmentation to traditional electric\nmotor-actuated legged robot to increase intermittent power density to perform\ninfrequent explosive hopping behaviors. The pneumatic system is composed of a\npneumatic pump, a tank, and a pneumatic actuator. The tank is charged up by the\npump during regular hopping motion that is created by the electric motors. At\nany time after reaching a desired air pressure in the tank, a solenoid valve is\nutilized to rapidly release the air pressure to the pneumatic actuator (piston)\nwhich is used in conjunction with the electric motors to perform explosive\nhopping, increasing maximum hopping height for one or subsequent cycles. We\nshow that, on a custom-designed one-legged hopping robot, without any\nadditional power source and with this novel pneumatic augmentation system,\ntheir associated system identification and optimal control, the robot is able\nto realize highly explosive hopping with power amplification per cycle by a\nfactor of approximately 5.4 times the power of electric motor actuation alone."
  },
  {
    "paper_no": "426",
    "authors": "Gupta, Sagar; Cosgun, Akansel",
    "title": "Audio-Visual Traffic Light State Detection for Urban Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.19281v1",
    "arxiv_abstract": "We present a multimodal traffic light state detection using vision and sound,\nfrom the viewpoint of a quadruped robot navigating in urban settings. This is a\nchallenging problem because of the visual occlusions and noise from robot\nlocomotion. Our method combines features from raw audio with the ratios of red\nand green pixels within bounding boxes, identified by established vision-based\ndetectors. The fusion method aggregates features across multiple frames in a\ngiven timeframe, increasing robustness and adaptability. Results show that our\napproach effectively addresses the challenge of visual occlusion and surpasses\nthe performance of single-modality solutions when the robot is in motion. This\nstudy serves as a proof of concept, highlighting the significant, yet often\noverlooked, potential of multi-modal perception in robotics."
  },
  {
    "paper_no": "427",
    "authors": "Yu, Hao; Min, Zhe; Liu, Mingyang; Song, Rui; Li, Yibin; Meng, Max Q.-H.",
    "title": "Bidirectional Partial-to-Full Non-Rigid Point Set Registration with Non-Overlapping Filtering",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "428",
    "authors": "Chen, Ziyang; Zhou, Zhangli; Li, Lin; Kan, Zhen",
    "title": "Soft Task Planning with Hierarchical Temporal Logic Specifications",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "432",
    "authors": "Zhang, Hao; Wang, Hao; Huang, Xiucai; Chen, Wenrui; Kan, Zhen",
    "title": "Exploiting Hybrid Policy in Reinforcement Learning for Interpretable Temporal Logic Manipulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.20338v1",
    "arxiv_abstract": "Reinforcement Learning (RL) based methods have been increasingly explored for\nrobot learning. However, RL based methods often suffer from low sampling\nefficiency in the exploration phase, especially for long-horizon manipulation\ntasks, and generally neglect the semantic information from the task level,\nresulted in a delayed convergence or even tasks failure. To tackle these\nchallenges, we propose a Temporal-Logic-guided Hybrid policy framework (HyTL)\nwhich leverages three-level decision layers to improve the agent's performance.\nSpecifically, the task specifications are encoded via linear temporal logic\n(LTL) to improve performance and offer interpretability. And a waypoints\nplanning module is designed with the feedback from the LTL-encoded task level\nas a high-level policy to improve the exploration efficiency. The middle-level\npolicy selects which behavior primitives to execute, and the low-level policy\nspecifies the corresponding parameters to interact with the environment. We\nevaluate HyTL on four challenging manipulation tasks, which demonstrate its\neffectiveness and interpretability. Our project is available at:\nhttps://sites.google.com/view/hytl-0257/."
  },
  {
    "paper_no": "433",
    "authors": "Wu, Shiyao; Shentu, Yide; Yi, Zhongke; Lin, Xingyu; Abbeel, Pieter",
    "title": "GELLO: A General, Low-Cost, and Intuitive Teleoperation Framework for Robot Manipulators",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "438",
    "authors": "Yuan, Zikang; Lang, Fengtian; Xu, Tianle; Yang, Xin",
    "title": "SR-LIO: LiDAR-Inertial Odometry with Sweep Reconstruction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "439",
    "authors": "Mao, Shouren; Dong, Wei; Qin, MingHao; Liu, Huajian; Gao, Yongzhuo",
    "title": "RAM-NAS: Resource-aware Multiobjective Neural Architecture Search Method for Robot Vision Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "440",
    "authors": "Cai, Mu; Luo, Chenxu; Lee, Yong Jae; Yang, Xiaodong",
    "title": "Cross-Modal Self-Supervised Learning with Effective Contrastive Units for LiDAR Point Clouds",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.06827v1",
    "arxiv_abstract": "3D perception in LiDAR point clouds is crucial for a self-driving vehicle to\nproperly act in 3D environment. However, manually labeling point clouds is hard\nand costly. There has been a growing interest in self-supervised pre-training\nof 3D perception models. Following the success of contrastive learning in\nimages, current methods mostly conduct contrastive pre-training on point clouds\nonly. Yet an autonomous driving vehicle is typically supplied with multiple\nsensors including cameras and LiDAR. In this context, we systematically study\nsingle modality, cross-modality, and multi-modality for contrastive learning of\npoint clouds, and show that cross-modality wins over other alternatives. In\naddition, considering the huge difference between the training sources in 2D\nimages and 3D point clouds, it remains unclear how to design more effective\ncontrastive units for LiDAR. We therefore propose the instance-aware and\nsimilarity-balanced contrastive units that are tailored for self-driving point\nclouds. Extensive experiments reveal that our approach achieves remarkable\nperformance gains over various point cloud models across the downstream\nperception tasks of LiDAR based 3D object detection and 3D semantic\nsegmentation on the four popular benchmarks including Waymo Open Dataset,\nnuScenes, SemanticKITTI and ONCE."
  },
  {
    "paper_no": "443",
    "authors": "Wang, Tianheng; Roumeliotis, Stergios",
    "title": "A Direct Algorithm for Multi-Gyroscope Infield Calibration",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.08177v1",
    "arxiv_abstract": "In this paper, we address the problem of estimating the rotational\nextrinsics, as well as the scale factors of two gyroscopes rigidly mounted on\nthe same device. In particular, we formulate the problem as a least-squares\nminimization and introduce a direct algorithm that computes the estimated\nquantities without any iterations, hence avoiding local minima and improving\nefficiency. Furthermore, we show that the rotational extrinsics are observable\nwhile the scale factors can be determined up to global scale for general\nconfigurations of the gyroscopes. To this end, we also study special placements\nof the gyroscopes where a pair, or all, of their axes are parallel and analyze\ntheir impact on the scale factors' observability. Lastly, we evaluate our\nalgorithm in simulations and real-world experiments to assess its performance\nas a function of key motion and sensor characteristics."
  },
  {
    "paper_no": "444",
    "authors": "Srisuchinnawong, Arthicha; Baech, Jonas; Hyzy, Marek Piotr; Kounalakis, Tsampikos; Boukas, Evangelos; Manoonpong, Poramate",
    "title": "Unsupervised Multiple Proactive Behavior Learning of Mobile Robots for Smooth and Safe Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "446",
    "authors": "Lee, Myung Ho; Im, Jintaek; Prieto Prada, John David; Song, Cheol",
    "title": "Advanced Handheld Micro-Surgical System using Hall Sensor and Magnet Trocar for Improved Precision in Retinal Surgery",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "448",
    "authors": "Inoue, Riku; Tsuchiya, Masamitsu; Yasui, Yuji",
    "title": "Channel-wise Motion Features for Efficient Motion Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "450",
    "authors": "Pourakbarian Niaz, Pouya; Erzin, Engin; Basdogan, Cagatay",
    "title": "Learning-based Adaptive Admittance Controller for Efficient and Safe pHRI in Contact-Rich Manufacturing Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "451",
    "authors": "Cho, Gichan; Im, Jintaek; Kwon, Hyun-Jung; Song, Cheol",
    "title": "An Optical Interferometer-based Force Sensor System for Enhancing Precision in Epidural Injection Procedure",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "452",
    "authors": "Kusuhara, Rina; Higashimori, Mitsuru",
    "title": "Task-Oriented Design Method for Monolithic Flexible Hands with Wire Drive Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "457",
    "authors": "Kreutz, Thomas; Lemke, Jens; Mühlhäuser, Max; Sanchez Guinea, Alejandro",
    "title": "LiOn-XA: Unsupervised Domain Adaptation via LiDAR-Only Cross-Modal Adversarial Training",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "458",
    "authors": "Ding, Junsheng; Zhang, Haifan; Li, Weihang; Zhou, Liangwei; Perzylo, Alexander Clifford",
    "title": "Knowledge-based Programming by Demonstration using semantic action models for industrial assembly",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "460",
    "authors": "Opra, István Balázs; Le Dem, Betty; Walls, Jeffrey; Lukarski, Dimitar; Stachniss, Cyrill",
    "title": "Leveraging GNSS and Onboard Visual Data from Consumer Vehicles for Robust Road Network Estimation",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.01640v1",
    "arxiv_abstract": "Maps are essential for diverse applications, such as vehicle navigation and\nautonomous robotics. Both require spatial models for effective route planning\nand localization. This paper addresses the challenge of road graph construction\nfor autonomous vehicles. Despite recent advances, creating a road graph remains\nlabor-intensive and has yet to achieve full automation. The goal of this paper\nis to generate such graphs automatically and accurately. Modern cars are\nequipped with onboard sensors used for today's advanced driver assistance\nsystems like lane keeping. We propose using global navigation satellite system\n(GNSS) traces and basic image data acquired from these standard sensors in\nconsumer vehicles to estimate road-level maps with minimal effort. We exploit\nthe spatial information in the data by framing the problem as a road centerline\nsemantic segmentation task using a convolutional neural network. We also\nutilize the data's time series nature to refine the neural network's output by\nusing map matching. We implemented and evaluated our method using a fleet of\nreal consumer vehicles, only using the deployed onboard sensors. Our evaluation\ndemonstrates that our approach not only matches existing methods on simpler\nroad configurations but also significantly outperforms them on more complex\nroad geometries and topologies. This work received the 2023 Woven by Toyota\nInvention Award."
  },
  {
    "paper_no": "463",
    "authors": "Wu, Qiwei; Peng, Xuanbin; Zhou, Jiayu; Sun, Zhuoran; Xiong, Xiaogang; Lou, Yunjiang",
    "title": "RTTF: Rapid Tactile Transfer Framework for Contact-Rich Manipulation Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "464",
    "authors": "Zieli&#324;ski, Krzysztof; Penning, Ryan; Blumberg, Bruce; Schlette, Christian; Mikkel, Kjærgaard",
    "title": "RobotGraffiti: An AR tool for semi-automated construction of workcell models to optimize robot deployment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "465",
    "authors": "Fu, Xingdou; Miao, Lin; Ohnishi, Yasuhiro; Hasegawa, Yuki; Suwa, Masaki",
    "title": "A low-cost, high-speed, and robust bin picking system for factory automation enabled by a none-stop, multiple-view, and active vision scheme",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.00706v1",
    "arxiv_abstract": "Bin picking systems in factory automation usually face robustness issues\ncaused by sparse and noisy 3D data of metallic objects. Utilizing multiple\nviews, especially with a one-shot 3D sensor and \"sensor on hand\" configuration\nis getting more popularity due to its effectiveness, flexibility, and low cost.\nWhile moving the 3D sensor to acquire multiple views for 3D fusion, joint\noptimization, or active vision suffers from low-speed issues. That is because\nsensing is taken as a decoupled module from motion tasks and is not\nintentionally designed for a bin picking system. To address the problems, we\ndesigned a bin picking system, which tightly couples a multi-view, active\nvision scheme with motion tasks in a \"sensor on hand\" configuration. It not\nonly speeds up the system by parallelizing the high-speed sensing scheme to the\nrobot place action but also decides the next sensing path to maintain the\ncontinuity of the whole picking process. Unlike others focusing only on sensing\nevaluation, we also evaluated our design by picking experiments on 5 different\ntypes of objects without human intervention. Our experiments show the whole\nsensing scheme can be finished within 1.682 seconds (maximum) on CPU and the\naverage picking complete rate is over 97.75%. Due to the parallelization with\nrobot motion, the sensing scheme accounts for only 0.635 seconds in takt time\non average."
  },
  {
    "paper_no": "472",
    "authors": "Chen, Guanyu; Zhou, Yiqun; Yang, Guoqing; Lv, Pan; Li, Hong",
    "title": "SmartKit&#65306; User-Friendly Robot with Multiple Operating Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "473",
    "authors": "Yao, Linghong; Modugno, Valerio; Delfaki, Andromachi Maria; Liu, Yuanchang; Stoyanov, Danail; Kanoulas, Dimitrios",
    "title": "Local Path Planning among Pushable Objects Based on Reinforcement Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2303.02407v3",
    "arxiv_abstract": "In this paper, we introduce a method to deal with the problem of robot local\npath planning among pushable objects -- an open problem in robotics. In\nparticular, we achieve that by training multiple agents simultaneously in a\nphysics-based simulation environment, utilizing an Advantage Actor-Critic\nalgorithm coupled with a deep neural network. The developed online policy\nenables these agents to push obstacles in ways that are not limited to axial\nalignments, adapt to unforeseen changes in obstacle dynamics instantaneously,\nand effectively tackle local path planning in confined areas. We tested the\nmethod in various simulated environments to prove the adaptation effectiveness\nto various unseen scenarios in unfamiliar settings. Moreover, we have\nsuccessfully applied this policy on an actual quadruped robot, confirming its\ncapability to handle the unpredictability and noise associated with real-world\nsensors and the inherent uncertainties present in unexplored object pushing\ntasks."
  },
  {
    "paper_no": "474",
    "authors": "Ding, Laiyan; Jiang, Hualie; Li, Jie; CHEN, Yongquan; Huang, Rui",
    "title": "Towards Cross-View-Consistent Self-Supervised Surround Depth Estimation",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.04041v3",
    "arxiv_abstract": "Depth estimation is a cornerstone for autonomous driving, yet acquiring\nper-pixel depth ground truth for supervised learning is challenging.\nSelf-Supervised Surround Depth Estimation (SSSDE) from consecutive images\noffers an economical alternative. While previous SSSDE methods have proposed\ndifferent mechanisms to fuse information across images, few of them explicitly\nconsider the cross-view constraints, leading to inferior performance,\nparticularly in overlapping regions. This paper proposes an efficient and\nconsistent pose estimation design and two loss functions to enhance cross-view\nconsistency for SSSDE. For pose estimation, we propose to use only front-view\nimages to reduce training memory and sustain pose estimation consistency. The\nfirst loss function is the dense depth consistency loss, which penalizes the\ndifference between predicted depths in overlapping regions. The second one is\nthe multi-view reconstruction consistency loss, which aims to maintain\nconsistency between reconstruction from spatial and spatial-temporal contexts.\nAdditionally, we introduce a novel flipping augmentation to improve the\nperformance further. Our techniques enable a simple neural model to achieve\nstate-of-the-art performance on the DDAD and nuScenes datasets. Last but not\nleast, our proposed techniques can be easily applied to other methods. The code\nis available at https://github.com/denyingmxd/CVCDepth."
  },
  {
    "paper_no": "475",
    "authors": "Bramblett, Lauren; Miloradovic, Branko; Sherman, Patrick; Papadopoulos, Alessandro Vittorio; Bezzo, Nicola",
    "title": "Robust Online Epistemic Replanning of Multi-Robot Missions",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.00641v1",
    "arxiv_abstract": "As Multi-Robot Systems (MRS) become more affordable and computing\ncapabilities grow, they provide significant advantages for complex applications\nsuch as environmental monitoring, underwater inspections, or space exploration.\nHowever, accounting for potential communication loss or the unavailability of\ncommunication infrastructures in these application domains remains an open\nproblem. Much of the applicable MRS research assumes that the system can\nsustain communication through proximity regulations and formation control or by\ndevising a framework for separating and adhering to a predetermined plan for\nextended periods of disconnection. The latter technique enables an MRS to be\nmore efficient, but breakdowns and environmental uncertainties can have a\ndomino effect throughout the system, particularly when the mission goal is\nintricate or time-sensitive. To deal with this problem, our proposed framework\nhas two main phases: i) a centralized planner to allocate mission tasks by\nrewarding intermittent rendezvous between robots to mitigate the effects of the\nunforeseen events during mission execution, and ii) a decentralized replanning\nscheme leveraging epistemic planning to formalize belief propagation and a\nMonte Carlo tree search for policy optimization given distributed rational\nbelief updates. The proposed framework outperforms a baseline heuristic and is\nvalidated using simulations and experiments with aerial vehicles."
  },
  {
    "paper_no": "481",
    "authors": "Khanal, Abhish; Bui, Hoang-Dung; Plaku, Erion; Stein, Gregory",
    "title": "Learning-informed Long-Horizon Navigation under Uncertainty for Vehicles with Dynamics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "487",
    "authors": "Gomes, Manuel; Görner, Michael; Oliveira, Miguel; Zhang, Jianwei",
    "title": "Sensor-agnostic Visuo-Tactile Robot Calibration Exploiting Assembly-Precision Model Geometries",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "488",
    "authors": "LaRocque, Damien; Guimont-Martin, William; Duclos, David-Alexandre; Giguère, Philippe; Pomerleau, Francois",
    "title": "Proprioception Is All You Need: Terrain Classification for Boreal Forests",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.16877v2",
    "arxiv_abstract": "Recent works in field robotics highlighted the importance of resiliency\nagainst different types of terrains. Boreal forests, in particular, are home to\nmany mobility-impeding terrains that should be considered for off-road\nautonomous navigation. Also, being one of the largest land biomes on Earth,\nboreal forests are an area where autonomous vehicles are expected to become\nincreasingly common. In this paper, we address this issue by introducing\nBorealTC, a publicly available dataset for proprioceptive-based terrain\nclassification (TC). Recorded with a Husky A200, our dataset contains 116 min\nof Inertial Measurement Unit (IMU), motor current, and wheel odometry data,\nfocusing on typical boreal forest terrains, notably snow, ice, and silty loam.\nCombining our dataset with another dataset from the state-of-the-art, we\nevaluate both a Convolutional Neural Network (CNN) and the novel state space\nmodel (SSM)-based Mamba architecture on a TC task. Interestingly, we show that\nwhile CNN outperforms Mamba on each separate dataset, Mamba achieves greater\naccuracy when trained on a combination of both. In addition, we demonstrate\nthat Mamba's learning capacity is greater than a CNN for increasing amounts of\ndata. We show that the combination of two TC datasets yields a latent space\nthat can be interpreted with the properties of the terrains. We also discuss\nthe implications of merging datasets on classification. Our source code and\ndataset are publicly available online:\nhttps://github.com/norlab-ulaval/BorealTC."
  },
  {
    "paper_no": "492",
    "authors": "Zong, Zeshun; Han, Xuchen; Jiang, Chenfanfu",
    "title": "A Convex Formulation of Frictional Contact for the Material Point Method and Rigid Bodies",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13783v3",
    "arxiv_abstract": "In this paper, we introduce a novel convex formulation that seamlessly\nintegrates the Material Point Method (MPM) with articulated rigid body dynamics\nin frictional contact scenarios. We extend the linear corotational hyperelastic\nmodel into the realm of elastoplasticity and include an efficient return\nmapping algorithm. This approach is particularly effective for MPM simulations\ninvolving significant deformation and topology changes, while preserving the\nconvexity of the optimization problem. Our method ensures global convergence,\nenabling the use of large simulation time steps without compromising\nrobustness. We have validated our approach through rigorous testing and\nperformance evaluations, highlighting its superior capabilities in managing\ncomplex simulations relevant to robotics. Compared to previous MPM-based\nrobotic simulators, our method significantly improves the stability of contact\nresolution - a critical factor in robot manipulation tasks. We make our method\navailable in the open-source robotics toolkit, Drake. The supplemental video is\navailable at https://youtu.be/5jrQtF5D0DA"
  },
  {
    "paper_no": "494",
    "authors": "Liang, Jinde; Chang, Yuan; Wang, Yanzhen; Yi, Xiaodong; Wang, Qian",
    "title": "DiaGBT: An Explainable and Evolvable Robot Control Framework using Dialogue Generative Behavior Trees",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "495",
    "authors": "Huang, Sheng Chi; Chiu, Wei-Chen",
    "title": "Skin the sheep not only once: Reusing Various Depth Datasets to Drive the Learning of Optical Flow",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.01833v1",
    "arxiv_abstract": "Optical flow estimation is crucial for various applications in vision and\nrobotics. As the difficulty of collecting ground truth optical flow in\nreal-world scenarios, most of the existing methods of learning optical flow\nstill adopt synthetic dataset for supervised training or utilize photometric\nconsistency across temporally adjacent video frames to drive the unsupervised\nlearning, where the former typically has issues of generalizability while the\nlatter usually performs worse than the supervised ones. To tackle such\nchallenges, we propose to leverage the geometric connection between optical\nflow estimation and stereo matching (based on the similarity upon finding pixel\ncorrespondences across images) to unify various real-world depth estimation\ndatasets for generating supervised training data upon optical flow.\nSpecifically, we turn the monocular depth datasets into stereo ones via\nsynthesizing virtual disparity, thus leading to the flows along the horizontal\ndirection; moreover, we introduce virtual camera motion into stereo data to\nproduce additional flows along the vertical direction. Furthermore, we propose\napplying geometric augmentations on one image of an optical flow pair,\nencouraging the optical flow estimator to learn from more challenging cases.\nLastly, as the optical flow maps under different geometric augmentations\nactually exhibit distinct characteristics, an auxiliary classifier which trains\nto identify the type of augmentation from the appearance of the flow map is\nutilized to further enhance the learning of the optical flow estimator. Our\nproposed method is general and is not tied to any particular flow estimator,\nwhere extensive experiments based on various datasets and optical flow\nestimation models verify its efficacy and superiority."
  },
  {
    "paper_no": "496",
    "authors": "Yu, Teng-Te; Lau, Yo-Chung; Wang, Kai-Li; Chen, Kuan-Wen",
    "title": "CollabLoc: Collaborative Information Sharing for Real-Time Multiuser Visual Localization System",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "498",
    "authors": "Qian, Tangyu; Zhang, Hao; Zhou, Zhangli; Wang, Hao; Mingyu, Cai; Kan, Zhen",
    "title": "LEEPS: Learning End-to-End Legged Perceptive Parkour Skills on Challenging Terrains",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "499",
    "authors": "Fuchioka, Yuni; Beltran-Hernandez, Cristian Camilo; Hai, Nguyen; Hamaya, Masashi",
    "title": "Robotic Object Insertion with a Soft Wrist through Sim-to-Real Privileged Training",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.17061v1",
    "arxiv_abstract": "This study addresses contact-rich object insertion tasks under unstructured\nenvironments using a robot with a soft wrist, enabling safe contact\ninteractions. For the unstructured environments, we assume that there are\nuncertainties in object grasp and hole pose and that the soft wrist pose cannot\nbe directly measured. Recent methods employ learning approaches and\nforce/torque sensors for contact localization; however, they require data\ncollection in the real world. This study proposes a sim-to-real approach using\na privileged training strategy. This method has two steps. 1) The teacher\npolicy is trained to complete the task with sensor inputs and ground truth\nprivileged information such as the peg pose, and then 2) the student encoder is\ntrained with data produced from teacher policy rollouts to estimate the\nprivileged information from sensor history. We performed sim-to-real\nexperiments under grasp and hole pose uncertainties. This resulted in 100\\%,\n95\\%, and 80\\% success rates for circular peg insertion with 0, +5, and -5\ndegree peg misalignments, respectively, and start positions randomly shifted\n$\\pm$ 10 mm from a default position. Also, we tested the proposed method with a\nsquare peg that was never seen during training. Additional simulation\nevaluations revealed that using the privileged strategy improved success rates\ncompared to training with only simulated sensor data. Our results demonstrate\nthe advantage of using sim-to-real privileged training for soft robots, which\nhas the potential to alleviate human engineering efforts for robotic assembly."
  },
  {
    "paper_no": "502",
    "authors": "Fang, Jiading; Tan, Xiangshan; Lin, Shengjie; Vasiljevic, Igor; Guizilini, Vitor; Mei, Hongyuan; Ambrus, Rares; Shakhnarovich, Gregory; Walter, Matthew",
    "title": "Transcrib3D: 3D Referring Expression Resolution through Large Language Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "504",
    "authors": "Do, Hoang Viet; Kim, Yong Hun; Lee, Joo Han; Lee, Min Ho; Song, Jin Woo",
    "title": "DeRO: Dead Reckoning Based on Radar Odometry With Accelerometers Aided for Robot Localization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "505",
    "authors": "Xu, Jialei; Yin, Wei; Gong, Dong; Jiang, Junjun; Liu, Xianming",
    "title": "SDGE:Stereo Guided Depth Estimation for 360°Camera Sets",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "507",
    "authors": "Peng, Zengqi; Zhou, Xiao; Zheng, Lei; Wang, Yubin; Ma, Jun",
    "title": "Reward-Driven Automated Curriculum Learning for Interaction-Aware Self-Driving at Unsignalized Intersections",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13674v1",
    "arxiv_abstract": "In this work, we present a reward-driven automated curriculum reinforcement\nlearning approach for interaction-aware self-driving at unsignalized\nintersections, taking into account the uncertainties associated with\nsurrounding vehicles (SVs). These uncertainties encompass the uncertainty of\nSVs' driving intention and also the quantity of SVs. To deal with this problem,\nthe curriculum set is specifically designed to accommodate a progressively\nincreasing number of SVs. By implementing an automated curriculum selection\nmechanism, the importance weights are rationally allocated across various\ncurricula, thereby facilitating improved sample efficiency and training\noutcomes. Furthermore, the reward function is meticulously designed to guide\nthe agent towards effective policy exploration. Thus the proposed framework\ncould proactively address the above uncertainties at unsignalized intersections\nby employing the automated curriculum learning technique that progressively\nincreases task difficulty, and this ensures safe self-driving through effective\ninteraction with SVs. Comparative experiments are conducted in $Highway\\_Env$,\nand the results indicate that our approach achieves the highest task success\nrate, attains strong robustness to initialization parameters of the curriculum\nselection module, and exhibits superior adaptability to diverse situational\nconfigurations at unsignalized intersections. Furthermore, the effectiveness of\nthe proposed method is validated using the high-fidelity CARLA simulator."
  },
  {
    "paper_no": "508",
    "authors": "Chen, Yu; Li, Junwei; Yang, Xudong; Wang, Yifan",
    "title": "Tunable Stiffness Glove for Tremor Suppression Based on 3D Printed Structured Fabrics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "510",
    "authors": "Kou, Wei-Bin; Lin, Qingfeng; Tang, Ming; Wang, Shuai; Zhu, Guangxu; Wu, Yik-Chung",
    "title": "FedRC: A Rapid-Converged Hierarchical Federated Learning Framework in Street Scene Semantic Understanding",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "513",
    "authors": "Chang, Hsuan-Jui; Huang, Tzu-Chun; Xu, Hao-Liang; Chen, Kuan-Wen",
    "title": "Photometric Consistency for Precise Drone Rephotography",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "515",
    "authors": "Li, Kai; Zhang, Yin; Zhao, Shiyu",
    "title": "Uncertainty-Aware Semi-Supervised Semantic Key Point Detection via Bundle Adjustment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "518",
    "authors": "Gao, Wei",
    "title": "Efficient Incremental Penetration Depth Estimation between Convex Geometries",
    "arxiv_pdf": "http://arxiv.org/pdf/2304.07357v2",
    "arxiv_abstract": "Penetration depth (PD) is essential for robotics due to its extensive\napplications in dynamic simulation, motion planning, haptic rendering, etc. The\nExpanding Polytope Algorithm (EPA) is the de facto standard for this problem,\nwhich estimates PD by expanding an inner polyhedral approximation of an\nimplicit set. In this paper, we propose a novel optimization-based algorithm\nthat incrementally estimates minimum penetration depth and its direction. One\nmajor advantage of our method is that it can be warm-started by exploiting the\nspatial and temporal coherence, which emerges naturally in many robotic\napplications (e.g., the temporal coherence between adjacent simulation time\nknots). As a result, our algorithm achieves substantial speedup -- we\ndemonstrate it is 5-30x faster than EPA on several benchmarks. Moreover, our\napproach is built upon the same implicit geometry representation as EPA, which\nenables easy integration and deployment into existing software stacks. We also\nprovide an open-source implementation on: https://github.com/weigao95/mind-fcl"
  },
  {
    "paper_no": "520",
    "authors": "Chen, Yushi; Zhao, Fang; Zhuge, Yue; liu, junxiong; Yan, Jiaquan; Luo, Haiyong",
    "title": "SMORE-SLAM: Semantic Monocular SLAM with Scale Correction and Reverse Loop Utilization in Outdoor Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "523",
    "authors": "Liu, Haotian; Qu, Sanqing; LU, FAN; Bu, Zongtao; Roehrbein, Florian; Knoll, Alois; Chen, Guang",
    "title": "PCDepth: Pattern-based Complementary Learning for Monocular Depth Estimation by Best of Both Worlds",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "528",
    "authors": "Li, Kunmo; Zhang, Yunzhou; Ning, Jian; Zhao, Xinge; Wang, Guiyuan; Liu, Wei",
    "title": "Neighborhood Consensus Guided Matching Based Place Recognition with Spatial-Channel Embedding",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "529",
    "authors": "KIM, NAYOUNG; Kwak, Sonya Sona",
    "title": "Investigating Behavioral and Cognitive Changes Induced by Autonomous Delivery Robots in Incidentally Copresent Persons",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "532",
    "authors": "Caporali, Alessio; Galassi, Kevin; Pantano, Matteo; Palli, Gianluca",
    "title": "Deformable Objects Perception is Just a Few Clicks Away  Dense Annotations from Sparse Inputs",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "533",
    "authors": "Benhamou, Jonas; Bonnabel, Silvere; Chapdelaine, Camille",
    "title": "Backpropagation-Based Analytical Derivatives of EKF Covariance for Active Sensing",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.17569v3",
    "arxiv_abstract": "To enhance accuracy of robot state estimation, active sensing (or\nperception-aware) methods seek trajectories that maximize the information\ngathered by the sensors. To this aim, one possibility is to seek trajectories\nthat minimize the (estimation error) covariance matrix output by an extended\nKalman filter (EKF), w.r.t. its control inputs over a given horizon. However,\nthis is computationally demanding. In this article, we derive novel\nbackpropagation analytical formulas for the derivatives of the covariance\nmatrices of an EKF w.r.t. all its inputs. We then leverage the obtained\nanalytical gradients as an enabling technology to derive perception-aware\noptimal motion plans. Simulations validate the approach, showcasing\nimprovements in execution time, notably over PyTorch's automatic\ndifferentiation. Experimental results on a real vehicle also support the\nmethod."
  },
  {
    "paper_no": "534",
    "authors": "Dai, Dun; Quan, Quan; Cai, Kai-Yuan",
    "title": "Sharing Attention Mechanism in V-SLAM: Relative Pose Estimation with Messenger Tokens on Small Datasets",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "538",
    "authors": "Taylor, Joshua; Nursultan, Imanberdiyev; Chuah, Meng Yee (Michael); Yau, Wei-Yun; Sartoretti, Guillaume Adrien; CAMCI, Efe",
    "title": "Reconfigurable multi-rotor for high-precision physical interaction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "542",
    "authors": "SUN, Yichong; Chan, Wai Shing; Li, Yehui; Zhang, Heng; Huang, Yisen; Hu, Haochen; Chiu, Philip, Wai-yan; Li, Zheng",
    "title": "An Octopus-inspired-configuration Sensor Array Concept toward Torso-oriented Magnetic Localization Task and Simulation Verification",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "545",
    "authors": "Cao, Zhengcai; Li, Junnian; Niu, Jie; Zhou, MengChu",
    "title": "QuerySOD: A Small Object Detection Algorithm Based on Sparse Convolutional Network and Query Mechanism",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "546",
    "authors": "Patsch, Constantin; Torjmene, Wael; Zakour, Marsil; Wu, Yuankai; Salihu, Driton; Steinbach, Eckehard",
    "title": "Sim-to-Real Domain Shift in Online Action Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "547",
    "authors": "ZHANG, Tianyi; Shimasaki, Kohei; Ishii, Idaku; Namiki, Akio",
    "title": "Dynamic-Range Focal Sweep: Seamless Continuous Autofocus Based on High-Speed Vision for Magnified Object Tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "548",
    "authors": "Lei, Maolin; Romiti, Edoardo; Laurenzi, Arturo; Tsagarakis, Nikos",
    "title": "Task-Driven Computational Framework for Simultaneously Optimizing Design and Mounted Pose of Modular Reconfigurable Manipulators",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.01923v2",
    "arxiv_abstract": "Modular reconfigurable manipulators enable quick adaptation and versatility\nto address different application environments and tailor to the specific\nrequirements of the tasks. Task performance significantly depends on the\nmanipulator's mounted pose and morphology design, therefore posing the need of\nmethodologies for selecting suitable modular robot configurations and mounted\npose that can address the specific task requirements and required performance.\nMorphological changes in modular robots can be derived through a discrete\noptimization process involving the selective addition or removal of modules. In\ncontrast, the adjustment of the mounted pose operates within a continuous\nspace, allowing for smooth and precise alterations in both orientation and\nposition. This work introduces a computational framework that simultaneously\noptimizes modular manipulators' mounted pose and morphology. The core of the\nwork is that we design a mapping function that \\textit{implicitly} captures the\nmorphological state of manipulators in the continuous space. This\ntransformation function unifies the optimization of mounted pose and morphology\nwithin a continuous space. Furthermore, our optimization framework incorporates\na array of performance metrics, such as minimum joint effort and maximum\nmanipulability, and considerations for trajectory execution error and physical\nand safety constraints. To highlight our method's benefits, we compare it with\nprevious methods that framed such problem as a combinatorial optimization\nproblem and demonstrate its practicality in selecting the modular robot\nconfiguration for executing a drilling task with the CONCERT modular robotic\nplatform."
  },
  {
    "paper_no": "550",
    "authors": "Pan, Jingyi; Li, Sihang; Chen, Yucheng; Zhu, Jinjing; Wang, Lin",
    "title": "Towards Dynamic and Small Objects Refinement for Unsupervised Domain Adaptative Nighttime Semantic Segmentation",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.04747v2",
    "arxiv_abstract": "Nighttime semantic segmentation plays a crucial role in practical\napplications, such as autonomous driving, where it frequently encounters\ndifficulties caused by inadequate illumination conditions and the absence of\nwell-annotated datasets. Moreover, semantic segmentation models trained on\ndaytime datasets often face difficulties in generalizing effectively to\nnighttime conditions. Unsupervised domain adaptation (UDA) has shown the\npotential to address the challenges and achieved remarkable results for\nnighttime semantic segmentation. However, existing methods still face\nlimitations in 1) their reliance on style transfer or relighting models, which\nstruggle to generalize to complex nighttime environments, and 2) their\nignorance of dynamic and small objects like vehicles and poles, which are\ndifficult to be directly learned from other domains. This paper proposes a\nnovel UDA method that refines both label and feature levels for dynamic and\nsmall objects for nighttime semantic segmentation. First, we propose a dynamic\nand small object refinement module to complement the knowledge of dynamic and\nsmall objects from the source domain to target the nighttime domain. These\ndynamic and small objects are normally context-inconsistent in under-exposed\nconditions. Then, we design a feature prototype alignment module to reduce the\ndomain gap by deploying contrastive learning between features and prototypes of\nthe same class from different domains, while re-weighting the categories of\ndynamic and small objects. Extensive experiments on three benchmark datasets\ndemonstrate that our method outperforms prior arts by a large margin for\nnighttime segmentation. Project page: https://rorisis.github.io/DSRNSS/."
  },
  {
    "paper_no": "551",
    "authors": "Fritsch, Simon; Landler, Stefan; Otto, Michael; Vogel-Heuser, Birgit; Zimmermann, Markus; Stahl, Karsten",
    "title": "Static Modeling of the Stiffness and Contact Forces of Rolling Element Eccentric Drives for Use in Robotic Drive Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "554",
    "authors": "Izzo, Riccardo Andrea; Bardaro, Gianluca; Matteucci, Matteo",
    "title": "BTGenBot: Behavior Tree Generation for Robotic Tasks with Lightweight LLMs",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "556",
    "authors": "Barros, Tiago; Premebida, Cristiano; Aravecchia, Stephanie; Pradalier, Cedric; Nunes, Urbano J.",
    "title": "SPVSoAP3D: A Second-order Average Pooling Approach to enhance 3D Place Recognition in Horticultural Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "561",
    "authors": "Wang, Wen; Xu, Xiaobin; Chen, Ziheng; Yang, Jian; Ran, Yingying; Tan, Zhiying; Luo, Minzhou",
    "title": "Research on Autonomous Navigation of Dual-mode Wheel-legged Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "564",
    "authors": "Baumgärtner, Jan; Puchta, Alexander; Fleischer, Jürgen",
    "title": "One Problem, One Solution: Unifying Robot Design and Cell Layout Optimization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "565",
    "authors": "Pai, Sameer; Takahashi, Kuniyuki; Masuda, Shimpei; Fukaya, Naoki; Yamane, Koki; Ummadisingu, Avinash",
    "title": "Precise Well-plate Placing Utilizing Contact During Sliding with Tactile-based Pose Estimation for Laboratory Automation",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.16170v2",
    "arxiv_abstract": "Micro well-plates are an apparatus commonly used in chemical and biological\nexperiments that are a few centimeters thick and contain wells or divets. In\nthis paper, we aim to solve the task of placing the well-plate onto a\nwell-plate holder (referred to as holder). This task is challenging due to the\nholder's raised grooves being a few millimeters in height, with a clearance of\nless than 1 mm between the well-plate and holder, thus requiring precise\ncontrol during placing. Our placing task has the following challenges: 1) The\nholder's detected pose is uncertain; 2) the required accuracy is at the\nmillimeter to sub-millimeter level due to the raised groove's shallow height\nand small clearance; 3) the holder is not fixed to a desk and is susceptible to\nmovement from external forces. To address these challenges, we developed\nmethods including a) using tactile sensors for accurate pose estimation of the\ngrasped well-plate to handle issue (1); b) sliding the well-plate onto the\ntarget holder while maintaining contact with the holder's groove and estimating\nits orientation for accurate alignment. This allows for high precision control\n(addressing issue (2)) and prevents displacement of the holder during placement\n(addressing issue (3)). We demonstrate a high success rate for the well-plate\nplacing task, even under noisy observation of the holder's pose."
  },
  {
    "paper_no": "569",
    "authors": "An, Siyuan; Zhong, Chengxi; Wang, Mingyue; LIU, Song",
    "title": "Real-Time Particle Cluster Manipulation with Holographic Acoustic End-Effector under Microscope",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "570",
    "authors": "Zeng, Zijin; Wang, Fengwu; Li, Chan; Tan, Menglu; Wang, Shengyuan; Feng, Lin",
    "title": "Dung Beetle Optimizer-based High-precision Localization for Magnetic-Controlled Capsule Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "571",
    "authors": "Liu, Zekun; Wei, Dunwen; Gao, Tao; Gong, Jumin",
    "title": "Kinematic Modeling of Twisted String Actuator Based on Invertible Neural Networks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "572",
    "authors": "Xie, Yusen; Huang, Zhenmin; Chen, Kai; Zhu, Lei; Ma, Jun",
    "title": "MCGMapper: Light-Weight Incremental Structure from Motion and Visual Localization With Planar Markers and Camera Groups",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "573",
    "authors": "Song, Peng; Corrales Ramon, Juan Antonio; Mezouar, Youcef",
    "title": "Multidirectional slip detection and avoidance using dynamic 3D tactile meshes from visuotactile sensors",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "574",
    "authors": "Wang, Zhicheng; Wei, Wandi; Yu, Ruiqi; Wu, Jun; Zhu, Qiuguo",
    "title": "Toward Understanding Key Estimation in Learning Robust Humanoid Locomotion",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.05868v1",
    "arxiv_abstract": "Accurate state estimation plays a critical role in ensuring the robust\ncontrol of humanoid robots, particularly in the context of learning-based\ncontrol policies for legged robots. However, there is a notable gap in\nanalytical research concerning estimations. Therefore, we endeavor to further\nunderstand how various types of estimations influence the decision-making\nprocesses of policies. In this paper, we provide quantitative insight into the\neffectiveness of learned state estimations, employing saliency analysis to\nidentify key estimation variables and optimize their combination for humanoid\nlocomotion tasks. Evaluations assessing tracking precision and robustness are\nconducted on comparative groups of policies with varying estimation\ncombinations in both simulated and real-world environments. Results validated\nthat the proposed policy is capable of crossing the sim-to-real gap and\ndemonstrating superior performance relative to alternative policy\nconfigurations."
  },
  {
    "paper_no": "580",
    "authors": "Lepowsky, Eric; Snyder, David; Glaser, Alexander; Majumdar, Anirudha",
    "title": "Privacy-Preserving Map-Free Exploration for Confirming the Absence of a Radioactive Source",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.17130v1",
    "arxiv_abstract": "Performing an inspection task while maintaining the privacy of the inspected\nsite is a challenging balancing act. In this work, we are motivated by the\nfuture of nuclear arms control verification, which requires both a high level\nof privacy and guaranteed correctness. For scenarios with limitations on\nsensors and stored information due to the potentially secret nature of\nobservable features, we propose a robotic verification procedure that provides\nmap-free exploration to perform a source verification task without requiring,\nnor revealing, any task-irrelevant, site-specific information. We provide\ntheoretical guarantees on the privacy and correctness of our approach,\nvalidated by extensive simulated and hardware experiments."
  },
  {
    "paper_no": "581",
    "authors": "Sheetz, Emily; Savchenko, Misha; Zemler, Emma; Presswala, Abbas; Crouch, Andrew; Azimi, Shaun; Kuipers, Benjamin",
    "title": "Multi-Fingered End-Effector Grasp Reflex Modeling for One-Shot Tactile Servoing in Tool Manipulation Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "582",
    "authors": "Ahmed, Syed Shabbir; Shalaby, Mohammed Ayman; Le Ny, Jerome; Forbes, James Richard",
    "title": "Optimal Robot Formations: Balancing Range-Based Observability and User-Defined Configurations",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "583",
    "authors": "Qin, Yuxiang; SUN, HAO",
    "title": "VoxelContrast: Voxel Contrast-Based Unsupervised Learning for 3D Point Clouds",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "584",
    "authors": "RAI, UTKARSH; Gangisetty, Shankar; Abdul Hafez, A. H.; Subramanian, Anbumani; Jawahar, C.V.",
    "title": "Visual Place Recognition in Unstructured Driving Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "591",
    "authors": "Varley, Jacob; Singh, Sumeet; Jain, Deepali; Choromanski, Krzysztof; Zeng, Andy; Basu Roy Chowdhury, Somnath; Dubey, Avinava; Sindhwani, Vikas",
    "title": "Embodied AI with Two Arms: Zero-shot Learning, Safety and Modularity",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.03570v3",
    "arxiv_abstract": "We present an embodied AI system which receives open-ended natural language\ninstructions from a human, and controls two arms to collaboratively accomplish\npotentially long-horizon tasks over a large workspace. Our system is modular:\nit deploys state of the art Large Language Models for task\nplanning,Vision-Language models for semantic perception, and Point Cloud\ntransformers for grasping. With semantic and physical safety in mind, these\nmodules are interfaced with a real-time trajectory optimizer and a compliant\ntracking controller to enable human-robot proximity. We demonstrate performance\nfor the following tasks: bi-arm sorting, bottle opening, and trash disposal\ntasks. These are done zero-shot where the models used have not been trained\nwith any real world data from this bi-arm robot, scenes or workspace. Composing\nboth learning- and non-learning-based components in a modular fashion with\ninterpretable inputs and outputs allows the user to easily debug points of\nfailures and fragilities. One may also in-place swap modules to improve the\nrobustness of the overall platform, for instance with imitation-learned\npolicies. Please see https://sites.google.com/corp/view/safe-robots ."
  },
  {
    "paper_no": "592",
    "authors": "Wang, Haoyang; BAI, HE; Zhang, Xiaoli; Jung, Yunsik; Bowman, Michael; Tao, Lingfeng",
    "title": "Real-time Dexterous Telemanipulation with an End-Effect-Oriented Learning-based Approach",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.00853v1",
    "arxiv_abstract": "Dexterous telemanipulation is crucial in advancing human-robot systems,\nespecially in tasks requiring precise and safe manipulation. However, it faces\nsignificant challenges due to the physical differences between human and\nrobotic hands, the dynamic interaction with objects, and the indirect control\nand perception of the remote environment. Current approaches predominantly\nfocus on mapping the human hand onto robotic counterparts to replicate motions,\nwhich exhibits a critical oversight: it often neglects the physical interaction\nwith objects and relegates the interaction burden to the human to adapt and\nmake laborious adjustments in response to the indirect and counter-intuitive\nobservation of the remote environment. This work develops an\nEnd-Effects-Oriented Learning-based Dexterous Telemanipulation (EFOLD)\nframework to address telemanipulation tasks. EFOLD models telemanipulation as a\nMarkov Game, introducing multiple end-effect features to interpret the human\noperator's commands during interaction with objects. These features are used by\na Deep Reinforcement Learning policy to control the robot and reproduce such\nend effects. EFOLD was evaluated with real human subjects and two end-effect\nextraction methods for controlling a virtual Shadow Robot Hand in\ntelemanipulation tasks. EFOLD achieved real-time control capability with low\ncommand following latency (delay<0.11s) and highly accurate tracking (MSE<0.084\nrad)."
  },
  {
    "paper_no": "594",
    "authors": "Zheng, Zhihao; Chuah, Mooi Choo",
    "title": "Latent Disentanglement for Low Light Image Enhancement",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.06245v1",
    "arxiv_abstract": "Many learning-based low-light image enhancement (LLIE) algorithms are based\non the Retinex theory. However, the Retinex-based decomposition techniques in\nsuch models introduce corruptions which limit their enhancement performance. In\nthis paper, we propose a Latent Disentangle-based Enhancement Network (LDE-Net)\nfor low light vision tasks. The latent disentanglement module disentangles the\ninput image in latent space such that no corruption remains in the disentangled\nContent and Illumination components. For LLIE task, we design a Content-Aware\nEmbedding (CAE) module that utilizes Content features to direct the enhancement\nof the Illumination component. For downstream tasks (e.g. nighttime UAV\ntracking and low-light object detection), we develop an effective light-weight\nenhancer based on the latent disentanglement framework. Comprehensive\nquantitative and qualitative experiments demonstrate that our LDE-Net\nsignificantly outperforms state-of-the-art methods on various LLIE benchmarks.\nIn addition, the great results obtained by applying our framework on the\ndownstream tasks also demonstrate the usefulness of our latent disentanglement\ndesign."
  },
  {
    "paper_no": "595",
    "authors": "Puranic, Aniruddh Gopinath; Deshmukh, Jyotirmoy; Nikolaidis, Stefanos",
    "title": "Signal Temporal Logic-Guided Apprenticeship Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2311.05084v1",
    "arxiv_abstract": "Apprenticeship learning crucially depends on effectively learning rewards,\nand hence control policies from user demonstrations. Of particular difficulty\nis the setting where the desired task consists of a number of sub-goals with\ntemporal dependencies. The quality of inferred rewards and hence policies are\ntypically limited by the quality of demonstrations, and poor inference of these\ncan lead to undesirable outcomes. In this letter, we show how temporal logic\nspecifications that describe high level task objectives, are encoded in a graph\nto define a temporal-based metric that reasons about behaviors of demonstrators\nand the learner agent to improve the quality of inferred rewards and policies.\nThrough experiments on a diverse set of robot manipulator simulations, we show\nhow our framework overcomes the drawbacks of prior literature by drastically\nimproving the number of demonstrations required to learn a control policy."
  },
  {
    "paper_no": "596",
    "authors": "Zou, Dehao; Qian, Xiaolong; Zhang, Yunzhou; Zhao, Xinge; Wang, Zhuo",
    "title": "Pos2VPR: Fast Position Consistency Validation with Positive Sample Mining for Hierarchical Place Recognition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "597",
    "authors": "Ogata, Kunihiro; Futawatari, Toshiki; Fujimoto, Masahiro; Imamura, Yumeko; Matsumoto, Yoshio",
    "title": "Modular Robot Ware for Walking Rehabilitation Assistance According to Physical Functionality",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "598",
    "authors": "ng, wen zheng terence; chen, jianda; Zhang, Tianwei",
    "title": "Off-dynamics Conditional Diffusion Planners",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "604",
    "authors": "Inoue, Shintaro; Kawaharazuka, Kento; Suzuki, Temma; Yuzaki, Sota; Okada, Kei; Inaba, Masayuki",
    "title": "CubiX: Portable Wire-Driven Parallel Robot Connecting to and Utilizing the Environment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "605",
    "authors": "Turrisi, Raymond; Benjamin, Michael",
    "title": "Decentralized Linear Convoying for Underactuated Surface Craft with Partial State Coupling",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "607",
    "authors": "Jiang, Yongpeng; Yu, Mingrui; Zhu, Xinghao; Tomizuka, Masayoshi; LI, Xiang",
    "title": "Contact-Implicit Model Predictive Control for Dexterous In-hand Manipulation: A Long-Horizon and Robust Approach",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.18897v3",
    "arxiv_abstract": "Dexterous in-hand manipulation is an essential skill of production and life.\nHowever, the highly stiff and mutable nature of contacts limits real-time\ncontact detection and inference, degrading the performance of model-based\nmethods. Inspired by recent advances in contact-rich locomotion and\nmanipulation, this paper proposes a novel model-based approach to control\ndexterous in-hand manipulation and overcome the current limitations. The\nproposed approach has an attractive feature, which allows the robot to robustly\nperform long-horizon in-hand manipulation without predefined contact sequences\nor separate planning procedures. Specifically, we design a high-level\ncontact-implicit model predictive controller to generate real-time contact\nplans executed by the low-level tracking controller. Compared to other\nmodel-based methods, such a long-horizon feature enables replanning and robust\nexecution of contact-rich motions to achieve large displacements in-hand\nmanipulation more efficiently; Compared to existing learning-based methods, the\nproposed approach achieves dexterity and also generalizes to different objects\nwithout any pre-training. Detailed simulations and ablation studies demonstrate\nthe efficiency and effectiveness of our method. It runs at 20Hz on the\n23-degree-of-freedom, long-horizon, in-hand object rotation task."
  },
  {
    "paper_no": "608",
    "authors": "Nishishita, Taisei; WATANABE, Keisuke; Hirano, Daichi; Mitani, Shinji",
    "title": "GNC Design and Orbital Performance Evaluation of ISS Onboard Autonomous Free-Flying Robot Int-Ball2",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "609",
    "authors": "Hiramatsu, Toshifumi; Saiki, Miyuki; Hara, Naohiro; Yamada, Masaki; Momii, Masaki; Uebayashi, Yuichi; Sugiura, Hisashi",
    "title": "Development Force Control of a Series Elastic Actuator to Excavator for Mechanization of Manual Work",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "613",
    "authors": "Suzuki, Kanata; Ogata, Tetsuya",
    "title": "Sensorimotor Attention and Language-based Regressions in Shared Latent Variables for Integrating Robot Motion Learning and LLM",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.09044v1",
    "arxiv_abstract": "In recent years, studies have been actively conducted on combining large\nlanguage models (LLM) and robotics; however, most have not considered\nend-to-end feedback in the robot-motion generation phase. The prediction of\ndeep neural networks must contain errors, it is required to update the trained\nmodel to correspond to the real environment to generate robot motion\nadaptively. This study proposes an integration method that connects the\nrobot-motion learning model and LLM using shared latent variables. When\ngenerating robot motion, the proposed method updates shared parameters based on\nprediction errors from both sensorimotor attention points and task language\ninstructions given to the robot. This allows the model to search for latent\nparameters appropriate for the robot task efficiently. Through simulator\nexperiments on multiple robot tasks, we demonstrated the effectiveness of our\nproposed method from two perspectives: position generalization and language\ninstruction generalization abilities."
  },
  {
    "paper_no": "614",
    "authors": "Salt Ducaju, Julian Mauricio; Olofsson, Bjorn; Johansson, Rolf",
    "title": "Iterative Reference Learning for Cartesian Impedance Control of Robot Manipulators",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "617",
    "authors": "Katayama, Sotaro; Takasugi, Noriaki; Kaneko, Mitsuhisa; Nagatsuka, Norio; Kinoshita, Masaya",
    "title": "Robust Locomotion via Zero-order Stochastic Nonlinear Model Predictive Control with Guard Saltation Matrix",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.14159v2",
    "arxiv_abstract": "This paper presents a stochastic/robust nonlinear model predictive control\n(NMPC) to enhance the robustness of model-based legged locomotion against\ncontact uncertainties. We integrate the contact uncertainties into the\ncovariance propagation of stochastic/robust NMPC framework by leveraging the\nguard saltation matrix and an extended Kalman filter-like covariance update. We\nachieve fast stochastic/robust NMPC computation by utilizing the zero-order\nalgorithm with additional improvements in computational efficiency concerning\nthe feedback gains. We conducted numerical experiments and demonstrate that the\nproposed method can accurately forecast future state covariance and generate\ntrajectories that satisfies constraints even in the presence of the contact\nuncertainties. Hardware experiments on the perceptive locomotion of a\nwheeled-legged robot were also carried out, validating the feasibility of the\nproposed method in a real-world system with limited on-board computation."
  },
  {
    "paper_no": "618",
    "authors": "Zhang, Lei; Zheng, Chuanxiong; Wang, Hui; Gomez, Randy; Nichols, Eric; Li, Guangliang",
    "title": "Autonomous Storytelling for Social Robot with Human-Centered Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "619",
    "authors": "Pathak, Saurabh; Shrestha, Samridha; AlMahmoud, Abdelrahman",
    "title": "Model Agnostic Defense against Adversarial Patch Attacks on Object Detection in Unmanned Aerial Vehicles",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.19179v1",
    "arxiv_abstract": "Object detection forms a key component in Unmanned Aerial Vehicles (UAVs) for\ncompleting high-level tasks that depend on the awareness of objects on the\nground from an aerial perspective. In that scenario, adversarial patch attacks\non an onboard object detector can severely impair the performance of upstream\ntasks. This paper proposes a novel model-agnostic defense mechanism against the\nthreat of adversarial patch attacks in the context of UAV-based object\ndetection. We formulate adversarial patch defense as an occlusion removal task.\nThe proposed defense method can neutralize adversarial patches located on\nobjects of interest, without exposure to adversarial patches during training.\nOur lightweight single-stage defense approach allows us to maintain a\nmodel-agnostic nature, that once deployed does not require to be updated in\nresponse to changes in the object detection pipeline. The evaluations in\ndigital and physical domains show the feasibility of our method for deployment\nin UAV object detection pipelines, by significantly decreasing the Attack\nSuccess Ratio without incurring significant processing costs. As a result, the\nproposed defense solution can improve the reliability of object detection for\nUAVs."
  },
  {
    "paper_no": "620",
    "authors": "Mizuno, Tomoki; Yabashi, Kazuya; Tasaki, Tsuyoshi",
    "title": "Object Pose Estimation by Camera Arm Control Based on Viewpoint Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "623",
    "authors": "Rocha, Lidia; Bidinotto, Jorge; Heintz, Fredrik; Tiger, Mattias; Vivaldini, Kelen Cristiane Teixeira",
    "title": "Enhancing Safety via Deep Reinforcement Learning in Trajectory Planning for Agile Flights within Unknown Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "625",
    "authors": "wang, jialu; zhou, kaichen; Markham, Andrew; Trigoni, Niki",
    "title": "WSCLoc: Weakly-Supervised Sparse-View Camera Relocalization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "627",
    "authors": "Belvedere, Tommaso; Scianca, Nicola; Lanari, Leonardo; Oriolo, Giuseppe",
    "title": "Joint-Level IS-MPC: a Whole-Body MPC with Centroidal Feasibility for Humanoid Locomotion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "629",
    "authors": "Kristoffersson Lind, Simon; Krueger, Volker; Triebel, Rudolph",
    "title": "Making the Flow Glow -- Robot Perception under Severe Lighting Conditions using Normalizing Flow Gradients",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "630",
    "authors": "Takasugi, Noriaki; Kinoshita, Masaya; Kamikawa, Yasuhisa; Tsuzaki, Ryoichi; Sakamoto, Atsushi; Kai, Toshimitsu; Kawanami, Yasunori",
    "title": "Real-time Perceptive Motion Control using Control Barrier Functions with Analytical Smoothing for Six-Wheeled-Telescopic-Legged Robot Tachyon 3",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.11792v3",
    "arxiv_abstract": "To achieve safe legged locomotion, it is important to generate motion in\nreal-time considering various constraints in robots and environments. In this\nstudy, we propose a lightweight real-time perspective motion control system for\nthe newly developed six-wheeled-telescopic-legged robot, Tachyon 3. In the\nproposed method, analytically smoothed constraints including Smooth Separating\nAxis Theorem (Smooth SAT) as a novel higher order differentiable collision\ndetection for 3D shapes is applied to the Control Barrier Function (CBF). The\nproposed system integrating the CBF achieves online motion generation in a\nshort control cycle of 1 ms that satisfies joint limitations, environmental\ncollision avoidance and safe convex foothold constraints. The efficiency of\nSmooth SAT is shown from the collision detection time of 1 us or less and the\nCBF constraint computation time for Tachyon3 of several us. Furthermore, the\neffectiveness of the proposed system is verified through the stair-climbing\nmotion, integrating online recognition in a simulation and a real machine."
  },
  {
    "paper_no": "631",
    "authors": "Tsuchiya, Yuki; Balch, Thomas; Drews, Paul; Rosman, Guy",
    "title": "Online Adaptation of Learned Vehicle Dynamics Model with Meta-Learning Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "633",
    "authors": "Lumpp, Francesco; Fummi, Franco; Bombieri, Nicola",
    "title": "Optimizing Kubernetes Deployment of Robotic Applications with HEFT-based Container Orchestration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "636",
    "authors": "Liu, Ruonan; Kong, Ping; Zhang, Weidong",
    "title": "Multiple Visual Features in Topological Map for Vision-and-Language Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "638",
    "authors": "Ng, Han Wei; Guan, Cuntai",
    "title": "Self-Selecting Semi-Supervised Transformer-Attention Convolutional Network for Four Class EEG-Based Motor Imagery Decoding",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "640",
    "authors": "DONG, CAN; Hong, Ziyang; Li, Siru; Hu, Liang; Gao, Huijun",
    "title": "Augmenting Vision with Radar for All-weather Geo-localization without a Prior HD Map",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "642",
    "authors": "Jin, Shutong; WANG, RUIYU; Zahid, Muhammad; Pokorny, Florian T.",
    "title": "How Physics and Background Attributes Impact Video Transformers in Robotic Manipulation: A Case Study on Planar Pushing",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.02044v4",
    "arxiv_abstract": "As model and dataset sizes continue to scale in robot learning, the need to\nunderstand how the composition and properties of a dataset affect model\nperformance becomes increasingly urgent to ensure cost-effective data\ncollection and model performance. In this work, we empirically investigate how\nphysics attributes (color, friction coefficient, shape) and scene background\ncharacteristics, such as the complexity and dynamics of interactions with\nbackground objects, influence the performance of Video Transformers in\npredicting planar pushing trajectories. We investigate three primary questions:\nHow do physics attributes and background scene characteristics influence model\nperformance? What kind of changes in attributes are most detrimental to model\ngeneralization? What proportion of fine-tuning data is required to adapt models\nto novel scenarios? To facilitate this research, we present\nCloudGripper-Push-1K, a large real-world vision-based robot pushing dataset\ncomprising 1278 hours and 460,000 videos of planar pushing interactions with\nobjects with different physics and background attributes. We also propose Video\nOcclusion Transformer (VOT), a generic modular video-transformer-based\ntrajectory prediction framework which features 3 choices of 2D-spatial encoders\nas the subject of our case study. The dataset and source code are available at\nhttps://cloudgripper.org."
  },
  {
    "paper_no": "646",
    "authors": "Du, Yuyang; Ye, Ruihua; Xu, Wenfu",
    "title": "Development of a Spherical Wheel-legged Composite Mobile Robot with Multimodal Motion Capabilities",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "648",
    "authors": "Li, Yi; Zhao, Hanying; Liu, Yiman; Wang, Tianyu; Jincheng, Yu; Shen, Yuan",
    "title": "High-Accuracy 3D AoA Estimation Using Lightweight UWB Arrays",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "649",
    "authors": "Noizet, Maxime; Xu, Philippe; Bonnifait, Philippe",
    "title": "Automatic Image Annotation for Mapped Features Detection",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.10438v1",
    "arxiv_abstract": "Detecting road features is a key enabler for autonomous driving and\nlocalization. For instance, a reliable detection of poles which are widespread\nin road environments can improve localization. Modern deep learning-based\nperception systems need a significant amount of annotated data. Automatic\nannotation avoids time-consuming and costly manual annotation. Because\nautomatic methods are prone to errors, managing annotation uncertainty is\ncrucial to ensure a proper learning process. Fusing multiple annotation sources\non the same dataset can be an efficient way to reduce the errors. This not only\nimproves the quality of annotations, but also improves the learning of\nperception models. In this paper, we consider the fusion of three automatic\nannotation methods in images: feature projection from a high accuracy vector\nmap combined with a lidar, image segmentation and lidar segmentation. Our\nexperimental results demonstrate the significant benefits of multi-modal\nautomatic annotation for pole detection through a comparative evaluation on\nmanually annotated images. Finally, the resulting multi-modal fusion is used to\nfine-tune an object detection model for pole base detection using unlabeled\ndata, showing overall improvements achieved by enhancing network\nspecialization. The dataset is publicly available."
  },
  {
    "paper_no": "650",
    "authors": "SHI, LIUYU; Yin, Longji; Kong, Fanze; Ren, Yunfan; Zhu, Fangcheng; Tang, Benxu; Zhang, Fu",
    "title": "Real-time Bandwidth-efficient Occupancy Grid Map Synchronization for Multi-Robot Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "651",
    "authors": "Tang, Wei; Li, Chao; Wu, Jun; Zhu, Qiuguo",
    "title": "Decentralized Communication-Maintained Coordination for Multi-Robot Exploration: Achieving Connectivity and Adaptability",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "653",
    "authors": "Sun, Huawei; Feng, Hao; Ott, Julius; Servadei, Lorenzo; Wille, Robert",
    "title": "CaFNet: A Confidence-Driven Framework for Radar Camera Depth Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "654",
    "authors": "Wahba, Khaled; Ortiz-Haro, Joaquim; Toussaint, Marc; Hoenig, Wolfgang",
    "title": "Kinodynamic Motion Planning for a Team of Multirotors Transporting a Cable-Suspended Payload in Cluttered Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.03394v3",
    "arxiv_abstract": "We propose a motion planner for cable-driven payload transportation using\nmultiple unmanned aerial vehicles (UAVs) in an environment cluttered with\nobstacles. Our planner is kinodynamic, i.e., it considers the full dynamics\nmodel of the transporting system including actuation constraints. Due to the\nhigh dimensionality of the planning problem, we use a hierarchical approach\nwhere we first solve the geometric motion planning using a sampling-based\nmethod with a novel sampler, followed by constrained trajectory optimization\nthat considers the full dynamics of the system. Both planning stages consider\ninter-robot and robot/obstacle collisions. We demonstrate in a\nsoftware-in-the-loop simulation and real flight experiments that there is a\nsignificant benefit in kinodynamic motion planning for such payload transport\nsystems with respect to payload tracking error and energy consumption compared\nto the standard methods of planning for the payload alone. Notably, we observe\na significantly higher success rate in scenarios where the team formation\nchanges are needed to move through tight spaces."
  },
  {
    "paper_no": "655",
    "authors": "Iacone, Luca; Lejeune, Erwin Edouard Kossi; Manoni, Tiziano; Manfredi, Sabato; Albani, Dario",
    "title": "Decentralized Acceleration-Based Bird-Inspired Flocking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "656",
    "authors": "Yakovlev, Konstantin; Andreychuk, Anton; Stern, Roni",
    "title": "Optimal and Bounded Suboptimal Any-Angle Multi-agent Pathfinding",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.16379v2",
    "arxiv_abstract": "Multi-agent pathfinding (MAPF) is the problem of finding a set of\nconflict-free paths for a set of agents. Typically, the agents' moves are\nlimited to a pre-defined graph of possible locations and allowed transitions\nbetween them, e.g. a 4-neighborhood grid. We explore how to solve MAPF problems\nwhen each agent can move between any pair of possible locations as long as\ntraversing the line segment connecting them does not lead to a collision with\nthe obstacles. This is known as any-angle pathfinding. We present the first\noptimal any-angle multi-agent pathfinding algorithm. Our planner is based on\nthe Continuous Conflict-based Search (CCBS) algorithm and an optimal any-angle\nvariant of the Safe Interval Path Planning (TO-AA-SIPP). The straightforward\ncombination of those, however, scales poorly since any-angle path finding\ninduces search trees with a very large branching factor. To mitigate this, we\nadapt two techniques from classical MAPF to the any-angle setting, namely\nDisjoint Splitting and Multi-Constraints. Experimental results on different\ncombinations of these techniques show they enable solving over 30% more\nproblems than the vanilla combination of CCBS and TO-AA-SIPP. In addition, we\npresent a bounded-suboptimal variant of our algorithm, that enables trading\nruntime for solution cost in a controlled manner."
  },
  {
    "paper_no": "658",
    "authors": "Zheng, Laura; Son, Sanghyun; Liang, Jing; Wang, Xijun; Clipp, Brian; Lin, Ming C.",
    "title": "Deep Stochastic Kinematic Models for Probabilistic Motion Forecasting in Traffic",
    "arxiv_pdf": "http://arxiv.org/pdf/2406.01431v4",
    "arxiv_abstract": "In trajectory forecasting tasks for traffic, future output trajectories can\nbe computed by advancing the ego vehicle's state with predicted actions\naccording to a kinematics model. By unrolling predicted trajectories via time\nintegration and models of kinematic dynamics, predicted trajectories should not\nonly be kinematically feasible but also relate uncertainty from one timestep to\nthe next. While current works in probabilistic prediction do incorporate\nkinematic priors for mean trajectory prediction, _variance_ is often left as a\nlearnable parameter, despite uncertainty in one time step being inextricably\ntied to uncertainty in the previous time step. In this paper, we show simple\nand differentiable analytical approximations describing the relationship\nbetween variance at one timestep and that at the next with the kinematic\nbicycle model. In our results, we find that encoding the relationship between\nvariance across timesteps works especially well in unoptimal settings, such as\nwith small or noisy datasets. We observe up to a 50% performance boost in\npartial dataset settings and up to an 8% performance boost in large-scale\nlearning compared to previous kinematic prediction methods on SOTA trajectory\nforecasting architectures out-of-the-box, with no fine-tuning."
  },
  {
    "paper_no": "659",
    "authors": "Casas Murrilo, Luis Felipe; Khargonkar, Ninad; Prabhakaran, B; Xiang, Yu",
    "title": "MultiGripperGrasp: A Dataset for Robotic Grasping from Parallel Jaw Grippers to Dexterous Hands",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "661",
    "authors": "Mikula, Jan; Kulich, Miroslav",
    "title": "Tr&#780;iVis: Versatile, Reliable, and High-Performance Tool for Computing Visibility in Polygonal Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "663",
    "authors": "Foster, James Paul; McCrory, Stephen; DeBuys, Christian; Bertrand, Sylvain; Griffin, Robert J.",
    "title": "Physically Consistent Online Inertial Adaptation for Humanoid Loco-manipulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.07901v1",
    "arxiv_abstract": "The ability to accomplish manipulation and locomotion tasks in the presence\nof significant time-varying external loads is a remarkable skill of humans that\nhas yet to be replicated convincingly by humanoid robots. Such an ability will\nbe a key requirement in the environments we envision deploying our robots:\ndull, dirty, and dangerous. External loads constitute a large model bias, which\nis typically unaccounted for. In this work, we enable our humanoid robot to\nengage in loco-manipulation tasks in the presence of significant model bias due\nto external loads. We propose an online estimation and control framework\ninvolving the combination of a physically consistent extended Kalman filter for\ninertial parameter estimation coupled to a whole-body controller. We showcase\nour results both in simulation and in hardware, where weights are mounted on\nNadia's wrist links as a proxy for engaging in tasks where large external loads\nare applied to the robot."
  },
  {
    "paper_no": "664",
    "authors": "XIN, Ren; Liu, Hongji; Chen, Yingbing; WANG, Sheng; Liu, Ming",
    "title": "A Generic Trajectory Planning Method for Constrained All-Wheel-Steering Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.09677v3",
    "arxiv_abstract": "This paper presents a generic trajectory planning method for wheeled robots\nwith fixed steering axes while the steering angle of each wheel is constrained.\nIn the existing literatures, All-Wheel-Steering (AWS) robots, incorporating\nmodes such as rotation-free translation maneuvers, in-situ rotational\nmaneuvers, and proportional steering, exhibit inefficient performance due to\ntime-consuming mode switches. This inefficiency arises from wheel rotation\nconstraints and inter-wheel cooperation requirements. The direct application of\na holonomic moving strategy can lead to significant slip angles or even\nstructural failure. Additionally, the limited steering range of AWS wheeled\nrobots exacerbates non-linearity characteristics, thereby complicating control\nprocesses. To address these challenges, we developed a novel planning method\ntermed Constrained AWS (C-AWS), which integrates second-order discrete search\nwith predictive control techniques. Experimental results demonstrate that our\nmethod adeptly generates feasible and smooth trajectories for C-AWS while\nadhering to steering angle constraints."
  },
  {
    "paper_no": "668",
    "authors": "Pragr, Milos; Bayer, Jan; Faigl, Jan",
    "title": "On Predicting Terrain Changes Induced by Mobile Robot Traversal",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "669",
    "authors": "Puhlmann, Steffen; Weber, Lion-Constantin; Hoeppner, Hannes",
    "title": "Programming Passive Fingertip Deformation for Improved Grasping and Manipulation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "670",
    "authors": "Ceder, Kristian; Zhang, Ze; Burman, Adam; Kuangaliyev, Ilya; Mattsson, Krister; Nyman, Gabriel; Petersén, Arvid; Wisell, Lukas; Akesson, Knut",
    "title": "Trajectory Planning of Multiple Robots using Vision-Based Continuous Deep Reinforcement Learning and Model Predictive Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "672",
    "authors": "Lee, Ho Jae; Hong, Seungwoo; Kim, Sangbae",
    "title": "Integrating Model-Based Footstep Planning with Model-Free Reinforcement Learning for Dynamic Legged Locomotion",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.02662v1",
    "arxiv_abstract": "In this work, we introduce a control framework that combines model-based\nfootstep planning with Reinforcement Learning (RL), leveraging desired footstep\npatterns derived from the Linear Inverted Pendulum (LIP) dynamics. Utilizing\nthe LIP model, our method forward predicts robot states and determines the\ndesired foot placement given the velocity commands. We then train an RL policy\nto track the foot placements without following the full reference motions\nderived from the LIP model. This partial guidance from the physics model allows\nthe RL policy to integrate the predictive capabilities of the physics-informed\ndynamics and the adaptability characteristics of the RL controller without\noverfitting the policy to the template model. Our approach is validated on the\nMIT Humanoid, demonstrating that our policy can achieve stable yet dynamic\nlocomotion for walking and turning. We further validate the adaptability and\ngeneralizability of our policy by extending the locomotion task to unseen,\nuneven terrain. During the hardware deployment, we have achieved forward\nwalking speeds of up to 1.5 m/s on a treadmill and have successfully performed\ndynamic locomotion maneuvers such as 90-degree and 180-degree turns."
  },
  {
    "paper_no": "673",
    "authors": "P, Jishnu Jaykumar; Palanisamy, Kamalesh; Chao, Yu-Wei; Du, Xinya; Xiang, Yu",
    "title": "Proto-CLIP: Vision-Language Prototypical Network for Few-Shot Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "674",
    "authors": "Frederiksen, Morten Roed; Stoy, Kasper; Mataric, Maja",
    "title": "Tactile Comfort: Lowering Heart Rate Through Touch Interactions with a Therapeutic Pocket Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "679",
    "authors": "Yu, Mingrui; Liang, Boyuan; Zhang, Xiang; Zhu, Xinghao; LI, Xiang; Tomizuka, Masayoshi",
    "title": "In-Hand Following of Deformable Linear Objects Using Dexterous Fingers with Tactile Sensing",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12676v2",
    "arxiv_abstract": "Most research on deformable linear object (DLO) manipulation assumes rigid\ngrasping. However, beyond rigid grasping and re-grasping, in-hand following is\nalso an essential skill that humans use to dexterously manipulate DLOs, which\nrequires continuously changing the grasp point by in-hand sliding while holding\nthe DLO to prevent it from falling. Achieving such a skill is very challenging\nfor robots without using specially designed but not versatile end-effectors.\nPrevious works have attempted using generic parallel grippers, but their\nrobustness is unsatisfactory owing to the conflict between following and\nholding, which is hard to balance with a one-degree-of-freedom gripper. In this\nwork, inspired by how humans use fingers to follow DLOs, we explore the usage\nof a generic dexterous hand with tactile sensing to imitate human skills and\nachieve robust in-hand DLO following. To enable the hardware system to function\nin the real world, we develop a framework that includes Cartesian-space\narm-hand control, tactile-based in-hand 3-D DLO pose estimation, and\ntask-specific motion design. Experimental results demonstrate the significant\nsuperiority of our method over using parallel grippers, as well as its great\nrobustness, generalizability, and efficiency."
  },
  {
    "paper_no": "682",
    "authors": "Singh, Kurran; Hong, Jungseok; Rypkema, Nicholas Rahardiyan; Leonard, John",
    "title": "Opti-Acoustic Semantic SLAM with Unknown Objects in Underwater Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12837v2",
    "arxiv_abstract": "Despite recent advances in semantic Simultaneous Localization and Mapping\n(SLAM) for terrestrial and aerial applications, underwater semantic SLAM\nremains an open and largely unaddressed research problem due to the unique\nsensing modalities and the object classes found underwater. This paper presents\nan object-based semantic SLAM method for underwater environments that can\nidentify, localize, classify, and map a wide variety of marine objects without\na priori knowledge of the object classes present in the scene. The method\nperforms unsupervised object segmentation and object-level feature aggregation,\nand then uses opti-acoustic sensor fusion for object localization.\nProbabilistic data association is used to determine observation to landmark\ncorrespondences. Given such correspondences, the method then jointly optimizes\nlandmark and vehicle position estimates. Indoor and outdoor underwater datasets\nwith a wide variety of objects and challenging acoustic and lighting conditions\nare collected for evaluation and made publicly available. Quantitative and\nqualitative results show the proposed method achieves reduced trajectory error\ncompared to baseline methods, and is able to obtain comparable map accuracy to\na baseline closed-set method that requires hand-labeled data of all objects in\nthe scene."
  },
  {
    "paper_no": "683",
    "authors": "Mao, Katherine; Spasojevic, Igor; Hsieh, M. Ani; Kumar, Vijay",
    "title": "TOPPQuad: Dynamically-Feasible Time-Optimal Path Parametrization for Quadrotors",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "685",
    "authors": "Ye, Xin; Handwerker, Karl; Hohmann, Sören",
    "title": "Adaptive Model Predictive Control for Differential-Algebraic Systems towards a Higher Path Accuracy for Physically Coupled Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.03387v1",
    "arxiv_abstract": "The physical coupling between robots has the potential to improve the\ncapabilities of multi-robot systems in challenging manufacturing processes.\nHowever, the path tracking accuracy of physically coupled robots is not studied\nadequately, especially considering the uncertain kinematic parameters, the\nmechanical elasticity, and the built-in controllers of off-the-shelf robots.\nThis paper addresses these issues with a novel differential-algebraic system\nmodel which is verified against measurement data from real execution. The\nuncertain kinematic parameters are estimated online to adapt the model.\nConsequently, an adaptive model predictive controller is designed as a\ncoordinator between the robots. The controller achieves a path tracking error\nreduction of 88.6% compared to the state-of-the-art benchmark in the\nsimulation."
  },
  {
    "paper_no": "687",
    "authors": "Villarreal, Michael; Poudel, Bibek; Wickman, Ryan; Shen, Yu; Li, Weizi",
    "title": "AutoJoin: Efficient Adversarial Training against Gradient-Free Perturbations for Robust Maneuvering via Denoising Autoencoder and Joint Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "692",
    "authors": "Xiao, Zhiyuan; Zhang, Xinyu; Zhou, Xiang; Zhang, Qingrui",
    "title": "PA-LOCO: Learning Perturbation-Adaptive Locomotion for Quadruped Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "696",
    "authors": "Mondal, Mohammad Safwan; Ramasamy, Subramanian; Bhounsule, Pranav",
    "title": "An Attention-aware Deep Reinforcement Learning Framework for UAV-UGV Collaborative Route Planning",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.09942v1",
    "arxiv_abstract": "Unmanned aerial vehicles (UAVs) are capable of surveying expansive areas, but\ntheir operational range is constrained by limited battery capacity. The\ndeployment of mobile recharging stations using unmanned ground vehicles (UGVs)\nsignificantly extends the endurance and effectiveness of UAVs. However,\noptimizing the routes of both UAVs and UGVs, known as the UAV-UGV cooperative\nrouting problem, poses substantial challenges, particularly with respect to the\nselection of recharging locations. Here in this paper, we leverage\nreinforcement learning (RL) for the purpose of identifying optimal recharging\nlocations while employing constraint programming to determine cooperative\nroutes for the UAV and UGV. Our proposed framework is then benchmarked against\na baseline solution that employs Genetic Algorithms (GA) to select rendezvous\npoints. Our findings reveal that RL surpasses GA in terms of reducing overall\nmission time, minimizing UAV-UGV idle time, and mitigating energy consumption\nfor both the UAV and UGV. These results underscore the efficacy of\nincorporating heuristics to assist RL, a method we refer to as\nheuristics-assisted RL, in generating high-quality solutions for intricate\nrouting problems."
  },
  {
    "paper_no": "697",
    "authors": "Ishikawa, Haruya; Iida, Takumi; Konishi, Yoshinori; Aoki, Yoshimitsu",
    "title": "PCT: Perspective Cue Training Framework for Multi-Camera BEV Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "699",
    "authors": "Yang, Ruihan; Kim, Yejin; Hendrix, Rose; Kembhavi, Aniruddha; Wang, Xiaolong; ehsani, kiana",
    "title": "Harmonic Mobile Manipulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2312.06639v3",
    "arxiv_abstract": "Recent advancements in robotics have enabled robots to navigate complex\nscenes or manipulate diverse objects independently. However, robots are still\nimpotent in many household tasks requiring coordinated behaviors such as\nopening doors. The factorization of navigation and manipulation, while\neffective for some tasks, fails in scenarios requiring coordinated actions. To\naddress this challenge, we introduce, HarmonicMM, an end-to-end learning method\nthat optimizes both navigation and manipulation, showing notable improvement\nover existing techniques in everyday tasks. This approach is validated in\nsimulated and real-world environments and adapts to novel unseen settings\nwithout additional tuning. Our contributions include a new benchmark for mobile\nmanipulation and the successful deployment with only RGB visual observation in\na real unseen apartment, demonstrating the potential for practical indoor robot\ndeployment in daily life. More results are on our project site:\nhttps://rchalyang.github.io/HarmonicMM/"
  },
  {
    "paper_no": "701",
    "authors": "Kawaharazuka, Kento; Okada, Kei; Inaba, Masayuki",
    "title": "Robot Design Optimization with Rotational and Prismatic Joints Using Black-Box Multi-Objective Optimization",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.20038v1",
    "arxiv_abstract": "Robots generally have a structure that combines rotational joints and links\nin a serial fashion. On the other hand, various joint mechanisms are being\nutilized in practice, such as prismatic joints, closed links, and wire-driven\nsystems. Previous research have focused on individual mechanisms, proposing\nmethods to design robots capable of achieving given tasks by optimizing the\nlength of links and the arrangement of the joints. In this study, we propose a\nmethod for the design optimization of robots that combine different types of\njoints, specifically rotational and prismatic joints. The objective is to\nautomatically generate a robot that minimizes the number of joints and link\nlengths while accomplishing a desired task, by utilizing a black-box\nmulti-objective optimization approach. This enables the simultaneous\nobservation of a diverse range of body designs through the obtained Pareto\nsolutions. Our findings confirm the emergence of practical and known\ncombinations of rotational and prismatic joints, as well as the discovery of\nnovel joint combinations."
  },
  {
    "paper_no": "705",
    "authors": "Li, Shengchen; Zuo, Haobo; Fu, Changhong; Wang, Zhiyong; Xu, Zhiqiang",
    "title": "Intelligent Fish Detection System with Similarity-Aware Transformer",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.19323v1",
    "arxiv_abstract": "Fish detection in water-land transfer has significantly contributed to the\nfishery. However, manual fish detection in crowd-collaboration performs\ninefficiently and expensively, involving insufficient accuracy. To further\nenhance the water-land transfer efficiency, improve detection accuracy, and\nreduce labor costs, this work designs a new type of lightweight and\nplug-and-play edge intelligent vision system to automatically conduct fast fish\ndetection with high-speed camera. Moreover, a novel similarity-aware vision\nTransformer for fast fish detection (FishViT) is proposed to onboard identify\nevery single fish in a dense and similar group. Specifically, a novel\nsimilarity-aware multi-level encoder is developed to enhance multi-scale\nfeatures in parallel, thereby yielding discriminative representations for\nvarying-size fish. Additionally, a new soft-threshold attention mechanism is\nintroduced, which not only effectively eliminates background noise from images\nbut also accurately recognizes both the edge details and overall features of\ndifferent similar fish. 85 challenging video sequences with high framerate and\nhigh-resolution are collected to establish a benchmark from real fish\nwater-land transfer scenarios. Exhaustive evaluation conducted with this\nchallenging benchmark has proved the robustness and effectiveness of FishViT\nwith over 80 FPS. Real work scenario tests validate the practicality of the\nproposed method. The code and demo video are available at\nhttps://github.com/vision4robotics/FishViT."
  },
  {
    "paper_no": "707",
    "authors": "Wu, Cho-Ying; Zhong, Yiqi; Wang, Junying; Neumann, Ulrich",
    "title": "Boosting Generalizability towards Zero-Shot Cross-Dataset Single-Image Indoor Depth by Meta-Initialization",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.02486v1",
    "arxiv_abstract": "Indoor robots rely on depth to perform tasks like navigation or obstacle\ndetection, and single-image depth estimation is widely used to assist\nperception. Most indoor single-image depth prediction focuses less on model\ngeneralizability to unseen datasets, concerned with in-the-wild robustness for\nsystem deployment. This work leverages gradient-based meta-learning to gain\nhigher generalizability on zero-shot cross-dataset inference. Unlike the\nmost-studied meta-learning of image classification associated with explicit\nclass labels, no explicit task boundaries exist for continuous depth values\ntied to highly varying indoor environments regarding object arrangement and\nscene composition. We propose fine-grained task that treats each RGB-D\nmini-batch as a task in our meta-learning formulation. We first show that our\nmethod on limited data induces a much better prior (max 27.8% in RMSE). Then,\nfinetuning on meta-learned initialization consistently outperforms baselines\nwithout the meta approach. Aiming at generalization, we propose zero-shot\ncross-dataset protocols and validate higher generalizability induced by our\nmeta-initialization, as a simple and useful plugin to many existing depth\nestimation methods. The work at the intersection of depth and meta-learning\npotentially drives both research to step closer to practical robotic and\nmachine perception usage."
  },
  {
    "paper_no": "708",
    "authors": "Wu, Yuning; Wei, Jiaying; Oh, Jean; Cardoso Llach, Daniel",
    "title": "Towards Human-Centered Construction Robotics: An RL-Driven Companion Robot For Contextually Assisting Carpentry Workers",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.19060v3",
    "arxiv_abstract": "In the dynamic construction industry, traditional robotic integration has\nprimarily focused on automating specific tasks, often overlooking the\ncomplexity and variability of human aspects in construction workflows. This\npaper introduces a human-centered approach with a \"work companion rover\"\ndesigned to assist construction workers within their existing practices, aiming\nto enhance safety and workflow fluency while respecting construction labor's\nskilled nature. We conduct an in-depth study on deploying a robotic system in\ncarpentry formwork, showcasing a prototype that emphasizes mobility, safety,\nand comfortable worker-robot collaboration in dynamic environments through a\ncontextual Reinforcement Learning (RL)-driven modular framework. Our research\nadvances robotic applications in construction, advocating for collaborative\nmodels where adaptive robots support rather than replace humans, underscoring\nthe potential for an interactive and collaborative human-robot workforce."
  },
  {
    "paper_no": "711",
    "authors": "Higa, Ryota; Kato, Takuro; Ho, Florence",
    "title": "Dual Process Optimization for Multi-Vehicle Route Planning and Parts Collection Sequencing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "713",
    "authors": "Wang, Zhaoying; Dong, Wei",
    "title": "A Collaborative Stereo Camera with Two UAVs for Long-distance Mapping of Urban Buildings",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "714",
    "authors": "Wang, Junbo; Liu, Wenhai; Yu, Qiaojun; You, Yang; Liu, Liu; Wang, Weiming; Lu, Cewu",
    "title": "RPMArt: Towards Robust Perception and Manipulation for Articulated Objects",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "727",
    "authors": "Liu, Mengyao; Chen, Bai; Wang, Lingyu; MAO, ZEBING; Shen, Yayi",
    "title": "Design and Preliminary Validation of A Reconfigurable Quadrotor Aerial-Aquatic Vehicle with Tilting Mechanism",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "729",
    "authors": "Zhao, Jianbo; Chen, Hao; Tian, Qingyao; Chen, Jian; Yang, Bingyu; Zhang, Zihui; Liu, Hongbin",
    "title": "BronchoCopilot: Towards Autonomous Robotic Bronchoscopy via Multimodal Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "731",
    "authors": "li, jianping; Nguyen, Thien-Minh; Yuan, Shenghai; Xie, Lihua",
    "title": "PSS-BA: LiDAR Bundle Adjustment with Progressive Spatial Smoothing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "733",
    "authors": "Yang, Donglin; Cai, Xinyu; Liu, Zhenfeng; Jiang, Wentao; Zhang, Bo; Yan, Guohang; Gao, Xing; Liu, Si; Shi, Botian",
    "title": "Realistic Rainy Weather Simulation for LiDARs in CARLA Simulator",
    "arxiv_pdf": "http://arxiv.org/pdf/2312.12772v1",
    "arxiv_abstract": "Employing data augmentation methods to enhance perception performance in\nadverse weather has attracted considerable attention recently. Most of the\nLiDAR augmentation methods post-process the existing dataset by physics-based\nmodels or machine-learning methods. However, due to the limited environmental\nannotations and the fixed vehicle trajectories in the existing dataset, it is\nchallenging to edit the scene and expand the diversity of traffic flow and\nscenario. To this end, we propose a simulator-based physical modeling approach\nto augment LiDAR data in rainy weather in order to improve the perception\nperformance of LiDAR in this scenario. We complete the modeling task of the\nrainy weather in the CARLA simulator and establish a pipeline for LiDAR data\ncollection. In particular, we pay special attention to the spray and splash\nrolled up by the wheels of surrounding vehicles in rain and complete the\nsimulation of this special scenario through the Spray Emitter method we\ndeveloped. In addition, we examine the influence of different weather\nconditions on the intensity of the LiDAR echo, develop a prediction network for\nthe intensity of the LiDAR echo, and complete the simulation of 4-feat LiDAR\npoint cloud data. In the experiment, we observe that the model augmented by the\nsynthetic data improves the object detection task's performance in the rainy\nsequence of the Waymo Open Dataset. Both the code and the dataset will be made\npublicly available at https://github.com/PJLab-ADG/PCSim#rainypcsim."
  },
  {
    "paper_no": "735",
    "authors": "Vuong, An Dinh; Nguyen, Tien Toan; Vu, Minh Nhat; Huang, Baoru; Binh, Huynh Thi Thanh; Vo, Thieu; Nguyen, Anh",
    "title": "HabiCrowd: A High Performance Simulator for Crowd-Aware Visual Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "737",
    "authors": "Puthumanaillam, Gokul; Vora, Manav Ketan; Ornik, Melkior",
    "title": "ComTraQ-MPC: Meta-Trained DQN-MPC Integration for Trajectory Tracking with Limited Active Localization Updates",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "744",
    "authors": "Min, Zhe; Zhang, Zhengyan; Zhang, Ang; Song, Rui; Li, Yibin; Meng, Max Q.-H.",
    "title": "DeepBHMR: Learning Bidirectional Hybrid Mixture Models for Generalized Rigid Point Set Registration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "745",
    "authors": "Ma, Fulong; YAN, Xiaoyang; ZHAO, Guoyang; Xu, Xiaojie; LIU, Yuxuan; Liu, Ming",
    "title": "Every Dataset Counts: Scaling up Monocular 3D Object Detection with Joint Datasets Training",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.00920v4",
    "arxiv_abstract": "Monocular 3D object detection plays a crucial role in autonomous driving.\nHowever, existing monocular 3D detection algorithms depend on 3D labels derived\nfrom LiDAR measurements, which are costly to acquire for new datasets and\nchallenging to deploy in novel environments. Specifically, this study\ninvestigates the pipeline for training a monocular 3D object detection model on\na diverse collection of 3D and 2D datasets. The proposed framework comprises\nthree components: (1) a robust monocular 3D model capable of functioning across\nvarious camera settings, (2) a selective-training strategy to accommodate\ndatasets with differing class annotations, and (3) a pseudo 3D training\napproach using 2D labels to enhance detection performance in scenes containing\nonly 2D labels. With this framework, we could train models on a joint set of\nvarious open 3D/2D datasets to obtain models with significantly stronger\ngeneralization capability and enhanced performance on new dataset with only 2D\nlabels. We conduct extensive experiments on\nKITTI/nuScenes/ONCE/Cityscapes/BDD100K datasets to demonstrate the scaling\nability of the proposed method."
  },
  {
    "paper_no": "747",
    "authors": "Kaduk, Julian; Weilbeer, Friederike; Hamann, Heiko",
    "title": "Emotional Tandem Robots: How Different Robot Behaviors Affect Human Perception While Controlling a Mobile Robot",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.03746v1",
    "arxiv_abstract": "In human-robot interaction (HRI), we study how humans interact with robots,\nbut also the effects of robot behavior on human perception and well-being.\nEspecially, the influence on humans by tandem robots with one human controlled\nand one autonomous robot or even semi-autonomous multi-robot systems is not yet\nfully understood. Here, we focus on a leader-follower scenario and study how\nemotionally expressive motion patterns of a small, mobile follower robot affect\nthe perception of a human operator controlling the leading robot. We examined\nthree distinct emotional behaviors for the follower compared to a neutral\ncondition: angry, happy and sad. We analyzed how participants maneuvered the\nleader robot along a set path while experiencing each follower behavior in a\nrandomized order. We identified a significant shift in attention toward the\nfollower with emotionally expressive behaviors compared to the neutral\ncondition. For example, the angry behavior significantly heightened participant\nstress levels and was considered the least preferred behavior. The happy\nbehavior was the most preferred and associated with increased excitement by the\nparticipants. Integrating the proposed behaviors in robots can profoundly\ninfluence the human operator's attention, emotional state, and overall\nexperience. These insights are valuable for future HRI tandem robot designs."
  },
  {
    "paper_no": "748",
    "authors": "Zhang, Tianyi; XU, Jiajun; Zhao, Mengcheng; Huang, Kaizhen; Chen, Bai; Li, You-Fu",
    "title": "Design and Control of a Soft Supernumerary Robotic Limb Based on Fiber-Reinforced Actuator",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "751",
    "authors": "Lach, Luca; Haschke, Robert; Tateo, Davide; Peters, Jan; Ritter, Helge Joachim; Borràs Sol, Júlia; Torras, Carme",
    "title": "Zero-Shot Transfer of a Tactile-based Continuous Force Control Policy from Simulation to Robot",
    "arxiv_pdf": "http://arxiv.org/pdf/2311.07245v1",
    "arxiv_abstract": "The advent of tactile sensors in robotics has sparked many ideas on how\nrobots can leverage direct contact measurements of their environment\ninteractions to improve manipulation tasks. An important line of research in\nthis regard is that of grasp force control, which aims to manipulate objects\nsafely by limiting the amount of force exerted on the object. While prior works\nhave either hand-modeled their force controllers, employed model-based\napproaches, or have not shown sim-to-real transfer, we propose a model-free\ndeep reinforcement learning approach trained in simulation and then transferred\nto the robot without further fine-tuning. We therefore present a simulation\nenvironment that produces realistic normal forces, which we use to train\ncontinuous force control policies. An evaluation in which we compare against a\nbaseline and perform an ablation study shows that our approach outperforms the\nhand-modeled baseline and that our proposed inductive bias and domain\nrandomization facilitate sim-to-real transfer. Code, models, and supplementary\nvideos are available on https://sites.google.com/view/rl-force-ctrl"
  },
  {
    "paper_no": "752",
    "authors": "Niijima, Shun; Suzuki, Atsushi; Tsuzaki, Ryoichi; Kinoshita, Masaya",
    "title": "Extrinsic Calibration of Multiple LiDARs for a Mobile Robot based on Floor Plane And Object Segmentation",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.14161v2",
    "arxiv_abstract": "Mobile robots equipped with multiple light detection and ranging (LiDARs) and\ncapable of recognizing their surroundings are increasing due to the\nminitualization and cost reduction of LiDAR. This paper proposes a target-less\nextrinsic calibration method of multiple LiDARs with non-overlapping field of\nview (FoV). The proposed method uses accumulated point clouds of floor plane\nand objects while in motion. It enables accurate calibration with challenging\nconfiguration of LiDARs that directed towards the floor plane, caused by biased\nfeature values. Additionally, the method includes a noise removal module that\nconsiders the scanning pattern to address bleeding points, which are noises of\nsignificant source of error in point cloud alignment using high-density LiDARs.\nEvaluations through simulation demonstrate that the proposed method achieved\nhigher accuracy extrinsic calibration with two and four LiDARs than\nconventional methods, regardless type of objects. Furthermore, the experiments\nusing a real mobile robot has shown that our proposed noise removal module can\neliminate noise more precisely than conventional methods, and the estimated\nextrinsic parameters have successfully created consistent 3D maps."
  },
  {
    "paper_no": "753",
    "authors": "Armani, Rayan; Holz, Christian",
    "title": "Accurate Relative Position Tracking on Moving Trackers based on UWB Ranging and Inertial Sensing",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.12505v1",
    "arxiv_abstract": "We present a tracking system for relative positioning that can operate on\nentirely moving tracking nodes without the need for stationary anchors. Each\nnode embeds a 9-DOF magnetic and inertial measurement unit and a single-antenna\nultra-wideband radio. We introduce a multi-stage filtering pipeline through\nwhich our system estimates the relative layout of all tracking nodes within the\ngroup. The key novelty of our method is the integration of a custom Extended\nKalman filter (EKF) with a refinement step via multidimensional scaling (MDS).\nOur method integrates the MDS output back into the EKF, thereby creating a\ndynamic feedback loop for more robust estimates. We complement our method with\nUWB ranging protocol that we designed to allow tracking nodes to\nopportunistically join and leave the group. In our evaluation with constantly\nmoving nodes, our system estimated relative positions with an error of 10.2cm\n(in 2D) and 21.7cm (in 3D), including obstacles that occluded the line of sight\nbetween tracking nodes. Our approach requires no external infrastructure,\nmaking it particularly suitable for operation in environments where stationary\nsetups are impractical."
  },
  {
    "paper_no": "759",
    "authors": "Fu, Shaowei; Duan, Yifan; Li, Yao; Meng, Chengzhen; Wang, Yingjie; Ji, Jianmin; Zhang, Yanyong",
    "title": "CRPlace: Camera-Radar Fusion with BEV Representation for Place Recognition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "760",
    "authors": "Girardi, Luca; Wu, Rui; Fukatsu, Yuki; Shigemune, Hiroki; Mintchev, Stefano",
    "title": "Biodegradable Gliding Paper Flyers Fabricated Through Inkjet Printing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "763",
    "authors": "Lobefaro, Luca; Malladi, Meher Venkata Ramakrishna; Guadagnino, Tiziano; Stachniss, Cyrill",
    "title": "Spatio-Temporal Consistent Mapping of Growing Plants for Agricultural Robots in the Wild",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "764",
    "authors": "Khatkar, Jayant; Sukkar, Fouad; Clemon, Lee; Mettu, Ramgopal",
    "title": "Coordinated Multi-arm 3D Printing using Reeb Decomposition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "765",
    "authors": "Hongo, Kazuo; Kito, Takashi; Kamikawa, Yasuhisa; Kinoshita, Masaya; Kawanami, Yasunori",
    "title": "Development of a Compact Robust Passive Transformable Omni-Ball for Enhanced Step-Climbing and Vibration Reduction",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.14160v2",
    "arxiv_abstract": "This paper introduces the Passive Transformable Omni-Ball (PTOB), an advanced\nomnidirectional wheel engineered to enhance step-climbing performance,\nincorporate built-in actuators, diminish vibrations, and fortify structural\nintegrity. By modifying the omni-ball's structure from two to three segments,\nwe have achieved improved in-wheel actuation and a reduction in vibrational\nfeedback. Additionally, we have implemented a sliding mechanism in the follower\nwheels to boost the wheel's step-climbing abilities. A prototype with a 127 mm\ndiameter PTOB was constructed, which confirmed its functionality for\nomnidirectional movement and internal actuation. Compared to a traditional\nomni-wheel, the PTOB demonstrated a comparable level of vibration while\noffering superior capabilities. Extensive testing in varied settings showed\nthat the PTOB can adeptly handle step obstacles up to 45 mm, equivalent to 35\n$\\%$ of the wheel's diameter, in both the forward and lateral directions. The\nPTOB showcased robust construction and proved to be versatile in navigating\nthrough environments with diverse obstacles."
  },
  {
    "paper_no": "766",
    "authors": "Lin, Qiushi; Ma, Hang",
    "title": "MFC-EQ: Mean-Field Control with Envelope $Q$-learning for Moving Decentralized Agents in Formation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "768",
    "authors": "Sherman, Patrick; Bezzo, Nicola",
    "title": "A Heterogeneous System of Systems Framework for Proactive Path Planning of a UAV-assisted UGV in Uncertain Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "770",
    "authors": "Liang, Jing; deng, zhuo; Zhou, Zheming; Ghasemalizadeh, Omid; Manocha, Dinesh; Sun, Min; KUO, CHENG-HAO; Sen, Arnab",
    "title": "PoCo: Point Context Cluster for RGBD Indoor Place Recognition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "771",
    "authors": "Cuau, Lénaïc; Cavalcanti Santos, Joao; Poignet, Philippe; Zemiti, Nabil",
    "title": "Direct TPS-based 3D non-rigid motion estimation on 3D colored point cloud in eye-in-hand configuration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "772",
    "authors": "Kulbaka, Iliya; Dutta, Ayan; Kreidl, Patrick; Bölöni, Ladislau; Roy, Swapnoneel",
    "title": "GDM-Net: Gas Distribution Mapping with a Mobile Robot Using Deep Reinforcement Learning and Gaussian Process Regression",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "774",
    "authors": "Gomaa, Amr; Mahdy, Bilal; Kleer, Niko; Krüger, Antonio",
    "title": "Towards a Surgeon-in-the-Loop Ophthalmic Robotic Apprentice using Reinforcement and Imitation Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2311.17693v3",
    "arxiv_abstract": "Robot-assisted surgical systems have demonstrated significant potential in\nenhancing surgical precision and minimizing human errors. However, existing\nsystems cannot accommodate individual surgeons' unique preferences and\nrequirements. Additionally, they primarily focus on general surgeries (e.g.,\nlaparoscopy) and are unsuitable for highly precise microsurgeries, such as\nophthalmic procedures. Thus, we propose an image-guided approach for\nsurgeon-centered autonomous agents that can adapt to the individual surgeon's\nskill level and preferred surgical techniques during ophthalmic cataract\nsurgery. Our approach trains reinforcement and imitation learning agents\nsimultaneously using curriculum learning approaches guided by image data to\nperform all tasks of the incision phase of cataract surgery. By integrating the\nsurgeon's actions and preferences into the training process, our approach\nenables the robot to implicitly learn and adapt to the individual surgeon's\nunique techniques through surgeon-in-the-loop demonstrations. This results in a\nmore intuitive and personalized surgical experience for the surgeon while\nensuring consistent performance for the autonomous robotic apprentice. We\ndefine and evaluate the effectiveness of our approach in a simulated\nenvironment using our proposed metrics and highlight the trade-off between a\ngeneric agent and a surgeon-centered adapted agent. Finally, our approach has\nthe potential to extend to other ophthalmic and microsurgical procedures,\nopening the door to a new generation of surgeon-in-the-loop autonomous surgical\nrobots. We provide an open-source simulation framework for future development\nand reproducibility at\nhttps://github.com/amrgomaaelhady/CataractAdaptSurgRobot."
  },
  {
    "paper_no": "775",
    "authors": "Luo, Xinyuan; Jin, Shengmiao; Huang, Hung-Jui; Yuan, Wenzhen",
    "title": "An Intelligent Robotic System for Perceptive Pancake Batter Stirring and Precise Pouring",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.01755v1",
    "arxiv_abstract": "Cooking robots have long been desired by the commercial market, while the\ntechnical challenge is still significant. A major difficulty comes from the\ndemand of perceiving and handling liquid with different properties. This paper\npresents a robot system that mixes batter and makes pancakes out of it, where\nunderstanding and handling the viscous liquid is an essential component. The\nsystem integrates Haptic Sensing and control algorithms to autonomously stir\nflour and water to achieve the desired batter uniformity, estimate the batter's\nproperties such as the water-flour ratio and liquid level, as well as perform\nprecise manipulations to pour the batter into any specified shape. Experimental\nresults show the system's capability to always produce batter of desired\nuniformity, estimate water-flour ratio and liquid level precisely, and\naccurately pour it into complex shapes. This research showcases the potential\nfor robots to assist in kitchens and step towards commercial culinary\nautomation."
  },
  {
    "paper_no": "776",
    "authors": "Seo, Junwon; Kim, Taekyung; Ahn, Seongyong; Kwak, Kiho",
    "title": "METAVerse: Meta-Learning Traversability Cost Map for Off-Road Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "777",
    "authors": "Tian, Chungeng; Hao, Ning; He, Fenghua; Yao, Haodi",
    "title": "Consistent Distributed Cooperative Localization: A Coordinate Transformation Approach",
    "arxiv_pdf": "http://arxiv.org/pdf/2303.01205v2",
    "arxiv_abstract": "This paper addresses the consistency issue of multi-robot distributed\ncooperative localization. We introduce a consistent distributed cooperative\nlocalization algorithm conducting state estimation in a transformed coordinate.\nThe core idea involves a linear time-varying coordinated transformation to\nrender the propagation Jacobian independent of the state and make it suitable\nfor a distributed manner. This transformation is seamlessly integrated into a\nserver-based distributed cooperative localization framework, in which each\nrobot estimates its own state while the server maintains the\ncross-correlations. The transformation ensures the correct observability\nproperty of the entire framework. Moreover, the algorithm accommodates various\ntypes of robot-to-robot relative measurements, broadening its applicability.\nThrough simulations and real-world dataset experiments, the proposed algorithm\nhas demonstrated better performance in terms of both consistency and accuracy\ncompared to existing algorithms."
  },
  {
    "paper_no": "781",
    "authors": "Tan, Longyue; Deng, Zhaokun; Hao, Mingrui; Hou, Xilong; Chen, Chen; Gu, Xiaolin; Hou, Zeng-Guang; Wang, Shuangyi",
    "title": "3D Ultrasound Image Acquisition and Diagnostic Analysis of the Common Carotid Artery with a Portable Robotic Device",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "784",
    "authors": "Tian, Qingyao; Liao, Huai; Huang, Xinyan; Chen, Jian; Zhang, Zihui; Yang, Bingyu; Ourselin, Sebastien; Liu, Hongbin",
    "title": "DD-VNB: A Depth-based Dual-Loop Framework for Real-time Visually Navigated Bronchoscopy",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "785",
    "authors": "YAZIDI, C45; Piranda, Benoit; Ouisse, Morvan; Bourgeois, Julien",
    "title": "Efficient Balance Detection for Modular Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "786",
    "authors": "Jin, Liren; Kuang, Haofei; Pan, Yue; Stachniss, Cyrill; Popovic, Marija",
    "title": "STAIR: Semantic-Targeted Active Implicit Reconstruction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "789",
    "authors": "Li, Ke; Bacher, Reinhard; Schmidt, Susanne; Leemans, Wim; Steinicke, Frank",
    "title": "Reality Fusion: Robust Real-time Immersive Mobile Robot Teleoperation with Volumetric Visual Data Fusion",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.01225v1",
    "arxiv_abstract": "We introduce Reality Fusion, a novel robot teleoperation system that\nlocalizes, streams, projects, and merges a typical onboard depth sensor with a\nphotorealistic, high resolution, high framerate, and wide field of view (FoV)\nrendering of the complex remote environment represented as 3D Gaussian splats\n(3DGS). Our framework enables robust egocentric and exocentric robot\nteleoperation in immersive VR, with the 3DGS effectively extending spatial\ninformation of a depth sensor with limited FoV and balancing the trade-off\nbetween data streaming costs and data visual quality. We evaluated our\nframework through a user study with 24 participants, which revealed that\nReality Fusion leads to significantly better user performance, situation\nawareness, and user preferences. To support further research and development,\nwe provide an open-source implementation with an easy-to-replicate custom-made\ntelepresence robot, a high-performance virtual reality 3DGS renderer, and an\nimmersive robot control package. (Source code:\nhttps://github.com/uhhhci/RealityFusion)"
  },
  {
    "paper_no": "791",
    "authors": "Pavlov, Konstantin; Tsepulin, Vladimir; Lutsyak, Nikolay; Khasianov, Rasul; Simchuk, Egor; Perchik, Alexey; Elena, Volkova",
    "title": "Automatic Dietary Monitoring Using Inertial Sensor in Smartwatch",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "793",
    "authors": "Trotti, Francesco; Farinelli, Alessandro; Muradore, Riccardo",
    "title": "Path Re-Planning with Stochastic Obstacle Modeling: A Monte Carlo Tree Search Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "794",
    "authors": "Shen, Yang; Kanazawa, Masanobu; Mori, Kazuki; Isono, Ryu; Nakazawa, Yuri; Takanishi, Atsuo; Otani, Takuya",
    "title": "Development of a Bilateral Control Teleoperation System for Bipedal Humanoid Robot Utilizing Foot Sole Haptics Feedback",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "795",
    "authors": "Novák, Filip; Baca, Tomas; Saska, Martin",
    "title": "Collaborative Object Manipulation on the Water Surface by a UAV-USV Team Using Tethers",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.08580v1",
    "arxiv_abstract": "This paper introduces an innovative methodology for object manipulation on\nthe surface of water through the collaboration of an Unmanned Aerial Vehicle\n(UAV) and an Unmanned Surface Vehicle (USV) connected to the object by tethers.\nWe propose a novel mathematical model of a robotic system that combines the\nUAV, USV, and the tethered floating object. A novel Model Predictive Control\n(MPC) framework is designed for using this model to achieve precise control and\nguidance for this collaborative robotic system. Extensive simulations in the\nrealistic robotic simulator Gazebo demonstrate the system's readiness for\nreal-world deployment, highlighting its versatility and effectiveness. Our\nmulti-robot system overcomes the state-of-the-art single-robot approach,\nexhibiting smaller control errors during the tracking of the floating object's\nreference. Additionally, our multi-robot system demonstrates a shorter recovery\ntime from a disturbance compared to the single-robot approach."
  },
  {
    "paper_no": "796",
    "authors": "Chen, Zhaorun; Zhao, Zhuokai; He, Tairan; Chen, BinHao; Zhao, Xuhao; Gong, Liang; Liu, Chengliang",
    "title": "Safe Reinforcement Learning via Hierarchical Adaptive Chance-Constraint Safeguards",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.03379v2",
    "arxiv_abstract": "Ensuring safety in Reinforcement Learning (RL), typically framed as a\nConstrained Markov Decision Process (CMDP), is crucial for real-world\nexploration applications. Current approaches in handling CMDP struggle to\nbalance optimality and feasibility, as direct optimization methods cannot\nensure state-wise in-training safety, and projection-based methods correct\nactions inefficiently through lengthy iterations. To address these challenges,\nwe propose Adaptive Chance-constrained Safeguards (ACS), an adaptive,\nmodel-free safe RL algorithm using the safety recovery rate as a surrogate\nchance constraint to iteratively ensure safety during exploration and after\nachieving convergence. Theoretical analysis indicates that the relaxed\nprobabilistic constraint sufficiently guarantees forward invariance to the safe\nset. And extensive experiments conducted on both simulated and real-world\nsafety-critical tasks demonstrate its effectiveness in enforcing safety (nearly\nzero-violation) while preserving optimality (+23.8%), robustness, and fast\nresponse in stochastic real-world settings."
  },
  {
    "paper_no": "797",
    "authors": "Lin, Tsung-Chi; Chen, Juo-Tung; Huang, Chien-Ming",
    "title": "Reducing Performance Variability and Overcoming Limited Spatial Ability: Targeted Training for Remote Robot Teleoperation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "803",
    "authors": "Sejnova, Gabriela; Vavrecka, Michal; Stepanova, Karla",
    "title": "Bridging Language, Vision and Action: Multimodal VAEs in Robotic Manipulation Tasks",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.01932v1",
    "arxiv_abstract": "In this work, we focus on unsupervised vision-language-action mapping in the\narea of robotic manipulation. Recently, multiple approaches employing\npre-trained large language and vision models have been proposed for this task.\nHowever, they are computationally demanding and require careful fine-tuning of\nthe produced outputs. A more lightweight alternative would be the\nimplementation of multimodal Variational Autoencoders (VAEs) which can extract\nthe latent features of the data and integrate them into a joint representation,\nas has been demonstrated mostly on image-image or image-text data for the\nstate-of-the-art models. Here we explore whether and how can multimodal VAEs be\nemployed in unsupervised robotic manipulation tasks in a simulated environment.\nBased on the obtained results, we propose a model-invariant training\nalternative that improves the models' performance in a simulator by up to 55%.\nMoreover, we systematically evaluate the challenges raised by the individual\ntasks such as object or robot position variability, number of distractors or\nthe task length. Our work thus also sheds light on the potential benefits and\nlimitations of using the current multimodal VAEs for unsupervised learning of\nrobotic motion trajectories based on vision and language."
  },
  {
    "paper_no": "806",
    "authors": "Li, Hongyu; Padir, Taskin; Jiang, Huaizu",
    "title": "StereoNavNet: Learning to Navigate using Stereo Cameras with Auxiliary Occupancy Voxels",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "811",
    "authors": "Li, Hongyu; Dikhale, Snehal; Cui, Jinda; Iba, Soshi; Jamali, Nawid",
    "title": "HyperTaxel: Hyper-Resolution for Taxel-Based Tactile Signal Through Contrastive Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "812",
    "authors": "Qu, William Ziming; Qu, Jessica; Li, Li; Yang, Jie; Jia, Yuanyuan",
    "title": "Bayesian Deep Predictive Coding for Snake-like Robotic Control in Unknown Terrains",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "815",
    "authors": "QIU, YUE; Egami, Shusaku; Fukuda, Ken; Miyata, Natsuki; Yagi, Takuma; Hara, Kensho; Iwata, Kenji; Sagawa, Ryusuke",
    "title": "DailySTR: A Daily Human Activity Pattern Recognition Dataset for Spatio-temporal Reasoning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "820",
    "authors": "Yu, Chen; Yang, Yichu; Liu, Tianlin; You, Yangwei; zhou, mingliang; Xiang, Diyun",
    "title": "State Estimation Transformers for Agile Legged Locomotion",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.13496v1",
    "arxiv_abstract": "We propose a state estimation method that can accurately predict the robot's\nprivileged states to push the limits of quadruped robots in executing advanced\nskills such as jumping in the wild. In particular, we present the State\nEstimation Transformers (SET), an architecture that casts the state estimation\nproblem as conditional sequence modeling. SET outputs the robot states that are\nhard to obtain directly in the real world, such as the body height and\nvelocities, by leveraging a causally masked Transformer. By conditioning an\nautoregressive model on the robot's past states, our SET model can predict\nthese privileged observations accurately even in highly dynamic locomotions. We\nevaluate our methods on three tasks -- running jumping, running backflipping,\nand running sideslipping -- on a low-cost quadruped robot, Cyberdog2. Results\nshow that SET can outperform other methods in estimation accuracy and\ntransferability in the simulation as well as success rates of jumping and\ntriggering a recovery controller in the real world, suggesting the superiority\nof such a Transformer-based explicit state estimator in highly dynamic\nlocomotion tasks."
  },
  {
    "paper_no": "821",
    "authors": "Wang, Di; Hu, Chengsong; Xie, Shuangyu; Johnson, Joe; Ji, Hojun; Jiang, Yingtao; Bagavathiannan, Muthukumar; Song, Dezhen",
    "title": "Toward Precise Robotic Weed Flaming Using a Mobile Manipulator with a Flamethrower",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.04929v1",
    "arxiv_abstract": "Robotic weed flaming is a new and environmentally friendly approach to weed\nremoval in the agricultural field. Using a mobile manipulator equipped with a\nflamethrower, we design a new system and algorithm to enable effective weed\nflaming, which requires robotic manipulation with a soft and deformable end\neffector, as the thermal coverage of the flame is affected by dynamic or\nunknown environmental factors such as gravity, wind, atmospheric pressure, fuel\ntank pressure, and pose of the nozzle. System development includes overall\ndesign, hardware integration, and software pipeline. To enable precise weed\nremoval, the greatest challenge is to detect and predict dynamic flame coverage\nin real time before motion planning, which is quite different from a\nconventional rigid gripper in grasping or a spray gun in painting. Based on the\nimages from two onboard infrared cameras and the pose information of the\nflamethrower nozzle on a mobile manipulator, we propose a new dynamic flame\ncoverage model. The flame model uses a center-arc curve with a Gaussian\ncross-section model to describe the flame coverage in real time. The\nexperiments have demonstrated the working system and shown that our model and\nalgorithm can achieve a mean average precision (mAP) of more than 76\\% in the\nreprojected images during online prediction."
  },
  {
    "paper_no": "822",
    "authors": "Zimmermann, Stefanie Antonia; Moberg, Stig",
    "title": "Efficient Estimation of Frequency Response Functions of Industrial Robots Using the Local Rational Method",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "823",
    "authors": "Zhang, Liding; Bing, Zhenshan; Zhang, Yu; Chen, Lingyun; Wu, Fan; Haddadin, Sami; Knoll, Alois",
    "title": "Elliptical K-Nearest Neighbors - Path Optimization via Coulomb's Law and Invalid Vertices in C-space Obstacles",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "824",
    "authors": "Mao, Yunxuan; Shen, Bingqi; Yang, Yifei; Wang, Kai; Xiong, Rong; Liao, Yiyi; Wang, Yue",
    "title": "$nu$-DBA: Neural Implicit Dense Bundle Adjustment Enables Image-Only Driving Scene Reconstruction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "825",
    "authors": "Hu, Zhiming; Schmitt, Syn; Haeufle, Daniel Florian Benedict; Bulling, Andreas",
    "title": "GazeMotion: Gaze-guided Human Motion Forecasting",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "826",
    "authors": "Anil Meera, Ajith; Lanillos, Pablo",
    "title": "Confidence-Aware Decision-Making and Control for Tool Selection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "829",
    "authors": "Jin, Rui; Gao, Yuman; Lu, Haojian; Xu, Chao; Gao, Fei",
    "title": "GS-Planner: A Gaussian-Splatting-based Planning Framework for Active High-Fidelity Reconstruction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "830",
    "authors": "Schmidt, Sebastian; Stumpp, Ludwig; Valverde Garrro, Diego; Günnemann, Stephan",
    "title": "Deep Sensor Fusion with Constraint Safety Bounds for High Precision Localization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "831",
    "authors": "Fu, Xiang; Xu, Yifan; su, hu; LIU, Song",
    "title": "NanoNeRF: Robot-assisted Nanoscale 360° reconstruction with neural radiance field under scanning electron microscope",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "833",
    "authors": "Wang, Gaotian; Ren, Kejia; Hang, Kaiyu",
    "title": "UNO Push: Unified Nonprehensile Object Pushing via Non-Parametric Estimation and Model Predictive Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13274v1",
    "arxiv_abstract": "Nonprehensile manipulation through precise pushing is an essential skill that\nhas been commonly challenged by perception and physical uncertainties, such as\nthose associated with contacts, object geometries, and physical properties. For\nthis, we propose a unified framework that jointly addresses system modeling,\naction generation, and control. While most existing approaches either heavily\nrely on a priori system information for analytic modeling, or leverage a large\ndataset to learn dynamic models, our framework approximates a system transition\nfunction via non-parametric learning only using a small number of exploratory\nactions (ca. 10). The approximated function is then integrated with model\npredictive control to provide precise pushing manipulation. Furthermore, we\nshow that the approximated system transition functions can be robustly\ntransferred across novel objects while being online updated to continuously\nimprove the manipulation accuracy. Through extensive experiments on a real\nrobot platform with a set of novel objects and comparing against a\nstate-of-the-art baseline, we show that the proposed unified framework is a\nlight-weight and highly effective approach to enable precise pushing\nmanipulation all by itself. Our evaluation results illustrate that the system\ncan robustly ensure millimeter-level precision and can straightforwardly work\non any novel object."
  },
  {
    "paper_no": "837",
    "authors": "Lee, Joonhyung; Park, Sangbeom; Kwon, Yongin; Lee, Jemin; Ahn, Minwook; Choi, Sungjoon",
    "title": "Visual Preference Inference: An Image Sequence-Based Preference Reasoning in Tabletop Object Manipulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.11513v1",
    "arxiv_abstract": "In robotic object manipulation, human preferences can often be influenced by\nthe visual attributes of objects, such as color and shape. These properties\nplay a crucial role in operating a robot to interact with objects and align\nwith human intention. In this paper, we focus on the problem of inferring\nunderlying human preferences from a sequence of raw visual observations in\ntabletop manipulation environments with a variety of object types, named Visual\nPreference Inference (VPI). To facilitate visual reasoning in the context of\nmanipulation, we introduce the Chain-of-Visual-Residuals (CoVR) method. CoVR\nemploys a prompting mechanism that describes the difference between the\nconsecutive images (i.e., visual residuals) and incorporates such texts with a\nsequence of images to infer the user's preference. This approach significantly\nenhances the ability to understand and adapt to dynamic changes in its visual\nenvironment during manipulation tasks. Furthermore, we incorporate such texts\nalong with a sequence of images to infer the user's preferences. Our method\noutperforms baseline methods in terms of extracting human preferences from\nvisual sequences in both simulation and real-world environments. Code and\nvideos are available at:\n\\href{https://joonhyung-lee.github.io/vpi/}{https://joonhyung-lee.github.io/vpi/}"
  },
  {
    "paper_no": "840",
    "authors": "Xu, Jingyi; Ma, Junyi; Wu, Qi; Zhou, Zijie; Wang, Yue; Chen, Xieyuanli; Yu, Wenxian; Pei, Ling",
    "title": "Explicit Interaction for Fusion-Based Place Recognition",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.17264v1",
    "arxiv_abstract": "Fusion-based place recognition is an emerging technique jointly utilizing\nmulti-modal perception data, to recognize previously visited places in\nGPS-denied scenarios for robots and autonomous vehicles. Recent fusion-based\nplace recognition methods combine multi-modal features in implicit manners.\nWhile achieving remarkable results, they do not explicitly consider what the\nindividual modality affords in the fusion system. Therefore, the benefit of\nmulti-modal feature fusion may not be fully explored. In this paper, we propose\na novel fusion-based network, dubbed EINet, to achieve explicit interaction of\nthe two modalities. EINet uses LiDAR ranges to supervise more robust vision\nfeatures for long time spans, and simultaneously uses camera RGB data to\nimprove the discrimination of LiDAR point clouds. In addition, we develop a new\nbenchmark for the place recognition task based on the nuScenes dataset. To\nestablish this benchmark for future research with comprehensive comparisons, we\nintroduce both supervised and self-supervised training schemes alongside\nevaluation protocols. We conduct extensive experiments on the proposed\nbenchmark, and the experimental results show that our EINet exhibits better\nrecognition performance as well as solid generalization ability compared to the\nstate-of-the-art fusion-based place recognition approaches. Our open-source\ncode and benchmark are released at: https://github.com/BIT-XJY/EINet."
  },
  {
    "paper_no": "846",
    "authors": "Takahashi, Kuniyuki; Masuda, Shimpei; Taniguchi, Tadahiro",
    "title": "Stable Object Placing using Curl and Diff Features of Vision-based Tactile Sensors",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.19129v1",
    "arxiv_abstract": "Ensuring stable object placement is crucial to prevent objects from toppling\nover, breaking, or causing spills. When an object makes initial contact to a\nsurface, and some force is exerted, the moment of rotation caused by the\ninstability of the object's placing can cause the object to rotate in a certain\ndirection (henceforth referred to as direction of corrective rotation).\nExisting methods often employ a Force/Torque (F/T) sensor to estimate the\ndirection of corrective rotation by detecting the moment of rotation as a\ntorque. However, its effectiveness may be hampered by sensor noise and the\ntension of the external wiring of robot cables. To address these issues, we\npropose a method for stable object placing using GelSights, vision-based\ntactile sensors, as an alternative to F/T sensors. Our method estimates the\ndirection of corrective rotation of objects using the displacement of the black\ndot pattern on the elastomeric surface of GelSight. We calculate the Curl from\nvector analysis, indicative of the rotational field magnitude and direction of\nthe displacement of the black dots pattern. Simultaneously, we calculate the\ndifference (Diff) of displacement between the left and right fingers'\nGelSight's black dots. Then, the robot can manipulate the objects' pose using\nCurl and Diff features, facilitating stable placing. Across experiments,\nhandling 18 differently characterized objects, our method achieves precise\nplacing accuracy (less than 1-degree error) in nearly 100% of cases. An\naccompanying video is available at the following link:\nhttps://youtu.be/fQbmCksVHlU"
  },
  {
    "paper_no": "848",
    "authors": "Milano, Francesco; Chung, Jen Jen; Blum, Hermann; Siegwart, Roland; Ott, Lionel",
    "title": "NeuSurfEmb: A Plug-and-Play Pipeline for Dense Correspondence-based 6D Object Pose Estimation without CAD Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "850",
    "authors": "Li, Meng; Zhao, Qi; Lyu, Shuchang; Wang, Chunlei; Ma, Yujing; Cheng, Guangliang; Yang, Chenguang",
    "title": "OVGNet: An Unified Visual-Linguistic Framework for Open-Vocabulary Robotic Grasping",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "851",
    "authors": "Zhu, He; Wang, Yunkai; Kong, Quyu; Xia, Xunlong; Deng, Bing; Xiong, Rong; Wang, Yue",
    "title": "OTVIC: A Dataset with Online Transmission for Vehicle-to-Infrastructure Cooperative 3D Object Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "852",
    "authors": "Xu, Xinglong; Ren, Weihong; Sun, Gan; Ji, Haoyu; Gao, Yu; Liu, Honghai",
    "title": "GroupTrack: Multi-Object Tracking by Using Group Motion Patterns",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "854",
    "authors": "ZHU, Puchen; Zhang, Huayu; ma, xin; Zheng, Xiaoyin; Wang, Xuchen; Au, K. W. Samuel",
    "title": "A CT-guided Control Framework of a Robotic Flexible Endoscope for the Diagnosis of the Maxillary Sinusitis",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.20374v1",
    "arxiv_abstract": "Flexible endoscopes are commonly adopted in narrow and confined anatomical\ncavities due to their higher reachability and dexterity. However, prolonged and\nunintuitive manipulation of these endoscopes leads to an increased workload on\nsurgeons and risks of collision. To address these challenges, this paper\nproposes a CT-guided control framework for the diagnosis of maxillary sinusitis\nby using a robotic flexible endoscope. In the CT-guided control framework, a\nfeasible path to the target position in the maxillary sinus cavity for the\nrobotic flexible endoscope is designed. Besides, an optimal control scheme is\nproposed to autonomously control the robotic flexible endoscope to follow the\nfeasible path. This greatly improves the efficiency and reduces the workload\nfor surgeons. Several experiments were conducted based on a widely utilized\nsinus phantom, and the results showed that the robotic flexible endoscope can\naccurately and autonomously follow the feasible path and reach the target\nposition in the maxillary sinus cavity. The results also verified the\nfeasibility of the CT-guided control framework, which contributes an effective\napproach to early diagnosis of sinusitis in the future."
  },
  {
    "paper_no": "865",
    "authors": "Huang, Shuaiyi; Levy, Mara; Jiang, Zhenyu; Anandkumar, Anima; Zhu, Yuke; Fan, Linxi; Huang, De-An; Shrivastava, Abhinav",
    "title": "ARDuP: Active Region Video Diffusion for Universal Policies",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "868",
    "authors": "Akutsu, Yuki; Kato, Yuki; Yoshida, Takahiro; Sueoka, Yuichiro; Osuka, Koichi",
    "title": "Proposal and Demonstration of a Robot Behavior Planning System Utilizing Video with an Open Source Model in Real-world Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "869",
    "authors": "Ding, Tianye; Li, Hongyu; Jiang, Huaizu",
    "title": "ODTFormer: Efficient Obstacle Detection and Tracking with Stereo Cameras Based on Transformer",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "872",
    "authors": "Zhang, Junbo; Ma, Kaisheng",
    "title": "MG-VLN: Benchmarking Multi-Goal and Long-Horizon Vision-Language Navigation with Language Enhanced Memory Map",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "874",
    "authors": "Kim, Minsoo; Kwon, Obin; Jun, Howoong; Oh, Songhwai",
    "title": "RNR-Nav: A Real-World Visual Navigation System Using Renderable Neural Radiance Maps",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "875",
    "authors": "Wang, Pengqin; Zhu, Meixin; Shen, Shaojie",
    "title": "Environment Transformer and Policy Optimization for Model-Based Offline Reinforcement Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2303.03811v2",
    "arxiv_abstract": "Interacting with the actual environment to acquire data is often costly and\ntime-consuming in robotic tasks. Model-based offline reinforcement learning\n(RL) provides a feasible solution. On the one hand, it eliminates the\nrequirements of interaction with the actual environment. On the other hand, it\nlearns the transition dynamics and reward function from the offline datasets\nand generates simulated rollouts to accelerate training. Previous model-based\noffline RL methods adopt probabilistic ensemble neural networks (NN) to model\naleatoric uncertainty and epistemic uncertainty. However, this results in an\nexponential increase in training time and computing resource requirements.\nFurthermore, these methods are easily disturbed by the accumulative errors of\nthe environment dynamics models when simulating long-term rollouts. To solve\nthe above problems, we propose an uncertainty-aware sequence modeling\narchitecture called Environment Transformer. It models the probability\ndistribution of the environment dynamics and reward function to capture\naleatoric uncertainty and treats epistemic uncertainty as a learnable noise\nparameter. Benefiting from the accurate modeling of the transition dynamics and\nreward function, Environment Transformer can be combined with arbitrary\nplanning, dynamics programming, or policy optimization algorithms for offline\nRL. In this case, we perform Conservative Q-Learning (CQL) to learn a\nconservative Q-function. Through simulation experiments, we demonstrate that\nour method achieves or exceeds state-of-the-art performance in widely studied\noffline RL benchmarks. Moreover, we show that Environment Transformer's\nsimulated rollout quality, sample efficiency, and long-term rollout simulation\ncapability are superior to those of previous model-based offline RL methods."
  },
  {
    "paper_no": "880",
    "authors": "Li, Boren; Li, Hang; Liu, Hangxin",
    "title": "Driving Animatronic Robot Facial Expression From Speech",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12670v3",
    "arxiv_abstract": "Animatronic robots hold the promise of enabling natural human-robot\ninteraction through lifelike facial expressions. However, generating realistic,\nspeech-synchronized robot expressions poses significant challenges due to the\ncomplexities of facial biomechanics and the need for responsive motion\nsynthesis. This paper introduces a novel, skinning-centric approach to drive\nanimatronic robot facial expressions from speech input. At its core, the\nproposed approach employs linear blend skinning (LBS) as a unifying\nrepresentation, guiding innovations in both embodiment design and motion\nsynthesis. LBS informs the actuation topology, facilitates human expression\nretargeting, and enables efficient speech-driven facial motion generation. This\napproach demonstrates the capability to produce highly realistic facial\nexpressions on an animatronic face in real-time at over 4000 fps on a single\nNvidia RTX 4090, significantly advancing robots' ability to replicate nuanced\nhuman expressions for natural interaction. To foster further research and\ndevelopment in this field, the code has been made publicly available at:\n\\url{https://github.com/library87/OpenRoboExp}."
  },
  {
    "paper_no": "881",
    "authors": "Mamedov, Shamil; Geist, Andreas René; Swevers, Jan; Trimpe, Sebastian",
    "title": "Pseudo-rigid body networks: learning interpretable deformable object dynamics from partial observations",
    "arxiv_pdf": "http://arxiv.org/pdf/2307.07975v4",
    "arxiv_abstract": "Accurately predicting deformable linear object (DLO) dynamics is challenging,\nespecially when the task requires a model that is both human-interpretable and\ncomputationally efficient. In this work, we draw inspiration from the\npseudo-rigid body method (PRB) and model a DLO as a serial chain of rigid\nbodies whose internal state is unrolled through time by a dynamics network.\nThis dynamics network is trained jointly with a physics-informed encoder that\nmaps observed motion variables to the DLO's hidden state. To encourage the\nstate to acquire a physically meaningful representation, we leverage the\nforward kinematics of the PRB model as a decoder. We demonstrate in robot\nexperiments that the proposed DLO dynamics model provides physically\ninterpretable predictions from partial observations while being on par with\nblack-box models regarding prediction accuracy. The project code is available\nat: http://tinyurl.com/prb-networks"
  },
  {
    "paper_no": "882",
    "authors": "Zhang, Yuanfan; XIAO, Renxiang; Hong, Ziyang; Hu, Liang; Liu, Jie",
    "title": "Adaptive Visual-Aided 4D Radar Odometry Through Transformer-Based Feature Fusion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "883",
    "authors": "Stephens, Alex; Lacerda, Bruno; Hawes, Nick",
    "title": "Planning for Long-Term Monitoring Missions in Time-Varying Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "884",
    "authors": "Chen, Lin; Wang, Yaonan; Miao, Zhiqiang; Feng, Mingtao; Wang, Yuanzhe; Mo, Yang; zhou, zhen; Wang, Hesheng; Wang, Danwei",
    "title": "Decentralized Multi-Robot Navigation Coupled with Spatial-Temporal RetNet Based on Deep Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "887",
    "authors": "Zhang, Tianlin; Lin, Fenghao; Peng, Xuanbin; Xiong, Xiaogang; Lou, Yunjiang",
    "title": "Whole-body Compliance Control for Quadruped Manipulator with Actuation Saturation of Joint Torque and Ground Friction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "890",
    "authors": "Lin, Xiaozhu; LIU, Song; Wang, Yang",
    "title": "Dynamic Modeling of Robotic Fish considering Background Flow using Koopman Operators",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "892",
    "authors": "He, Binglin; Zhang, Heng; LIU, Song; Wang, Yang",
    "title": "Data-Driven Modeling of Ground Effect For UAV Landing on a Vertical Oscillating Platform",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "893",
    "authors": "Ewers, Jan-Hendrik; Swinton, Sarah; Anderson, Dave; McGookin, Euan William; Thomson, Douglas",
    "title": "Enhancing Reinforcement Learning in Sensor Fusion: A Comparative Analysis of Cubature and Sampling-based Integration Methods for Rover Search Planning",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.08691v3",
    "arxiv_abstract": "This study investigates the computational speed and accuracy of two numerical\nintegration methods, cubature and sampling-based, for integrating an integrand\nover a 2D polygon. Using a group of rovers searching the Martian surface with a\nlimited sensor footprint as a test bed, the relative error and computational\ntime are compared as the area was subdivided to improve accuracy in the\nsampling-based approach. The results show that the sampling-based approach\nexhibits a $14.75\\%$ deviation in relative error compared to cubature when it\nmatches the computational performance at $100\\%$. Furthermore, achieving a\nrelative error below $1\\%$ necessitates a $10000\\%$ increase in relative time\nto calculate due to the $\\mathcal{O}(N^2)$ complexity of the sampling-based\nmethod. It is concluded that for enhancing reinforcement learning capabilities\nand other high iteration algorithms, the cubature method is preferred over the\nsampling-based method."
  },
  {
    "paper_no": "894",
    "authors": "Mamedov, Shamil; Reiter, Rudolf; Basiri Azad, Seyed Mahdi; Viljoen, Ruan Matthys; Boedecker, Joschka; Diehl, Moritz; Swevers, Jan",
    "title": "Safe Imitation Learning of Nonlinear Model Predictive Control for Flexible Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2212.02941v3",
    "arxiv_abstract": "Flexible robots may overcome some of the industry's major challenges, such as\nenabling intrinsically safe human-robot collaboration and achieving a higher\npayload-to-mass ratio. However, controlling flexible robots is complicated due\nto their complex dynamics, which include oscillatory behavior and a\nhigh-dimensional state space. Nonlinear model predictive control (NMPC) offers\nan effective means to control such robots, but its significant computational\ndemand often limits its application in real-time scenarios. To enable fast\ncontrol of flexible robots, we propose a framework for a safe approximation of\nNMPC using imitation learning and a predictive safety filter. Our framework\nsignificantly reduces computation time while incurring a slight loss in\nperformance. Compared to NMPC, our framework shows more than an eightfold\nimprovement in computation time when controlling a three-dimensional flexible\nrobot arm in simulation, all while guaranteeing safety constraints. Notably,\nour approach outperforms state-of-the-art reinforcement learning methods. The\ndevelopment of fast and safe approximate NMPC holds the potential to accelerate\nthe adoption of flexible robots in industry. The project code is available at:\ntinyurl.com/anmpc4fr"
  },
  {
    "paper_no": "899",
    "authors": "Wachowiak, Lennart; Coles, Andrew; Celiktutan, Oya; Canal, Gerard",
    "title": "Are Large Language Models Aligned with People's Social Intuitions for HumanRobot Interactions?",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.05701v2",
    "arxiv_abstract": "Large language models (LLMs) are increasingly used in robotics, especially\nfor high-level action planning. Meanwhile, many robotics applications involve\nhuman supervisors or collaborators. Hence, it is crucial for LLMs to generate\nsocially acceptable actions that align with people's preferences and values. In\nthis work, we test whether LLMs capture people's intuitions about behavior\njudgments and communication preferences in human-robot interaction (HRI)\nscenarios. For evaluation, we reproduce three HRI user studies, comparing the\noutput of LLMs with that of real participants. We find that GPT-4 strongly\noutperforms other models, generating answers that correlate strongly with\nusers' answers in two studies $\\unicode{x2014}$ the first study dealing with\nselecting the most appropriate communicative act for a robot in various\nsituations ($r_s$ = 0.82), and the second with judging the desirability,\nintentionality, and surprisingness of behavior ($r_s$ = 0.83). However, for the\nlast study, testing whether people judge the behavior of robots and humans\ndifferently, no model achieves strong correlations. Moreover, we show that\nvision models fail to capture the essence of video stimuli and that LLMs tend\nto rate different communicative acts and behavior desirability higher than\npeople."
  },
  {
    "paper_no": "905",
    "authors": "Zangeneh, Fereidoon; Bruns, Leonard; Dekel, Amit; Pieropan, Alessandro; Jensfelt, Patric",
    "title": "Conditional Variational Autoencoders for Probabilistic Pose Regression",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.04989v1",
    "arxiv_abstract": "Robots rely on visual relocalization to estimate their pose from camera\nimages when they lose track. One of the challenges in visual relocalization is\nrepetitive structures in the operation environment of the robot. This calls for\nprobabilistic methods that support multiple hypotheses for robot's pose. We\npropose such a probabilistic method to predict the posterior distribution of\ncamera poses given an observed image. Our proposed training strategy results in\na generative model of camera poses given an image, which can be used to draw\nsamples from the pose posterior distribution. Our method is streamlined and\nwell-founded in theory and outperforms existing methods on localization in\npresence of ambiguities."
  },
  {
    "paper_no": "907",
    "authors": "Keely, Maya; Nemlekar, Heramb; Losey, Dylan",
    "title": "Kiri-Spoon: A Soft Shape-Changing Utensil for Robot-Assisted Feeding",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "908",
    "authors": "Grimaldi, Michele; Palomeras, Narcis; Carlucho, Ignacio; Petillot, Yvan R.; Ridao, Pere",
    "title": "FRAGG-Map: Frustum Accelerated GPU-Based Grid Map",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "909",
    "authors": "Wang, Weiyao; Lei, Yutian; Jin, Shiyu; Hager, Gregory; Zhang, Liangjun",
    "title": "VIHE: Virtual In-Hand Eye Transformer for 3D Robotic Manipulation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "910",
    "authors": "Chen, Yuda; Dong, Haoze; Li, Zhongkui",
    "title": "Asynchronous Spatial-Temporal Allocation for Trajectory Planning of Heterogeneous Multi-Agent Systems",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.07431v3",
    "arxiv_abstract": "To plan the trajectories of a large-scale heterogeneous swarm, sequentially\nor synchronously distributed methods usually become intractable due to the lack\nof global clock synchronization. To this end, we provide a novel asynchronous\nspatial-temporal allocation method. Specifically, between a pair of agents, the\nallocation is proposed to determine their corresponding derivable time-stamped\nspace and can be updated in an asynchronous way, by inserting a waiting\nduration between two consecutive replanning steps. Via theoretical analysis,\nthe inter-agent collision is proved to be avoided and the allocation ensures\ntimely updates. Comprehensive simulations and comparisons with five baselines\nvalidate the effectiveness of the proposed method and illustrate its\nimprovement in completion time and moving distance. Finally, hardware\nexperiments are carried out, where $8$ heterogeneous unmanned ground vehicles\nwith onboard computation navigate in cluttered scenarios with high agility."
  },
  {
    "paper_no": "914",
    "authors": "Yoshida, Kodai; Tanaka, Motoyasu",
    "title": "Climbing Gait for a Snake Robot by Adapting to a Flexible Net",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "916",
    "authors": "Park, J. hyeon; Choi, Wonhyuk; Hong, Sunpyo; Seo, Hoseong; Ahn, Joonmo; Ha, Changsu; Han, Heungwoo; Kwon, Junghyun",
    "title": "Hierarchical Action Chunking Transformer: Learning Temporal Multimodality from Demonstrations with Fast Imitation Behavior",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "921",
    "authors": "Hu, Yutong; Wen, Kehan; Yu, Fisher",
    "title": "DexDribbler: Learning Dexterous Soccer Manipulation via Dynamic Supervision",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "924",
    "authors": "Hu, Yuhang; Wang, Yunzhe; Liu, Ruibo; Shen, Zhou; Lipson, Hod",
    "title": "Reconfigurable Robot Identification from Motion Data",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10496v1",
    "arxiv_abstract": "Integrating Large Language Models (VLMs) and Vision-Language Models (VLMs)\nwith robotic systems enables robots to process and understand complex natural\nlanguage instructions and visual information. However, a fundamental challenge\nremains: for robots to fully capitalize on these advancements, they must have a\ndeep understanding of their physical embodiment. The gap between AI models\ncognitive capabilities and the understanding of physical embodiment leads to\nthe following question: Can a robot autonomously understand and adapt to its\nphysical form and functionalities through interaction with its environment?\nThis question underscores the transition towards developing self-modeling\nrobots without reliance on external sensory or pre-programmed knowledge about\ntheir structure. Here, we propose a meta self modeling that can deduce robot\nmorphology through proprioception (the internal sense of position and\nmovement). Our study introduces a 12 DoF reconfigurable legged robot,\naccompanied by a diverse dataset of 200k unique configurations, to\nsystematically investigate the relationship between robotic motion and robot\nmorphology. Utilizing a deep neural network model comprising a robot signature\nencoder and a configuration decoder, we demonstrate the capability of our\nsystem to accurately predict robot configurations from proprioceptive signals.\nThis research contributes to the field of robotic self-modeling, aiming to\nenhance understanding of their physical embodiment and adaptability in real\nworld scenarios."
  },
  {
    "paper_no": "925",
    "authors": "Lin, Zhenchao; He, Li; Yang, Hongqiang; xiaoqun, sun; zhang, guojin; Chen, Weinan; Guan, Yisheng; Zhang, Hong",
    "title": "SWCF-Net: Similarity-Weighted Convolution and Local-Global Fusion for Efficient Large-Scale Point Cloud Semantic Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "932",
    "authors": "Ni, Zhe; Deng, Xiaoxin; Tai, Cong; Zhu, Xinyue; Xie, Qinghongbing; Huang, Weihang; wu, xiang; Zeng, Long",
    "title": "GRID: Scene-Graph-based Instruction-driven Robotic Task Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "933",
    "authors": "Pey, Javier Jia Jie; Samarakoon Mudiyanselage, Bhagya Prasangi Samarakoon; Muthugala Arachchige, Viraj Jagathpriya Muthugala; Elara, Mohan Rajesh",
    "title": "A Decentralized Partially Observable Markov Decision Process for Dynamic Obstacle Avoidance and Complete Area Coverage using Multiple Reconfigurable Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "935",
    "authors": "Ishibashi, Kyosuke; Ishikawa, Hiroki; Azami, Osamu; Yamamoto, Ko",
    "title": "Modeling of Hydraulic Soft Hand with Rubber Sheet Reservoir and Evaluation of its Grasping Flexibility and Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "940",
    "authors": "Tahiraj, Ilir; Fent, Felix; Hafemann, Philipp; Ye, Egon; lienkamp, Markus",
    "title": "GMMCalib: Extrinsic Calibration of LiDAR Sensors using GMM-based Joint Registration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "941",
    "authors": "Manetas, Argyris; Mermigkas, Panagiotis; Maragos, Petros",
    "title": "SDPL-SLAM: Introducing Lines in Dynamic Visual SLAM and Multi-Object Tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "943",
    "authors": "Janna, Run; Tarapongnivat, Kanut; Sricom, Natchaya; Akkawutvanich, Akkawutvanich; Xiong, Xiaofeng; Manoonpong, Poramate",
    "title": "Online Adaptive Impedance Control with Gravity Compensation for an Interactive Lower-Limb Exoskeleton",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "946",
    "authors": "Amaya, Camilo; Eames, Evan; Palinauskas, Gintautas; Perzylo, Alexander Clifford; Sandamirskaya, Yulia; von Arnim, Axel",
    "title": "Neuromorphic force-control in an industrial task: validating energy and latency benefits",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.08928v3",
    "arxiv_abstract": "As robots become smarter and more ubiquitous, optimizing the power\nconsumption of intelligent compute becomes imperative towards ensuring the\nsustainability of technological advancements. Neuromorphic computing hardware\nmakes use of biologically inspired neural architectures to achieve energy and\nlatency improvements compared to conventional von Neumann computing\narchitecture. Applying these benefits to robots has been demonstrated in\nseveral works in the field of neurorobotics, typically on relatively simple\ncontrol tasks. Here, we introduce an example of neuromorphic computing applied\nto the real-world industrial task of object insertion. We trained a spiking\nneural network (SNN) to perform force-torque feedback control using a\nreinforcement learning approach in simulation. We then ported the SNN to the\nIntel neuromorphic research chip Loihi interfaced with a KUKA robotic arm. At\ninference time we show latency competitive with current CPU/GPU architectures,\nand one order of magnitude less energy usage in comparison to state-of-the-art\nlow-energy edge-hardware. We offer this example as a proof of concept\nimplementation of a neuromoprhic controller in real-world robotic setting,\nhighlighting the benefits of neuromorphic hardware for the development of\nintelligent controllers for robots."
  },
  {
    "paper_no": "948",
    "authors": "Dai, Cunxi; Liu, Xiaohan; Shu, Roberto; Hollis, Ralph",
    "title": "Wheelchair Maneuvering with a Single-Spherical-Wheeled Balancing Mobile Manipulator",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.13206v1",
    "arxiv_abstract": "In this work, we present a control framework to effectively maneuver\nwheelchairs with a dynamically stable mobile manipulator. Wheelchairs are a\ntype of nonholonomic cart system, maneuvering such systems with mobile\nmanipulators (MM) is challenging mostly due to the following reasons: 1) These\nsystems feature nonholonomic constraints and considerably varying inertial\nparameters that require online identification and adaptation. 2) These systems\nare widely used in human-centered environments, which demand the MM to operate\nin potentially crowded spaces while ensuring compliance for safe physical\nhuman-robot interaction (pHRI). We propose a control framework that plans\nwhole-body motion based on quasi-static analysis to maneuver heavy nonholonomic\ncarts while maintaining overall compliance. We validated our approach\nexperimentally by maneuvering a wheelchair with a bimanual mobile manipulator,\nthe CMU ballbot. The experiments demonstrate the proposed framework is able to\ntrack desired wheelchair velocity with loads varying from 11.8 kg to 79.4 kg at\na maximum linear velocity of 0.45 m/s and angular velocity of 0.3 rad/s.\nFurthermore, we verified that the proposed method can generate human-like\nmotion smoothness of the wheelchair while ensuring safe interactions with the\nenvironment."
  },
  {
    "paper_no": "952",
    "authors": "Zhang, Zhe; He, Zhou; Ran, Ning; Reniers, Michel",
    "title": "Multi-Robot Path Planning with Boolean Specification Tasks under Motion Uncertainties",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "954",
    "authors": "YE, Baijun; Liu, Caiyun; Xiaoyu, Ye; Chen, Yuantao; Wang, Yuhai; Yan, Zike; Shi, Yongliang; Zhao, Hao; Zhou, Guyue",
    "title": "Blending Distributed NeRFs with Tri-stage Robust Pose Optimization",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.02880v1",
    "arxiv_abstract": "Due to the limited model capacity, leveraging distributed Neural Radiance\nFields (NeRFs) for modeling extensive urban environments has become a\nnecessity. However, current distributed NeRF registration approaches encounter\naliasing artifacts, arising from discrepancies in rendering resolutions and\nsuboptimal pose precision. These factors collectively deteriorate the fidelity\nof pose estimation within NeRF frameworks, resulting in occlusion artifacts\nduring the NeRF blending stage. In this paper, we present a distributed NeRF\nsystem with tri-stage pose optimization. In the first stage, precise poses of\nimages are achieved by bundle adjusting Mip-NeRF 360 with a coarse-to-fine\nstrategy. In the second stage, we incorporate the inverting Mip-NeRF 360,\ncoupled with the truncated dynamic low-pass filter, to enable the achievement\nof robust and precise poses, termed Frame2Model optimization. On top of this,\nwe obtain a coarse transformation between NeRFs in different coordinate\nsystems. In the third stage, we fine-tune the transformation between NeRFs by\nModel2Model pose optimization. After obtaining precise transformation\nparameters, we proceed to implement NeRF blending, showcasing superior\nperformance metrics in both real-world and simulation scenarios. Codes and data\nwill be publicly available at https://github.com/boilcy/Distributed-NeRF."
  },
  {
    "paper_no": "955",
    "authors": "Zhang, Gengyu; Yan, Yan",
    "title": "Towards More Accurate Dynamics and Reward Modeling for Model-Based Offline Inverse Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "956",
    "authors": "Zhang, Chengjun; Yip, Ka-Wa; Yang, Bo; Zhang, Zhiyong; Yuan, Mengwen; Tang, Huajin",
    "title": "CASRL: Collision Avoidance with Spiking Reinforcement Learning Among Dynamic, Decision-Making Agents",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "957",
    "authors": "Kuroki, So; Nishimura, Mai; Kozuno, Tadashi",
    "title": "Multi-Agent Behavior Retrieval: Retrieval-Augmented Policy Training for Cooperative Push Manipulation by Mobile Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2312.02008v3",
    "arxiv_abstract": "Due to the complex interactions between agents, learning multi-agent control\npolicy often requires a prohibited amount of data. This paper aims to enable\nmulti-agent systems to effectively utilize past memories to adapt to novel\ncollaborative tasks in a data-efficient fashion. We propose the Multi-Agent\nCoordination Skill Database, a repository for storing a collection of\ncoordinated behaviors associated with key vectors distinctive to them. Our\nTransformer-based skill encoder effectively captures spatio-temporal\ninteractions that contribute to coordination and provides a unique skill\nrepresentation for each coordinated behavior. By leveraging only a small number\nof demonstrations of the target task, the database enables us to train the\npolicy using a dataset augmented with the retrieved demonstrations.\nExperimental evaluations demonstrate that our method achieves a significantly\nhigher success rate in push manipulation tasks compared with baseline methods\nlike few-shot imitation learning. Furthermore, we validate the effectiveness of\nour retrieve-and-learn framework in a real environment using a team of wheeled\nrobots."
  },
  {
    "paper_no": "960",
    "authors": "Yu, Wenlu; Xu, Jie; Zhao, Chengwei; zhao, lijun; Nguyen, Thien-Minh; Yuan, Shenghai; Bai, Mingming; Xie, Lihua",
    "title": "I2EKF-LO: A Dual-Iteration Extended Kalman Filter Based LiDAR Odometry",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "961",
    "authors": "Yang, Zhenyuan; Rishan Sachinthana, Wijenayaka Kankanamge; Samarakoon Mudiyanselage, Bhagya Prasangi Samarakoon; Elara, Mohan Rajesh",
    "title": "Semantic SLAM Fusing Moving Constraint for Dynamic Objects under Indoor Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "962",
    "authors": "Yang, Xu; Wenhao, Li; Ge, Qijie; Suo, Lulu; Tang, Weijie; WEI, ZHENGYU; Huang, Long-Xiang; Wang, Bo",
    "title": "C3P-VoxelMap: Compact, Cumulative and Coalescible Probabilistic Voxel Mapping",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "964",
    "authors": "Kan, Longxin; Lam, Jia Qing Joshua; Qin, Zhihang; Li, Keyi; Tang, Zhiqiang; Laschi, Cecilia",
    "title": "Bistable valve for electronics-free soft robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "967",
    "authors": "Taioli, Francesco; Rosa, Stefano; Castellini, Alberto; Natale, Lorenzo; Del Bue, Alessio; Farinelli, Alessandro; Cristani, Marco; Wang, Yiming",
    "title": "Mind the Error! Detection and Localization of Instruction Errors in Vision-and-Language Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "969",
    "authors": "Ding, Kairui; Chen, Boyuan; Wu, Ruihai; Li, Yuyang; Zhang, Zongzheng; Gao, Huan-ang; Li, Siqi; Zhu, Yixin; Zhou, Guyue; Dong, Hao; Zhao, Hao",
    "title": "PreAfford: An Affordance-based Pre-grasping Framework with high Adaptability",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "971",
    "authors": "Pratheepkumar, Anish; Ikeda, Markus; Hofmann, Michael; Widmoser, Fabian; Pichler, Andreas; Vincze, Markus",
    "title": "NRDF - Neural Region Descriptor Fields as Implicit ROI Representation for Robotic 3D Surface Processing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "973",
    "authors": "Dominguez-Vidal, Jose Enrique; Sanfeliu, Alberto",
    "title": "Force and Velocity Prediction in Human-Robot Collaborative Transportation Tasks through Video Retentive Networks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "974",
    "authors": "Chakravarty, Arjo; Grey, Michael; Muthugala Arachchige, Viraj Jagathpriya Muthugala; Elara, Mohan Rajesh",
    "title": "Time-Ordered Ad-hoc Resource Sharing for Independent Robotic Agents",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.07942v1",
    "arxiv_abstract": "Resource sharing is a crucial part of a multi-robot system. We propose a\nBoolean satisfiability based approach to resource sharing. Our key\ncontributions are an algorithm for converting any constrained assignment to a\nweighted-SAT based optimization. We propose a theorem that allows optimal\nresource assignment problems to be solved via repeated application of a SAT\nsolver. Additionally we show a way to encode continuous time ordering\nconstraints using Conjunctive Normal Form (CNF). We benchmark our new\nalgorithms and show that they can be used in an ad-hoc setting. We test our\nalgorithms on a fleet of simulated and real world robots and show that the\nalgorithms are able to handle real world situations. Our algorithms and test\nharnesses are opensource and build on Open-RMFs fleet management system."
  },
  {
    "paper_no": "975",
    "authors": "Liu, Songting; Teo, Tat Joo; Lin, Zhiping; Zhu, Haiyue",
    "title": "RelationGrasp: Object-Oriented Prompt Learning for Simultaneously Grasp Detection and Manipulation Relationship in Open Vocabulary",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "977",
    "authors": "Wei, Jiachen; Li, Zhengwei; Liu, Zeyu; Cheng, Long",
    "title": "FOCWS: A High Sensitive Flexible Optical Curvature Sensor Inspired by Arthropod Sensory Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "979",
    "authors": "Zhou, Xun; Yan, Qingqing; Zhu, Minghao; hu, mengxian; Liu, Chengju; Chen, Qijun",
    "title": "SNF-Feat: Semantic-Guided Negative-Sample-Free Representation Learning for Local Feature Extraction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "981",
    "authors": "Yang, Jinrong; Yu, En; Li, Zeming; Li, Xiaoping; Tao, Wenbing",
    "title": "QTrack: Embracing Quality Clues for Robust 3D Multi-Object Tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "982",
    "authors": "Kim, Junyoung; Seo, Junwon; Min, Jihong",
    "title": "Evidential Semantic Mapping in Off-road Environments with Uncertainty-aware Bayesian Kernel Inference",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.14138v1",
    "arxiv_abstract": "Robotic mapping with Bayesian Kernel Inference (BKI) has shown promise in\ncreating semantic maps by effectively leveraging local spatial information.\nHowever, existing semantic mapping methods face challenges in constructing\nreliable maps in unstructured outdoor scenarios due to unreliable semantic\npredictions. To address this issue, we propose an evidential semantic mapping,\nwhich can enhance reliability in perceptually challenging off-road\nenvironments. We integrate Evidential Deep Learning into the semantic\nsegmentation network to obtain the uncertainty estimate of semantic prediction.\nSubsequently, this semantic uncertainty is incorporated into an\nuncertainty-aware BKI, tailored to prioritize more confident semantic\npredictions when accumulating semantic information. By adaptively handling\nsemantic uncertainties, the proposed framework constructs robust\nrepresentations of the surroundings even in previously unseen environments.\nComprehensive experiments across various off-road datasets demonstrate that our\nframework enhances accuracy and robustness, consistently outperforming existing\nmethods in scenes with high perceptual uncertainties."
  },
  {
    "paper_no": "985",
    "authors": "Wang, TingTing; Zhang, Yunzhou; Yang, Linghao; Lv, Yuezhang; Li, Wu; Zhang, Jinpeng",
    "title": "LV-MOTPO: Multi-object Tracking and Pose Optimization Using LiDAR and Camera",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "986",
    "authors": "Cano, Lorenzo; Mosteo, Alejandro R.; Tardioli, Danilo",
    "title": "Procedural generation of tunnel networks for unsupervised training and testing in underground applications.",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "990",
    "authors": "Zhang, Yuyin; Wang, Yue; Liu, Na; Zhong, Songyi; Li, Long; Zhang, Quan; Yue, Tao; Fukuda, Toshio",
    "title": "A Facile one-step injection novel composite sensor for robot tactile assistance",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "992",
    "authors": "Röfer, Adrian; Nematollahi, Iman; Welschehold, Tim; Burgard, Wolfram; Valada, Abhinav",
    "title": "Bayesian Optimization for Sample-Efficient Policy Improvement in Robotic Manipulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.14305v2",
    "arxiv_abstract": "Sample efficient learning of manipulation skills poses a major challenge in\nrobotics. While recent approaches demonstrate impressive advances in the type\nof task that can be addressed and the sensing modalities that can be\nincorporated, they still require large amounts of training data. Especially\nwith regard to learning actions on robots in the real world, this poses a major\nproblem due to the high costs associated with both demonstrations and\nreal-world robot interactions. To address this challenge, we introduce\nBOpt-GMM, a hybrid approach that combines imitation learning with own\nexperience collection. We first learn a skill model as a dynamical system\nencoded in a Gaussian Mixture Model from a few demonstrations. We then improve\nthis model with Bayesian optimization building on a small number of autonomous\nskill executions in a sparse reward setting. We demonstrate the sample\nefficiency of our approach on multiple complex manipulation skills in both\nsimulations and real-world experiments. Furthermore, we make the code and\npre-trained models publicly available at http://bopt-gmm. cs.uni-freiburg.de."
  },
  {
    "paper_no": "994",
    "authors": "Das, Sourav; Camporese, Guglielmo; Cheng, Shaokang; Ballan, Lamberto",
    "title": "Distilling Knowledge for Short-to-Long Term Trajectory Prediction",
    "arxiv_pdf": "http://arxiv.org/pdf/2305.08553v4",
    "arxiv_abstract": "Long-term trajectory forecasting is an important and challenging problem in\nthe fields of computer vision, machine learning, and robotics. One fundamental\ndifficulty stands in the evolution of the trajectory that becomes more and more\nuncertain and unpredictable as the time horizon grows, subsequently increasing\nthe complexity of the problem. To overcome this issue, in this paper, we\npropose Di-Long, a new method that employs the distillation of a short-term\ntrajectory model forecaster that guides a student network for long-term\ntrajectory prediction during the training process. Given a total sequence\nlength that comprehends the allowed observation for the student network and the\ncomplementary target sequence, we let the student and the teacher solve two\ndifferent related tasks defined over the same full trajectory: the student\nobserves a short sequence and predicts a long trajectory, whereas the teacher\nobserves a longer sequence and predicts the remaining short target trajectory.\nThe teacher's task is less uncertain, and we use its accurate predictions to\nguide the student through our knowledge distillation framework, reducing\nlong-term future uncertainty. Our experiments show that our proposed Di-Long\nmethod is effective for long-term forecasting and achieves state-of-the-art\nperformance on the Intersection Drone Dataset (inD) and the Stanford Drone\nDataset (SDD)."
  },
  {
    "paper_no": "996",
    "authors": "Bertoncelli, Filippo; Sabattini, Lorenzo",
    "title": "Streamlining Object Pushing: Behavior Tree-Based Coordination of Control and Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "997",
    "authors": "Marza, Pierre; Matignon, Laetitia; Simonin, Olivier; Batra, Dhruv; Wolf, Christian; Chaplot, Devendra Singh",
    "title": "AutoNeRF: Training Implicit Scene Representations with Autonomous Agents",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "998",
    "authors": "Huber, Johann; Hélénon, François; Kappel, Mathilde; Chelly, Elie; Khoramshahi, Mahdi; BEN AMAR, Faiz; Doncieux, Stéphane",
    "title": "Speeding up 6-DoF Grasp Sampling with Quality-Diversity",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.06173v1",
    "arxiv_abstract": "Recent advances in AI have led to significant results in robotic learning,\nincluding natural language-conditioned planning and efficient optimization of\ncontrollers using generative models. However, the interaction data remains the\nbottleneck for generalization. Getting data for grasping is a critical\nchallenge, as this skill is required to complete many manipulation tasks.\nQuality-Diversity (QD) algorithms optimize a set of solutions to get diverse,\nhigh-performing solutions to a given problem. This paper investigates how QD\ncan be combined with priors to speed up the generation of diverse grasps poses\nin simulation compared to standard 6-DoF grasp sampling schemes. Experiments\nconducted on 4 grippers with 2-to-5 fingers on standard objects show that QD\noutperforms commonly used methods by a large margin. Further experiments show\nthat QD optimization automatically finds some efficient priors that are usually\nhard coded. The deployment of generated grasps on a 2-finger gripper and an\nAllegro hand shows that the diversity produced maintains sim-to-real\ntransferability. We believe these results to be a significant step toward the\ngeneration of large datasets that can lead to robust and generalizing robotic\ngrasping policies."
  },
  {
    "paper_no": "1000",
    "authors": "Tesfazgi, Samuel; Keßler, Markus; Trigili, Emilio; Lederer, Armin; Hirche, Sandra",
    "title": "Data-driven Force Observer for Human-Robot Interaction with Series Elastic Actuators using Gaussian Processes",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.08711v1",
    "arxiv_abstract": "Ensuring safety and adapting to the user's behavior are of paramount\nimportance in physical human-robot interaction. Thus, incorporating elastic\nactuators in the robot's mechanical design has become popular, since it offers\nintrinsic compliance and additionally provide a coarse estimate for the\ninteraction force by measuring the deformation of the elastic components. While\nobserver-based methods have been shown to improve these estimates, they rely on\naccurate models of the system, which are challenging to obtain in complex\noperating environments. In this work, we overcome this issue by learning the\nunknown dynamics components using Gaussian process (GP) regression. By\nemploying the learned model in a Bayesian filtering framework, we improve the\nestimation accuracy and additionally obtain an observer that explicitly\nconsiders local model uncertainty in the confidence measure of the state\nestimate. Furthermore, we derive guaranteed estimation error bounds, thus,\nfacilitating the use in safety-critical applications. We demonstrate the\neffectiveness of the proposed approach experimentally in a human-exoskeleton\ninteraction scenario."
  },
  {
    "paper_no": "1002",
    "authors": "de La Rochefoucauld, Virgile; Lacroix, Simon; Ratsamee, Photchara; Takemura, Haruo",
    "title": "Solving Multi-Robot Task Allocation and Planning in Trans-media Scenarios",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1005",
    "authors": "Mueller, Andreas; Gattringer, Hubert; Marauli, Tobias",
    "title": "Smooth Invariant Interpolation on Lie groups with Prescribed Terminal Conditions for Robot Motion Planning and Modeling of Soft Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1006",
    "authors": "Trumpp, Raphael; Javanmardi, Ehsan; Nakazato, Jin; Tsukada, Manabu; Caccamo, Marco",
    "title": "RaceMOP: Mapless Online Path Planning for Multi-Agent Autonomous Racing using Residual Policy Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1008",
    "authors": "Wang, Xijun; Xian, Ruiqi; Guan, Tianrui; Liu, Fuxiao; Manocha, Dinesh",
    "title": "SCP: Soft Conditional Prompt Learning for Aerial Video Action Recognition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1009",
    "authors": "Yan, Zhongxia; Wu, Cathy",
    "title": "Scalability of Platoon-based Coordination for Mixed Autonomy Intersections",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1014",
    "authors": "Etesam, Yasaman; Yalcin, Ozge; Zhang, Chuxuan; Lim, Angelica",
    "title": "Contextual Emotion Recognition using Large Vision Language Models",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.08992v1",
    "arxiv_abstract": "\"How does the person in the bounding box feel?\" Achieving human-level\nrecognition of the apparent emotion of a person in real world situations\nremains an unsolved task in computer vision. Facial expressions are not enough:\nbody pose, contextual knowledge, and commonsense reasoning all contribute to\nhow humans perform this emotional theory of mind task. In this paper, we\nexamine two major approaches enabled by recent large vision language models: 1)\nimage captioning followed by a language-only LLM, and 2) vision language\nmodels, under zero-shot and fine-tuned setups. We evaluate the methods on the\nEmotions in Context (EMOTIC) dataset and demonstrate that a vision language\nmodel, fine-tuned even on a small dataset, can significantly outperform\ntraditional baselines. The results of this work aim to help robots and agents\nperform emotionally sensitive decision-making and interaction in the future."
  },
  {
    "paper_no": "1015",
    "authors": "Yu, Wenhao; Caluwaerts, Ken; Iscen, Atil; Kew, J. Chase; Zhang, Tingnan; Freeman, Daniel; Lee, Lisa; Saliceti, Stefano; Zhuang, Vincent; Batchelor, Nathan; Bohez, Steven; Casarini, Federico; CHEN, Jose Enrique; Coumans, Erwin; Dostmohamed, Adil; Dulac-Arnold, Gabriel; Escontrela, Alejandro; Frey, Erik; Hafner, Roland; Jain, Deepali; Jyenis, Bauyrjan; Kuang, Yuheng; Lee, Edward; Nachum, Ofir; Oslund, Kenneth; Romano, Francesco; Sadeghi, Fereshteh; Tabanpour, Baruch; Zheng, Daniel; Neunert, Michael; Hadsell, Raia; Heess, Nicolas; Nori, Francesco; Seto, Jeff; Parada, Carolina; Sindhwani, Vikas; Vanhoucke, Vincent; Tan, Jie; Lee, Kuang-Huei",
    "title": "The Design of the Barkour Benchmark for Robot Agility",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1017",
    "authors": "Fredin, Erik; Diller, Eric D.",
    "title": "Estimating the Joint Angles of a Magnetic Surgical Tool using Monocular 3D Keypoint Detection and Particle Filtering",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1018",
    "authors": "Eguchi, Michikuni; Nishimura, Mai; Yoshida, Shigeo; Hiraki, Takefumi",
    "title": "Robot Swarm Control Based on Smoothed Particle Hydrodynamics for Obstacle-Unaware Navigation",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.16309v1",
    "arxiv_abstract": "Robot swarms hold immense potential for performing complex tasks far beyond\nthe capabilities of individual robots. However, the challenge in unleashing\nthis potential is the robots' limited sensory capabilities, which hinder their\nability to detect and adapt to unknown obstacles in real-time. To overcome this\nlimitation, we introduce a novel robot swarm control method with an indirect\nobstacle detector using a smoothed particle hydrodynamics (SPH) model. The\nindirect obstacle detector can predict the collision with an obstacle and its\ncollision point solely from the robot's velocity information. This approach\nenables the swarm to effectively and accurately navigate environments without\nthe need for explicit obstacle detection, significantly enhancing their\noperational robustness and efficiency. Our method's superiority is\nquantitatively validated through a comparative analysis, showcasing its\nsignificant navigation and pattern formation improvements under\nobstacle-unaware conditions."
  },
  {
    "paper_no": "1019",
    "authors": "Zheng, Zhi; Jiang, Tao; Tan, Senqi; Zhang, Hao; Ye, Jianchuan",
    "title": "Segmented Safety Docking Control for Mobile Self-Reconfigurable Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1022",
    "authors": "Zhang, Hao; Jiang, Tao; Tan, Senqi; Ye, Jianchuan; Zheng, Zhi",
    "title": "Tracking Control with Uncertainty Smoothing Estimation under Aggressive Maneuvers of Aerial Vehicles",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1024",
    "authors": "Wang, Yuxuan; yuan, shaoke; Pu, Zihan; Wang, Jiangbei; Yanqiong, Fei",
    "title": "Design and Control of a Novel Soft-Rigid Lower Limb Exoskeleton Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1025",
    "authors": "Chen, Jiayi; Chen, Yuxing; Zhang, Jialiang; Wang, He",
    "title": "Task-Oriented Dexterous Hand Pose Synthesis via Differentiable Grasp Wrench Boundary Estimator",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.13586v3",
    "arxiv_abstract": "This work tackles the problem of task-oriented dexterous hand pose synthesis,\nwhich involves generating a static hand pose capable of applying a\ntask-specific set of wrenches to manipulate objects. Unlike previous approaches\nthat focus solely on force-closure grasps, which are unsuitable for\nnon-prehensile manipulation tasks (\\textit{e.g.}, turning a knob or pressing a\nbutton), we introduce a unified framework covering force-closure grasps,\nnon-force-closure grasps, and a variety of non-prehensile poses. Our key idea\nis a novel optimization objective quantifying the disparity between the Task\nWrench Space (TWS, the desired wrenches predefined as a task prior) and the\nGrasp Wrench Space (GWS, the achievable wrenches computed from the current hand\npose). By minimizing this objective, gradient-based optimization algorithms can\nsynthesize task-oriented hand poses without additional human demonstrations.\nOur specific contributions include 1) a fast, accurate, and differentiable\ntechnique for estimating the GWS boundary; 2) a task-oriented objective\nfunction based on the disparity between the estimated GWS boundary and the\nprovided TWS boundary; and 3) an efficient implementation of the synthesis\npipeline that leverages CUDA accelerations and supports large-scale\nparalleling. Experimental results on 10 diverse tasks demonstrate a 72.6\\%\nsuccess rate in simulation. Furthermore, real-world validation for 4 tasks\nconfirms the effectiveness of synthesized poses for manipulation. Notably,\ndespite being primarily tailored for task-oriented hand pose synthesis, our\npipeline can generate force-closure grasps 50 times faster than DexGraspNet\nwhile maintaining comparable grasp quality. Project page:\nhttps://pku-epic.github.io/TaskDexGrasp/."
  },
  {
    "paper_no": "1027",
    "authors": "Hu, Xingyu; Li, Yuebing; Zhang, Wuxiang; Feng, Yanggang",
    "title": "A Series Variable-stiffness Joint for Robot-assisted Resistance Training",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1028",
    "authors": "Zhang, Wentao; Xu, Shaohang; Cai, Peiyuan; Zhu, Lijun",
    "title": "Agile and Safe Trajectory Planning for Quadruped Navigation with Motion Anisotropy Awareness",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10101v1",
    "arxiv_abstract": "Quadruped robots demonstrate robust and agile movements in various terrains;\nhowever, their navigation autonomy is still insufficient. One of the challenges\nis that the motion capabilities of the quadruped robot are anisotropic along\ndifferent directions, which significantly affects the safety of quadruped robot\nnavigation. This paper proposes a navigation framework that takes into account\nthe motion anisotropy of quadruped robots including kinodynamic trajectory\ngeneration, nonlinear trajectory optimization, and nonlinear model predictive\ncontrol. In simulation and real robot tests, we demonstrate that our\nmotion-anisotropy-aware navigation framework could: (1) generate more efficient\ntrajectories and realize more agile quadruped navigation; (2) significantly\nimprove the navigation safety in challenging scenarios. The implementation is\nrealized as an open-source package at\nhttps://github.com/ZWT006/agile_navigation."
  },
  {
    "paper_no": "1031",
    "authors": "Shinjo, Mirai; Beltran-Hernandez, Cristian Camilo; Hamaya, Masashi; Tanaka, Kazutoshi",
    "title": "Low-cost air hockey robot using a five-bar linkage mechanism driven by position-control servomotors",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1033",
    "authors": "Kim, Dawit; Koo, Jungmo; YUN, Jongseob; Park, Soonyong",
    "title": "Real-time Birds-Eye-View Panoptic Segmentation for Monocular-based Indoor Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1035",
    "authors": "Takano, Rin; Takaya, Kei; Oyama, Hiroyuki",
    "title": "NFPDE: Normalizing Flow-based Parameter Distribution Estimation for Offline Adaptive Domain Randomization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1038",
    "authors": "Rosyid, Abdur; El-Khasawneh, Bashar",
    "title": "Analysis of Lockable Passive Prismatic and Revolute Joints",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1041",
    "authors": "Okuma, Ryusei; Naruse, Yuta; Ito, Fumio; Nakamura, Taro",
    "title": "Peristaltic Soft Robot for Long-distance Pipe Inspection with an Endoskeletal Structure for Propulsion and Traction Amplification",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1043",
    "authors": "Wang, Ziming; Liu, Qingchen; Qin, Jiahu; Li, Man",
    "title": "Ensuring Safety in LLM-Driven Robotics: A Cross-Layer Sequence Supervision Mechanism",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1045",
    "authors": "Wang, Hanqing; Wang, Zan; Liang, Wei",
    "title": "Mastering Scene Rearrangement with Expert-assisted Curriculum Learning and Adaptive Trade-Off Tree-Search",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1048",
    "authors": "Yin, Zhong; Pei, Hai-Long",
    "title": "A Novel Ducted Fan UAV for Safe Aerial Grabbing and Transfer of Multiple Loads Using Electromagnets",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.15822v1",
    "arxiv_abstract": "In recent years, research on aerial grasping, manipulation, and\ntransportation of objects has garnered significant attention. These tasks often\nrequire UAVs to operate safely close to environments or objects and to\nefficiently grasp payloads. However, current widely adopted flying platforms\npose safety hazards: unprotected high-speed rotating propellers can cause harm\nto the surroundings. Additionally, the space for carrying payloads on the\nfuselage is limited, and the restricted position of the payload also hinders\nefficient grasping. To address these issues, this paper presents a coaxial\nducted fan UAV which is equipped with electromagnets mounted externally on the\nfuselage, enabling safe grasping and transfer of multiple loads in midair\nwithout complex additional actuators. It also has the capability to achieve\ndirect human-UAV cargo transfer in the air. The forces acting on the loads\nduring magnetic attachment and their influencing factors were analyzed. An ADRC\ncontroller is utilized to counteract disturbances during grasping and achieve\nattitude control. Finally, flight tests are conducted to verify the UAV's\nability to directly grasp multiple loads from human hands in flight while\nmaintaining attitude tracking."
  },
  {
    "paper_no": "1049",
    "authors": "Xie, Weidong; Luo, Lun; Ye, Nanfei; Ren, Yi; Du, Shaoyi; Wang, Minhang; Xu, Jintao; Ai, Rui; Gu, Weihao; Chen, Xieyuanli",
    "title": "ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place Recognition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1052",
    "authors": "Tang, Huijie; Berto, Federico; Park, Jinkyoo",
    "title": "Ensembling Prioritized Hybrid Policies for Multi-agent Pathfinding",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.07559v2",
    "arxiv_abstract": "Multi-Agent Reinforcement Learning (MARL) based Multi-Agent Path Finding\n(MAPF) has recently gained attention due to its efficiency and scalability.\nSeveral MARL-MAPF methods choose to use communication to enrich the information\none agent can perceive. However, existing works still struggle in structured\nenvironments with high obstacle density and a high number of agents. To further\nimprove the performance of the communication-based MARL-MAPF solvers, we\npropose a new method, Ensembling Prioritized Hybrid Policies (EPH). We first\npropose a selective communication block to gather richer information for better\nagent coordination within multi-agent environments and train the model with a Q\nlearning-based algorithm. We further introduce three advanced inference\nstrategies aimed at bolstering performance during the execution phase. First,\nwe hybridize the neural policy with single-agent expert guidance for navigating\nconflict-free zones. Secondly, we propose Q value-based methods for prioritized\nresolution of conflicts as well as deadlock situations. Finally, we introduce a\nrobust ensemble method that can efficiently collect the best out of multiple\npossible solutions. We empirically evaluate EPH in complex multi-agent\nenvironments and demonstrate competitive performance against state-of-the-art\nneural methods for MAPF. We open-source our code at\nhttps://github.com/ai4co/eph-mapf."
  },
  {
    "paper_no": "1053",
    "authors": "He, Yuzhe; Liang, Shuang; Rui, XiaoFei; Cai, Chengying; Wan, Guowei",
    "title": "EgoVM: Achieving Precise Ego-Localization using Lightweight Vectorized Maps",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1057",
    "authors": "Kim, Dong Hyun; Park, Junghoon; Shin, Gyowook; Yoon, Chiyul; Kim, Yongtae Giovanni; Kim, Sang-Hun; Hyung, SeungYong; KANG, SUNG-CHUL; Lee, Minhyung",
    "title": "A velocity dependent delayed output feedback control (v-DOFC) for gait assistance with an ergonomically designed bi-directional cable-driven hip assist device",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1059",
    "authors": "Ligtenberg, Leendert-Jan Wouter; de Boer, Marcus Cornelis Johannes; Mulder, Iris; Lomme, Roger MLM; Wasserberg, Dorothee; Klein Rot, Emily A. M.; Ben Ami, Doron; Sadeh, Udi; Liefers, Herman Remco; Shoseyov, Oded; Jonkheijm, Pascal; Warle, Michiel; Khalil, Islam S.M.",
    "title": "X-Ray-Guided Magnetic Fields for Wireless Control of Untethered Magnetic Robots in Cerebral Vascular Phantoms",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1060",
    "authors": "Li, Chao; Chen, Xuechao; hengbo, qi; Li, Qingqing; Zhao, Qingrui; Shi, Yongliang; YU, Zhangguo; Jiang, Zhihong",
    "title": "Feasible Region Construction by Polygon Merging for Continuous Bipedal Walking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1063",
    "authors": "Sun, XiaoLou; Quan, Zhibin; si, wufei; wang, chunyan; Li, Yuntian; wu, yuan",
    "title": "CLAT: Convolutional Local Attention Tracker for Real-time UAV Target Tracking System with Feedback Information",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1064",
    "authors": "Wen, ZhuangLei; Dong, Mingze; chen, xiai",
    "title": "Collision-Free Robot Navigation in Crowded Environments using Learning based Convex Model Predictive Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.01450v3",
    "arxiv_abstract": "Navigating robots safely and efficiently in crowded and complex environments\nremains a significant challenge. However, due to the dynamic and intricate\nnature of these settings, planning efficient and collision-free paths for\nrobots to track is particularly difficult. In this paper, we uniquely bridge\nthe robot's perception, decision-making and control processes by utilizing the\nconvex obstacle-free region computed from 2D LiDAR data. The overall pipeline\nis threefold: (1) We proposes a robot navigation framework that utilizes deep\nreinforcement learning (DRL), conceptualizing the observation as the convex\nobstacle-free region, a departure from general reliance on raw sensor inputs.\n(2) We design the action space, derived from the intersection of the robot's\nkinematic limits and the convex region, to enable efficient sampling of\ninherently collision-free reference points. These actions assists in guiding\nthe robot to move towards the goal and interact with other obstacles during\nnavigation. (3) We employ model predictive control (MPC) to track the\ntrajectory formed by the reference points while satisfying constraints imposed\nby the convex obstacle-free region and the robot's kinodynamic limits. The\neffectiveness of proposed improvements has been validated through two sets of\nablation studies and a comparative experiment against the Timed Elastic Band\n(TEB), demonstrating improved navigation performance in crowded and complex\nenvironments."
  },
  {
    "paper_no": "1067",
    "authors": "Dahlquist, Niklas; Nikolakopoulos, George; Saradagi, Akshit",
    "title": "Behavior Tree Based Decentralized Multi-agent Coordination for Balanced Servicing of Time Varying Task Queues",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1068",
    "authors": "Kuhne, Moritz; Giubilato, Riccardo; Roa, Maximo A.",
    "title": "Perception-aware Full Body Trajectory Planning for Autonomous Systems using Motion Primitives",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1071",
    "authors": "Samuel, Kangwagye; Haninger, Kevin; Haddadin, Sami; Oh, Sehoon",
    "title": "Improved Contact Stability for Admittance Control of Industrial Robots with Inverse Model Compensation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1073",
    "authors": "YU, Jingwen; Ye, Hanjing; JIAO, Jianhao; Tan, Ping; Zhang, Hong",
    "title": "GV-Bench: Benchmarking Local Feature Matching for Geometric Verification of Long-term Loop Closure Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1077",
    "authors": "Lee, Joonho; Schroth, Lukas; Klemm, Victor; Bjelonic, Marko; Reske, Alexander; Hutter, Marco",
    "title": "Exploring Constrained Reinforcement Learning Algorithms for Quadrupedal Locomotion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1078",
    "authors": "Innes, Craig; Ramamoorthy, Subramanian",
    "title": "Adaptive Splitting of Reusable Temporal Monitors for Rare Traffic Violations",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.15771v2",
    "arxiv_abstract": "Autonomous Vehicles (AVs) are often tested in simulation to estimate the\nprobability they will violate safety specifications. Two common issues arise\nwhen using existing techniques to produce this estimation: If violations occur\nrarely, simple Monte-Carlo sampling techniques can fail to produce efficient\nestimates; if simulation horizons are too long, importance sampling techniques\n(which learn proposal distributions from past simulations) can fail to\nconverge. This paper addresses both issues by interleaving rare-event sampling\ntechniques with online specification monitoring algorithms. We use adaptive\nmulti-level splitting to decompose simulations into partial trajectories, then\ncalculate the distance of those partial trajectories to failure by leveraging\nrobustness metrics from Signal Temporal Logic (STL). By caching those partial\nrobustness metric values, we can efficiently re-use computations across\nmultiple sampling stages. Our experiments on an interstate lane-change scenario\nshow our method is viable for testing simulated AV-pipelines, efficiently\nestimating failure probabilities for STL specifications based on real traffic\nrules. We produce better estimates than Monte-Carlo and importance sampling in\nfewer simulations."
  },
  {
    "paper_no": "1079",
    "authors": "Martinez, Jorge L.; Morales, Jesús; Sánchez-Montero, Manuel; García-Cerezo, Alfonso",
    "title": "ICR-based Kinematics for Wheeled Skid-Steer Vehicles on Firm Slopes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1080",
    "authors": "Chen, Zhiming; Fang, Haozhe; Chen, Jiapeng; Wang, Michael Yu; Yu, Hongyu",
    "title": "MOE: A Dense LiDAR Moving Event Dataset, Detection Benchmark and LeaderBoard",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1085",
    "authors": "Li, Albert H.; Culbertson, Preston; Ames, Aaron",
    "title": "Toward An Analytic Theory of Intrinsic Robustness for Dexterous Grasping",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.07249v2",
    "arxiv_abstract": "Conventional approaches to grasp planning require perfect knowledge of an\nobject's pose and geometry. Uncertainties in these quantities induce\nuncertainties in the quality of planned grasps, which can lead to failure.\nClassically, grasp robustness refers to the ability to resist external\ndisturbances after grasping an object. In contrast, this work studies\nrobustness to intrinsic sources of uncertainty like object pose or geometry\naffecting grasp planning before execution. To do so, we develop a novel\nanalytic theory of grasping that reasons about this intrinsic robustness by\ncharacterizing the effect of friction cone uncertainty on a grasp's force\nclosure status. We apply this result in two ways. First, we analyze the\ntheoretical guarantees on intrinsic robustness of two grasp metrics in the\nliterature, the classical Ferrari-Canny metric and more recent min-weight\nmetric. We validate these results with hardware trials that compare grasps\nsynthesized with and without robustness guarantees, showing a clear improvement\nin success rates. Second, we use our theory to develop a novel analytic notion\nof probabilistic force closure, which we show can generate unique,\nuncertainty-aware grasps in simulation."
  },
  {
    "paper_no": "1087",
    "authors": "Kapuria, Siddhartha; Bonyun, Jeff; Kulkarni, Yash; Ikoma, Naruhiko; Chinchali, Sandeep; Alambeigi, Farshid",
    "title": "Robot-Enabled Machine Learning-Based Diagnosis of Gastric Cancer Polyps Using Partial Surface Tactile Imaging",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.01554v1",
    "arxiv_abstract": "In this paper, to collectively address the existing limitations on endoscopic\ndiagnosis of Advanced Gastric Cancer (AGC) Tumors, for the first time, we\npropose (i) utilization and evaluation of our recently developed Vision-based\nTactile Sensor (VTS), and (ii) a complementary Machine Learning (ML) algorithm\nfor classifying tumors using their textural features. Leveraging a seven DoF\nrobotic manipulator and unique custom-designed and additively-manufactured\nrealistic AGC tumor phantoms, we demonstrated the advantages of automated data\ncollection using the VTS addressing the problem of data scarcity and biases\nencountered in traditional ML-based approaches. Our synthetic-data-trained ML\nmodel was successfully evaluated and compared with traditional ML models\nutilizing various statistical metrics even under mixed morphological\ncharacteristics and partial sensor contact."
  },
  {
    "paper_no": "1088",
    "authors": "Bayer, Jan; Faigl, Jan",
    "title": "Reward-field Guided Motion Planner for Navigation with Limited Sensing Range",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1091",
    "authors": "Bacchin, Alberto; Barcellona, Leonardo; Terreran, Matteo; Ghidoni, Stefano; Menegatti, Emanuele; Kiyokawa, Takuya",
    "title": "WasteGAN: Data Augmentation for Robotic Waste Sorting through Generative Adversarial Networks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1094",
    "authors": "George Philip, Allen; Ren, Zhongqiang; Rathinam, Sivakumar; Choset, Howie",
    "title": "A Mixed-Integer Conic Program for the Moving-Target Traveling Salesman Problem based on a Graph of Convex Sets",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.04917v2",
    "arxiv_abstract": "This paper introduces a new formulation that finds the optimum for the\nMoving-Target Traveling Salesman Problem (MT-TSP), which seeks to find a\nshortest path for an agent, that starts at a depot, visits a set of moving\ntargets exactly once within their assigned time-windows, and returns to the\ndepot. The formulation relies on the key idea that when the targets move along\nlines, their trajectories become convex sets within the space-time coordinate\nsystem. The problem then reduces to finding the shortest path within a graph of\nconvex sets, subject to some speed constraints. We compare our formulation with\nthe current state-of-the-art Mixed Integer Conic Program (MICP) solver for the\nMT-TSP. The experimental results show that our formulation outperforms the MICP\nfor instances with up to 20 targets, with up to two orders of magnitude\nreduction in runtime, and up to a 60\\% tighter optimality gap. We also show\nthat the solution cost from the convex relaxation of our formulation provides\nsignificantly tighter lower bounds for the MT-TSP than the ones from the MICP."
  },
  {
    "paper_no": "1095",
    "authors": "Nazeri, Mohammad; Wang, Junzhe; payandeh, amirreza; Xiao, Xuesu",
    "title": "VANP: Learning Where to See for Navigation with Self-Supervised Vision-Action Pre-Training",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1096",
    "authors": "Yang, Wenhao; Bai, Shi; Zhang, Yunbo",
    "title": "RADAR: Robotics Assembly by Demonstration via Augmented Reality",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1097",
    "authors": "Han, Juyeop; Lao Beyer, Lukas; Cavalheiro, Guilherme; Karaman, Sertac",
    "title": "NVINS: Robust Visual Inertial Navigation Fused with NeRF-augmented Camera Pose Regressor and Uncertainty Quantification",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1098",
    "authors": "Circe, Jeannette; Giglia, Michael; Rivera, Isaiah; Vardanyan, Ani; Bunt, Brandon, Kiau; Rosen, Michelle",
    "title": "A Circular Soft Pneumatic Actuator with Bi-Directional Bending Behavior",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1099",
    "authors": "Fan, Xiaozhou; Gehrke, Alexander; Breuer, Kenneth",
    "title": "Wing twist and folding work in synergy to propel flapping wing animals and robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.15577v1",
    "arxiv_abstract": "We designed and built a three degrees-of-freedom (DOF) flapping wing robot,\nFlapperoo, to study the aerodynamic benefits of wing folding and twisting.\nForces and moments of this physical model are measured in wind tunnel tests\nover a Strouhal number range of St = 0.2 - 0.4, typical for animal flight. We\nperform particle image velocimetry (PIV) measurements to visualize the air jet\nproduced by wing clapping under the ventral side of the body when wing folding\nis at the extreme. The results show that this jet can be directed by\ncontrolling the wing twist at the moment of clapping, which leads to greatly\nenhanced cycle-averaged thrust, especially at high St or low flight speeds.\nAdditional benefits of more thrust and less negative lift are gained during\nupstroke using wing twist. Remarkably, less total actuating force, or less\ntotal power, is required during upstroke with wing twist. These findings\nemphasize the benefits of critical wing articulation for the future flapping\nwing/fin robots and for an accurate test platform to study natural flapping\nwing flight or underwater vehicles."
  },
  {
    "paper_no": "1102",
    "authors": "Okada, Masashi; Komatsu, Mayumi; Taniguchi, Tadahiro",
    "title": "A Contact Model based on Denoising Diffusion to Learn Variable Impedance Control for Contact-rich Manipulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13221v1",
    "arxiv_abstract": "In this paper, a novel approach is proposed for learning robot control in\ncontact-rich tasks such as wiping, by developing Diffusion Contact Model (DCM).\nPrevious methods of learning such tasks relied on impedance control with\ntime-varying stiffness tuning by performing Bayesian optimization by\ntrial-and-error with robots. The proposed approach aims to reduce the cost of\nrobot operation by predicting the robot contact trajectories from the variable\nstiffness inputs and using neural models. However, contact dynamics are\ninherently highly nonlinear, and their simulation requires iterative\ncomputations such as convex optimization. Moreover, approximating such\ncomputations by using finite-layer neural models is difficult. To overcome\nthese limitations, the proposed DCM used the denoising diffusion models that\ncould simulate the complex dynamics via iterative computations of multi-step\ndenoising, thus improving the prediction accuracy. Stiffness tuning experiments\nconducted in simulated and real environments showed that the DCM achieved\ncomparable performance to a conventional robot-based optimization method while\nreducing the number of robot trials."
  },
  {
    "paper_no": "1105",
    "authors": "Lai, Tin; Morere, Philippe",
    "title": "Do One Thing and Do It Well: Delegate Responsibilities in Classical Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1106",
    "authors": "Baek, DongHoon; Sim, Youngwoo; Purushottam, Amartya; Gupta, Saurabh; Ramos, Joao",
    "title": "Real-to-Sim Adaptation via High-Fidelity Simulation to Control a Wheeled-Humanoid Robot with Unknown Dynamics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1108",
    "authors": "Kim, Inbeom; Ko, Kwangsung",
    "title": "Development of Contextual Collision Risk framework for Operational Envelope of autonomous navigation system",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1116",
    "authors": "Sankaranarayanan, Viswa Narayanan; Saradagi, Akshit; Satpute, Sumeet; Nikolakopoulos, George",
    "title": "Time-varying Control Barrier Function for Safe and Precise Landing of a UAV on a Moving Target",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1120",
    "authors": "Kamijo, Tatsuya; Beltran-Hernandez, Cristian Camilo; Hamaya, Masashi",
    "title": "Learning Variable Compliance Control From a Few Demonstrations for Bimanual Robot with Haptic Feedback Teleoperation System",
    "arxiv_pdf": "http://arxiv.org/pdf/2406.14990v2",
    "arxiv_abstract": "Automating dexterous, contact-rich manipulation tasks using rigid robots is a\nsignificant challenge in robotics. Rigid robots, defined by their actuation\nthrough position commands, face issues of excessive contact forces due to their\ninability to adapt to contact with the environment, potentially causing damage.\nWhile compliance control schemes have been introduced to mitigate these issues\nby controlling forces via external sensors, they are hampered by the need for\nfine-tuning task-specific controller parameters. Learning from Demonstrations\n(LfD) offers an intuitive alternative, allowing robots to learn manipulations\nthrough observed actions. In this work, we introduce a novel system to enhance\nthe teaching of dexterous, contact-rich manipulations to rigid robots. Our\nsystem is twofold: firstly, it incorporates a teleoperation interface utilizing\nVirtual Reality (VR) controllers, designed to provide an intuitive and\ncost-effective method for task demonstration with haptic feedback. Secondly, we\npresent Comp-ACT (Compliance Control via Action Chunking with Transformers), a\nmethod that leverages the demonstrations to learn variable compliance control\nfrom a few demonstrations. Our methods have been validated across various\ncomplex contact-rich manipulation tasks using single-arm and bimanual robot\nsetups in simulated and real-world environments, demonstrating the\neffectiveness of our system in teaching robots dexterous manipulations with\nenhanced adaptability and safety. Code available at:\nhttps://github.com/omron-sinicx/CompACT"
  },
  {
    "paper_no": "1122",
    "authors": "Zhou, Yuwei; Lu, Guoyu",
    "title": "Indoor 3D Reconstruction Based on Shading and Motion Clues",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1124",
    "authors": "Hu, Junpeng; Cheng, Lei; Yan, Haodong; Gladkova, Mariia; Huang, Tianyu; Liu, Yunhui; Cremers, Daniel; Li, Haoang",
    "title": "Physically-Based Photometric Bundle Adjustment in Non-Lambertian Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.11854v1",
    "arxiv_abstract": "Photometric bundle adjustment (PBA) is widely used in estimating the camera\npose and 3D geometry by assuming a Lambertian world. However, the assumption of\nphotometric consistency is often violated since the non-diffuse reflection is\ncommon in real-world environments. The photometric inconsistency significantly\naffects the reliability of existing PBA methods. To solve this problem, we\npropose a novel physically-based PBA method. Specifically, we introduce the\nphysically-based weights regarding material, illumination, and light path.\nThese weights distinguish the pixel pairs with different levels of photometric\ninconsistency. We also design corresponding models for material estimation\nbased on sequential images and illumination estimation based on point clouds.\nIn addition, we establish the first SLAM-related dataset of non-Lambertian\nscenes with complete ground truth of illumination and material. Extensive\nexperiments demonstrated that our PBA method outperforms existing approaches in\naccuracy."
  },
  {
    "paper_no": "1127",
    "authors": "Li, Chunyu; He, Mengfan; Lyu, Xu; Meng, Ziyang",
    "title": "In-Flight Initialization of Global Visual-Inertial Estimators using Geospatial Data",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1128",
    "authors": "Li, Yunfei; Yuan, Ying; Cui, Jingzhi; Huan, Haoran; Fu, Wei; Gao, Jiaxuan; Xu, Zekai; Wu, Yi",
    "title": "Robot Generating Data for Learning Generalizable Visual Robotic Manipulation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1134",
    "authors": "Renault, Benoit; Saraydaryan, Jacques; Brown, David; Simonin, Olivier",
    "title": "Multi-Robot Navigation Among Movable Obstacles: Implicit Coordination to Deal with Conflicts and Deadlocks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1136",
    "authors": "Zhang, Jing; Wang, Baichuan; Pan, Zhijie; Li, Weiqi; Li, Mengtang",
    "title": "Automatic Field of View Adjustment of an RCM Constraint-Free Continuum Laparoscopic Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1138",
    "authors": "Wang, Yikun; Sierra M., Sergio D.; Harris, Nigel; Munera, Marcela; Cifuentes, Carlos A.",
    "title": "Multimodal Haptic Interface for Walker-Assisted Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1147",
    "authors": "Dasgupta, Saptarshi; Gupta, Akshat; Tuli, Shreshth; Paul, Rohan",
    "title": "Uncertainty-aware Active Learning of NeRF-based Object Models for Robot Manipulators using Visual and Re-orientation Actions",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.01812v1",
    "arxiv_abstract": "Manipulating unseen objects is challenging without a 3D representation, as\nobjects generally have occluded surfaces. This requires physical interaction\nwith objects to build their internal representations. This paper presents an\napproach that enables a robot to rapidly learn the complete 3D model of a given\nobject for manipulation in unfamiliar orientations. We use an ensemble of\npartially constructed NeRF models to quantify model uncertainty to determine\nthe next action (a visual or re-orientation action) by optimizing\ninformativeness and feasibility. Further, our approach determines when and how\nto grasp and re-orient an object given its partial NeRF model and re-estimates\nthe object pose to rectify misalignments introduced during the interaction.\nExperiments with a simulated Franka Emika Robot Manipulator operating in a\ntabletop environment with benchmark objects demonstrate an improvement of (i)\n14% in visual reconstruction quality (PSNR), (ii) 20% in the geometric/depth\nreconstruction of the object surface (F-score) and (iii) 71% in the task\nsuccess rate of manipulating objects a-priori unseen orientations/stable\nconfigurations in the scene; over current methods. The project page can be\nfound here: https://actnerf.github.io."
  },
  {
    "paper_no": "1148",
    "authors": "Hiraoka, Takuma; Kunita, Ren; Kojima, Kunio; Hiraoka, Naoki; Konishi, Masanori; Makabe, Tasuku; Okada, Kei; Inaba, Masayuki",
    "title": "Magnetic tactile sensor with load tolerance and flexibility using frame structures for estimating triaxial contact force distribution of humanoid",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1149",
    "authors": "Yuan, Quan; Liang, Xu; Su, Tingting; Bai, Weibang",
    "title": "Development of a Novel Redundant Parallel Mechanism with Enlarged Workspace and Enhanced Dexterity for Fracture Reduction Surgery",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1152",
    "authors": "Karacan, Kübra; Zhang, Anran; Sadeghian, Hamid; Wu, Fan; Haddadin, Sami",
    "title": "Visuo-Tactile Exploration of Unknown Rigid 3D Curvatures by Vision-Augmented Unified Force-Impedance Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.14219v1",
    "arxiv_abstract": "Despite recent advancements in torque-controlled tactile robots, integrating\nthem into manufacturing settings remains challenging, particularly in complex\nenvironments. Simplifying robotic skill programming for non-experts is crucial\nfor increasing robot deployment in manufacturing. This work proposes an\ninnovative approach, Vision-Augmented Unified Force-Impedance Control\n(VA-UFIC), aimed at intuitive visuo-tactile exploration of unknown 3D\ncurvatures. VA-UFIC stands out by seamlessly integrating vision and tactile\ndata, enabling the exploration of diverse contact shapes in three dimensions,\nincluding point contacts, flat contacts with concave and convex curvatures, and\nscenarios involving contact loss. A pivotal component of our method is a robust\nonline contact alignment monitoring system that considers tactile error, local\nsurface curvature, and orientation, facilitating adaptive adjustments of robot\nstiffness and force regulation during exploration. We introduce virtual energy\ntanks within the control framework to ensure safety and stability, effectively\naddressing inherent safety concerns in visuo-tactile exploration. Evaluation\nusing a Franka Emika research robot demonstrates the efficacy of VA-UFIC in\nexploring unknown 3D curvatures while adhering to arbitrarily defined\nforce-motion policies. By seamlessly integrating vision and tactile sensing,\nVA-UFIC offers a promising avenue for intuitive exploration of complex\nenvironments, with potential applications spanning manufacturing, inspection,\nand beyond."
  },
  {
    "paper_no": "1153",
    "authors": "de Wolde, Jelmer; Knoedler, Luzia; Garofalo, Gianluca; Alonso-Mora, Javier",
    "title": "Current-Based Impedance Control for Interacting with Mobile Manipulators",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13079v1",
    "arxiv_abstract": "As robots shift from industrial to human-centered spaces, adopting mobile\nmanipulators, which expand workspace capabilities, becomes crucial. In these\nsettings, seamless interaction with humans necessitates compliant control. Two\ncommon methods for safe interaction, admittance, and impedance control, require\nforce or torque sensors, often absent in lower-cost or lightweight robots. This\npaper presents an adaption of impedance control that can be used on\ncurrent-controlled robots without the use of force or torque sensors and its\napplication for compliant control of a mobile manipulator. A calibration method\nis designed that enables estimation of the actuators' current/torque ratios and\nfrictions, used by the adapted impedance controller, and that can handle model\nerrors. The calibration method and the performance of the designed controller\nare experimentally validated using the Kinova GEN3 Lite arm. Results show that\nthe calibration method is consistent and that the designed controller for the\narm is compliant while also being able to track targets with five-millimeter\nprecision when no interaction is present. Additionally, this paper presents two\noperational modes for interacting with the mobile manipulator: one for guiding\nthe robot around the workspace through interacting with the arm and another for\nexecuting a tracking task, both maintaining compliance to external forces.\nThese operational modes were tested in real-world experiments, affirming their\npractical applicability and effectiveness."
  },
  {
    "paper_no": "1155",
    "authors": "Herynek, Jáchym; Edelkamp, Stefan",
    "title": "Multi-Robot Multi-Goal Mission Planning in Terrains of Varying Energy Consumption",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1156",
    "authors": "Liu, Lilu; Jiao, Yanmei; An, Zhou; Ma, Honghai; Zhou, Chunlin; Lu, Haojian; Hu, Jian; Xiong, Rong; Wang, Yue",
    "title": "Vertebrea-based Global X-ray to CT Registration for Thoracic Surgeries",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1158",
    "authors": "An, Seoki; Lee, Somang; Lee, Jeongmin; Park, Sunkyung; Lee, Dongjun",
    "title": "Collision Detection between Smooth Convex Bodies via Riemannian Optimization Framework",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1159",
    "authors": "Wang, Wenshuo; Zhu, Haiyue; Ang Jr, Marcelo H",
    "title": "GraspContrast: Self-supervised Contrastive Learning with False Negative Elimination for 6-DoF Grasp Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1160",
    "authors": "Wang, Yunfei; Sun, Weiyuan; Tang, Wei; Zhang, Xianrui; Yu, Zhenping; Cao, Shunxiang; Qu, Juntian",
    "title": "CFD-enabled Approach for Optimizing CPG Control Network for Underwater Soft Robotic Fish",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1161",
    "authors": "Doula, Achref; Yin, Huijie; Mühlhäuser, Max; Sanchez Guinea, Alejandro",
    "title": "NeSyMoF: A Neuro-Symbolic Model for Motion Forecasting",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1162",
    "authors": "Hu, Wenfei; Lin, Weikai; Fang, Hongyu; Wang, Yi; Luo, Dingsheng",
    "title": "OW3Det: Toward Open-World 3D Object Detection for Autonomous Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1164",
    "authors": "Yang, Junjie; Zhao, Zhihao; Zhao, Yinzheng; Zapp, Daniel; Maier, Mathias; Huang, Kai; Navab, Nassir; Nasseri, M. Ali",
    "title": "Intraocular Reflection Modeling and Avoidance Planning in Image-Guided Ophthalmic Surgeries",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1168",
    "authors": "huang, dingtao; Lin, Ente; Chen, Lipeng; Liu, lifu; Zeng, Long",
    "title": "SD-Net: Symmetric-Aware Keypoint Prediction and Domain Adaptation for 6D Pose Estimation In Bin-picking Scenarios",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1170",
    "authors": "Liu, Jianbang; Li, Guangyang; Mao, Xinyu; Meng, Fei; Mei, Jie; Meng, Max Q.-H.",
    "title": "SparseGTN: Human Trajectory Forecasting with Sparsely Represented Scene and Incomplete Trajectories",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1171",
    "authors": "de Moura Martins Gomes, Nelson; Garrido Carpio, Fernando José; Nashashibi, Fawzi",
    "title": "Improving behavior profile discovery for vehicles",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.15786v2",
    "arxiv_abstract": "Multiple approaches have already been proposed to mimic real driver behaviors\nin simulation. This article proposes a new one, based solely on the exploration\nof undisturbed observation of intersections. From them, the behavior profiles\nfor each macro-maneuver will be discovered. Using the macro-maneuvers already\nidentified in previous works, a comparison method between trajectories with\ndifferent lengths using an Extended Kalman Filter (EKF) is proposed, which\ncombined with an Expectation-Maximization (EM) inspired method, defines the\ndifferent clusters that represent the behaviors observed. This is also paired\nwith a Kullback-Liebler divergent (KL) criteria to define when the clusters\nneed to be split or merged. Finally, the behaviors for each macro-maneuver are\ndetermined by each cluster discovered, without using any map information about\nthe environment and being dynamically consistent with vehicle motion. By\nobservation it becomes clear that the two main factors for driver's behavior\nare their assertiveness and interaction with other road users."
  },
  {
    "paper_no": "1177",
    "authors": "Naik, Lakshadeep; Kalkan, Sinan; Sørensen, Sune Lundø; Mikkel, Kjærgaard; Krüger, Norbert",
    "title": "BaSeNet: A Learning-based Mobile Manipulator Base Pose Sequence Planning for Pickup Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1178",
    "authors": "Lin, Junru; Nachkov, Asen; Peng, Songyou; Van Gool, Luc; Paudel, Danda Pani",
    "title": "Ternary-Type Opacity and Hybrid Odometry for RGB NeRF-SLAM",
    "arxiv_pdf": "http://arxiv.org/pdf/2312.13332v3",
    "arxiv_abstract": "In this work, we address the challenge of deploying Neural Radiance Field\n(NeRFs) in Simultaneous Localization and Mapping (SLAM) under the condition of\nlacking depth information, relying solely on RGB inputs. The key to unlocking\nthe full potential of NeRF in such a challenging context lies in the\nintegration of real-world priors. A crucial prior we explore is the binary\nopacity prior of 3D space with opaque objects. To effectively incorporate this\nprior into the NeRF framework, we introduce a ternary-type opacity (TT) model\ninstead, which categorizes points on a ray intersecting a surface into three\nregions: before, on, and behind the surface. This enables a more accurate\nrendering of depth, subsequently improving the performance of image warping\ntechniques. Therefore, we further propose a novel hybrid odometry (HO) scheme\nthat merges bundle adjustment and warping-based localization. Our integrated\napproach of TT and HO achieves state-of-the-art performance on synthetic and\nreal-world datasets, in terms of both speed and accuracy. This breakthrough\nunderscores the potential of NeRF-SLAM in navigating complex environments with\nhigh fidelity."
  },
  {
    "paper_no": "1181",
    "authors": "Yao, Gongxin; Xuan, Yixin; Li, Xinyang; Pan, Yu",
    "title": "CMR-Agent: Learning a Cross-Modal Agent for Iterative Image-to-Point Cloud Registration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1183",
    "authors": "Díaz Rosales, Alejandro; Rodriguez-Nogueira, Jose; Matheson, Eloise; Abbink, David A.; Peternel, Luka",
    "title": "Interactive Multi-Stiffness Mixed Reality Interface: Controlling and Visualizing Robot and Environment Stiffnes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1187",
    "authors": "Dechaux, Amaury; Kitazaki, Michiteru; Lagarde, Julien; Ganesh, Gowrishankar",
    "title": "Design and Evaluation of a Prototype Tactile Radar for Active Sensing of Proximal Objects",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1189",
    "authors": "She, Mengkun; Seegräber, Felix; Nakath, David; Koeser, Kevin",
    "title": "Refractive COLMAP: Refractive Structure-from-Motion Revisited",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.08640v3",
    "arxiv_abstract": "In this paper, we present a complete refractive Structure-from-Motion (RSfM)\nframework for underwater 3D reconstruction using refractive camera setups (for\nboth, flat- and dome-port underwater housings). Despite notable achievements in\nrefractive multi-view geometry over the past decade, a robust, complete and\npublicly available solution for such tasks is not available at present, and\noften practical applications have to resort to approximating refraction effects\nby the intrinsic (distortion) parameters of a pinhole camera model. To fill\nthis gap, we have integrated refraction considerations throughout the entire\nSfM process within the state-of-the-art, open-source SfM framework COLMAP.\nNumerical simulations and reconstruction results on synthetically generated but\nphoto-realistic images with ground truth validate that enabling refraction does\nnot compromise accuracy or robustness as compared to in-air reconstructions.\nFinally, we demonstrate the capability of our approach for large-scale\nrefractive scenarios using a dataset consisting of nearly 6000 images. The\nimplementation is released as open-source at:\nhttps://cau-git.rz.uni-kiel.de/inf-ag-koeser/colmap_underwater."
  },
  {
    "paper_no": "1191",
    "authors": "Jiang, Haochen; Xu, Yueming; Zeng, Yihan; XU, Hang; Zhang, Wei; Feng, Jianfeng; Zhang, Li",
    "title": "OpenOcc: Open Vocabulary 3D Scene Reconstruction via Occupancy Representation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1193",
    "authors": "Josifovski, Josip; Auddy, Sayantan; Malmir, Mohammadhossein; Piater, Justus; Knoll, Alois; Navarro-Guerrero, Nicolás",
    "title": "Continual Domain Randomization",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12193v2",
    "arxiv_abstract": "Domain Randomization (DR) is commonly used for sim2real transfer of\nreinforcement learning (RL) policies in robotics. Most DR approaches require a\nsimulator with a fixed set of tunable parameters from the start of the\ntraining, from which the parameters are randomized simultaneously to train a\nrobust model for use in the real world. However, the combined randomization of\nmany parameters increases the task difficulty and might result in sub-optimal\npolicies. To address this problem and to provide a more flexible training\nprocess, we propose Continual Domain Randomization (CDR) for RL that combines\ndomain randomization with continual learning to enable sequential training in\nsimulation on a subset of randomization parameters at a time. Starting from a\nmodel trained in a non-randomized simulation where the task is easier to solve,\nthe model is trained on a sequence of randomizations, and continual learning is\nemployed to remember the effects of previous randomizations. Our robotic\nreaching and grasping tasks experiments show that the model trained in this\nfashion learns effectively in simulation and performs robustly on the real\nrobot while matching or outperforming baselines that employ combined\nrandomization or sequential randomization without continual learning. Our code\nand videos are available at https://continual-dr.github.io/."
  },
  {
    "paper_no": "1194",
    "authors": "Rato, Daniela; Oliveira, Miguel; Santos, Vitor; Sappa, Angel",
    "title": "Multi-View 2D to 3D Lifting Video-Based Optimization: A Robust Approach for Human Pose Estimation with Occluded Joint Prediction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1198",
    "authors": "Lorang, Pierrick; Goel, Shivam; Shukla, Yash; Zips, Patrik; Scheutz, Matthias",
    "title": "A Framework for Neurosymbolic Goal-Conditioned Continual Learning for Open World Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1200",
    "authors": "Li, Ye; Yang, Wenchao; Lin, Dekun; Wang, Qianlei; Cui, Zhe; Qin, Xiaolin",
    "title": "AVM-SLAM: Semantic Visual SLAM with Multi-Sensor Fusion in a Bird's Eye View for Automated Valet Parking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1204",
    "authors": "Oh, Haedam; Chebrolu, Nived; Mattamala, Matias; Freißmuth, Leonard; Fallon, Maurice",
    "title": "Evaluation and Deployment of LiDAR-based Place Recognition in Dense Forests",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.14326v2",
    "arxiv_abstract": "Many LiDAR place recognition systems have been developed and tested\nspecifically for urban driving scenarios. Their performance in natural\nenvironments such as forests and woodlands have been studied less closely. In\nthis paper, we analyzed the capabilities of four different LiDAR place\nrecognition systems, both handcrafted and learning-based methods, using LiDAR\ndata collected with a handheld device and legged robot within dense forest\nenvironments. In particular, we focused on evaluating localization where there\nis significant translational and orientation difference between corresponding\nLiDAR scan pairs. This is particularly important for forest survey systems\nwhere the sensor or robot does not follow a defined road or path. Extending our\nanalysis we then incorporated the best performing approach, Logg3dNet, into a\nfull 6-DoF pose estimation system -- introducing several verification layers\nfor precise registration. We demonstrated the performance of our methods in\nthree operational modes: online SLAM, offline multi-mission SLAM map merging,\nand relocalization into a prior map. We evaluated these modes using data\ncaptured in forests from three different countries, achieving 80% of correct\nloop closures candidates with baseline distances up to 5m, and 60% up to 10m.\nVideo at: https://youtu.be/86l-oxjwmjY"
  },
  {
    "paper_no": "1209",
    "authors": "Ravenberg, Jevon Gianni; Belli, Italo; Prendergast, J. Micah; Seth, Ajay; Peternel, Luka",
    "title": "Creating Discomfort Maps via Hand-held Human Feedback Interface for Robotic Shoulder Physiotherapy",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1210",
    "authors": "Zhang, Chuxuan; Burkanova, Bermet; Kim, Lawrence H.; Yip, Lauren; Cupcic, Ugo; Lallée, Stéphane; Lim, Angelica",
    "title": "React to This! How Humans Challenge Interactive Agents using Nonverbal Behaviors",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1212",
    "authors": "Freißmuth, Leonard; Mattamala, Matias; Chebrolu, Nived; Schaefer, Simon; Leutenegger, Stefan; Fallon, Maurice",
    "title": "Online Tree Reconstruction and Forest Inventory on a Mobile Robotic System",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.17622v1",
    "arxiv_abstract": "Terrestrial laser scanning (TLS) is the standard technique used to create\naccurate point clouds for digital forest inventories. However, the measurement\nprocess is demanding, requiring up to two days per hectare for data collection,\nsignificant data storage, as well as resource-heavy post-processing of 3D data.\nIn this work, we present a real-time mapping and analysis system that enables\nonline generation of forest inventories using mobile laser scanners that can be\nmounted e.g. on mobile robots. Given incrementally created and locally accurate\nsubmaps-data payloads-our approach extracts tree candidates using a custom,\nVoronoi-inspired clustering algorithm. Tree candidates are reconstructed using\nan adapted Hough algorithm, which enables robust modeling of the tree stem.\nFurther, we explicitly incorporate the incremental nature of the data\ncollection by consistently updating the database using a pose graph LiDAR SLAM\nsystem. This enables us to refine our estimates of the tree traits if an area\nis revisited later during a mission. We demonstrate competitive accuracy to TLS\nor manual measurements using laser scanners that we mounted on backpacks or\nmobile robots operating in conifer, broad-leaf and mixed forests. Our results\nachieve RMSE of 1.93 cm, a bias of 0.65 cm and a standard deviation of 1.81 cm\n(averaged across these sequences)-with no post-processing required after the\nmission is complete."
  },
  {
    "paper_no": "1214",
    "authors": "Agand, Pedram; Mahdavian, Mohammad; Savva, Manolis; Chen, Mo",
    "title": "DMFuser: Distilled Multi-Task Learning for End-to-end Transformer-Based Sensor Fusion in Autonomous Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1216",
    "authors": "Park, Heemang; AHN, Kyuree; Park, Jinkyoo",
    "title": "NLNS-MASPF for solving Multi-Agent scheduling and Path-Finding",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1217",
    "authors": "Huang, Xingshuai; Wu, Di; Jenkin, Michael; Boulet, Benoit",
    "title": "Towards Enhanced Fairness and Sample Efficiency in Traffic Signal Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1218",
    "authors": "Chanrungmaneekul, Podshara; Ren, Kejia; Grace, Joshua; Dollar, Aaron; Hang, Kaiyu",
    "title": "Interactive Robot-Environment Self-Calibration via Compliant Exploratory Actions",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13144v1",
    "arxiv_abstract": "Calibrating robots into their workspaces is crucial for manipulation tasks.\nExisting calibration techniques often rely on sensors external to the robot\n(cameras, laser scanners, etc.) or specialized tools. This reliance complicates\nthe calibration process and increases the costs and time requirements.\nFurthermore, the associated setup and measurement procedures require\nsignificant human intervention, which makes them more challenging to operate.\nUsing the built-in force-torque sensors, which are nowadays a default component\nin collaborative robots, this work proposes a self-calibration framework where\nrobot-environmental spatial relations are automatically estimated through\ncompliant exploratory actions by the robot itself. The self-calibration\napproach converges, verifies its own accuracy, and terminates upon completion,\nautonomously purely through interactive exploration of the environment's\ngeometries. Extensive experiments validate the effectiveness of our\nself-calibration approach in accurately establishing the robot-environment\nspatial relationships without the need for additional sensing equipment or any\nhuman intervention."
  },
  {
    "paper_no": "1219",
    "authors": "Chen, Changan; Ramos Chen, Jordi; Tomar, Anshul; Grauman, Kristen",
    "title": "Sim2Real Transfer for Audio-Visual Navigation with Frequency-Adaptive Acoustic Field Prediction",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.02821v2",
    "arxiv_abstract": "Sim2real transfer has received increasing attention lately due to the success\nof learning robotic tasks in simulation end-to-end. While there has been a lot\nof progress in transferring vision-based navigation policies, the existing\nsim2real strategy for audio-visual navigation performs data augmentation\nempirically without measuring the acoustic gap. The sound differs from light in\nthat it spans across much wider frequencies and thus requires a different\nsolution for sim2real. We propose the first treatment of sim2real for\naudio-visual navigation by disentangling it into acoustic field prediction\n(AFP) and waypoint navigation. We first validate our design choice in the\nSoundSpaces simulator and show improvement on the Continuous AudioGoal\nnavigation benchmark. We then collect real-world data to measure the spectral\ndifference between the simulation and the real world by training AFP models\nthat only take a specific frequency subband as input. We further propose a\nfrequency-adaptive strategy that intelligently selects the best frequency band\nfor prediction based on both the measured spectral difference and the energy\ndistribution of the received audio, which improves the performance on the real\ndata. Lastly, we build a real robot platform and show that the transferred\npolicy can successfully navigate to sounding objects. This work demonstrates\nthe potential of building intelligent agents that can see, hear, and act\nentirely from simulation, and transferring them to the real world."
  },
  {
    "paper_no": "1220",
    "authors": "Ismail, Seif; Arbues, Antonio; Cotterell, Ryan; Zurbrügg, René; Amo Alonso, Carmen",
    "title": "NARRATE: Versatile Language Architecture for Optimal Control in Robotics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1223",
    "authors": "Baek, Jongbeom; Kim, Gyeongnyeon; Park, Seonghoon; An, Honggyu; Poggi, Matteo; Kim, Seungryong",
    "title": "MaskingDepth: Masked Consistency Regularization for Semi-Supervised Monocular Depth Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1224",
    "authors": "Honari, Homayoun; Soufi Enayati, Amir Mehdi; Ghafarian Tamizi, Mehran; Najjaran, Homayoun",
    "title": "Meta SAC-Lag: Towards Deployable Safe Reinforcement Learning via MetaGradient-based Hyperparameter Tuning",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.07962v1",
    "arxiv_abstract": "Safe Reinforcement Learning (Safe RL) is one of the prevalently studied\nsubcategories of trial-and-error-based methods with the intention to be\ndeployed on real-world systems. In safe RL, the goal is to maximize reward\nperformance while minimizing constraints, often achieved by setting bounds on\nconstraint functions and utilizing the Lagrangian method. However, deploying\nLagrangian-based safe RL in real-world scenarios is challenging due to the\nnecessity of threshold fine-tuning, as imprecise adjustments may lead to\nsuboptimal policy convergence. To mitigate this challenge, we propose a unified\nLagrangian-based model-free architecture called Meta Soft Actor-Critic\nLagrangian (Meta SAC-Lag). Meta SAC-Lag uses meta-gradient optimization to\nautomatically update the safety-related hyperparameters. The proposed method is\ndesigned to address safe exploration and threshold adjustment with minimal\nhyperparameter tuning requirement. In our pipeline, the inner parameters are\nupdated through the conventional formulation and the hyperparameters are\nadjusted using the meta-objectives which are defined based on the updated\nparameters. Our results show that the agent can reliably adjust the safety\nperformance due to the relatively fast convergence rate of the safety\nthreshold. We evaluate the performance of Meta SAC-Lag in five simulated\nenvironments against Lagrangian baselines, and the results demonstrate its\ncapability to create synergy between parameters, yielding better or competitive\nresults. Furthermore, we conduct a real-world experiment involving a robotic\narm tasked with pouring coffee into a cup without spillage. Meta SAC-Lag is\nsuccessfully trained to execute the task, while minimizing effort constraints."
  },
  {
    "paper_no": "1225",
    "authors": "Miyake, Hibiki; Ayusawa, Ko; Sagawa, Ryusuke; Yoshida, Eiichi",
    "title": "Contacts from Motion: Learning Discrete Features for Automatic Contact Detection and Estimation from Human Movements",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1227",
    "authors": "Nguyen, An; Le, Chuong; Walunj, Pratik; Do, Thanh Nho; Netchaev, Anton; La, Hung",
    "title": "A Multi-model Fusion of LiDAR-inertial Odometry via Localization and Mapping",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1228",
    "authors": "Qian, Chen; Liu, Tangyou; Wu, Liao",
    "title": "Effects of fiber number and density on fiber jamming: Towards follow-the-leader deployment of a continuum robot",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.13529v1",
    "arxiv_abstract": "Fiber jamming modules (FJMs) offer flexibility and quick stiffness variation,\nmaking them suitable for follow-the-leader (FTL) motions in continuum robots,\nwhich is ideal for minimally invasive surgery (MIS). However, their potential\nhas not been fully exploited, particularly in designing and manufacturing\nsmall-sized FJMs with high stiffness variation. Although existing research has\nfocused on factors like fiber materials and geometry to maximize stiffness\nvariation, the results often do not apply to FJMs for MIS due to size\nconstraints. Meanwhile, other factors such as fiber number and packing density,\nless significant to large FJMs but critical to small-sized FJMs, have received\ninsufficient investigation regarding their impact on the stiffness variation\nfor FTL deployment. In this paper, we design and fabricate FJMs with a diameter\nof 4mm. Through theoretical and experimental analysis, we find that fiber\nnumber and packing density significantly affect both absolute stiffness and\nstiffness variation. Our experiments confirm the feasibility of using FJMs in a\nmedical FTL robot design. The optimal configuration is a 4mm FJM with 0.4mm\nfibers at a 56% packing density, achieving up to 3400% stiffness variation. A\nvideo demonstration of a prototype robot using the suggested parameters for\nachieving FTL motions can be found at https://youtu.be/7pI5U0z7kcE."
  },
  {
    "paper_no": "1232",
    "authors": "Kim, Jinyeob; DAEWON, KWAK; RIM, Hyunwoo; Kim, Donghan",
    "title": "Belief-Aided Navigation using Bayesian Reinforcement Learning for Avoiding Humans in Blind Spots",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10105v1",
    "arxiv_abstract": "Recent research on mobile robot navigation has focused on socially aware\nnavigation in crowded environments. However, existing methods do not adequately\naccount for human robot interactions and demand accurate location information\nfrom omnidirectional sensors, rendering them unsuitable for practical\napplications. In response to this need, this study introduces a novel\nalgorithm, BNBRL+, predicated on the partially observable Markov decision\nprocess framework to assess risks in unobservable areas and formulate movement\nstrategies under uncertainty. BNBRL+ consolidates belief algorithms with\nBayesian neural networks to probabilistically infer beliefs based on the\npositional data of humans. It further integrates the dynamics between the\nrobot, humans, and inferred beliefs to determine the navigation paths and\nembeds social norms within the reward function, thereby facilitating socially\naware navigation. Through experiments in various risk laden scenarios, this\nstudy validates the effectiveness of BNBRL+ in navigating crowded environments\nwith blind spots. The model's ability to navigate effectively in spaces with\nlimited visibility and avoid obstacles dynamically can significantly improve\nthe safety and reliability of autonomous vehicles."
  },
  {
    "paper_no": "1233",
    "authors": "Rahman, Sharmin; DiPietro, Robert; Kedarisetti, Dharanish; Kulathumani, Vinod",
    "title": "Large-scale Indoor Mapping with Failure Detection and Recovery in SLAM",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1234",
    "authors": "Swann, Aiden; Strong, Matthew; Do, Won Kyung; Sznaier Camps, Gadiel; Schwager, Mac; Kennedy, Monroe",
    "title": "Touch-GS: Visual-Tactile Supervised 3D Gaussian Splatting",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1235",
    "authors": "Liao, Jing-Yan; Doshi, Parth Jaydip; Zhang, Zihan; Paz, David; Christensen, Henrik Iskov",
    "title": "OSM vs HD Maps: Map Representations for Trajectory Prediction",
    "arxiv_pdf": "http://arxiv.org/pdf/2311.02305v1",
    "arxiv_abstract": "While High Definition (HD) Maps have long been favored for their precise\ndepictions of static road elements, their accessibility constraints and\nsusceptibility to rapid environmental changes impede the widespread deployment\nof autonomous driving, especially in the motion forecasting task. In this\ncontext, we propose to leverage OpenStreetMap (OSM) as a promising alternative\nto HD Maps for long-term motion forecasting. The contributions of this work are\nthreefold: firstly, we extend the application of OSM to long-horizon\nforecasting, doubling the forecasting horizon compared to previous studies.\nSecondly, through an expanded receptive field and the integration of\nintersection priors, our OSM-based approach exhibits competitive performance,\nnarrowing the gap with HD Map-based models. Lastly, we conduct an exhaustive\ncontext-aware analysis, providing deeper insights in motion forecasting across\ndiverse scenarios as well as conducting class-aware comparisons. This research\nnot only advances long-term motion forecasting with coarse map representations\nbut additionally offers a potential scalable solution within the domain of\nautonomous driving."
  },
  {
    "paper_no": "1239",
    "authors": "Zhang, Yuxuan; Koppal, Sanjeev",
    "title": "FoveaCam++: Systems-Level Advances for Long Range Multi-Object High-Resolution Tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1241",
    "authors": "Wang, Yuanzhe; Dai, Yunxiang; Wang, Danwei",
    "title": "Real-Time Path Generation and Alignment Control for Autonomous Curb Following",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1242",
    "authors": "Malone, Connor; Vora, Ankit; Peynot, Thierry; Milford, Michael J",
    "title": "Dynamically Modulating Visual Place Recognition Sequence Length For Minimum Acceptable Performance Scenarios",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.00863v1",
    "arxiv_abstract": "Mobile robots and autonomous vehicles are often required to function in\nenvironments where critical position estimates from sensors such as GPS become\nuncertain or unreliable. Single image visual place recognition (VPR) provides\nan alternative for localization but often requires techniques such as sequence\nmatching to improve robustness, which incurs additional computation and latency\ncosts. Even then, the sequence length required to localize at an acceptable\nperformance level varies widely; and simply setting overly long fixed sequence\nlengths creates unnecessary latency, computational overhead, and can even\ndegrade performance. In these scenarios it is often more desirable to meet or\nexceed a set target performance at minimal expense. In this paper we present an\napproach which uses a calibration set of data to fit a model that modulates\nsequence length for VPR as needed to exceed a target localization performance.\nWe make use of a coarse position prior, which could be provided by any other\nlocalization system, and capture the variation in appearance across this\nregion. We use the correlation between appearance variation and sequence length\nto curate VPR features and fit a multilayer perceptron (MLP) for selecting the\noptimal length. We demonstrate that this method is effective at modulating\nsequence length to maximize the number of sections in a dataset which meet or\nexceed a target performance whilst minimizing the median length used. We show\napplicability across several datasets and reveal key phenomena like\ngeneralization capabilities, the benefits of curating features and the utility\nof non-state-of-the-art feature extractors with nuanced properties."
  },
  {
    "paper_no": "1243",
    "authors": "Luo, Xubo; Wan, Xue; Gao, Yixing; Tian, Yaolin; Zhang, Wei; Shu, Leizheng",
    "title": "JointLoc: A Real-time Visual Localization Framework for Planetary UAVs Based on Joint Relative and Absolute Pose Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1247",
    "authors": "Zhang, Dongshuo; Chen, Nanhua; WU, MEIQING; Lam, Siew Kei",
    "title": "CurricularVPR: Curricular Contrastive Loss for Visual Place Recognition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1248",
    "authors": "Al-Dubooni, Mohammed; Wong, Cuebong; Althoefer, Kaspar",
    "title": "Hybrid Continuum-Eversion Robot: Precise Navigation and Decontamination in Nuclear Environments using Vine Robot",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.13135v2",
    "arxiv_abstract": "Soft growing vine robots show great potential for navigation and\ndecontamination tasks in the nuclear industry. This paper introduces a novel\nhybrid continuum-eversion robot designed to address certain challenges in\nrelation to navigating and operating within pipe networks and enclosed remote\nvessels. The hybrid robot combines the flexibility of a soft eversion robot\nwith the precision of a continuum robot at its tip, allowing for controlled\nsteering and movement in hard to access and/or complex environments. The design\nenables the delivery of sensors, liquids, and aerosols to remote areas,\nsupporting remote decontamination activities. This paper outlines the design\nand construction of the robot and the methods by which it achieves selective\nsteering. We also include a comprehensive review of current related work in\neversion robotics, as well as other steering devices and actuators currently\nunder research, which underpin this novel active steering approach. This is\nfollowed by an experimental evaluation that demonstrates the robot's real-world\ncapabilities in delivering liquids and aerosols to remote locations. The\nexperiments reveal successful outcomes, with over 95% success in precision\nspraying tests. The paper concludes by discussing future work alongside\nlimitations in the current design, ultimately showcasing its potential as a\nsolution for remote decontamination operations in the nuclear industry."
  },
  {
    "paper_no": "1249",
    "authors": "Kumar, Aakash; Chen, Chen; Mian, Ajmal; Lobo, Niels; Shah, Mubarak",
    "title": "Sparse Points to Dense Clouds: Enhancing 3D Detection with Limited LiDAR Data",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.06715v1",
    "arxiv_abstract": "3D detection is a critical task that enables machines to identify and locate\nobjects in three-dimensional space. It has a broad range of applications in\nseveral fields, including autonomous driving, robotics and augmented reality.\nMonocular 3D detection is attractive as it requires only a single camera,\nhowever, it lacks the accuracy and robustness required for real world\napplications. High resolution LiDAR on the other hand, can be expensive and\nlead to interference problems in heavy traffic given their active\ntransmissions. We propose a balanced approach that combines the advantages of\nmonocular and point cloud-based 3D detection. Our method requires only a small\nnumber of 3D points, that can be obtained from a low-cost, low-resolution\nsensor. Specifically, we use only 512 points, which is just 1% of a full LiDAR\nframe in the KITTI dataset. Our method reconstructs a complete 3D point cloud\nfrom this limited 3D information combined with a single image. The\nreconstructed 3D point cloud and corresponding image can be used by any\nmulti-modal off-the-shelf detector for 3D object detection. By using the\nproposed network architecture with an off-the-shelf multi-modal 3D detector,\nthe accuracy of 3D detection improves by 20% compared to the state-of-the-art\nmonocular detection methods and 6% to 9% compare to the baseline multi-modal\nmethods on KITTI and JackRabbot datasets."
  },
  {
    "paper_no": "1250",
    "authors": "Jeong, Gu-Cheol; Bahety, Arpit; Pedraza, Gabriel; Deshpande, Ashish; Martín-Martín, Roberto",
    "title": "BaRiFlex: A Robotic Gripper with Versatility and Collision Robustness for Robot Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1251",
    "authors": "Xi, Haoyu; Li, Wei; Zhao, Fangzhou; Chen, Liang; Hu, Yu",
    "title": "A Safe and Efficient Timed-Elastic-Band Planner for Unstructured Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1253",
    "authors": "Xu, Haoyuan; Zhao, Shuyong; Zhi, Jiale; Bi, Chongze; Wen, Li",
    "title": "A Biomimetic Robot Crawling Upstream using Adhesive Suckers Inspired by Net-winged Midge Larvae",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1254",
    "authors": "Liu, Weimin; Wang, Wenjun; Sun, Zhaocong",
    "title": "Supervised Articulation Angles Estimation for Multi-Articulated Vehicles Based on Panoramic Camera System",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1255",
    "authors": "Zhao, Guiyu; Guo, Zhentao; Ma, Hongbin",
    "title": "SGOR: Outlier Removal by Leveraging Semantic and Geometric Information for Robust Point Cloud Registration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1256",
    "authors": "Min, Chaerin; Cha, sehyun; Won, Changhee; Lim, Jongwoo",
    "title": "Fast Spatial Reasoning of Implicit 3D maps through Explicit Near-Far Sampling Range Prediction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1257",
    "authors": "Xiang, Pingyu; Qiu, Ke; Sun, Danying; zhang, jingyu; Fang, Qin; Mi, Xiangyu; Chen, Mengxiao; Wang, Yue; Xiong, Rong; Lu, Haojian",
    "title": "Learning the Inverse Kinematics of Magnetic Continuum Robot for Teleoperated Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1261",
    "authors": "Akturk, Sait; Valentine, Justin; Ahmad, Junaid; Jagersand, Martin",
    "title": "Immersive Human-in-the-Loop Control: Real-Time 3D Surface Meshing and Physics Simulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.13752v1",
    "arxiv_abstract": "This paper introduces the TactiMesh Teleoperator Interface (TTI), a novel\npredictive visual and haptic system designed explicitly for human-in-the-loop\nrobot control using a head-mounted display (HMD). By employing simultaneous\nlocalization and mapping (SLAM)in tandem with a space carving method (CARV),\nTTI creates a real time 3D surface mesh of remote environments from an RGB\ncamera mounted on a Barrett WAM arm. The generated mesh is integrated into a\nphysics simulator, featuring a digital twin of the WAM robot arm to create a\nvirtual environment. In this virtual environment, TTI provides haptic feedback\ndirectly in response to the operator's movements, eliminating the problem with\ndelayed response from the haptic follower robot. Furthermore, texturing the 3D\nmesh with keyframes from SLAM allows the operator to control the viewpoint of\ntheir Head Mounted Display (HMD) independently of the arm-mounted robot camera,\ngiving a better visual immersion and improving manipulation speed.\nIncorporating predictive visual and haptic feedback significantly improves\nteleoperation in applications such as search and rescue, inspection, and remote\nmaintenance."
  },
  {
    "paper_no": "1263",
    "authors": "Tao, Chuyuan; Cheng, Sheng; Zhao, Yang; Wang, Fanxin; HOVAKIMYAN, NAIRA",
    "title": "An Optimization-Based Planner with B-spline Parameterized Continuous-Time Reference Signals",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.00133v1",
    "arxiv_abstract": "For the cascaded planning and control modules implemented for robot\nnavigation, the frequency gap between the planner and controller has received\nlimited attention. In this study, we introduce a novel B-spline parameterized\noptimization-based planner (BSPOP) designed to address the frequency gap\nchallenge with limited onboard computational power in robots. The proposed\nplanner generates continuous-time control inputs for low-level controllers\nrunning at arbitrary frequencies to track. Furthermore, when considering the\nconvex control action sets, BSPOP uses the convex hull property to\nautomatically constrain the continuous-time control inputs within the convex\nset. Consequently, compared with the discrete-time optimization-based planners,\nBSPOP reduces the number of decision variables and inequality constraints,\nwhich improves computational efficiency as a byproduct. Simulation results\ndemonstrate that our approach can achieve a comparable planning performance to\nthe high-frequency baseline optimization-based planners while demanding less\ncomputational power. Both simulation and experiment results show that the\nproposed method performs better in planning compared with baseline planners in\nthe same frequency."
  },
  {
    "paper_no": "1269",
    "authors": "Li, Xiufei; Yang, Miao; Qi, Yuanxin; Li, Zhuowei; zhang, miao",
    "title": "Voltage Regulation in Polymer Electrolyte Fuel Cell Systems Using Gaussian Process Model Predictive Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.16170v1",
    "arxiv_abstract": "This study introduces a novel approach utilizing Gaussian process model\npredictive control (MPC) to stabilize the output voltage of a polymer\nelectrolyte fuel cell (PEFC) system by simultaneously regulating hydrogen and\nairflow rates. Two Gaussian process models are developed to capture PEFC\ndynamics, taking into account constraints including hydrogen pressure and input\nchange rates, thereby aiding in mitigating errors inherent to PEFC predictive\ncontrol. The dynamic performance of the physical model and Gaussian process MPC\nin constraint handling and system inputs is compared and analyzed. Simulation\noutcomes demonstrate that the proposed Gaussian process MPC effectively\nmaintains the voltage at the target 48 V while adhering to safety constraints,\neven amidst workload disturbances ranging from 110-120 A. In comparison to\ntraditional MPC using detailed system models, Gaussian process MPC exhibits a\n43\\% higher overshoot and 25\\% slower response time. Nonetheless, it offers the\nadvantage of not requiring the underlying true system model and needing less\nsystem information."
  },
  {
    "paper_no": "1271",
    "authors": "Zheng, Yanqiu; Yan, Cong; HE, YUETONG; Asano, Fumihiko; Tokuda, Isao",
    "title": "Modeling and Gait Analysis of Passive Rimless Wheel with Compliant Feet",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1276",
    "authors": "Shin, Jungkyoo; Han, Jieun; Kim, Seungjun; Oh, Yoonseon; Kim, Eunwoo",
    "title": "Task Planning for Long-Horizon Cooking Tasks Based on Large Language Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1278",
    "authors": "Wang, He; Lin, Minshen; Zhang, Guofeng",
    "title": "Contrastive Mask Denoising Transformer for 3D Instance Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1283",
    "authors": "Barroso Ramírez, Sergio; Zapata Cornejo, Noé José; Pérez González, Gerardo; Bustos, Pablo; Núñez, Pedro",
    "title": "Real-time Hazard Prediction in Connected Autonomous Vehicles: A Digital Twin Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1285",
    "authors": "Luo, Lifan; Zhang, Boyang; Peng, Zhijie; Cheung, Yik Kin; Zhang, Guanlan; Li, Zhigang; Wang, Michael Yu; Yu, Hongyu",
    "title": "CompdVision: Combining Near-Field 3D Visual and Tactile Sensing Using a Compact Compound-Eye Imaging System",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1287",
    "authors": "B Nair, Gokul; Milford, Michael J; Fischer, Tobias",
    "title": "Enhancing Visual Place Recognition via Fast and Slow Adaptive Biasing in Event Cameras",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.16425v2",
    "arxiv_abstract": "Event cameras are increasingly popular in robotics due to beneficial features\nsuch as low latency, energy efficiency, and high dynamic range. Nevertheless,\ntheir downstream task performance is greatly influenced by the optimization of\nbias parameters. These parameters, for instance, regulate the necessary change\nin light intensity to trigger an event, which in turn depends on factors such\nas the environment lighting and camera motion. This paper introduces feedback\ncontrol algorithms that automatically tune the bias parameters through two\ninteracting methods: 1) An immediate, on-the-fly \\textit{fast} adaptation of\nthe refractory period, which sets the minimum interval between consecutive\nevents, and 2) if the event rate exceeds the specified bounds even after\nchanging the refractory period repeatedly, the controller adapts the pixel\nbandwidth and event thresholds, which stabilizes after a short period of noise\nevents across all pixels (\\textit{slow} adaptation). Our evaluation focuses on\nthe visual place recognition task, where incoming query images are compared to\na given reference database. We conducted comprehensive evaluations of our\nalgorithms' adaptive feedback control in real-time. To do so, we collected the\nQCR-Fast-and-Slow dataset that contains DAVIS346 event camera streams from 366\nrepeated traversals of a Scout Mini robot navigating through a 100 meter long\nindoor lab setting (totaling over 35km distance traveled) in varying brightness\nconditions with ground truth location information. Our proposed feedback\ncontrollers result in superior performance when compared to the standard bias\nsettings and prior feedback control methods. Our findings also detail the\nimpact of bias adjustments on task performance and feature ablation studies on\nthe fast and slow adaptation mechanisms."
  },
  {
    "paper_no": "1288",
    "authors": "Song, Wenxuan; Zhao, Han; Ding, Pengxiang; Cui, Can; Lyu, Shangke; Fan, YaNing; Wang, Donglin",
    "title": "GeRM: A Generalist Robotic Model with Mixture-of-experts for Quadruped Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1290",
    "authors": "Gu, Rongqi; Yang, Chu; Lu, Yaohan; Liu, Peigen; WU, FEI; Chen, Guang",
    "title": "3D Object Detection via Stereo Pyramid Transformers with Rich Semantic Feature Fusion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1301",
    "authors": "Shen, Zhipeng; Zhou, Guanzhong; Huang, Hailong",
    "title": "Sequential Convex Programming for Time-optimal Quadrotor Waypoint Flight",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1302",
    "authors": "Yan, Xiangjie; Shaqi, Luo; Jiang, Yongpeng; Yu, Mingrui; Chen, Chen; Huang, Gao; LI, Xiang",
    "title": "A Unified Interaction Control Framework for Safe Robotic Ultrasound Scanning with Human-Intention-Aware Compliance",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.19545v1",
    "arxiv_abstract": "The ultrasound scanning robot operates in environments where frequent\nhuman-robot interactions occur. Most existing control methods for ultrasound\nscanning address only one specific interaction situation or implement hard\nswitches between controllers for different situations, which compromises both\nsafety and efficiency. In this paper, we propose a unified interaction control\nframework for ultrasound scanning robots capable of handling all common\ninteractions, distinguishing both human-intended and unintended types, and\nadapting with appropriate compliance. Specifically, the robot suspends or\nmodulates its ongoing main task if the interaction is intended, e.g., when the\ndoctor grasps the robot to lead the end effector actively. Furthermore, it can\nidentify unintended interactions and avoid potential collision in the null\nspace beforehand. Even if that collision has happened, it can become compliant\nwith the collision in the null space and try to reduce its impact on the main\ntask (where the scan is ongoing) kinematically and dynamically. The multiple\nsituations are integrated into a unified controller with a smooth transition to\ndeal with the interactions by exhibiting human-intention-aware compliance.\nExperimental results validate the framework's ability to cope with all common\ninteractions including intended intervention and unintended collision in a\ncollaborative carotid artery ultrasound scanning task."
  },
  {
    "paper_no": "1303",
    "authors": "Li, Xiaodong; Tian, Guohui; Cui, yongcheng; Gu, Yu",
    "title": "Transformer-Based Relationship Inference Model for Household Object Organization by Integrating Graph Topology and Ontology",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1308",
    "authors": "Du, Yidong; Chen, Xuechao; YU, Zhangguo; Zhang, YuanXi; zhou, zishun; Huang, Qiang",
    "title": "Safe and Efficient Auto-tuning to Cross Sim-to-real Gap for Bipedal Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1310",
    "authors": "Li, Shuo; Cui, Yubo; Li, Zhiheng; Fang, Zheng",
    "title": "FlowTrack: Point-level Flow Network for 3D Single Object Tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1312",
    "authors": "Yoon, Jeonghyeon; Park, Junhyun; Park, Hyojae; Lee, Hakyoon; Lee, Sang Won; Hwang, Minho",
    "title": "Optimizing Base Placement of Surgical Robot: Kinematics Data-Driven Approach by Analyzing Working Pattern",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.16101v2",
    "arxiv_abstract": "In robot-assisted minimally invasive surgery (RAMIS), optimal placement of\nthe surgical robot base is crucial for successful surgery. Improper placement\ncan hinder performance because of manipulator limitations and inaccessible\nworkspaces. Conventional base placement relies on the experience of trained\nmedical staff. This study proposes a novel method for determining the optimal\nbase pose based on the surgeon's working pattern. The proposed method analyzes\nrecorded end-effector poses using a machine learning-based clustering technique\nto identify key positions and orientations preferred by the surgeon. We\nintroduce two scoring metrics to address the joint limit and singularity\nissues: joint margin and manipulability scores. We then train a multi-layer\nperceptron regressor to predict the optimal base pose based on these scores.\nEvaluation in a simulated environment using the da Vinci Research Kit shows\nunique base pose score maps for four volunteers, highlighting the individuality\nof the working patterns. Results comparing with 20,000 randomly selected base\nposes suggest that the score obtained using the proposed method is 28.2% higher\nthan that obtained by random base placement. These results emphasize the need\nfor operator-specific optimization during base placement in RAMIS."
  },
  {
    "paper_no": "1313",
    "authors": "Wang, Jiaxu; Zhang, Qiang; SUN, Jingkai; Cao, Jiahang; Han, Gang; Zhao, Wen; ZHANG, Weining; Guo, Yijie; Shao, Yecheng; Xu, Renjing",
    "title": "Reinforcement Learning with Generalizable Gaussian Splatting",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.07950v3",
    "arxiv_abstract": "An excellent representation is crucial for reinforcement learning (RL)\nperformance, especially in vision-based reinforcement learning tasks. The\nquality of the environment representation directly influences the achievement\nof the learning task. Previous vision-based RL typically uses explicit or\nimplicit ways to represent environments, such as images, points, voxels, and\nneural radiance fields. However, these representations contain several\ndrawbacks. They cannot either describe complex local geometries or generalize\nwell to unseen scenes, or require precise foreground masks. Moreover, these\nimplicit neural representations are akin to a ``black box\", significantly\nhindering interpretability. 3D Gaussian Splatting (3DGS), with its explicit\nscene representation and differentiable rendering nature, is considered a\nrevolutionary change for reconstruction and representation methods. In this\npaper, we propose a novel Generalizable Gaussian Splatting framework to be the\nrepresentation of RL tasks, called GSRL. Through validation in the RoboMimic\nenvironment, our method achieves better results than other baselines in\nmultiple tasks, improving the performance by 10%, 44%, and 15% compared with\nbaselines on the hardest task. This work is the first attempt to leverage\ngeneralizable 3DGS as a representation for RL."
  },
  {
    "paper_no": "1316",
    "authors": "Li, Xudong; Wang, Zhixiang; Zhang, Yizhai; Zhang, Fan; Huang, Panfeng",
    "title": "Asynchronous Event-Inertial Odometry using a Unified Gaussian Process Regression Framework",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.03136v1",
    "arxiv_abstract": "Recent works have combined monocular event camera and inertial measurement\nunit to estimate the $SE(3)$ trajectory. However, the asynchronicity of event\ncameras brings a great challenge to conventional fusion algorithms. In this\npaper, we present an asynchronous event-inertial odometry under a unified\nGaussian Process (GP) regression framework to naturally fuse asynchronous data\nassociations and inertial measurements. A GP latent variable model is leveraged\nto build data-driven motion prior and acquire the analytical integration\ncapacity. Then, asynchronous event-based feature associations and integral\npseudo measurements are tightly coupled using the same GP framework.\nSubsequently, this fusion estimation problem is solved by underlying factor\ngraph in a sliding-window manner. With consideration of sparsity, those\nhistorical states are marginalized orderly. A twin system is also designed for\ncomparison, where the traditional inertial preintegration scheme is embedded in\nthe GP-based framework to replace the GP latent variable model. Evaluations on\npublic event-inertial datasets demonstrate the validity of both systems.\nComparison experiments show competitive precision compared to the\nstate-of-the-art synchronous scheme."
  },
  {
    "paper_no": "1317",
    "authors": "Galelli Christmann, Guilherme Henrique; Luo, Ying-Sheng; Mandala, Hanjaya; Chen, Wei-Chao",
    "title": "Benchmarking Smoothness and Reducing High-Frequency Oscillations in Continuous Control Policies",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.16632v1",
    "arxiv_abstract": "Reinforcement learning (RL) policies are prone to high-frequency\noscillations, especially undesirable when deploying to hardware in the\nreal-world. In this paper, we identify, categorize, and compare methods from\nthe literature that aim to mitigate high-frequency oscillations in deep RL. We\ndefine two broad classes: loss regularization and architectural methods. At\ntheir core, these methods incentivize learning a smooth mapping, such that\nnearby states in the input space produce nearby actions in the output space. We\npresent benchmarks in terms of policy performance and control smoothness on\ntraditional RL environments from the Gymnasium and a complex manipulation task,\nas well as three robotics locomotion tasks that include deployment and\nevaluation with real-world hardware. Finally, we also propose hybrid methods\nthat combine elements from both loss regularization and architectural methods.\nWe find that the best-performing hybrid outperforms other methods, and improves\ncontrol smoothness by 26.8% over the baseline, with a worst-case performance\ndegradation of just 2.8%."
  },
  {
    "paper_no": "1318",
    "authors": "mao, baijin; yuan, qiangjing; xiang, yuyaocen; zhou, kunyu; wang, weichen; chen, yaozhen; hao, hongwei; Qu, Juntian",
    "title": "A Soft Robotic Finger Inspired by Biological Perception Models for Tactile Sensing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1319",
    "authors": "Fu, Linya; He, Yuanzheng; Wang, Jiang; Qiao, Xu; Kong, He",
    "title": "I-ASM: Iterative Acoustic Scene Mapping for Enhanced Robot Auditory Perception in Complex Indoor Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1320",
    "authors": "Aoki, Junki; Sasaki, Fumihiro; Matsumoto, Kohei; Yamashina, Ryota; Kurazume, Ryo",
    "title": "Environmental and Behavioral Imitation for Autonomous Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1324",
    "authors": "Zhu, Zeyu; Wang, Shuai; Zhao, Huijing",
    "title": "Uncertainty-aware Deep Imitation Learning and Deployment for Autonomous Navigation through Crowded Intersections",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1326",
    "authors": "Luu, Tung; Lee, Donghoon; Yoo, Chang D.",
    "title": "Predictive Coding for Decision Transformer",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.03408v1",
    "arxiv_abstract": "Recent work in offline reinforcement learning (RL) has demonstrated the\neffectiveness of formulating decision-making as return-conditioned supervised\nlearning. Notably, the decision transformer (DT) architecture has shown promise\nacross various domains. However, despite its initial success, DTs have\nunderperformed on several challenging datasets in goal-conditioned RL. This\nlimitation stems from the inefficiency of return conditioning for guiding\npolicy learning, particularly in unstructured and suboptimal datasets,\nresulting in DTs failing to effectively learn temporal compositionality.\nMoreover, this problem might be further exacerbated in long-horizon\nsparse-reward tasks. To address this challenge, we propose the Predictive\nCoding for Decision Transformer (PCDT) framework, which leverages generalized\nfuture conditioning to enhance DT methods. PCDT utilizes an architecture that\nextends the DT framework, conditioned on predictive codings, enabling\ndecision-making based on both past and future factors, thereby improving\ngeneralization. Through extensive experiments on eight datasets from the\nAntMaze and FrankaKitchen environments, our proposed method achieves\nperformance on par with or surpassing existing popular value-based and\ntransformer-based methods in offline goal-conditioned RL. Furthermore, we also\nevaluate our method on a goal-reaching task with a physical robot."
  },
  {
    "paper_no": "1329",
    "authors": "Wachter, Alexander; Kugi, Andreas; Hartl-Nesic, Christian",
    "title": "Time-Optimal TCP and Robot Base Placement for Pick-and-Place Tasks in Highly Constrained Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1331",
    "authors": "Li, Yuhang; Li, Changsheng; Fan, Baoyu; Li, Rongqing; Zhang, Ziyue; Ren, Dongchun; Yuan, Ye; Wang, Guoren",
    "title": "FDNet: Feature Decoupling Framework for Trajectory Prediction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1332",
    "authors": "Wang, Haozheng; Jia, Hao; Sun, Zhe; Duan, Feng",
    "title": "Online Hand Movement Recognition System with EEG-EMG Fusion Using One-Dimensional Convolutional Neural Network",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1333",
    "authors": "Duan, Yufei; Achermann, Florian; Lim, Jaeyoung; Siegwart, Roland",
    "title": "Energy-Optimized Planning in Non-Uniform Wind Fields with Fixed-Wing Aerial Vehicles",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.02077v2",
    "arxiv_abstract": "Fixed-wing small uncrewed aerial vehicles (sUAVs) possess the capability to\nremain airborne for extended durations and traverse vast distances. However,\ntheir operation is susceptible to wind conditions, particularly in regions of\ncomplex terrain where high wind speeds may push the aircraft beyond its\noperational limitations, potentially raising safety concerns. Moreover, wind\nimpacts the energy required to follow a path, especially in locations where the\nwind direction and speed are not favorable. Incorporating wind information into\nmission planning is essential to ensure both safety and energy efficiency. In\nthis paper, we propose a sampling-based planner using the kinematic Dubins\naircraft paths with respect to the ground, to plan energy-efficient paths in\nnon-uniform wind fields. We study the planner characteristics with synthetic\nand real-world wind data and compare its performance against baseline cost and\npath formulations. We demonstrate that the energy-optimized planner effectively\nutilizes updrafts to minimize energy consumption, albeit at the expense of\nincreased travel time. The ground-relative path formulation facilitates the\ngeneration of safe trajectories onboard sUAVs within reasonable computational\ntimeframes."
  },
  {
    "paper_no": "1335",
    "authors": "Gao, Yu; Ren, Weihong; Xu, Xinglong; wang, yan; Wang, Zhiyong; Liu, Honghai",
    "title": "MLPER: Multi-Level Prompts for Adaptively Enhancing Vision-Language Emotion Recognition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1340",
    "authors": "Xu, Kai; Zheng, Lanxiang; Wei, Mingxin; Cheng, Hui",
    "title": "VRExplorer: An Efficient View-Region based Autonomous Exploration Method in Unknown Environments for UAV",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1341",
    "authors": "Marks, Elias Ariel; Bömer, Jonas; Magistri, Federico; Sah, Anurag; Behley, Jens; Stachniss, Cyrill",
    "title": "BonnBeetClouds3D: A Dataset Towards Point Cloud-Based Organ-Level Phenotyping of Sugar Beet Plants Under Real Field Conditions",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1343",
    "authors": "Michalczyk, Jan; Quell, Julius Karsten Oskar; Steidle, Florian; Müller, Marcus Gerhard; Weiss, Stephan",
    "title": "Tightly-Coupled Factor Graph Formulation For Radar-Inertial Odometry",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1349",
    "authors": "Chen, Lin; Huang, Jianan; zhou, zhen; Mo, Yang; Wang, Yaonan; Miao, Zhiqiang; zeng, kia; Feng, Mingtao; Wang, Danwei",
    "title": "Domain Adaptation in Visual Reinforcement Learning via Self-Expert Imitation with Purifying Latent Feature",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1350",
    "authors": "Pyo, Sanghun; Choi, Jinsun; Yoon, Jungwon",
    "title": "Development of a Super-thin and Fast Omnidirectional Treadmill through a Novel Helical Transmission Mechanism",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1351",
    "authors": "Goblirsch, Sven; Weinmann, Marcel; Betz, Johannes",
    "title": "Three-Dimensional Vehicle Dynamics State Estimation for High-Speed Race Cars under varying Signal Quality",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.14885v1",
    "arxiv_abstract": "This work aims to present a three-dimensional vehicle dynamics state\nestimation under varying signal quality. Few researchers have investigated the\nimpact of three-dimensional road geometries on the state estimation and, thus,\nneglect road inclination and banking. Especially considering high velocities\nand accelerations, the literature does not address these effects. Therefore, we\ncompare two- and three-dimensional state estimation schemes to outline the\nimpact of road geometries. We use an Extended Kalman Filter with a point-mass\nmotion model and extend it by an additional formulation of reference angles.\nFurthermore, virtual velocity measurements significantly improve the estimation\nof road angles and the vehicle's side slip angle. We highlight the importance\nof steady estimations for vehicle motion control algorithms and demonstrate the\nchallenges of degraded signal quality and Global Navigation Satellite System\ndropouts. The proposed adaptive covariance facilitates a smooth estimation and\nenables stable controller behavior. The developed state estimation has been\ndeployed on a high-speed autonomous race car at various racetracks. Our\nfindings indicate that our approach outperforms state-of-the-art vehicle\ndynamics state estimators and an industry-grade Inertial Navigation System.\nFurther studies are needed to investigate the performance under varying track\nconditions and on other vehicle types."
  },
  {
    "paper_no": "1352",
    "authors": "Zheng, Hao; Lee, Regina; Liang, Huachang; Lu, Yuqian; Xu, Xun",
    "title": "DuCAS: a knowledge-enhanced dual-hand compositional action segmentation method for human-robot collaborative assembly",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1354",
    "authors": "Ferrari, Davide; Pupa, Andrea; Secchi, Cristian",
    "title": "Compliant Blind Handover Control for Human-Robot Collaboration",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.07155v1",
    "arxiv_abstract": "This paper presents a Human-Robot Blind Handover architecture within the\ncontext of Human-Robot Collaboration (HRC). The focus lies on a blind handover\nscenario where the operator is intentionally faced away, focused in a task, and\nrequires an object from the robot. In this context, it is imperative for the\nrobot to autonomously manage the entire handover process. Key considerations\ninclude ensuring safety while handing the object to the operator's hand, and\ndetect the proper timing to release the object. The article explores strategies\nto navigate these challenges, emphasizing the need for a robot to operate\nsafely and independently in facilitating blind handovers, thereby contributing\nto the advancement of HRC protocols and fostering a natural and efficient\ncollaboration between humans and robots."
  },
  {
    "paper_no": "1355",
    "authors": "Zhang, Dingzhi; Birner, Lukas; Pancheri, Felix; Rehekampff, Christoph; Lueth, Tim C.",
    "title": "A Hybrid Human Tracking System using UWB Sensors and Monocular Visual Data Fusion for Human Following Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1357",
    "authors": "Xu, Yi; Peng, Kunyu; Wen, Di; LIU, Ruiping; Zheng, Junwei; Chen, Yufan; Zhang, Jiaming; Roitberg, Alina; Yang, Kailun; Stiefelhagen, Rainer",
    "title": "Skeleton-Based Human Action Recognition with Noisy Labels",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.09975v2",
    "arxiv_abstract": "Understanding human actions from body poses is critical for assistive robots\nsharing space with humans in order to make informed and safe decisions about\nthe next interaction. However, precise temporal localization and annotation of\nactivity sequences is time-consuming and the resulting labels are often noisy.\nIf not effectively addressed, label noise negatively affects the model's\ntraining, resulting in lower recognition quality. Despite its importance,\naddressing label noise for skeleton-based action recognition has been\noverlooked so far. In this study, we bridge this gap by implementing a\nframework that augments well-established skeleton-based human action\nrecognition methods with label-denoising strategies from various research areas\nto serve as the initial benchmark. Observations reveal that these baselines\nyield only marginal performance when dealing with sparse skeleton data.\nConsequently, we introduce a novel methodology, NoiseEraSAR, which integrates\nglobal sample selection, co-teaching, and Cross-Modal Mixture-of-Experts\n(CM-MOE) strategies, aimed at mitigating the adverse impacts of label noise.\nOur proposed approach demonstrates better performance on the established\nbenchmark, setting new state-of-the-art standards. The source code for this\nstudy is accessible at https://github.com/xuyizdby/NoiseEraSAR."
  },
  {
    "paper_no": "1358",
    "authors": "Kim, Taekyun; Yoon, Byoungkwon; Lee, Dongjun",
    "title": "UWB-Based Localization System Considering Antenna Anisotropy and NLOS/Multipath Conditions",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1361",
    "authors": "Schmid, Nicolaj; von Einem, Cornelius; Cadena Lerma, Cesar; Siegwart, Roland; Hruby, Lorenz; Tschopp, Florian",
    "title": "VIRUS-NeRF - Vision, InfraRed and UltraSonic based Neural Radiance Fields",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1362",
    "authors": "Ramos, Orion Yari Santiago; De Arco, Laura; Munera, Marcela; Robledo, Jorge; Moazen, Mehran; Wurdemann, Helge Arne; Cifuentes, Carlos A.",
    "title": "Development and Functional Evaluation of The PrHand V2 Soft-Robotics Prosthetic Hand",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1364",
    "authors": "Surov, Maksim; Pchelkin, Stepan; Shiriaev, Anton; Gusev, Sergei V.; Freidovich, Leonid",
    "title": "On performing non-prehensile rolling manipulations: Stabilizing synchronous motions of Butterfly robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1365",
    "authors": "Tangellapalli, Srisai Anirudh; Sangha, Harman Singh; Peschel, Joshua; Duncan, Brittany",
    "title": "Assessing Monocular Depth Estimation Networks for UAS Deployment in Rainforest Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1368",
    "authors": "Yang, Junjie; Inagaki, Satoshi; Zhao, Zhihao; Zapp, Daniel; Maier, Mathias; Huang, Kai; Navab, Nassir; Nasseri, M. Ali",
    "title": "Shadow Maintenance for Automatic Light-Probe Control in Ophthalmic Surgeries Using Only 2D information",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1369",
    "authors": "Zhong, Zhengjun; He, Ying; Li, Pengteng; Yu, Fei; Ma, Fei",
    "title": "A Language-Driven Navigation Strategy Integrating Semantic Maps and Large Language Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1370",
    "authors": "Ferrari, Davide; Pupa, Andrea; Secchi, Cristian",
    "title": "Collaborative Conversation in Safe Multimodal Human-Robot Collaboration",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.07158v1",
    "arxiv_abstract": "In the context of Human-Robot Collaboration (HRC), it is crucial that the two\nactors are able to communicate with each other in a natural and efficient\nmanner. The absence of a communication interface is often a cause of undesired\nslowdowns. On one hand, this is because unforeseen events may occur, leading to\nerrors. On the other hand, due to the close contact between humans and robots,\nthe speed must be reduced significantly to comply with safety standard ISO/TS\n15066. In this paper, we propose a novel architecture that enables operators\nand robots to communicate efficiently, emulating human-to-human dialogue, while\naddressing safety concerns. This approach aims to establish a communication\nframework that not only facilitates collaboration but also reduces undesired\nspeed reduction. Through the use of a predictive simulator, we can anticipate\nsafety-related limitations, ensuring smoother workflows, minimizing risks, and\noptimizing efficiency. The overall architecture has been validated with a UR10e\nand compared with a state of the art technique. The results show a significant\nimprovement in user experience, with a corresponding 23% reduction in execution\ntimes and a 50% decrease in robot downtime."
  },
  {
    "paper_no": "1373",
    "authors": "Spielbauer, Niklas; Laube, Till Jasper; Oberacker, David; Roennau, Arne; Dillmann, Rüdiger",
    "title": "Roaming with Robots: Utilizing Artificial Curiosity in Global Path Planning for Autonomous Mobile Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1374",
    "authors": "Zanatta, Giacomo; Caiazza, Gianluca; Ferrara, Pietro; Negrini, Luca; White, Ruffin",
    "title": "Automating ROS2 Security Policies Extraction through Static Analysis",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1376",
    "authors": "Zhang, hongyang; Wang, Shuting; Li, Hu; Xie, Yuanlong",
    "title": "Modelling and Analysis of Joint-to-End Variable Stiffness for Cable-Driven Hyper-Redundant Manipulator",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1380",
    "authors": "Gharab, Saddam; Ben Ftima, Salma; Feliu, Vicente",
    "title": "Adaptive Smith Predictor Fractional Control of a Tele-operated Flexible Link Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1384",
    "authors": "Yang, Yang; Kejin, Zhu; Xie, Yuan; Yan, Shaoyang; Yi, Juan; Jiang, Pei; Li, Yunquan; Li, Yingtian",
    "title": "Origami Actuator with Tunable Limiting Layer for Reconfigurable Soft Robotic Grasping",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1385",
    "authors": "Zhu, Jiahui; Yu, Guitao; He, Yang; Yang, Kui; Liang, Dongtai",
    "title": "Research of calibration method for fusion of LDS sensor and ToF low-cost sensor",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1387",
    "authors": "Li, Xin-Zhuo; Tu, Yuxiao; Liang, Guanqi; Wu, Di; Lam, Tin Lun",
    "title": "Energy Sharing Mechanism for Freeform Robots Utilizing Conductive Spherical Sliding Surfaces",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1390",
    "authors": "Avogaro, Andrea; Toaiari, Andrea; Cunico, Federico; Xu, Xiangmin; Dafas, Haralambos; Vinciarelli, Alessandro; Li, Liying Emma; Cristani, Marco",
    "title": "Exploring 3D Human Pose Estimation and Forecasting from the Robots Perspective: The HARPER Dataset",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.14447v2",
    "arxiv_abstract": "We introduce HARPER, a novel dataset for 3D body pose estimation and forecast\nin dyadic interactions between users and Spot, the quadruped robot manufactured\nby Boston Dynamics. The key-novelty is the focus on the robot's perspective,\ni.e., on the data captured by the robot's sensors. These make 3D body pose\nanalysis challenging because being close to the ground captures humans only\npartially. The scenario underlying HARPER includes 15 actions, of which 10\ninvolve physical contact between the robot and users. The Corpus contains not\nonly the recordings of the built-in stereo cameras of Spot, but also those of a\n6-camera OptiTrack system (all recordings are synchronized). This leads to\nground-truth skeletal representations with a precision lower than a millimeter.\nIn addition, the Corpus includes reproducible benchmarks on 3D Human Pose\nEstimation, Human Pose Forecasting, and Collision Prediction, all based on\npublicly available baseline approaches. This enables future HARPER users to\nrigorously compare their results with those we provide in this work."
  },
  {
    "paper_no": "1391",
    "authors": "Yang, Andong; Li, Wei; Hu, Yu",
    "title": "SCOML: Trajectory Planning Based on Self-Correcting Meta-Reinforcement Learning in Hybird Terrain for Mobile Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1392",
    "authors": "Mayer, Matthias; Li, Zihao; Althoff, Matthias",
    "title": "Efficient Path Planning for Modular Reconfigurable Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1394",
    "authors": "Saied, Hussein; Chemori, Ahmed; Bouri, Mohamed; EL RAFEI, Maher; Francis, Clovis",
    "title": "Adaptive Feedforward Super-Twisting Sliding Mode Control of Parallel Kinematic Manipulators With Real-Time Experiments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1395",
    "authors": "Abboud, Nicolas; Sayour, Malak; Elhajj, Imad; Zelek, John S.; Asmar, Daniel",
    "title": "Inline Photometrically Calibrated Hybrid Visual SLAM",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.16810v1",
    "arxiv_abstract": "This paper presents an integrated approach to Visual SLAM, merging online\nsequential photometric calibration within a Hybrid direct-indirect visual SLAM\n(H-SLAM). Photometric calibration helps normalize pixel intensity values under\ndifferent lighting conditions, and thereby improves the direct component of our\nH-SLAM. A tangential benefit also results to the indirect component of H-SLAM\ngiven that the detected features are more stable across variable lighting\nconditions. Our proposed photometrically calibrated H-SLAM is tested on several\ndatasets, including the TUM monoVO as well as on a dataset we created.\nCalibrated H-SLAM outperforms other state of the art direct, indirect, and\nhybrid Visual SLAM systems in all the experiments. Furthermore, in online SLAM\ntested at our site, it also significantly outperformed the other SLAM Systems."
  },
  {
    "paper_no": "1396",
    "authors": "Hou, Shengyu; Song, Wenjie; Wang, Rongchuan; Wang, Meiling; Yang, Yi; Fu, Mengyin",
    "title": "Self-supervised Monocular Depth Estimation in Challenging Environments Based On Illumination Compensation PoseNet",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1402",
    "authors": "al-rawashdeh, Yazan; Al Saaideh, Mohammad; Pumphrey, Michael Joseph; Alatawneh, Natheer; Al Janaideh, Mohammad",
    "title": "Data-Driven Modeling of Cable Slab Dynamics via Neural Networks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1406",
    "authors": "Tay Yu Liang, Jonathan; Tanaka, Kanji",
    "title": "Robot Traversability Prediction: Towards Third-Person-View Extension of Walk2Map with Photometric and Physical Constraints",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1407",
    "authors": "Duo, Youning; Duan, Jinxi; Chen, Xingyu; Liu, Wenbo; Wang, Shengxue; Wen, Li",
    "title": "A Laser-Induced Graphene-Based Flexible Multimodal Sensor for Material and Texture Perception",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1413",
    "authors": "Ge, Fudong; Zhang, Yiwei; Shen, Shuhan; Hu, Weiming; Wang, Yue; Gao, Jin",
    "title": "BEV$^2$PR: BEV-Enhanced Visual Place Recognition with Structural Cues",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.06600v2",
    "arxiv_abstract": "In this paper, we propose a new image-based visual place recognition (VPR)\nframework by exploiting the structural cues in bird's-eye view (BEV) from a\nsingle monocular camera. The motivation arises from two key observations about\nplace recognition methods based on both appearance and structure: 1) For the\nmethods relying on LiDAR sensors, the integration of LiDAR in robotic systems\nhas led to increased expenses, while the alignment of data between different\nsensors is also a major challenge. 2) Other image-/camera-based methods,\ninvolving integrating RGB images and their derived variants (eg, pseudo depth\nimages, pseudo 3D point clouds), exhibit several limitations, such as the\nfailure to effectively exploit the explicit spatial relationships between\ndifferent objects. To tackle the above issues, we design a new BEV-enhanced VPR\nframework, namely BEV$^2$PR, generating a composite descriptor with both visual\ncues and spatial awareness based on a single camera. The key points lie in: 1)\nWe use BEV features as an explicit source of structural knowledge in\nconstructing global features. 2) The lower layers of the pre-trained backbone\nfrom BEV generation are shared for visual and structural streams in VPR,\nfacilitating the learning of fine-grained local features in the visual stream.\n3) The complementary visual and structural features can jointly enhance VPR\nperformance. Our BEV$^2$PR framework enables consistent performance\nimprovements over several popular aggregation modules for RGB global features.\nThe experiments on our collected VPR-NuScenes dataset demonstrate an absolute\ngain of 2.47% on Recall@1 for the strong Conv-AP baseline to achieve the best\nperformance in our setting, and notably, a 18.06% gain on the hard set. The\ncode and dataset will be available at https://github.com/FudongGe/BEV2PR."
  },
  {
    "paper_no": "1415",
    "authors": "Ren, Hanwen; Qureshi, Ahmed H.",
    "title": "Multi-Stage Monte Carlo Tree Search for Non-Monotone Object Rearrangement Planning in Narrow Confined Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2305.17175v3",
    "arxiv_abstract": "Non-monotone object rearrangement planning in confined spaces such as\ncabinets and shelves is a widely occurring but challenging problem in robotics.\nBoth the robot motion and the available regions for object relocation are\nhighly constrained because of the limited space. This work proposes a\nMulti-Stage Monte Carlo Tree Search (MS-MCTS) method to solve non-monotone\nobject rearrangement planning problems in confined spaces. Our approach\ndecouples the complex problem into simpler subproblems using an object stage\ntopology. A subgoal-focused tree expansion algorithm that jointly considers the\nhigh-level planning and the low-level robot motion is designed to reduce the\nsearch space and better guide the search process. By fitting the task into the\nMCTS paradigm, our method produces optimistic solutions by balancing\nexploration and exploitation. The experiments demonstrate that our method\noutperforms the existing methods in terms of the planning time, the number of\nsteps, and the total move distance. Moreover, we deploy our MS-MCTS to a\nreal-world robot system and verify its performance in different scenarios."
  },
  {
    "paper_no": "1417",
    "authors": "Liu, Yao; Wang, Ruoyu; Cao, Yuanjiang; Sheng, Quan Z.; Yao, Lina",
    "title": "Multi-agent Traffic Prediction via Denoised Endpoint Distribution",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.07041v1",
    "arxiv_abstract": "The exploration of high-speed movement by robots or road traffic agents is\ncrucial for autonomous driving and navigation. Trajectory prediction at high\nspeeds requires considering historical features and interactions with\nsurrounding entities, a complexity not as pronounced in lower-speed\nenvironments. Prior methods have assessed the spatio-temporal dynamics of\nagents but often neglected intrinsic intent and uncertainty, thereby limiting\ntheir effectiveness. We present the Denoised Endpoint Distribution model for\ntrajectory prediction, which distinctively models agents' spatio-temporal\nfeatures alongside their intrinsic intentions and uncertainties. By employing\nDiffusion and Transformer models to focus on agent endpoints rather than entire\ntrajectories, our approach significantly reduces model complexity and enhances\nperformance through endpoint information. Our experiments on open datasets,\ncoupled with comparison and ablation studies, demonstrate our model's efficacy\nand the importance of its components. This approach advances trajectory\nprediction in high-speed scenarios and lays groundwork for future developments."
  },
  {
    "paper_no": "1418",
    "authors": "Tang, Kai; Lang, Xiaolei; Ma, Yukai; Huang, Yuehao; Li, Laijian; Liu, Yong; Lv, Jiajun",
    "title": "Monocular Event-Inertial Odometry with Adaptive decay-based Time Surface and Polarity-aware Tracking",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.13971v1",
    "arxiv_abstract": "Event cameras have garnered considerable attention due to their advantages\nover traditional cameras in low power consumption, high dynamic range, and no\nmotion blur. This paper proposes a monocular event-inertial odometry\nincorporating an adaptive decay kernel-based time surface with polarity-aware\ntracking. We utilize an adaptive decay-based Time Surface to extract texture\ninformation from asynchronous events, which adapts to the dynamic\ncharacteristics of the event stream and enhances the representation of\nenvironmental textures. However, polarity-weighted time surfaces suffer from\nevent polarity shifts during changes in motion direction. To mitigate its\nadverse effects on feature tracking, we optimize the feature tracking by\nincorporating an additional polarity-inverted time surface to enhance the\nrobustness. Comparative analysis with visual-inertial and event-inertial\nodometry methods shows that our approach outperforms state-of-the-art\ntechniques, with competitive results across various datasets."
  },
  {
    "paper_no": "1424",
    "authors": "Kleer, Niko; Feick, Martin; Gomaa, Amr; Feld, Michael; Krüger, Antonio",
    "title": "Bridging the Gap to Natural Language-based Grasp Predictions through Semantic Information Extraction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1428",
    "authors": "Kim, Jisu; Cho, Jinman; Kang, Yeon; LEE, Changhwa; Yun, Dongwon",
    "title": "Development of a Modular Robotic Finger for Gripping Various Shaped Objects",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1429",
    "authors": "Arrizabalaga, Jon; Manchester, Zachary; Ryll, Markus",
    "title": "Differentiable Collision-Free Parametric Corridors",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.12283v1",
    "arxiv_abstract": "This paper presents a method to compute differentiable collision-free\nparametric corridors. In contrast to existing solutions that decompose the\nobstacle-free space into multiple convex sets, the continuous corridors\ncomputed by our method are smooth and differentiable, making them compatible\nwith existing numerical techniques for learning and optimization. To achieve\nthis, we represent the collision-free corridors as a path-parametric\noff-centered ellipse with a polynomial basis. We show that the problem of\nmaximizing the volume of such corridors is convex, and can be efficiently\nsolved. To assess the effectiveness of the proposed method, we examine its\nperformance in a synthetic case study and subsequently evaluate its\napplicability in a real-world scenario from the KITTI dataset."
  },
  {
    "paper_no": "1430",
    "authors": "Slawik, Tom; Vyas, Shubham; Christensen, Leif; Kirchner, Frank",
    "title": "Attitude Control of the Hydrobatic Intervention AUV Cuttlefish Using Incremental Nonlinear Dynamic Inversion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1434",
    "authors": "Manas, Kumar; Zwicklbauer, Stefan; Paschke, Adrian",
    "title": "CoT-TL: Low-Resource Temporal Knowledge Representation of Planning Instructions using Chain-of-Thought Reasoning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1437",
    "authors": "Lan, Xiaoxiong; Liu, Shenghao; Zhang, Zhiyong; Qiu, Changzhen",
    "title": "DCSANet: Dual Cross-channel and Spatial Attention Make RGB-T Object Detection Better",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1440",
    "authors": "Schramm, Jonas; Vödisch, Niclas; Petek, Kürsat; Ravi, Kiran; Yogamani, Senthil; Burgard, Wolfram; Valada, Abhinav",
    "title": "BEVCar: Camera-Radar Fusion for BEV Map and Object Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1441",
    "authors": "Sood, Shivam; SUN, GE; LI, Peizhuo; Sartoretti, Guillaume Adrien",
    "title": "DecAP : Decaying Action Priors for Accelerated Learning of Torque-Based Legged Locomotion Policies",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1443",
    "authors": "Jing, Xinghui; Xiong, Xin; Li, Fuhao; Zhang, Tao; Zeng, Long",
    "title": "A Two-Stage Reinforcement Learning Approach for Robot Navigation in Long-range Indoor Dense Crowd Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1446",
    "authors": "Li, Dong; Chen, Lineng; Xu, Chengzhong; Kong, Hui",
    "title": "UMAD: University of Macau Anomaly Detection Benchmark Dataset",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1447",
    "authors": "Pant, Kartik Anand; Lin, Li-Yu; Kim, Jaehyeok; Sribunma, Worawis; Goppert, James; Hwang, Inseok",
    "title": "MIXED-SENSE: A Mixed Reality Sensor Emulation Framework for Test and Evaluation of UAVs Against False Data Injection Attacks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1448",
    "authors": "Hannus, Eric Mikael Leonard; Nguyen Le, Tran; Blanco-Mulero, David; Kyrki, Ville",
    "title": "Dynamic Manipulation of Deformable Objects using Imitation Learning with Adaptation to Hardware Constraints",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12685v1",
    "arxiv_abstract": "Imitation Learning (IL) is a promising paradigm for learning dynamic\nmanipulation of deformable objects since it does not depend on\ndifficult-to-create accurate simulations of such objects. However, the\ntranslation of motions demonstrated by a human to a robot is a challenge for\nIL, due to differences in the embodiments and the robot's physical limits.\nThese limits are especially relevant in dynamic manipulation where high\nvelocities and accelerations are typical. To address this problem, we propose a\nframework that first maps a dynamic demonstration into a motion that respects\nthe robot's constraints using a constrained Dynamic Movement Primitive. Second,\nthe resulting object state is further optimized by quasi-static refinement\nmotions to optimize task performance metrics. This allows both efficiently\naltering the object state by dynamic motions and stable small-scale\nrefinements. We evaluate the framework in the challenging task of bag opening,\ndesigning the system BILBO: Bimanual dynamic manipulation using Imitation\nLearning for Bag Opening. Our results show that BILBO can successfully open a\nwide range of crumpled bags, using a demonstration with a single bag. See\nsupplementary material at https://sites.google.com/view/bilbo-bag."
  },
  {
    "paper_no": "1453",
    "authors": "He, Zongtao; Wang, Liuyi; Chen, Lu; Li, Shu; Yan, Qingqing; Liu, Chengju; Chen, Qijun",
    "title": "Multimodal Evolutionary Encoder for Continuous Vision-Language Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1454",
    "authors": "Shi, Danqing; Zhu, Shibei; Weinkauf, Tino; Oulasvirta, Antti",
    "title": "Interactive Reward Tuning: A Visual Analytics Approach for Preference Elicitation with User Feedback",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1456",
    "authors": "Chu, Yen-Cheng; Lian, Feng-Li",
    "title": "Attainable Force Approximation and Full-Pose Tracking Control of an Over-Actuated Thrust-Vectoring Modular Team UAV",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.03445v1",
    "arxiv_abstract": "Traditional vertical take-off and landing (VTOL) aircraft can not achieve\noptimal efficiency for various payload weights and has limited mobility due to\nits under-actuation. With the thrust-vectoring mechanism, the proposed modular\nteam UAV is fully actuated at certain attitudes. However, the attainable force\nspace (AFS) differs according to the team configuration, which makes the\ncontroller design difficult. We propose an approximation to the AFS and a\nfull-pose tracking controller with an attitude planner and a force projection,\nwhich guarantees the control force is feasible. The proposed approach can be\napplied to UAVs having multiple thrust-vectoring effectors with homogeneous\nagents. The simulation and experiment demonstrate a tilting motion during\nhovering for a 4-agent team."
  },
  {
    "paper_no": "1457",
    "authors": "Nasrat, Shady; Yi, Jae-Bong; Jo, Minseong; Yi, Seung-Joon",
    "title": "PICaSo: A Collaborative Robotics System for Inpainting on Physical Canvas using Marker and Eraser",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1459",
    "authors": "PERAUD, Charly; Filliung, Martin; Anthierens, Cedric; Dune, Claire; boizot, nicolas; HUGEL, Vincent",
    "title": "IMU-based Monitoring of Buoy-Ballast System through Cable Dynamics Simulation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1462",
    "authors": "Mina&#345;ík, Michal; Penicka, Robert; Vonasek, Vojtech; Saska, Martin",
    "title": "Model Predictive Path Integral Control for Agile Unmanned Aerial Vehicles",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.09812v1",
    "arxiv_abstract": "This paper introduces a control architecture for real-time and onboard\ncontrol of Unmanned Aerial Vehicles (UAVs) in environments with obstacles using\nthe Model Predictive Path Integral (MPPI) methodology. MPPI allows the use of\nthe full nonlinear model of UAV dynamics and a more general cost function at\nthe cost of a high computational demand. To run the controller in real-time,\nthe sampling-based optimization is performed in parallel on a graphics\nprocessing unit onboard the UAV. We propose an approach to the simulation of\nthe nonlinear system which respects low-level constraints, while also able to\ndynamically handle obstacle avoidance, and prove that our methods are able to\nrun in real-time without the need for external computers. The MPPI controller\nis compared to MPC and SE(3) controllers on the reference tracking task,\nshowing a comparable performance. We demonstrate the viability of the proposed\nmethod in multiple simulation and real-world experiments, tracking a reference\nat up to 44 km/h and acceleration close to 20 m/s^2, while still being able to\navoid obstacles. To the best of our knowledge, this is the first method to\ndemonstrate an MPPI-based approach in real flight."
  },
  {
    "paper_no": "1464",
    "authors": "Tang, Tao; Liu, Hong; You, Yingxuan; Wang, Ti; Li, Wenhao",
    "title": "Dual-Branch Graph Transformer Network for 3D Human Mesh Reconstruction from Video",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.01179v1",
    "arxiv_abstract": "Human Mesh Reconstruction (HMR) from monocular video plays an important role\nin human-robot interaction and collaboration. However, existing video-based\nhuman mesh reconstruction methods face a trade-off between accurate\nreconstruction and smooth motion. These methods design networks based on either\nRNNs or attention mechanisms to extract local temporal correlations or global\ntemporal dependencies, but the lack of complementary long-term information and\nlocal details limits their performance. To address this problem, we propose a\n\\textbf{D}ual-branch \\textbf{G}raph \\textbf{T}ransformer network for 3D human\nmesh \\textbf{R}econstruction from video, named DGTR. DGTR employs a dual-branch\nnetwork including a Global Motion Attention (GMA) branch and a Local Details\nRefine (LDR) branch to parallelly extract long-term dependencies and local\ncrucial information, helping model global human motion and local human details\n(e.g., local motion, tiny movement). Specifically, GMA utilizes a global\ntransformer to model long-term human motion. LDR combines modulated graph\nconvolutional networks and the transformer framework to aggregate local\ninformation in adjacent frames and extract crucial information of human\ndetails. Experiments demonstrate that our DGTR outperforms state-of-the-art\nvideo-based methods in reconstruction accuracy and maintains competitive motion\nsmoothness. Moreover, DGTR utilizes fewer parameters and FLOPs, which validate\nthe effectiveness and efficiency of the proposed DGTR. Code is publicly\navailable at\n\\href{https://github.com/TangTao-PKU/DGTR}{\\textcolor{myBlue}{https://github.com/TangTao-PKU/DGTR}}."
  },
  {
    "paper_no": "1471",
    "authors": "Escourrou, Maxime; Al Hage, Joelle; Bonnifait, Philippe",
    "title": "Decentralized Collaborative Localization and Map Update with Buildings",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1479",
    "authors": "Zhuang, Zheyu; Kyrki, Ville; Kragic, Danica",
    "title": "Raising Body Ownership in End-to-End Visuomotor Policy Learning via Robot-Centric Pooling",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.04331v1",
    "arxiv_abstract": "We present Robot-centric Pooling (RcP), a novel pooling method designed to\nenhance end-to-end visuomotor policies by enabling differentiation between the\nrobots and similar entities or their surroundings. Given an\nimage-proprioception pair, RcP guides the aggregation of image features by\nhighlighting image regions correlating with the robot's proprioceptive states,\nthereby extracting robot-centric image representations for policy learning.\nLeveraging contrastive learning techniques, RcP integrates seamlessly with\nexisting visuomotor policy learning frameworks and is trained jointly with the\npolicy using the same dataset, requiring no extra data collection involving\nself-distractors. We evaluate the proposed method with reaching tasks in both\nsimulated and real-world settings. The results demonstrate that RcP\nsignificantly enhances the policies' robustness against various unseen\ndistractors, including self-distractors, positioned at different locations.\nAdditionally, the inherent robot-centric characteristic of RcP enables the\nlearnt policy to be far more resilient to aggressive pixel shifts compared to\nthe baselines."
  },
  {
    "paper_no": "1482",
    "authors": "Wang, Hanwen; Ying, Zhang; Wang, Yunlong; LI, Jian",
    "title": "6-DoF Grasp Detection in Clutter with Enhanced Receptive Field and Graspable Balance Sampling",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.01209v2",
    "arxiv_abstract": "6-DoF grasp detection of small-scale grasps is crucial for robots to perform\nspecific tasks. This paper focuses on enhancing the recognition capability of\nsmall-scale grasping, aiming to improve the overall accuracy of grasping\nprediction results and the generalization ability of the network. We propose an\nenhanced receptive field method that includes a multi-radii cylinder grouping\nmodule and a passive attention module. This method enhances the receptive field\narea within the graspable space and strengthens the learning of graspable\nfeatures. Additionally, we design a graspable balance sampling module based on\na segmentation network, which enables the network to focus on features of small\nobjects, thereby improving the recognition capability of small-scale grasping.\nOur network achieves state-of-the-art performance on the GraspNet-1Billion\ndataset, with an overall improvement of approximately 10% in average\nprecision@k (AP). Furthermore, we deployed our grasp detection model in\npybullet grasping platform, which validates the effectiveness of our method."
  },
  {
    "paper_no": "1483",
    "authors": "Chaubey, Shivam; Verdoja, Francesco; Kyrki, Ville",
    "title": "Jointly Learning Cost and Constraints from Demonstrations for Safe Trajectory Generation",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.03491v2",
    "arxiv_abstract": "Learning from Demonstration allows robots to mimic human actions. However,\nthese methods do not model constraints crucial to ensure safety of the learned\nskill. Moreover, even when explicitly modelling constraints, they rely on the\nassumption of a known cost function, which limits their practical usability for\ntask with unknown cost. In this work we propose a two-step optimization process\nthat allow to estimate cost and constraints by decoupling the learning of cost\nfunctions from the identification of unknown constraints within the\ndemonstrated trajectories. Initially, we identify the cost function by\nisolating the effect of constraints on parts of the demonstrations.\nSubsequently, a constraint leaning method is used to identify the unknown\nconstraints. Our approach is validated both on simulated trajectories and a\nreal robotic manipulation task. Our experiments show the impact that incorrect\ncost estimation has on the learned constraints and illustrate how the proposed\nmethod is able to infer unknown constraints, such as obstacles, from\ndemonstrated trajectories without any initial knowledge of the cost."
  },
  {
    "paper_no": "1484",
    "authors": "Jilani, Radhouane; Villard, Pierre-Frederic; Kerrien, Erwan",
    "title": "Solving Dynamic Cosserat Rods with Frictional Contact Using the Shooting Method and Implicit Surfaces",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1485",
    "authors": "Lang, Christopher; Braun, Alexander; Schillingmann, Lars; Valada, Abhinav",
    "title": "A Point-Based Approach to Efficient LiDAR Multi-Task Perception",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.12798v1",
    "arxiv_abstract": "Multi-task networks can potentially improve performance and computational\nefficiency compared to single-task networks, facilitating online deployment.\nHowever, current multi-task architectures in point cloud perception combine\nmultiple task-specific point cloud representations, each requiring a separate\nfeature encoder and making the network structures bulky and slow. We propose\nPAttFormer, an efficient multi-task architecture for joint semantic\nsegmentation and object detection in point clouds that only relies on a\npoint-based representation. The network builds on transformer-based feature\nencoders using neighborhood attention and grid-pooling and a query-based\ndetection decoder using a novel 3D deformable-attention detection head design.\nUnlike other LiDAR-based multi-task architectures, our proposed PAttFormer does\nnot require separate feature encoders for multiple task-specific point cloud\nrepresentations, resulting in a network that is 3x smaller and 1.4x faster\nwhile achieving competitive performance on the nuScenes and KITTI benchmarks\nfor autonomous driving perception. Our extensive evaluations show substantial\ngains from multi-task learning, improving LiDAR semantic segmentation by +1.7%\nin mIou and 3D object detection by +1.7% in mAP on the nuScenes benchmark\ncompared to the single-task models."
  },
  {
    "paper_no": "1486",
    "authors": "Zhang, Zhiyuan; Tsiotras, Panagiotis",
    "title": "BuzzRacer: A Palm-sized Autonomous Vehicle Platform for Testing Multi-Agent Adversarial Decision-Making",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1488",
    "authors": "Ren, Ruilong; Cao, Jian; Xu, Weichen; Fu, Tianhao; Dong, Yilei; Xu, Xinxin; Hu, Zicong; Zhang, Xing",
    "title": "Boosting 3D Visual Grounding by Object-Centric Referring Network",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1489",
    "authors": "Dionigi, Alberto; Costante, Gabriele; Loianno, Giuseppe",
    "title": "The Power of Input: Benchmarking Zero-Shot Sim-to-Real Transfer of Reinforcement Learning Control Policies for Quadrotor Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.07686v2",
    "arxiv_abstract": "In the last decade, data-driven approaches have become popular choices for\nquadrotor control, thanks to their ability to facilitate the adaptation to\nunknown or uncertain flight conditions. Among the different data-driven\nparadigms, Deep Reinforcement Learning (DRL) is currently one of the most\nexplored. However, the design of DRL agents for Micro Aerial Vehicles (MAVs)\nremains an open challenge. While some works have studied the output\nconfiguration of these agents (i.e., what kind of control to compute), there is\nno general consensus on the type of input data these approaches should employ.\nMultiple works simply provide the DRL agent with full state information,\nwithout questioning if this might be redundant and unnecessarily complicate the\nlearning process, or pose superfluous constraints on the availability of such\ninformation in real platforms. In this work, we provide an in-depth benchmark\nanalysis of different configurations of the observation space. We optimize\nmultiple DRL agents in simulated environments with different input choices and\nstudy their robustness and their sim-to-real transfer capabilities with\nzero-shot adaptation. We believe that the outcomes and discussions presented in\nthis work supported by extensive experimental results could be an important\nmilestone in guiding future research on the development of DRL agents for\naerial robot tasks."
  },
  {
    "paper_no": "1490",
    "authors": "Gao, Wei; Sun, Zezhou; Zhao, Mingle; Xu, Chengzhong; Kong, Hui",
    "title": "Active Loop Closure for OSM-guided Robotic Mapping in Large-Scale Urban Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.17078v1",
    "arxiv_abstract": "The autonomous mapping of large-scale urban scenes presents significant\nchallenges for autonomous robots. To mitigate the challenges, global planning,\nsuch as utilizing prior GPS trajectories from OpenStreetMap (OSM), is often\nused to guide the autonomous navigation of robots for mapping. However, due to\nfactors like complex terrain, unexpected body movement, and sensor noise, the\nuncertainty of the robot's pose estimates inevitably increases over time,\nultimately leading to the failure of robotic mapping. To address this issue, we\npropose a novel active loop closure procedure, enabling the robot to actively\nre-plan the previously planned GPS trajectory. The method can guide the robot\nto re-visit the previous places where the loop-closure detection can be\nperformed to trigger the back-end optimization, effectively reducing errors and\nuncertainties in pose estimation. The proposed active loop closure mechanism is\nimplemented and embedded into a real-time OSM-guided robot mapping framework.\nEmpirical results on several large-scale outdoor scenarios demonstrate its\neffectiveness and promising performance."
  },
  {
    "paper_no": "1493",
    "authors": "chen, shi; Zhang, Bihao; Feng, Kehan; Wang, Yizhou; Zhang, Wenzeng",
    "title": "A Novel Geometrical Structure Robot Hand for Linear-parallel Pinching and Coupled Self-adaptive Hybrid Grasping",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1495",
    "authors": "Herneth, Christopher; Li, Junnan; Fatoni, Muhammad Hilman; Ganguly, Amartya; Haddadin, Sami",
    "title": "Object Augmentation Algorithm: Computing virtual object motion and object induced interaction wrench from optical markers",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.07434v3",
    "arxiv_abstract": "This study addresses the critical need for diverse and comprehensive data\nfocused on human arm joint torques while performing activities of daily living\n(ADL). Previous studies have often overlooked the influence of objects on joint\ntorques during ADL, resulting in limited datasets for analysis. To address this\ngap, we propose an Object Augmentation Algorithm (OAA) capable of augmenting\nexisting marker-based databases with virtual object motions and object-induced\njoint torque estimations. The OAA consists of five phases: (1) computing hand\ncoordinate systems from optical markers, (2) characterising object movements\nwith virtual markers, (3) calculating object motions through inverse kinematics\n(IK), (4) determining the wrench necessary for prescribed object motion using\ninverse dynamics (ID), and (5) computing joint torques resulting from object\nmanipulation. The algorithm's accuracy is validated through trajectory tracking\nand torque analysis on a 5+4 degree of freedom (DoF) robotic hand-arm system,\nmanipulating three unique objects. The results show that the OAA can accurately\nand precisely estimate 6 DoF object motion and object-induced joint torques.\nCorrelations between computed and measured quantities were > 0.99 for object\ntrajectories and > 0.93 for joint torques. The OAA was further shown to be\nrobust to variations in the number and placement of input markers, which are\nexpected between databases. Differences between repeated experiments were minor\nbut significant (p < 0.05). The algorithm expands the scope of available data\nand facilitates more comprehensive analyses of human-object interaction\ndynamics."
  },
  {
    "paper_no": "1497",
    "authors": "Tsagkas, Nikolaos; Rome, Jack A; Ramamoorthy, Subramanian; Mac Aodha, Oisin; Lu, Chris Xiaoxuan",
    "title": "Click to Grasp: Zero-Shot Precise Manipulation via Visual Diffusion Descriptors",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.14526v1",
    "arxiv_abstract": "Precise manipulation that is generalizable across scenes and objects remains\na persistent challenge in robotics. Current approaches for this task heavily\ndepend on having a significant number of training instances to handle objects\nwith pronounced visual and/or geometric part ambiguities. Our work explores the\ngrounding of fine-grained part descriptors for precise manipulation in a\nzero-shot setting by utilizing web-trained text-to-image diffusion-based\ngenerative models. We tackle the problem by framing it as a dense semantic part\ncorrespondence task. Our model returns a gripper pose for manipulating a\nspecific part, using as reference a user-defined click from a source image of a\nvisually different instance of the same object. We require no manual grasping\ndemonstrations as we leverage the intrinsic object geometry and features.\nPractical experiments in a real-world tabletop scenario validate the efficacy\nof our approach, demonstrating its potential for advancing semantic-aware\nrobotics manipulation. Web page: https://tsagkas.github.io/click2grasp"
  },
  {
    "paper_no": "1498",
    "authors": "Kim, Hyungjoo; Min, Sungjae; Kang, Gyuree; Kim, Jihyeok; Shim, David Hyunchul",
    "title": "Fly by Book: How to Train a Humanoid Robot to Fly an Airplane using Large Language Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1499",
    "authors": "Dong, Shaohua; Feng, Yunhe; Yang, Qing; Huang, Yan; Liu, Dongfang; Fan, Heng",
    "title": "Efficient Multimodal Semantic Segmentation via Dual-Prompt Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2312.00360v2",
    "arxiv_abstract": "Multimodal (e.g., RGB-Depth/RGB-Thermal) fusion has shown great potential for\nimproving semantic segmentation in complex scenes (e.g., indoor/low-light\nconditions). Existing approaches often fully fine-tune a dual-branch\nencoder-decoder framework with a complicated feature fusion strategy for\nachieving multimodal semantic segmentation, which is training-costly due to the\nmassive parameter updates in feature extraction and fusion. To address this\nissue, we propose a surprisingly simple yet effective dual-prompt learning\nnetwork (dubbed DPLNet) for training-efficient multimodal (e.g., RGB-D/T)\nsemantic segmentation. The core of DPLNet is to directly adapt a frozen\npre-trained RGB model to multimodal semantic segmentation, reducing parameter\nupdates. For this purpose, we present two prompt learning modules, comprising\nmultimodal prompt generator (MPG) and multimodal feature adapter (MFA). MPG\nworks to fuse the features from different modalities in a compact manner and is\ninserted from shadow to deep stages to generate the multi-level multimodal\nprompts that are injected into the frozen backbone, while MPG adapts prompted\nmultimodal features in the frozen backbone for better multimodal semantic\nsegmentation. Since both the MPG and MFA are lightweight, only a few trainable\nparameters (3.88M, 4.4% of the pre-trained backbone parameters) are introduced\nfor multimodal feature fusion and learning. Using a simple decoder (3.27M\nparameters), DPLNet achieves new state-of-the-art performance or is on a par\nwith other complex approaches on four RGB-D/T semantic segmentation datasets\nwhile satisfying parameter efficiency. Moreover, we show that DPLNet is general\nand applicable to other multimodal tasks such as salient object detection and\nvideo semantic segmentation. Without special design, DPLNet outperforms many\ncomplicated models. Our code will be available at\ngithub.com/ShaohuaDong2021/DPLNet."
  },
  {
    "paper_no": "1500",
    "authors": "Song, Jingyu; Bagoren, Onur; Venkatramanan Sethuraman, Advaith; Andigani, Razan; Skinner, Katherine",
    "title": "Real-time Localization and Dense Mapping of Low-texture Underwater Environments with a Low-cost Unmanned Underwater Vehicle",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.01569v2",
    "arxiv_abstract": "Significant work has been done on advancing localization and mapping in\nunderwater environments. Still, state-of-the-art methods are challenged by\nlow-texture environments, which is common for underwater settings. This makes\nit difficult to use existing methods in diverse, real-world scenes. In this\npaper, we present TURTLMap, a novel solution that focuses on textureless\nunderwater environments through a real-time localization and mapping method. We\nshow that this method is low-cost, and capable of tracking the robot\naccurately, while constructing a dense map of a low-textured environment in\nreal-time. We evaluate the proposed method using real-world data collected in\nan indoor water tank with a motion capture system and ground truth reference\nmap. Qualitative and quantitative results validate the proposed system achieves\naccurate and robust localization and precise dense mapping, even when subject\nto wave conditions. The project page for TURTLMap is\nhttps://umfieldrobotics.github.io/TURTLMap."
  },
  {
    "paper_no": "1501",
    "authors": "Leblanc, Lilyan; Vialle, Raphael; de Farias, Cristiana; SAGHBINY, Elie; Marturi, Naresh; TAMADAZTE, Brahim",
    "title": "Pedicle Drilling Planning Transfer for Spine Surgery Using Functional Map Correspondences",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1504",
    "authors": "Zhou, Yizhi; JIN, WANXIN; Wang, Xuan",
    "title": "D3G: Learning Multi-robot Coordination from Demonstrations",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1507",
    "authors": "Beddow, Luke Jonathan; Wurdemann, Helge Arne; Kanoulas, Dimitrios",
    "title": "Exploration of Efficacy of Movable Palm in Caging Inspired Grasping using a Reinforcement Learning-based Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1509",
    "authors": "Carlotti, Nicholas; Nava, Mirko; Giusti, Alessandro",
    "title": "Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.10661v2",
    "arxiv_abstract": "We consider the problem of training a fully convolutional network to estimate\nthe relative 6D pose of a robot given a camera image, when the robot is\nequipped with independent controllable LEDs placed in different parts of its\nbody. The training data is composed by few (or zero) images labeled with a\nground truth relative pose and many images labeled only with the true state\n(\\textsc{on} or \\textsc{off}) of each of the peer LEDs. The former data is\nexpensive to acquire, requiring external infrastructure for tracking the two\nrobots; the latter is cheap as it can be acquired by two unsupervised robots\nmoving randomly and toggling their LEDs while sharing the true LED states via\nradio. Training with the latter dataset on estimating the LEDs' state of the\npeer robot (\\emph{pretext task}) promotes learning the relative localization\ntask (\\emph{end task}). Experiments on real-world data acquired by two\nautonomous wheeled robots show that a model trained only on the pretext task\nsuccessfully learns to localize a peer robot on the image plane; fine-tuning\nsuch model on the end task with few labeled images yields statistically\nsignificant improvements in 6D relative pose estimation with respect to\nbaselines that do not use pretext-task pre-training, and alternative\napproaches. Estimating the state of multiple independent LEDs promotes learning\nto estimate relative heading. The approach works even when a large fraction of\ntraining images do not include the peer robot and generalizes well to unseen\nenvironments."
  },
  {
    "paper_no": "1510",
    "authors": "Bellusci, Matteo; Matteucci, Matteo",
    "title": "Automatic 3D Road Surface Reconstruction via Cross-Section Modeling and Interpolation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1512",
    "authors": "Förster, Julian; Chung, Jen Jen; Ott, Lionel; Siegwart, Roland",
    "title": "On Learning Scene-aware Generative State Abstractions for Task-level Mobile Manipulation Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1514",
    "authors": "Parag, Amit; Misimi, Ekrem; Adelson, Edward",
    "title": "Learning incipient slip with GelSight sensors: Attention Classification with Video Vision Transformers",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1515",
    "authors": "Borvorntanajanya, Korn; Ahmed, Jabed F; Runciman, Mark; Franco, Enrico; Patel, Nisha; Rodriguez y Baena, Ferdinando",
    "title": "Development of a Low Pressure Pouch Sensor for Force Measurement in Colonoscopy Procedures",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1516",
    "authors": "Kingery, Aaron; Song, Dezhen",
    "title": "Road Boundary Estimation Using Sparse Automotive Radar Inputs",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.08341v1",
    "arxiv_abstract": "This paper presents a new approach to detecting road boundaries based on\nsparse radar signals. We model the roadway using a homogeneous model and derive\nits conditional predictive model under known radar motion. Using the\nconditional predictive model and model radar points using a Dirichlet Process\nMixture Model (DPMM), we employ Mean Field Variational Inference (MFVI) to\nderive an unconditional road boundary model distribution. In order to generate\ninitial candidate solutions for the MFVI, we develop a custom Random Sample and\nConsensus (RANSAC) variant to propose unseen model instances as candidate road\nboundaries. For each radar point cloud we alternate the MFVI and RANSAC\nproposal steps until convergence to generate the best estimate of all candidate\nmodels. We select the candidate model with the minimum lateral distance to the\nradar on each side as the estimates of the left and right boundaries. We have\nimplemented the proposed algorithm in C++. We have tested the algorithm and it\nhas shown satisfactory results. More specifically, the mean lane boundary\nestimation error is not more than 11.0 cm."
  },
  {
    "paper_no": "1518",
    "authors": "Greene, Rebecca J.; Hunt, Christopher; Acosta, Brooklyn Paige; Huang, Zihan; Kaliki, Rahul; Thakor, Nitish V.",
    "title": "Evaluating the Impact of a Semi-Autonomous Interface on Configuration Space Accessibility for Multi-DOF Upper Limb Prostheses",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1521",
    "authors": "Fan, Rizhao; Poggi, Matteo; Mattoccia, Stefano",
    "title": "Exploring Few-Beam LiDAR Assistance in Self-Supervised Multi-Frame Depth Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1523",
    "authors": "Pares-Morlans, Carlota; Chen, Claire; Weng, Yijia; Yi, Michelle; Huang, Yuying; Heppert, Nick; Zhou, Linqi; Guibas, Leonidas; Bohg, Jeannette",
    "title": "AO-Grasp: Articulated Object Grasp Generation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1527",
    "authors": "Shankar, Tanmay; Chawla, Chaitanya; Hassan, Almutwakel Khalid; Oh, Jean",
    "title": "Translating Agent-Environment Interactions from Humans to Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1530",
    "authors": "Bodo, Giulia; Tessari, Federico; Capitta, Gianluca; De Guglielmo, Luca; Buccelli, Stefano; Laffranchi, Matteo",
    "title": "Design Improvements to the Float Upper-Limb Exoskeleton Better Mimics the Glenohumeral Complex Kinematics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1534",
    "authors": "Rothomphiwat, Kongkiat; Manoonpong, Poramate",
    "title": "Robust Precision Landing of a Quadrotor with Online Temporal Scaling Adaptation of Dynamic Movement Primitives",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1537",
    "authors": "Chung, Jaehoon; Fayyad, Jamil; Najjaran, Homayoun",
    "title": "The Effectiveness of State Representation Model in Multi-Agent Proximal Policy Optimization for Multi-Agent Path Finding",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1544",
    "authors": "Lu, Hao; Kurniawati, Hanna; Shome, Rahul",
    "title": "Sampling-based Motion Planning for Optimal Probability of Collision under Environment Uncertainty",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1547",
    "authors": "Blaha, Till Martin; Smeur, Ewoud; Remes, Bart",
    "title": "Control of Unknown Quadrotors from a Single Throw",
    "arxiv_pdf": "http://arxiv.org/pdf/2406.11723v3",
    "arxiv_abstract": "This paper presents a method to recover quadrotor UAV from a throw, when no\ncontrol parameters are known before the throw. We leverage the availability of\nhigh-frequency rotor speed feedback available in racing drone hardware and\nsoftware to find control effectiveness values and fit a motor model using\nrecursive least squares (RLS) estimation. Furthermore, we propose an excitation\nsequence that provides large actuation commands while guaranteeing to stay\nwithin gyroscope sensing limits. After 450ms of excitation, an INDI attitude\ncontroller uses the 52 fitted parameters to arrest rotational motion and\nrecover an upright attitude. Finally, a NDI position controller drives the\ncraft to a position setpoint. The proposed algorithm runs efficiently on\nmicrocontrollers found in common UAV flight controllers, and was shown to\nrecover an agile quadrotor every time in 57 live experiments with as low as\n3.5m throw height, demonstrating robustness against initial rotations and\nnoise. We also demonstrate control of randomized quadrotors in simulated\nthrows, where the parameter fitting RMS error is typically within 10% of the\ntrue value.\n  This work has been submitted to IROS 2024 for possible publication. Copyright\nmay be transferred without notice, after which this version may no longer be\naccessible."
  },
  {
    "paper_no": "1548",
    "authors": "Tanaka, Hiroaki; Matsumoto, Ojiro; Kawasetsu, Takumi; Hosoda, Koh",
    "title": "Tension Feedback Control for Musculoskeletal Quadrupedal Locomotion over Uneven Terrain.",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1549",
    "authors": "Le, Viet-Anh; Chalaki, Behdad; Tadiparthi, Vaishnav; Nourkhiz Mahjoub, Hossein; D'sa, Jovin; Moradi-Pari, Ehsan",
    "title": "Social Navigation in Crowded Environments with Model Predictive Control and Deep Learning-Based Human Trajectory Prediction",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.16838v1",
    "arxiv_abstract": "Crowd navigation has received increasing attention from researchers over the\nlast few decades, resulting in the emergence of numerous approaches aimed at\naddressing this problem to date. Our proposed approach couples agent motion\nprediction and planning to avoid the freezing robot problem while\nsimultaneously capturing multi-agent social interactions by utilizing a\nstate-of-the-art trajectory prediction model i.e., social long short-term\nmemory model (Social-LSTM). Leveraging the output of Social-LSTM for the\nprediction of future trajectories of pedestrians at each time-step given the\nrobot's possible actions, our framework computes the optimal control action\nusing Model Predictive Control (MPC) for the robot to navigate among\npedestrians. We demonstrate the effectiveness of our proposed approach in\nmultiple scenarios of simulated crowd navigation and compare it against several\nstate-of-the-art reinforcement learning-based methods."
  },
  {
    "paper_no": "1550",
    "authors": "Dastider, Apan; Fang, Hao; Mingjie, Lin",
    "title": "Unified Control Framework for Real-Time Interception and Obstacle Avoidance of Fast-Moving Objects with Diffusion Variational Autoencoder",
    "arxiv_pdf": "http://arxiv.org/pdf/2209.13628v2",
    "arxiv_abstract": "Real-time interception of fast-moving objects by robotic arms in dynamic\nenvironments poses a formidable challenge due to the need for rapid reaction\ntimes, often within milliseconds, amidst dynamic obstacles. This paper\nintroduces a unified control framework to address the above challenge by\nsimultaneously intercepting dynamic objects and avoiding moving obstacles.\nCentral to our approach is using diffusion-based variational autoencoder for\nmotion planning to perform both object interception and obstacle avoidance. We\nbegin by encoding the high-dimensional temporal information from streaming\nevents into a two-dimensional latent manifold, enabling the discrimination\nbetween safe and colliding trajectories, culminating in the construction of an\noffline densely connected trajectory graph. Subsequently, we employ an extended\nKalman filter to achieve precise real-time tracking of the moving object.\nLeveraging a graph-traversing strategy on the established offline dense graph,\nwe generate encoded robotic motor control commands. Finally, we decode these\ncommands to enable real-time motion of robotic motors, ensuring effective\nobstacle avoidance and high interception accuracy of fast-moving objects.\nExperimental validation on both computer simulations and autonomous 7-DoF\nrobotic arms demonstrates the efficacy of our proposed framework. Results\nindicate the capability of the robotic manipulator to navigate around multiple\nobstacles of varying sizes and shapes while successfully intercepting\nfast-moving objects thrown from different angles by hand. Complete video\ndemonstrations of our experiments can be found in\nhttps://sites.google.com/view/multirobotskill/home."
  },
  {
    "paper_no": "1551",
    "authors": "Malle, Nicolaj; Ebeid, Emad",
    "title": "Autonomous Power Line Tracking with mmWave Radar",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1552",
    "authors": "Shome, Rahul",
    "title": "Alternative Connection Radius for Asymptotic Optimality in RRT Star",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1553",
    "authors": "Mehta, Shaunak; Habibian, Soheil; Losey, Dylan",
    "title": "Waypoint-Based Reinforcement Learning for Robot Manipulation Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1555",
    "authors": "Burns, Kaylee; Jain, Ajinkya; Go, Keegan; Xia, Fei; Stark, Michael; Schaal, Stefan; Hausman, Karol",
    "title": "GenChIP: Generating Robot PolicyCode forHigh-Precision and Contact-Rich Manipulation Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1557",
    "authors": "Stamatopoulou, Maria; Liu, Jianwei; Kanoulas, Dimitrios",
    "title": "DiPPeST: Diffusion-based Path Planner for Synthesizing Trajectories applied on Quadruped Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1560",
    "authors": "Zhou, Jingzong; Kulkarni, Priya; Agrawal, Sunil",
    "title": "A parallel-actuated robot with two end-effector degrees-of-freedom: application as a novel wearable head-neck traction brace",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1561",
    "authors": "Agrawal, Sourav; Corley, Isaac; Wallace, Conor; Vaughn, Clovis; Lwowski, Jonathan",
    "title": "Barely-Visible Surface Crack Detection for Wind Turbine Sustainability",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.07186v1",
    "arxiv_abstract": "The production of wind energy is a crucial part of sustainable development\nand reducing the reliance on fossil fuels. Maintaining the integrity of wind\nturbines to produce this energy is a costly and time-consuming task requiring\nrepeated inspection and maintenance. While autonomous drones have proven to\nmake this process more efficient, the algorithms for detecting anomalies to\nprevent catastrophic damage to turbine blades have fallen behind due to some\ndangerous defects, such as hairline cracks, being barely-visible. Existing\ndatasets and literature are lacking and tend towards detecting obvious and\nvisible defects in addition to not being geographically diverse. In this paper\nwe introduce a novel and diverse dataset of barely-visible hairline cracks\ncollected from numerous wind turbine inspections. To prove the efficacy of our\ndataset, we detail our end-to-end deployed turbine crack detection pipeline\nfrom the image acquisition stage to the use of predictions in providing\nautomated maintenance recommendations to extend the life and efficiency of wind\nturbines."
  },
  {
    "paper_no": "1563",
    "authors": "Bartelt, Stefanie; Kuhlenkötter, Bernd",
    "title": "Evaluation of the Design of a Tool for the Automated Assembly of Preconfigured Wires",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1568",
    "authors": "Nagpal, Kartik; Mehr, Negar",
    "title": "Optimal Robotic Assembly Sequence Planning (ORASP): A Sequential Decision-Making Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1569",
    "authors": "Zhang, Yongzhou; Mirus, Florian; Pasch, Frederik; Scholl, Kay-Ulrich; Wurll, Christian; Hein, Björn",
    "title": "A Comprehensive Modeling and Scheduling Approach for Allocating Distributed Multi-Robot Software to the Edge/Cloud",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1570",
    "authors": "Jeong, Mingi; Chadda, Arihant; Quattrini Li, Alberto",
    "title": "Active Learning-augmented Intent-aware Obstacle Avoidance of Autonomous Surface Vehicles in High-traffic Waters",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.01011v1",
    "arxiv_abstract": "This paper enhances the obstacle avoidance of Autonomous Surface Vehicles\n(ASVs) for safe navigation in high-traffic waters with an active state\nestimation of obstacle's passing intention and reducing its uncertainty. We\nintroduce a topological modeling of passing intention of obstacles, which can\nbe applied to varying encounter situations based on the inherent embedding of\ntopological concepts in COLREGs. With a Long Short-Term Memory (LSTM) neural\nnetwork, we classify the passing intention of obstacles. Then, for determining\nthe ASV maneuver, we propose a multi-objective optimization framework including\ninformation gain about the passing obstacle intention and safety. We validate\nthe proposed approach under extensive Monte Carlo simulations (2,400 runs) with\na varying number of obstacles, dynamic properties, encounter situations, and\ndifferent behavioral patterns of obstacles (cooperative, non-cooperative). We\nalso present the results from a real marine accident case study as well as\nreal-world experiments of a real ASV with environmental disturbances, showing\nsuccessful collision avoidance with our strategy in real-time."
  },
  {
    "paper_no": "1573",
    "authors": "Schoch, Philipp; Yang, Fan; Ma, Yuntao; Leutenegger, Stefan; Hutter, Marco; Leboutet, Quentin",
    "title": "IN-Sight: Interactive Navigation through Sight",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1574",
    "authors": "Malik, Ashish; Lee, Stefan; Fern, Alan",
    "title": "Interruptive Language Control of Bipedal Locomotion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1576",
    "authors": "Cao, Yue; Cheng, Ziang; Li, Hongdong",
    "title": "Recurrent Non-Rigid Point Cloud Registration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1577",
    "authors": "Wu, Jiayi; Lin, Xiaomin; Negahdaripour, Shahriar; Fermuller, Cornelia; Aloimonos, Yiannis",
    "title": "MARVIS: Motion & Geometry Aware Real and Virtual Image Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1583",
    "authors": "Malliaropoulos, Marios; Rousseas, Panagiotis; Bechlioulis, Charalampos; Kyriakopoulos, Kostas",
    "title": "An Actor-Critic Reinforcement Learning Scheme for Reactive 3D Optimal Motion Planning Based on Fluid Dynamics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1585",
    "authors": "Erich, Floris Marc Arden; Chiba, Naoya; Mustafa, Abdullah; Yoshiyasu, Yusuke; Ando, Noriaki; Hanai, Ryo; Domae, Yukiyasu",
    "title": "NeuralLabeling: A versatile toolset for labeling vision datasets using Neural Radiance Fields",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1586",
    "authors": "Chen, Zhuo; Ou, Ni; Jiang, Jiaqi; LUO, SHAN",
    "title": "Deep Domain Adaptation Regression for Force Calibration of Optical Tactile Sensors",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.14380v1",
    "arxiv_abstract": "Optical tactile sensors provide robots with rich force information for robot\ngrasping in unstructured environments. The fast and accurate calibration of\nthree-dimensional contact forces holds significance for new sensors and\nexisting tactile sensors which may have incurred damage or aging. However, the\nconventional neural-network-based force calibration method necessitates a large\nvolume of force-labeled tactile images to minimize force prediction errors,\nwith the need for accurate Force/Torque measurement tools as well as a\ntime-consuming data collection process. To address this challenge, we propose a\nnovel deep domain-adaptation force calibration method, designed to transfer the\nforce prediction ability from a calibrated optical tactile sensor to\nuncalibrated ones with various combinations of domain gaps, including marker\npresence, illumination condition, and elastomer modulus. Experimental results\nshow the effectiveness of the proposed unsupervised force calibration method,\nwith lowest force prediction errors of 0.102N (3.4\\% in full force range) for\nnormal force, and 0.095N (6.3\\%) and 0.062N (4.1\\%) for shear forces along the\nx-axis and y-axis, respectively. This study presents a promising, general force\ncalibration methodology for optical tactile sensors."
  },
  {
    "paper_no": "1587",
    "authors": "Ye, Sean; Gombolay, Matthew",
    "title": "Efficient Trajectory Forecasting and Generation with Conditional Flow Matching",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10809v2",
    "arxiv_abstract": "Trajectory prediction and generation are crucial for autonomous robots in\ndynamic environments. While prior research has typically focused on either\nprediction or generation, our approach unifies these tasks to provide a\nversatile framework and achieve state-of-the-art performance. While diffusion\nmodels excel in trajectory generation, their iterative sampling process is\ncomputationally intensive, hindering robotic systems' dynamic capabilities. We\nintroduce Trajectory Conditional Flow Matching (T-CFM), a novel approach using\nflow matching techniques to learn a solver time-varying vector field for\nefficient, fast trajectory generation. T-CFM demonstrates effectiveness in\nadversarial tracking, real-world aircraft trajectory forecasting, and\nlong-horizon planning, outperforming state-of-the-art baselines with 35% higher\npredictive accuracy and 142% improved planning performance. Crucially, T-CFM\nachieves up to 100$\\times$ speed-up compared to diffusion models without\nsacrificing accuracy, enabling real-time decision making in robotics. Codebase:\nhttps://github.com/CORE-Robotics-Lab/TCFM"
  },
  {
    "paper_no": "1588",
    "authors": "Hu, Yan; Meijering, Erik; Song, Yang",
    "title": "Refining Airway Segmentation Through Breakage Filling and Leakage Reduction Using Point Clouds",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1590",
    "authors": "Thierauf, Christopher; Scheutz, Matthias",
    "title": "Fixing symbolic plans with reinforcement learning in object-based action spaces",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1591",
    "authors": "Umemura, Ayumi; Sakurada, Ken; Onishi, Masaki; Yoshida, Kazuya",
    "title": "SDFT: Structural Discrete Fourier Transform for Place Recognition and Traversability Analysis",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1593",
    "authors": "Liang, Jing; payandeh, amirreza; Song, Daeun; Xiao, Xuesu; Manocha, Dinesh",
    "title": "DTG : Diffusion-based Trajectory Generation for Mapless Global Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1594",
    "authors": "Qu, Jia; Otsubo, Shun; Yamanokuchi, Tomoya; Matsubara, Takamitsu; Miwa, Shotaro",
    "title": "Domain Randomization-free Sim-to-Real : An Attention-Augmented Memory Approach for Robotic Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1597",
    "authors": "Kim, Donghyun; Choi, Sunghyun; Song, Bongsub; Song, Jinhyeok; Yoon, Jingon; Yun, Dongwon",
    "title": "GripFlexer: Development of hybrid gripper with a novel shape that can perform in narrow spaces",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1598",
    "authors": "Li, Wu; Zhang, Yunzhou; Lv, Yuezhang; Wang, TingTing; Wang, Sizhan; Wang, Guiyuan",
    "title": "ESO-SLAM: Tightly-Coupled and Simultaneous Estimation of Self and Multi-Object Pose via Sensor Fusion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1599",
    "authors": "Wang, Yunlong; Zhang, Lei; Tu, Yuyang; Zhang, Hui; Bai, Kaixin; Chen, Zhaopeng; Zhang, Jianwei",
    "title": "ToolEENet: Tool Affordance 6D Pose Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1600",
    "authors": "Briscoe-Martinez, Gilberto; Pasricha, Anuj; Abderezaei, Ava; Chaganti, Rama Durga Santosh Kumar; Vajrala, Sarath Chandra; Popuri, Srikanth; Roncone, Alessandro",
    "title": "Exploring How Non-Prehensile Manipulation Expands Capability in Robots Experiencing Multi-Joint Failure",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.01102v1",
    "arxiv_abstract": "This work explores non-prehensile manipulation (NPM) and whole-body\ninteraction as strategies for enabling robotic manipulators to conduct\nmanipulation tasks despite experiencing locked multi-joint (LMJ) failures. LMJs\nare critical system faults where two or more joints become inoperable; they\nimpose constraints on the robot's configuration and control spaces,\nconsequently limiting the capability and reach of a prehensile-only approach.\nThis approach involves three components: i) modeling the failure-constrained\nworkspace of the robot, ii) generating a kinodynamic map of NPM actions within\nthis workspace, and iii) a manipulation action planner that uses a\nsim-in-the-loop approach to select the best actions to take from the\nkinodynamic map. The experimental evaluation shows that our approach can\nincrease the failure-constrained reachable area in LMJ cases by 79%. Further,\nit demonstrates the ability to complete real-world manipulation with up to\n88.9% success when the end-effector is unusable and up to 100% success when it\nis usable."
  },
  {
    "paper_no": "1602",
    "authors": "Li, Kejun; Kim, Jeeseop; Xiong, Xiaobin; Akbari Hamed, Kaveh; Yue, Yisong; Ames, Aaron",
    "title": "Data-Driven Predictive Control for Robust Exoskeleton Locomotion",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.15658v2",
    "arxiv_abstract": "Exoskeleton locomotion must be robust while being adaptive to different users\nwith and without payloads. To address these challenges, this work introduces a\ndata-driven predictive control (DDPC) framework to synthesize walking gaits for\nlower-body exoskeletons, employing Hankel matrices and a state transition\nmatrix for its data-driven model. The proposed approach leverages DDPC through\na multi-layer architecture. At the top layer, DDPC serves as a planner\nemploying Hankel matrices and a state transition matrix to generate a\ndata-driven model that can learn and adapt to varying users and payloads. At\nthe lower layer, our method incorporates inverse kinematics and passivity-based\ncontrol to map the planned trajectory from DDPC into the full-order states of\nthe lower-body exoskeleton. We validate the effectiveness of this approach\nthrough numerical simulations and hardware experiments conducted on the\nAtalante lower-body exoskeleton with different payloads. Moreover, we conducted\na comparative analysis against the model predictive control (MPC) framework\nbased on the reduced-order linear inverted pendulum (LIP) model. Through this\ncomparison, the paper demonstrates that DDPC enables robust bipedal walking at\nvarious velocities while accounting for model uncertainties and unknown\nperturbations."
  },
  {
    "paper_no": "1603",
    "authors": "Cheng, Richard; Papazov, Chavdar; Helmick, Daniel; Tjersland, Mark",
    "title": "A Direct Semi-Exhaustive Search Method for Robust, Partial-to-Full Point Cloud Registration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1605",
    "authors": "Luo, Jun; Wang, Gang; Liu, Hongliang; wu, lang; Huang, Tao; Xiao, Dengyu; Pu, Huayan; Luo, Jun",
    "title": "BE-SLAM: BEV-Enhanced Dynamic Semantic SLAM with Static Object Reconstruction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1607",
    "authors": "Cao, Zhengcai; Xia, Ji; Shi, Yinbin; Zhou, MengChu",
    "title": "A Lightweight De-confounding Transformer for Image Captioning in Wearable Assistive Navigation Device",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1608",
    "authors": "Bonczek, Paul; Bezzo, Nicola",
    "title": "A Cooperative Recovery Framework for Resilient Multi-Robot Swarm Operations Under Loss of Localization in Unknown Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1612",
    "authors": "Li, Ruyue; Zhu, Yaguang; Wang, Yuntong; He, Zhimin; Zhou, Mengnan",
    "title": "An Active and Dexterous Bionic Torso for A Quadruped Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1613",
    "authors": "Luu, Quan; Albini, Alessandro; Maiolino, Perla; Ho, Van",
    "title": "TacLink-Integrated Robot Arm toward Safe Human-Robot Interaction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1618",
    "authors": "Shah, Aamir Bader; WEN, Yu; Chen, Jiefu; Wu, Xuqing; Fu, Xin",
    "title": "Safe Offline-to-Online Multi-Agent Decision Transformer: A Safety Conscious Sequence Modeling Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1621",
    "authors": "Karkour, Ammar; Harras, Khaled; FEO, EDUARDO",
    "title": "Text2Map: From Navigational Instructions to Graph-Based Indoor Map Representations Using LLMs",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1624",
    "authors": "Zhong, Zhuoyun; Li, Zhi; Chamzas, Constantinos",
    "title": "Expansion-GRR: Efficient Generation of Smooth Global Redundancy Resolution Roadmaps",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1627",
    "authors": "Rippy, Kevin; Gangopadhyay, Aryya; Jayarajah, Kasthuri",
    "title": "GestRight: Understanding the Feasibility of Gesture-driven Tele-Operation in Human-Robot Teams",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1631",
    "authors": "Zheng, Han; Yan, Zhongxia; Wu, Cathy",
    "title": "Multi-agent Path Finding for Mixed Autonomy Traffic Coordination",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.03881v1",
    "arxiv_abstract": "In the evolving landscape of urban mobility, the prospective integration of\nConnected and Automated Vehicles (CAVs) with Human-Driven Vehicles (HDVs)\npresents a complex array of challenges and opportunities for autonomous driving\nsystems. While recent advancements in robotics have yielded Multi-Agent Path\nFinding (MAPF) algorithms tailored for agent coordination task characterized by\nsimplified kinematics and complete control over agent behaviors, these\nsolutions are inapplicable in mixed-traffic environments where uncontrollable\nHDVs must coexist and interact with CAVs. Addressing this gap, we propose the\nBehavior Prediction Kinematic Priority Based Search (BK-PBS), which leverages\nan offline-trained conditional prediction model to forecast HDV responses to\nCAV maneuvers, integrating these insights into a Priority Based Search (PBS)\nwhere the A* search proceeds over motion primitives to accommodate kinematic\nconstraints. We compare BK-PBS with CAV planning algorithms derived by\nrule-based car-following models, and reinforcement learning. Through\ncomprehensive simulation on a highway merging scenario across diverse scenarios\nof CAV penetration rate and traffic density, BK-PBS outperforms these baselines\nin reducing collision rates and enhancing system-level travel delay. Our work\nis directly applicable to many scenarios of multi-human multi-robot\ncoordination."
  },
  {
    "paper_no": "1632",
    "authors": "Wang, He; Zhang, Qi; Zheng, Zhiwen; Li, Xiaoli; Li, Ru",
    "title": "A Low-Texture Robust Hybrid Feature Based Visual Odometry",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1633",
    "authors": "Yang, Jianbing; Wang, Yuanzhe; Jiang, Hao; Zhao, Bin; Li, Yiming; Wang, Danwei",
    "title": "Calibration-Free Vision-Assisted Container Loading of RTG Cranes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1634",
    "authors": "gong, yansong; zhang, xinglian; FENG, JINGYI; He, Xiao; Zhang, Dan",
    "title": "LiDAR-based HD Map Localization using Semantic Generalized ICP with Road Marking Detection",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.02061v1",
    "arxiv_abstract": "In GPS-denied scenarios, a robust environmental perception and localization\nsystem becomes crucial for autonomous driving. In this paper, a LiDAR-based\nonline localization system is developed, incorporating road marking detection\nand registration on a high-definition (HD) map. Within our system, a road\nmarking detection approach is proposed with real-time performance, in which an\nadaptive segmentation technique is first introduced to isolate high-reflectance\npoints correlated with road markings, enhancing real-time efficiency. Then, a\nspatio-temporal probabilistic local map is formed by aggregating historical\nLiDAR scans, providing a dense point cloud. Finally, a LiDAR bird's-eye view\n(LiBEV) image is generated, and an instance segmentation network is applied to\naccurately label the road markings. For road marking registration, a semantic\ngeneralized iterative closest point (SG-ICP) algorithm is designed. Linear road\nmarkings are modeled as 1-manifolds embedded in 2D space, mitigating the\ninfluence of constraints along the linear direction, addressing the\nunder-constrained problem and achieving a higher localization accuracy on HD\nmaps than ICP. Extensive experiments are conducted in real-world scenarios,\ndemonstrating the effectiveness and robustness of our system."
  },
  {
    "paper_no": "1636",
    "authors": "Wang, Jiahui; Deng, Yinan; Yang, Yi; Yue, Yufeng",
    "title": "LCP-Fusion: A Neural Implicit SLAM with Enhanced Local Constraints and Computable Prior",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1637",
    "authors": "Han, Xingyao; Cao, Bo; Liu, Zhe; Zhou, Shunbo; Zhang, Heng; Wang, Hesheng",
    "title": "Toward Universal and Scalable Road Graph Partitioning for Efficient Multi-Robot Path Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1642",
    "authors": "Dastider, Apan; Fang, Hao; Mingjie, Lin",
    "title": "APEX: Ambidextrous Dual-Arm Robotic Manipulation Using Collision-Free Generative Diffusion Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1644",
    "authors": "Zhao, Wang; Liu, Jiachen; Zhang, Sheng; Li, Yishu; Chen, Sili; Huang, Sharon X.; Liu, Yong-Jin; Guo, Hengkai",
    "title": "MonoPlane:Exploiting Monocular Geometric Cues for Generalizable 3D Plane Reconstruction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1645",
    "authors": "Chen, Jingxi; He, Botao; Singh, Chahat Deep; Fermuller, Cornelia; Aloimonos, Yiannis",
    "title": "Active Human Pose Estimation via an Autonomous UAV Agent",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.01811v1",
    "arxiv_abstract": "One of the core activities of an active observer involves moving to secure a\n\"better\" view of the scene, where the definition of \"better\" is task-dependent.\nThis paper focuses on the task of human pose estimation from videos capturing a\nperson's activity. Self-occlusions within the scene can complicate or even\nprevent accurate human pose estimation. To address this, relocating the camera\nto a new vantage point is necessary to clarify the view, thereby improving 2D\nhuman pose estimation. This paper formalizes the process of achieving an\nimproved viewpoint. Our proposed solution to this challenge comprises three\nmain components: a NeRF-based Drone-View Data Generation Framework, an On-Drone\nNetwork for Camera View Error Estimation, and a Combined Planner for devising a\nfeasible motion plan to reposition the camera based on the predicted errors for\ncamera views. The Data Generation Framework utilizes NeRF-based methods to\ngenerate a comprehensive dataset of human poses and activities, enhancing the\ndrone's adaptability in various scenarios. The Camera View Error Estimation\nNetwork is designed to evaluate the current human pose and identify the most\npromising next viewing angles for the drone, ensuring a reliable and precise\npose estimation from those angles. Finally, the combined planner incorporates\nthese angles while considering the drone's physical and environmental\nlimitations, employing efficient algorithms to navigate safe and effective\nflight paths. This system represents a significant advancement in active 2D\nhuman pose estimation for an autonomous UAV agent, offering substantial\npotential for applications in aerial cinematography by improving the\nperformance of autonomous human pose estimation and maintaining the operational\nsafety and efficiency of UAVs."
  },
  {
    "paper_no": "1646",
    "authors": "Limoyo, Oliver; Konar, Abhisek; Ablett, Trevor; Kelly, Jonathan; Hogan, Francois; Dudek, Gregory",
    "title": "Working Backwards: Learning to Place by Picking",
    "arxiv_pdf": "http://arxiv.org/pdf/2312.02352v4",
    "arxiv_abstract": "We present placing via picking (PvP), a method to autonomously collect\nreal-world demonstrations for a family of placing tasks in which objects must\nbe manipulated to specific, contact-constrained locations. With PvP, we\napproach the collection of robotic object placement demonstrations by reversing\nthe grasping process and exploiting the inherent symmetry of the pick and place\nproblems. Specifically, we obtain placing demonstrations from a set of grasp\nsequences of objects initially located at their target placement locations. Our\nsystem can collect hundreds of demonstrations in contact-constrained\nenvironments without human intervention using two modules: compliant control\nfor grasping and tactile regrasping. We train a policy directly from visual\nobservations through behavioural cloning, using the autonomously-collected\ndemonstrations. By doing so, the policy can generalize to object placement\nscenarios outside of the training environment without privileged information\n(e.g., placing a plate picked up from a table). We validate our approach in\nhome robot scenarios that include dishwasher loading and table setting. Our\napproach yields robotic placing policies that outperform policies trained with\nkinesthetic teaching, both in terms of success rate and data efficiency, while\nrequiring no human supervision."
  },
  {
    "paper_no": "1647",
    "authors": "Al Omoush, Muhammad H.; Kishore, Sameer; Mehigan, Tracey",
    "title": "Towards Designing a Low-Cost Humanoid Robot with Flex Sensors-Based Movement",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1651",
    "authors": "Romero Sorozabal, Pablo; Delgado-Oleas, Gabriel; Laudanski, Annemarie F; Gutierrez, Alvaro; Rocon, Eduardo",
    "title": "Discover2Walk: A cable-driven robotic platform to promote gait in pediatric population",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1653",
    "authors": "Asano, Yuki; Okada, Kei; Shiomi, Junichiro",
    "title": "Robotic Measurement for Electrical Property of Polymers by Force-Sensing Robot toward Materials Lab-Automation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1655",
    "authors": "Ankile, Lars; Simeonov, Anthony; Shenfeld, Idan; Agrawal, Pulkit",
    "title": "JUICER: Data-Efficient Imitation Learning for Robotic Assembly",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1657",
    "authors": "Fu, Yue Yang; Kilic, Ali Umut; Braun, David",
    "title": "Energy Minimization using Custom-Designed Magnetic-Spring Actuators",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1660",
    "authors": "Qu, Deyuan; Chen, Qi; Bai, Tianyu; Lu, Hongsheng; Fan, Heng; Zhang, Hao; Fu, Song; Yang, Qing",
    "title": "SiCP: Simultaneous Individual and Cooperative Perception for 3D Object Detection in Connected and Automated Vehicles",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1661",
    "authors": "Yue, Linzhu; Zhang, Lingwei; Song, Zhitao; Zhang, Hongbo; Dong, Jinhu; Zeng, Xuanqi; Liu, Yunhui",
    "title": "A Fast Online Omnidirectional Quadrupedal Jumping Framework Via Virtual-Model Control and Minimum Jerk Trajectory Generation",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.00658v1",
    "arxiv_abstract": "Exploring the limits of quadruped robot agility, particularly in the context\nof rapid and real-time planning and execution of omnidirectional jump\ntrajectories, presents significant challenges due to the complex dynamics\ninvolved, especially when considering significant impulse contacts. This paper\nintroduces a new framework to enable fast, omnidirectional jumping capabilities\nfor quadruped robots. Utilizing minimum jerk technology, the proposed framework\nefficiently generates jump trajectories that exploit its analytical solutions,\nensuring numerical stability and dynamic compatibility with minimal\ncomputational resources. The virtual model control is employed to formulate a\nQuadratic Programming (QP) optimization problem to accurately track the Center\nof Mass (CoM) trajectories during the jump phase. The whole-body control\nstrategies facilitate precise and compliant landing motion. Moreover, the\ndifferent jumping phase is triggered by time-schedule. The framework's efficacy\nis demonstrated through its implementation on an enhanced version of the\nopen-source Mini Cheetah robot. Omnidirectional jumps-including forward,\nbackward, and other directional-were successfully executed, showcasing the\nrobot's capability to perform rapid and consecutive jumps with an average\ntrajectory generation and tracking solution time of merely 50 microseconds."
  },
  {
    "paper_no": "1662",
    "authors": "Bartlett, Tara; Manchester, Ian",
    "title": "Real-time Coupled Centroidal Motion and Footstep Planning for Biped Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.09939v1",
    "arxiv_abstract": "This paper presents an algorithm that finds a centroidal motion and footstep\nplan for a Spring-Loaded Inverted Pendulum (SLIP)-like bipedal robot model\nsubstantially faster than real-time. This is achieved with a novel\nrepresentation of the dynamic footstep planning problem, where each point in\nthe environment is considered a potential foothold that can apply a force to\nthe center of mass to keep it on a desired trajectory. For a biped, up to two\nsuch footholds per time step must be selected, and we approximate this\ncardinality constraint with an iteratively reweighted $l_1$-norm minimization.\nAlong with a linearizing approximation of an angular momentum constraint, this\nresults in a quadratic program can be solved for a contact schedule and center\nof mass trajectory with automatic gait discovery. A 2 s planning horizon with\n13 time steps and 20 surfaces available at each time is solved in 142 ms,\nroughly ten times faster than comparable existing methods in the literature. We\ndemonstrate the versatility of this program in a variety of simulated\nenvironments."
  },
  {
    "paper_no": "1667",
    "authors": "ORD, Samuel; Marino, Matthew; Wiley, Timothy Colin",
    "title": "Modernising Delivery: A Low-Energy Tethered Package System using Fixed-Wing Drones",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1670",
    "authors": "Wu, Jason; Wang, Ziqi; Ouyang, Xiaomin; Jeong, Ho Lyun; Samplawski, Colin; Kaplan, Lance; Marlin, Benjamin; Srivastava, Mani",
    "title": "FlexLoc: Conditional Neural Networks for Zero-Shot Sensor Perspective Invariance in Object Localization with Distributed Multimodal Sensors",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1671",
    "authors": "Wu, Xuankang; Sun, Haoxiang; Xiao, Tong; Pan, Yanzhang; Fang, Zheng",
    "title": "Trans-Rotor: An Active Omnidirectional Aerial-Ground Vehicle With Differential Gear Joint Transformation Mechanism",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1675",
    "authors": "Zhang, Rongge; Bong, Haechan Mark; Beltrame, Giovanni",
    "title": "Active Semantic Mapping and Pose Graph Spectral Analysis for Robot Exploration",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.14726v2",
    "arxiv_abstract": "Exploration in unknown and unstructured environments is a pivotal requirement\nfor robotic applications. A robot's exploration behavior can be inherently\naffected by the performance of its Simultaneous Localization and Mapping (SLAM)\nsubsystem, although SLAM and exploration are generally studied separately. In\nthis paper, we formulate exploration as an active mapping problem and extend it\nwith semantic information. We introduce a novel active metric-semantic SLAM\napproach, leveraging recent research advances in information theory and\nspectral graph theory: we combine semantic mutual information and the\nconnectivity metrics of the underlying pose graph of the SLAM subsystem. We use\nthe resulting utility function to evaluate different trajectories to select the\nmost favorable strategy during exploration. Exploration and SLAM metrics are\nanalyzed in experiments. Running our algorithm on the Habitat dataset, we show\nthat, while maintaining efficiency close to the state-of-the-art exploration\nmethods, our approach effectively increases the performance of metric-semantic\nSLAM with a 21% reduction in average map error and a 9% improvement in average\nsemantic classification accuracy."
  },
  {
    "paper_no": "1677",
    "authors": "Yang, Shunpeng; Hong, Zejun; Li, sen; Wensing, Patrick M.; Zhang, Wei; Chen, Hua",
    "title": "Task-Space Riccati Feedback based Whole Body Control for Underactuated Legged Locomotion",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.00591v1",
    "arxiv_abstract": "This manuscript primarily aims to enhance the performance of whole-body\ncontrollers(WBC) for underactuated legged locomotion. We introduce a systematic\nparameter design mechanism for the floating-base feedback control within the\nWBC. The proposed approach involves utilizing the linearized model of\nunactuated dynamics to formulate a Linear Quadratic Regulator(LQR) and solving\na Riccati gain while accounting for potential physical constraints through a\nsecond-order approximation of the log-barrier function. And then the user-tuned\nfeedback gain for the floating base task is replaced by a new one constructed\nfrom the solved Riccati gain. Extensive simulations conducted in MuJoCo with a\npoint bipedal robot, as well as real-world experiments performed on a quadruped\nrobot, demonstrate the effectiveness of the proposed method. In the different\nbipedal locomotion tasks, compared with the user-tuned method, the proposed\napproach is at least 12% better and up to 50% better at linear velocity\ntracking, and at least 7% better and up to 47% better at angular velocity\ntracking. In the quadruped experiment, linear velocity tracking is improved by\nat least 3% and angular velocity tracking is improved by at least 23% using the\nproposed method."
  },
  {
    "paper_no": "1678",
    "authors": "Senevirathna, Nushen M; De Silva, Oscar; Mann, George K. I.; Gosine, Raymond G.",
    "title": "Ultra Tightly Coupled Passive UWB Localization for Low-density Anchor Networks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1679",
    "authors": "Huang, Haoxu; Lin, Fanqi; Hu, Yingdong; Wang, Shengjie; Gao, Yang",
    "title": "CoPa: General Robotic Manipulation through Spatial Constraints of Parts with Foundation Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1680",
    "authors": "Zuo, Runze; Mehta, Mayank; Han, Dong Heon; Bruder, Daniel",
    "title": "Embedded Valves for Distributed Control of Soft Pneumatic Actuators",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1682",
    "authors": "Ren, Fan; Wang, Xiangyu; Fang, Yongchun; Qin, Yanding; Wang, Hongpeng; Yu, Ningbo; Han, Jianda",
    "title": "Control-Oriented Reinforcement Active Modeling Scheme for Hysteresis Compensation of Flexible Endoscopic Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1683",
    "authors": "Lee, Jongwon; Hanley, David; Bretl, Timothy",
    "title": "Efficient Extrinsic Self-Calibration of Multiple IMUs using Measurement Subset Selection",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.02232v2",
    "arxiv_abstract": "This paper addresses the problem of choosing a sparse subset of measurements\nfor quick calibration parameter estimation. A standard solution to this is\nselecting a measurement only if its utility -- the difference between posterior\n(with the measurement) and prior information (without the measurement) --\nexceeds some threshold. Theoretically, utility, a function of the parameter\nestimate, should be evaluated at the estimate obtained with all measurements\nselected so far, hence necessitating a recalibration with each new measurement.\nHowever, we hypothesize that utility is insensitive to changes in the parameter\nestimate for many systems of interest, suggesting that evaluating utility at\nsome initial parameter guess would yield equivalent results in practice. We\nprovide evidence supporting this hypothesis for extrinsic calibration of\nmultiple inertial measurement units (IMUs), showing the reduction in\ncalibration time by two orders of magnitude by forgoing recalibration for each\nmeasurement."
  },
  {
    "paper_no": "1690",
    "authors": "He, Tairan; Luo, Zhengyi; Xiao, Wenli; Zhang, Chong; Kitani, Kris; Liu, Changliu; Shi, Guanya",
    "title": "Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.04436v1",
    "arxiv_abstract": "We present Human to Humanoid (H2O), a reinforcement learning (RL) based\nframework that enables real-time whole-body teleoperation of a full-sized\nhumanoid robot with only an RGB camera. To create a large-scale retargeted\nmotion dataset of human movements for humanoid robots, we propose a scalable\n\"sim-to-data\" process to filter and pick feasible motions using a privileged\nmotion imitator. Afterwards, we train a robust real-time humanoid motion\nimitator in simulation using these refined motions and transfer it to the real\nhumanoid robot in a zero-shot manner. We successfully achieve teleoperation of\ndynamic whole-body motions in real-world scenarios, including walking, back\njumping, kicking, turning, waving, pushing, boxing, etc. To the best of our\nknowledge, this is the first demonstration to achieve learning-based real-time\nwhole-body humanoid teleoperation."
  },
  {
    "paper_no": "1691",
    "authors": "Jin, Ye; Yang, Ruoxuan; Yi, Zhijie; SHEN, Xiaoxi; Huiling, Peng; Liu, Xiaoan; Qin, Jingli; Jiayang, Li; Gao, Peizhong; Zhou, Guyue; Gong, Jiangtao",
    "title": "SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based on Human Drivers' Driving-thinking Data",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1692",
    "authors": "HUANG, LU; Jing, Xingjian",
    "title": "Asymptotically Optimal Lazy Lifelong Sampling-based Algorithm for Efficient Motion Planning in Dynamic Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.06521v2",
    "arxiv_abstract": "The paper introduces an asymptotically optimal lifelong sampling-based path\nplanning algorithm that combines the merits of lifelong planning algorithms and\nlazy search algorithms for rapid replanning in dynamic environments where edge\nevaluation is expensive. By evaluating only sub-path candidates for the optimal\nsolution, the algorithm saves considerable evaluation time and thereby reduces\nthe overall planning cost. It employs a novel informed rewiring cascade to\nefficiently repair the search tree when the underlying search graph changes.\nSimulation results demonstrate that the algorithm outperforms various\nstate-of-the-art sampling-based planners in addressing both static and dynamic\nmotion planning problems."
  },
  {
    "paper_no": "1694",
    "authors": "Abdollah Chalaki, Mahdi; Soleymani, Abed; Li, Xingyu; Mushahwar, Vivian K.; Tavakoli, Mahdi",
    "title": "Evaluating Gait Symmetry with a Smart Robotic Walker: A Novel Approach to Mobility Assessment",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.12005v1",
    "arxiv_abstract": "Gait asymmetry, a consequence of various neurological or physical conditions\nsuch as aging and stroke, detrimentally impacts bipedal locomotion, causing\nbiomechanical alterations, increasing the risk of falls and reducing quality of\nlife. Addressing this critical issue, this paper introduces a novel diagnostic\nmethod for gait symmetry analysis through the use of an assistive robotic Smart\nWalker equipped with an innovative asymmetry detection scheme. This method\nanalyzes sensor measurements capturing the interaction torque between user and\nwalker. By applying a seasonal-trend decomposition tool, we isolate\ngait-specific patterns within these data, allowing for the estimation of stride\ndurations and calculation of a symmetry index. Through experiments involving 5\nexperimenters, we demonstrate the Smart Walker's capability in detecting and\nquantifying gait asymmetry by achieving an accuracy of 84.9% in identifying\nasymmetric cases in a controlled testing environment. Further analysis explores\nthe classification of these asymmetries based on their underlying causes,\nproviding valuable insights for gait assessment. The results underscore the\npotential of the device as a precise, ready-to-use monitoring tool for\npersonalized rehabilitation, facilitating targeted interventions for enhanced\npatient outcomes."
  },
  {
    "paper_no": "1699",
    "authors": "Wang, Dong; Ye, Hongkai; Pan, Neng; Huang, Jinxin; Zhang, Bangyan; Mao, Yinian; Huang, Guoquan; Xu, Chao; Gao, Fei",
    "title": "Flexible and Topological Consistent Local Replanning for Multirotors",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1701",
    "authors": "Bian, Gui-Bin; Zhang, Mingyang; Ye, Qiang; Ren, Han; Zhai, Yu-Peng; Li, Zhen",
    "title": "Design and Modeling of a Thin-walled Multi-segment Continuum Robotic Bronchoscope",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1703",
    "authors": "Zhan, Weishu; Chin, Peter",
    "title": "Safe multi-agent reinforcement learning for bimanual dexterous manipulation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1704",
    "authors": "Jiang, Han; Chang, Yanchun; yang, liying; He, Yuqing",
    "title": "Small Multi-Rotor UAV Oriented Direct Thrust Sensor Based on Lightweight Barometers",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1705",
    "authors": "Li, Feng; Yang, Ming; Chen, ziqiang; Luan, Mengbo; Tian, Dingkui; Wu, Xinyu",
    "title": "A Closed-loop Control for Lower Limb Exoskeleton Considering Overall Deformations: A Simple and Direct Application Method",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1706",
    "authors": "Keum, Jaeyeong; Kim, Jaemin; Lee, Changgi; Lim, Seunghyun; Ju, Insung; Yun, Dongwon",
    "title": "Development of a Throwbot with Shock Absorption Structure",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1709",
    "authors": "Azuma, Daichi; Miyanishi, Taiki; Kurita, Shuhei; Sakamoto, Koya; Kawanabe, Motoaki",
    "title": "Answerability Fields: Answerable Location Estimation via Diffusion Models",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.18497v1",
    "arxiv_abstract": "In an era characterized by advancements in artificial intelligence and\nrobotics, enabling machines to interact with and understand their environment\nis a critical research endeavor. In this paper, we propose Answerability\nFields, a novel approach to predicting answerability within complex indoor\nenvironments. Leveraging a 3D question answering dataset, we construct a\ncomprehensive Answerability Fields dataset, encompassing diverse scenes and\nquestions from ScanNet. Using a diffusion model, we successfully infer and\nevaluate these Answerability Fields, demonstrating the importance of objects\nand their locations in answering questions within a scene. Our results showcase\nthe efficacy of Answerability Fields in guiding scene-understanding tasks,\nlaying the foundation for their application in enhancing interactions between\nintelligent agents and their environments."
  },
  {
    "paper_no": "1714",
    "authors": "Abood, Damian; Manchester, Ian",
    "title": "Path-Parameterised RRTs for Underactuated Systems",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.05278v1",
    "arxiv_abstract": "We present a sample-based motion planning algorithm specialised to a class of\nunderactuated systems using path parameterisation. The structure this class\npresents under a path parameterisation enables the trivial computation of\ndynamic feasibility along a path. Using this, a specialised state-based\nsteering mechanism within an RRT motion planning algorithm is developed,\nenabling the generation of both geometric paths and their time\nparameterisations without introducing excessive computational overhead. We find\nwith two systems that our algorithm computes feasible trajectories with higher\nrates of success and lower mean computation times compared to existing\napproaches."
  },
  {
    "paper_no": "1717",
    "authors": "Wang, Yingyu; Zhao, Liang; Huang, Shoudong",
    "title": "Grid-based Submap Joining: An Efficient Algorithm for Simultaneously Optimizing Global Occupancy Map and Local Submap Frames",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1721",
    "authors": "Liu, Zhiyang; Zhao, Ruiteng; Zhou, Lei; Yuan, Chengran; Wu, Yuwei; Guo, Sheng; Zhang, Zhengshen; Liu, Chenchen; Ang Jr, Marcelo H",
    "title": "3D Affordance Keypoint Detection for Robotic Manipulation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1723",
    "authors": "Wen, Feiyang; Zhao, Hanying; Jincheng, Yu; Cui, Shulin; Shen, Yuan",
    "title": "CATOA:Cooperative Calibration of Timestamp Measurements for Distributed Multi-Robot Localization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1724",
    "authors": "Zhang, Tianyi; Huang, Kaining; Zhi, Weiming; Johnson-Roberson, Matthew",
    "title": "DarkGS: Learning Neural Illumination and 3D Gaussians Relighting for Robotic Exploration in the Dark",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1727",
    "authors": "Wang, Xingshuo; Zhang, Yunzhou; Zhang, Zhiyao; Wang, Mengting; Li, Zhiteng; Chen, Xuanhua",
    "title": "FI-SLAM: Feature Fusion and Instance Reconstruction for Neural Implicit SLAM",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1728",
    "authors": "Wang, Dong; Wang, Jingping; He, Suqin; Huang, Jinxin; Zhang, Bangyan; Mao, Yinian; Huang, Guoquan; Xu, Chao; Gao, Fei",
    "title": "Multi-Fov-Constrained Trajectory Planning for Multirotor Safe Landing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1729",
    "authors": "Liang, Anthony; B&#305;y&#305;k, Erdem; Thomason, Jesse",
    "title": "ViSaRL: Visual Reinforcement Learning Guided by Human Saliency",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1730",
    "authors": "Wang, Yichen; Liu, Qiming; Liu, Zhe; Wang, Hesheng",
    "title": "Enhancing Exploratory Capability of Visual Navigation Using Uncertainty of Implicit Scene Representation",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.03487v1",
    "arxiv_abstract": "In the context of visual navigation in unknown scenes, both \"exploration\" and\n\"exploitation\" are equally crucial. Robots must first establish environmental\ncognition through exploration and then utilize the cognitive information to\naccomplish target searches. However, most existing methods for image-goal\nnavigation prioritize target search over the generation of exploratory\nbehavior. To address this, we propose the Navigation with Uncertainty-driven\nExploration (NUE) pipeline, which uses an implicit and compact scene\nrepresentation, NeRF, as a cognitive structure. We estimate the uncertainty of\nNeRF and augment the exploratory ability by the uncertainty to in turn\nfacilitate the construction of implicit representation. Simultaneously, we\nextract memory information from NeRF to enhance the robot's reasoning ability\nfor determining the location of the target. Ultimately, we seamlessly combine\nthe two generated abilities to produce navigational actions. Our pipeline is\nend-to-end, with the environmental cognitive structure being constructed\nonline. Extensive experimental results on image-goal navigation demonstrate the\ncapability of our pipeline to enhance exploratory behaviors, while also\nenabling a natural transition from the exploration to exploitation phase. This\nenables our model to outperform existing memory-based cognitive navigation\nstructures in terms of navigation performance."
  },
  {
    "paper_no": "1734",
    "authors": "Wei, Dunwen; Cui, Chenguang; Yu, Haitao; Gao, Tao; Hussain, Sajjad; Ficuciello, Fanny",
    "title": "Novel Multi-port Output Twisted String Actuator with Self-differential Mechanism: Hand Glove Application",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1735",
    "authors": "Yang, Yiqiao; Pang, Chenglin; Wu, Chengdong; Fang, Zheng",
    "title": "Geometry-aided Underwater 3D Mapping Using Side-scan Sonar",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1737",
    "authors": "Liu, Tianliang; Yang, Sicheng; Li, Jingchen; Chen, Xiangchi; WANG, Shuai; Teng, Xiao; Lee, Wang Wei; LI, XIONG; Zheng, Yu",
    "title": "A High-Performance Anthropomorphic Robotic Arm for Household Applications",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1738",
    "authors": "Xu, Gengchen; Chen, Haofeng; Yang, Xuanxuan; ma, gang; Wang, Xiaojie",
    "title": "Pseudo-Domain Adversarial Networks with Electrical Impedance Tomography for Electrode Offset Error",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1742",
    "authors": "Yuan, Dong; Maire, Frederic; Dayoub, Feras",
    "title": "Temporal Attention for Cross-View Sequential Image Localization",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.15569v1",
    "arxiv_abstract": "This paper introduces a novel approach to enhancing cross-view localization,\nfocusing on the fine-grained, sequential localization of street-view images\nwithin a single known satellite image patch, a significant departure from\ntraditional one-to-one image retrieval methods. By expanding to sequential\nimage fine-grained localization, our model, equipped with a novel Temporal\nAttention Module (TAM), leverages contextual information to significantly\nimprove sequential image localization accuracy. Our method shows substantial\nreductions in both mean and median localization errors on the Cross-View Image\nSequence (CVIS) dataset, outperforming current state-of-the-art single-image\nlocalization techniques. Additionally, by adapting the KITTI-CVL dataset into\nsequential image sets, we not only offer a more realistic dataset for future\nresearch but also demonstrate our model's robust generalization capabilities\nacross varying times and areas, evidenced by a 75.3% reduction in mean distance\nerror in cross-view sequential image localization."
  },
  {
    "paper_no": "1744",
    "authors": "Hong, Kai-Yin; Wang, Chieh-Chih; Lin, Wen-Chieh",
    "title": "Multi-modal Motion Prediction using Temporal Ensembling with Learning-based Aggregation",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.19606v1",
    "arxiv_abstract": "Recent years have seen a shift towards learning-based methods for trajectory\nprediction, with challenges remaining in addressing uncertainty and capturing\nmulti-modal distributions. This paper introduces Temporal Ensembling with\nLearning-based Aggregation, a meta-algorithm designed to mitigate the issue of\nmissing behaviors in trajectory prediction, which leads to inconsistent\npredictions across consecutive frames. Unlike conventional model ensembling,\ntemporal ensembling leverages predictions from nearby frames to enhance spatial\ncoverage and prediction diversity. By confirming predictions from multiple\nframes, temporal ensembling compensates for occasional errors in individual\nframe predictions. Furthermore, trajectory-level aggregation, often utilized in\nmodel ensembling, is insufficient for temporal ensembling due to a lack of\nconsideration of traffic context and its tendency to assign candidate\ntrajectories with incorrect driving behaviors to final predictions. We further\nemphasize the necessity of learning-based aggregation by utilizing mode queries\nwithin a DETR-like architecture for our temporal ensembling, leveraging the\ncharacteristics of predictions from nearby frames. Our method, validated on the\nArgoverse 2 dataset, shows notable improvements: a 4% reduction in minADE, a 5%\ndecrease in minFDE, and a 1.16% reduction in the miss rate compared to the\nstrongest baseline, QCNet, highlighting its efficacy and potential in\nautonomous driving."
  },
  {
    "paper_no": "1747",
    "authors": "Guo, Yanjiang; Wang, Yen-Jen; Zha, Lihan; Chen, Jianyu",
    "title": "DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1748",
    "authors": "Shinde, Nikhil; Chiu, Zih-Yun; Richter, Florian; Lim, Jason; Zhi, Yuheng; Herbert, Sylvia; Yip, Michael C.",
    "title": "SURESTEP: An Uncertainty-Aware Trajectory Optimization Framework to Enhance Visual Tool Tracking for Robust Surgical Automation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1749",
    "authors": "Monninger, Thomas; Dokkadi, Vandana; Anwar, Md Zafar; Staab, Steffen",
    "title": "TempBEV: Improving Learned BEV Encoders with Combined Image and BEV Space Temporal Aggregation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1750",
    "authors": "Itsuka, Tomoya; Kurazume, Ryo",
    "title": "Indoor Position Estimation Using NLoS Reflect Path by Wireless Distance Sensors",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1755",
    "authors": "Gong, Chen; Meghjani, Malika; Prasetyo, Marcel Bartholomeus",
    "title": "Robot Guided Evacuation with Viewpoint Constraints",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.19466v1",
    "arxiv_abstract": "We present a viewpoint-based non-linear Model Predictive Control (MPC) for\nevacuation guiding robots. Specifically, the proposed MPC algorithm enables\nevacuation guiding robots to track and guide cooperative human targets in\nemergency scenarios. Our algorithm accounts for the environment layout as well\nas distances between the robot and human target and distance to the goal\nlocation. A key challenge for evacuation guiding robot is the trade-off between\nits planned motion for leading the target toward a goal position and staying in\nthe target's viewpoint while maintaining line-of-sight for guiding. We\nillustrate the effectiveness of our proposed evacuation guiding algorithm in\nboth simulated and real-world environments with an Unmanned Aerial Vehicle\n(UAV) guiding a human. Our results suggest that using the contextual\ninformation from the environment for motion planning, increases the visibility\nof the guiding UAV to the human while achieving faster total evacuation time."
  },
  {
    "paper_no": "1757",
    "authors": "Aoki, Mizuho; Honda, Kohei; Okuda, Hiroyuki; Suzuki, Tatsuya",
    "title": "Switching Sampling Space of Model Predictive Path-Integral Controller to Balance Efficiency and Safety in 4WIDS Vehicle Navigation",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.08648v1",
    "arxiv_abstract": "Four-wheel independent drive and steering vehicle (4WIDS Vehicle, Swerve\nDrive Robot) has the ability to move in any direction by its eight degrees of\nfreedom (DoF) control inputs. Although the high maneuverability enables\nefficient navigation in narrow spaces, obtaining the optimal command is\nchallenging due to the high dimension of the solution space. This paper\npresents a navigation architecture using the Model Predictive Path Integral\n(MPPI) control algorithm to avoid collisions with obstacles of any shape and\nreach a goal point. The key idea to make the problem easier is to explore the\noptimal control input in a reasonably reduced dimension that is adequate for\nnavigation. Through evaluation in simulation, we found that selecting the\nsampling space of MPPI greatly affects navigation performance. In addition, our\nproposed controller which switches multiple sampling spaces according to the\nreal-time situation can achieve balanced behavior between efficiency and\nsafety. Source code is available at\nhttps://github.com/MizuhoAOKI/mppi_swerve_drive_ros"
  },
  {
    "paper_no": "1758",
    "authors": "Hong, Jin song; Yeo, Changmin; Bae, Sangjin; Hong, Jeongwoo; Oh, Sehoon",
    "title": "SLIP Nature Embodied Robust Quadruped Robot Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1760",
    "authors": "Jung, Dae-Hwan; Hong, Hyun Seok; Park, Sahng-Gyu; Lee, Yeongrok; Lee, Woosub",
    "title": "Advanced Liquid and Dust Detection Sensor Setup and Algorithm Based on YOLO and Feature Extraction for Commercial Autonomous Cleaning Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1761",
    "authors": "Ming, Zhenxing; Berrio Perez, Julie Stephany; Shan, Mao; Worrall, Stewart",
    "title": "InverseMatrixVT3D: An Efficient Projection Matrix-Based Approach for 3D Occupancy Prediction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1763",
    "authors": "Naveed, Kanwal; Anjum, Muhammad Latif; Hussain, Wajahat; LEE, DONGHWAN",
    "title": "Deeper Introspective SLAM: How to Avoid Tracking Failures Over Longer Routes?",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1765",
    "authors": "Sun, Na; Fan, Zhengqiang; Qiu, Quan; Li, Tao; Feng, Qingchun; Ji, Chao; Zhao, Chunjiang",
    "title": "TriLoc-NetVLAD: Enhancing Long-term Place Recognition in Orchards with a Novel LiDAR-Based Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1769",
    "authors": "HU, ZHIQIANG; Yu, Tao; Huang, Shouren",
    "title": "Dynamic SpectraFormer for Ultra-High Resolution Underwater Image Enhancement",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1770",
    "authors": "Sulaiman, Shifa; MENON, MEHUL; Schetter, Francesco; Ficuciello, Fanny",
    "title": "Design, Modelling, and Experimental Validation of a Soft Continuum Wrist Section developed for a Prosthetic Hand",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1773",
    "authors": "Ummadisingu, Avinash; Choi, Jongkeum; Yamane, Koki; Masuda, Shimpei; Fukaya, Naoki; Takahashi, Kuniyuki",
    "title": "SAID-NeRF: Segmentation-AIDed NeRF for Depth Completion of Transparent Objects",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1774",
    "authors": "Zhang, Liwang; Liang, Dong; Li, Minglong; YANG, WENJING; Yang, Shaowu",
    "title": "Coalition Formation Game Approach for Task Allocation in Heterogeneous Multi-Robot Systems under Resource Constraints",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1775",
    "authors": "Zeng, Weizhen; Fan, Jiaqi; Tian, Xuelin; Chu, Hongqing; Gao, Bingzhao",
    "title": "FusionTrack: An Online 3D Multi-object Tracking Framework Based on Camera-LiDAR Fusion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1777",
    "authors": "Bui, Huy Hoang; Bui, Bach-Thuan; Tran, Dinh Tuan; Lee, Joo-Ho",
    "title": "Leveraging Neural Radiance Field in Descriptor Synthesis for Keypoints Scene Coordinate Regression",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10297v2",
    "arxiv_abstract": "Classical structural-based visual localization methods offer high accuracy\nbut face trade-offs in terms of storage, speed, and privacy. A recent\ninnovation, keypoint scene coordinate regression (KSCR) named D2S addresses\nthese issues by leveraging graph attention networks to enhance keypoint\nrelationships and predict their 3D coordinates using a simple multilayer\nperceptron (MLP). Camera pose is then determined via PnP+RANSAC, using\nestablished 2D-3D correspondences. While KSCR achieves competitive results,\nrivaling state-of-the-art image-retrieval methods like HLoc across multiple\nbenchmarks, its performance is hindered when data samples are limited due to\nthe deep learning model's reliance on extensive data. This paper proposes a\nsolution to this challenge by introducing a pipeline for keypoint descriptor\nsynthesis using Neural Radiance Field (NeRF). By generating novel poses and\nfeeding them into a trained NeRF model to create new views, our approach\nenhances the KSCR's generalization capabilities in data-scarce environments.\nThe proposed system could significantly improve localization accuracy by up to\n50% and cost only a fraction of time for data synthesis. Furthermore, its\nmodular design allows for the integration of multiple NeRFs, offering a\nversatile and efficient solution for visual localization. The implementation is\npublicly available at: https://github.com/ais-lab/DescriptorSynthesis4Feat2Map."
  },
  {
    "paper_no": "1778",
    "authors": "Han, Fuzhang; Jia, Shenhan; Huang, Wenjun; Wang, Yue; Xiong, Rong",
    "title": "VIVO: A Visual-Inertial-Velocity Odometry with Online Calibration in Challenging Condition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1780",
    "authors": "D'Amely di Melendugno, Guido Maria; Flaborea, Alessandro; Mettes, Pascal; Galasso, Fabio",
    "title": "Hyp2Nav: Hyperbolic Planning and Curiosity for Crowd Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1785",
    "authors": "Zhang, Qi; Gou, Siyuan; Li, Wenbin",
    "title": "Visual Perception System for Autonomous Driving",
    "arxiv_pdf": "http://arxiv.org/pdf/2303.02257v2",
    "arxiv_abstract": "The recent surge in interest in autonomous driving stems from its rapidly\ndeveloping capacity to enhance safety, efficiency, and convenience. A pivotal\naspect of autonomous driving technology is its perceptual systems, where core\nalgorithms have yielded more precise algorithms applicable to autonomous\ndriving, including vision-based Simultaneous Localization and Mapping (SLAMs),\nobject detection, and tracking algorithms. This work introduces a visual-based\nperception system for autonomous driving that integrates trajectory tracking\nand prediction of moving objects to prevent collisions, while addressing\nautonomous driving's localization and mapping requirements. The system\nleverages motion cues from pedestrians to monitor and forecast their movements\nand simultaneously maps the environment. This integrated approach resolves\ncamera localization and the tracking of other moving objects in the scene,\nsubsequently generating a sparse map to facilitate vehicle navigation. The\nperformance, efficiency, and resilience of this approach are substantiated\nthrough comprehensive evaluations of both simulated and real-world datasets."
  },
  {
    "paper_no": "1786",
    "authors": "Kim, Jaeyeul; Woo, Jungwan; Shin, Ukcheol; Oh, Jean; Im, Sunghoon",
    "title": "Density-aware Domain Generalization for LiDAR Semantic Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1788",
    "authors": "Murakami, Ryo; Mori, Satoshi; Zhang, Haichong",
    "title": "Thermal Ablation Therapy Control with Tissue Necrosis-driven Temperature Feedback Enabled by Neural State Space Model with Extended Kalman Filter",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1793",
    "authors": "KANA, SREEKANTH; Pérez Arias, Antonia; Kahlau, Robert; Kanajar, Pavan; Sharma, Shashank",
    "title": "Saturation in the Null-Space (SNS) for Tele-operated Surgery: Prioritized Motion Control for RCM and Joint Limit Constraints",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1794",
    "authors": "Zhou, Zhuyun; Wu, Zongwei; Paudel, Danda Pani; Boutteau, Rémi; Yang, Fan; Van Gool, Luc; Timofte, Radu; Ginhac, Dominique",
    "title": "Event-Free Moving Object Segmentation from Moving Ego Vehicle",
    "arxiv_pdf": "http://arxiv.org/pdf/2305.00126v3",
    "arxiv_abstract": "Moving object segmentation (MOS) in dynamic scenes is an important,\nchallenging, but under-explored research topic for autonomous driving,\nespecially for sequences obtained from moving ego vehicles. Most segmentation\nmethods leverage motion cues obtained from optical flow maps. However, since\nthese methods are often based on optical flows that are pre-computed from\nsuccessive RGB frames, this neglects the temporal consideration of events\noccurring within the inter-frame, consequently constraining its ability to\ndiscern objects exhibiting relative staticity but genuinely in motion. To\naddress these limitations, we propose to exploit event cameras for better video\nunderstanding, which provide rich motion cues without relying on optical flow.\nTo foster research in this area, we first introduce a novel large-scale dataset\ncalled DSEC-MOS for moving object segmentation from moving ego vehicles, which\nis the first of its kind. For benchmarking, we select various mainstream\nmethods and rigorously evaluate them on our dataset. Subsequently, we devise\nEmoFormer, a novel network able to exploit the event data. For this purpose, we\nfuse the event temporal prior with spatial semantic maps to distinguish\ngenuinely moving objects from the static background, adding another level of\ndense supervision around our object of interest. Our proposed network relies\nonly on event data for training but does not require event input during\ninference, making it directly comparable to frame-only methods in terms of\nefficiency and more widely usable in many application cases. The exhaustive\ncomparison highlights a significant performance improvement of our method over\nall other methods. The source code and dataset are publicly available at:\nhttps://github.com/ZZY-Zhou/DSEC-MOS."
  },
  {
    "paper_no": "1797",
    "authors": "LIM, HYUNGTAE; Jang, Seoyeon; Mersch, Benedikt; Behley, Jens; Myung, Hyun; Stachniss, Cyrill",
    "title": "HeLiMOS: A Dataset for Moving Object Segmentation in 3D Point Clouds From Heterogeneous LiDAR Sensors",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1798",
    "authors": "W&#281;grzynowski, Jan; Czechmanowski, Grzegorz; Kicki, Piotr; Walas, Krzysztof, Tadeusz",
    "title": "Learning dynamics models for velocity estimation in autonomous racing",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.15610v1",
    "arxiv_abstract": "Velocity estimation is of great importance in autonomous racing. Still,\nexisting solutions are characterized by limited accuracy, especially in the\ncase of aggressive driving or poor generalization to unseen road conditions. To\naddress these issues, we propose to utilize Unscented Kalman Filter (UKF) with\na learned dynamics model that is optimized directly for the state estimation\ntask. Moreover, we propose to aid this model with the online-estimated friction\ncoefficient, which increases the estimation accuracy and enables zero-shot\nadaptation to the new road conditions. To evaluate the UKF-based velocity\nestimator with the proposed dynamics model, we introduced a publicly available\ndataset of aggressive manoeuvres performed by an F1TENTH car, with sideslip\nangles reaching 40{\\deg}. Using this dataset, we show that learning the\ndynamics model through UKF leads to improved estimation performance and that\nthe proposed solution outperforms state-of-the-art learning-based state\nestimators by 17% in the nominal scenario. Moreover, we present unseen\nzero-shot adaptation abilities of the proposed method to the new road surface\nthanks to the use of the proposed learning-based tire dynamics model with\nonline friction estimation."
  },
  {
    "paper_no": "1804",
    "authors": "Kato, Yuki; Yoshida, Takahiro; Sueoka, Yuichiro; Osuka, Koichi; Yajima, Ryosuke; Nagatani, Keiji; Asama, Hajime",
    "title": "An Adaptive Coordination System based on Functional Expressions of Robots and Environment Understanding",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1806",
    "authors": "Duan, Chengyao; Yang, Zhiliu",
    "title": "TivNe-SLAM: Dynamic Mapping and Tracking via Time-Varying Neural Radiance Fields",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1812",
    "authors": "Wu, Yuchen; Yang, Yifan; Xu, Gang; Cao, Junjie; Chen, Yansong; Wen, Licheng; Liu, Yong",
    "title": "Hierarchical Search-Based Cooperative Motion Planning",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.15710v1",
    "arxiv_abstract": "Cooperative path planning, a crucial aspect of multi-agent systems research,\nserves a variety of sectors, including military, agriculture, and industry.\nMany existing algorithms, however, come with certain limitations, such as\nsimplified kinematic models and inadequate support for multiple group\nscenarios. Focusing on the planning problem associated with a nonholonomic\nAckermann model for Unmanned Ground Vehicles (UGV), we propose a leaderless,\nhierarchical Search-Based Cooperative Motion Planning (SCMP) method. The\nhigh-level utilizes a binary conflict search tree to minimize runtime, while\nthe low-level fabricates kinematically feasible, collision-free paths that are\nshape-constrained. Our algorithm can adapt to scenarios featuring multiple\ngroups with different shapes, outlier agents, and elaborate obstacles. We\nconduct algorithm comparisons, performance testing, simulation, and real-world\ntesting, verifying the effectiveness and applicability of our algorithm. The\nimplementation of our method will be open-sourced at\nhttps://github.com/WYCUniverStar/SCMP."
  },
  {
    "paper_no": "1813",
    "authors": "YE, Tianxiang; Wu, Qi; DENG, Junyuan; Liu, Guoqing; Liu, Liu; Xia, Songpengcheng; Pang, Liang; Yu, Wenxian; Pei, Ling",
    "title": "Thermal-NeRF: Neural Radiance Fields from an Infrared Camera",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1815",
    "authors": "Yang, Sicheng; Lee, Wang Wei; Zhang, Zhong; Xiong, youda; Liang, Jiaming; Lu, Peng; ZHU, YONGHUI; Liu, Tianliang; Li, Jingchen; Wang, Rui; LI, XIONG; Zheng, Yu",
    "title": "A Multi-DoF Anthropomorphic Hand with Integrated Tactile Feedback for Grasping and Manipulation in Human Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1816",
    "authors": "Pitz, Johannes; Röstel, Lennart; Sievers, Leon; Burschka, Darius; Bäuml, Berthold",
    "title": "Learning a Shape-Conditioned Agent for Purely Tactile In-Hand Manipulation of Various Objects",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.18834v2",
    "arxiv_abstract": "Reorienting diverse objects with a multi-fingered hand is a challenging task.\nCurrent methods in robotic in-hand manipulation are either object-specific or\nrequire permanent supervision of the object state from visual sensors. This is\nfar from human capabilities and from what is needed in real-world applications.\nIn this work, we address this gap by training shape-conditioned agents to\nreorient diverse objects in hand, relying purely on tactile feedback (via\ntorque and position measurements of the fingers' joints). To achieve this, we\npropose a learning framework that exploits shape information in a reinforcement\nlearning policy and a learned state estimator. We find that representing 3D\nshapes by vectors from a fixed set of basis points to the shape's surface,\ntransformed by its predicted 3D pose, is especially helpful for learning\ndexterous in-hand manipulation. In simulation and real-world experiments, we\nshow the reorientation of many objects with high success rates, on par with\nstate-of-the-art results obtained with specialized single-object agents.\nMoreover, we show generalization to novel objects, achieving success rates of\n$\\sim$90% even for non-convex shapes."
  },
  {
    "paper_no": "1818",
    "authors": "Palmieri, Jozsef; Di Lillo, Paolo; Sanfeliu, Alberto; Marino, Alessandro",
    "title": "Perception-Driven Shared Control Architecture for Agricultural Robots Performing Harvesting Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1819",
    "authors": "Yu, Chenyao; Cai, Yingfeng; Zhang, Jiaxin; Sui, Wei; Kong, Hui; Yang, Cong",
    "title": "VRSO: Visual-Centric Reconstruction for Static Object Annotation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1820",
    "authors": "Jang, Hun; Petrichenko, Valentyn; Bae, Joonbum; Haninger, Kevin",
    "title": "Soft finger rotational stability for precision grasps",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.04846v2",
    "arxiv_abstract": "Soft robotic fingers can safely grasp fragile or variable form objects, but\ntheir force capacity is limited, especially with less contact area: precision\ngrasps and when objects are smaller or not spherical. Current research is\nimproving force capacity through mechanical design by increasing contact area\nor stiffness, typically without models which explain soft finger force\nlimitations. To address this, this paper considers two types of soft grip\nfailure, slip and dynamic rotational stability. For slip, the validity of a\nCoulomb model investigated, identifying the effect of contact area, pressure,\nand relative pose. For rotational stability, bulk linear stiffness of the\nfingers is used to develop conditions for dynamic stability and identify when\nrotation leads to slip. Together, these models suggest contact area improves\nforce capacity by increasing transverse stiffness and normal force. The models\nare validated on pneumatic fingers, both custom PneuNets-based and commercially\navailable. The models are used to find grip parameters which increase force\ncapacity without failure."
  },
  {
    "paper_no": "1823",
    "authors": "Pertzovsky, Arseniy; Stern, Roni; Zivan, Roie",
    "title": "CGA: Corridor Generating Algorithm for Multi-Agent Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1825",
    "authors": "Timoneda, Xavier; Herb, Markus; Duerr, Fabian; Goehring, Daniel; Yu, Fisher",
    "title": "Multi-modal NeRF Self-Supervision for LiDAR Semantic Segmentation",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.02969v1",
    "arxiv_abstract": "LiDAR Semantic Segmentation is a fundamental task in autonomous driving\nperception consisting of associating each LiDAR point to a semantic label.\nFully-supervised models have widely tackled this task, but they require labels\nfor each scan, which either limits their domain or requires impractical amounts\nof expensive annotations. Camera images, which are generally recorded alongside\nLiDAR pointclouds, can be processed by the widely available 2D foundation\nmodels, which are generic and dataset-agnostic. However, distilling knowledge\nfrom 2D data to improve LiDAR perception raises domain adaptation challenges.\nFor example, the classical perspective projection suffers from the parallax\neffect produced by the position shift between both sensors at their respective\ncapture times. We propose a Semi-Supervised Learning setup to leverage\nunlabeled LiDAR pointclouds alongside distilled knowledge from the camera\nimages. To self-supervise our model on the unlabeled scans, we add an auxiliary\nNeRF head and cast rays from the camera viewpoint over the unlabeled voxel\nfeatures. The NeRF head predicts densities and semantic logits at each sampled\nray location which are used for rendering pixel semantics. Concurrently, we\nquery the Segment-Anything (SAM) foundation model with the camera image to\ngenerate a set of unlabeled generic masks. We fuse the masks with the rendered\npixel semantics from LiDAR to produce pseudo-labels that supervise the pixel\npredictions. During inference, we drop the NeRF head and run our model with\nonly LiDAR. We show the effectiveness of our approach in three public LiDAR\nSemantic Segmentation benchmarks: nuScenes, SemanticKITTI and ScribbleKITTI."
  },
  {
    "paper_no": "1828",
    "authors": "Rozzi, Filippo; Roveda, Loris; Haninger, Kevin",
    "title": "Combining Sampling- and Gradient-based Planning for Contact-rich Manipulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.04822v2",
    "arxiv_abstract": "Planning over discontinuous dynamics is needed for robotics tasks like\ncontact-rich manipulation, which presents challenges in the numerical stability\nand speed of planning methods when either neural network or analytical models\nare used. On the one hand, sampling-based planners require higher sample\ncomplexity in high-dimensional problems and cannot describe safety constraints\nsuch as force limits. On the other hand, gradient-based solvers can suffer from\nlocal optima and convergence issues when the Hessian is poorly conditioned. We\npropose a planning method with both sampling- and gradient-based elements,\nusing the Cross-entropy Method to initialize a gradient-based solver, providing\nbetter search over local minima and the ability to handle explicit constraints.\nWe show the approach allows smooth, stable contact-rich planning for an\nimpedance-controlled robot making contact with a stiff environment,\nbenchmarking against gradient-only MPC and CEM."
  },
  {
    "paper_no": "1829",
    "authors": "Tang, Jiadong; Gao, Yu; Jiang, Tianji; Yang, Yi; Fu, Mengyin",
    "title": "Fine-tuning the Diffusion Model and Distilling Informative Priors for Sparse-view 3D Reconstruction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1830",
    "authors": "Pitcher, Thomas; Förster, Julian; Chung, Jen Jen",
    "title": "Reinforcement Learning for Active Search and Grasp in Clutter",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1831",
    "authors": "Yu, Xuan; Liu, Yili; Han, Chenrui; Mao, Sitong; ZHOU, Shunbo; Xiong, Rong; Liao, Yiyi; Wang, Yue",
    "title": "PanopticRecon: Leverage Open-vocabulary Instance Segmentation for Zero-shot Panoptic Reconstruction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1832",
    "authors": "Zou, Zhenghao; Zhao, Chunhui; Kao, XiRui; Liu, jiang bo; Chai, Haochen; Lyu, Yang",
    "title": "SwiftBase: A dataset based on high-frequency visual measurement for Visual-Inertial Localization in high-speed motion scenes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1835",
    "authors": "Fukaya, Naoki; Yamane, Koki; Masuda, Shimpei; Ummadisingu, Avinash; Maeda, Shin-ichi; Takahashi, Kuniyuki",
    "title": "Four-Axis Adaptive Fingers Hand for Object Insertion: FAAF Hand",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1836",
    "authors": "Kienle, Claudius; Alt, Benjamin; Celik, Onur; Becker, Philipp; Katic, Darko; Jäkel, Rainer; Neumann, Gerhard",
    "title": "MuTT: A Multimodal Trajectory Transformer for Robot Skills",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1839",
    "authors": "Saito, Namiko; Moura, Joao; Uchida, Hiroki; Vijayakumar, Sethu",
    "title": "Latent Object Characteristics Recognition with Visual to Haptic-Audio Cross-modal Transfer Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10689v1",
    "arxiv_abstract": "Recognising the characteristics of objects while a robot handles them is\ncrucial for adjusting motions that ensure stable and efficient interactions\nwith containers. Ahead of realising stable and efficient robot motions for\nhandling/transferring the containers, this work aims to recognise the latent\nunobservable object characteristics. While vision is commonly used for object\nrecognition by robots, it is ineffective for detecting hidden objects. However,\nrecognising objects indirectly using other sensors is a challenging task. To\naddress this challenge, we propose a cross-modal transfer learning approach\nfrom vision to haptic-audio. We initially train the model with vision, directly\nobserving the target object. Subsequently, we transfer the latent space learned\nfrom vision to a second module, trained only with haptic-audio and motor data.\nThis transfer learning framework facilitates the representation of object\ncharacteristics using indirect sensor data, thereby improving recognition\naccuracy. For evaluating the recognition accuracy of our proposed learning\nframework we selected shape, position, and orientation as the object\ncharacteristics. Finally, we demonstrate online recognition of both trained and\nuntrained objects using the humanoid robot Nextage Open."
  },
  {
    "paper_no": "1840",
    "authors": "Schirmer, Robert; Vaskevicius, Narunas; Biber, Peter; Stachniss, Cyrill",
    "title": "Fast Global Point Cloud Registration using Semantic NDT",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1842",
    "authors": "Zakir, Raina; Dorigo, Marco; Reina, Andreagiovanni",
    "title": "Miscommunication between robots can improve group accuracy in best-of-n decision-making",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1843",
    "authors": "Wang, Yufeng; wu, houping; Li, Chenchen; Peng, Yu Lian; Wang, Hongbo",
    "title": "A Perceptive Pneumatic Artificial Muscle Empowered by Double Helix Fiber Reinforcement",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1844",
    "authors": "Agunloye, Ayomide Oluwaseyi; Ramchurn, Sarvapali; Soorati, Mohammad D.",
    "title": "Learning to Imitate Spatial Organization in Multi-robot Systems",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.11592v3",
    "arxiv_abstract": "Understanding collective behavior and how it evolves is important to ensure\nthat robot swarms can be trusted in a shared environment. One way to understand\nthe behavior of the swarm is through collective behavior reconstruction using\nprior demonstrations. Existing approaches often require access to the swarm\ncontroller which may not be available. We reconstruct collective behaviors in\ndistinct swarm scenarios involving shared environments without using swarm\ncontroller information. We achieve this by transforming prior demonstrations\ninto features that describe multi-agent interactions before behavior\nreconstruction with multi-agent generative adversarial imitation learning\n(MA-GAIL). We show that our approach outperforms existing algorithms in spatial\norganization, and can be used to observe and reconstruct a swarm's behavior for\nfurther analysis and testing, which might be impractical or undesirable on the\noriginal robot swarm."
  },
  {
    "paper_no": "1846",
    "authors": "wang, tao; He, Yuesheng; Zhuang, Hanyang; Yang, Ming",
    "title": "An Online Automatic Calibration Method for Infrastructure-Based LiDAR-Camera via Cross-modal Object Matching",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1847",
    "authors": "Li, Dayou; Zhao, Chenkun; Yang, Shuo; Song, Ran; Li, Xiaolei; Zhang, Wei",
    "title": "MPGNet: Learning Move-Push-Grasping Synergy for Target-Oriented Grasping in Occluded Scenes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1849",
    "authors": "Matsuzawa, Fumiya; QIU, YUE; Sun, Yanjun; Iwata, Kenji; Kataoka, Hirokatsu; Satoh, Yutaka",
    "title": "Subtle-Diff: A Dataset for Precise Recognition of Subtle Differences Among Visually Similar Objects",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1851",
    "authors": "Cao, Zhengcai; Sun, Yiyang; Ma, Zhe; Zhou, MengChu",
    "title": "A Context-Enhanced Full-Resolution Floor Plan Segmentation Network for Topological Semantic Mapping",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1857",
    "authors": "El Hariry, Matteo; Richard, Antoine; Muralidharan, Vivek; Geist, Matthieu; Olivares-Mendez, Miguel A.",
    "title": "DRIFT: Deep Reinforcement Learning for Intelligent Floating Platforms Trajectories",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1859",
    "authors": "Guesmi, Amira; Hanif, Muhammad Abdullah; Alouani, Ihsen; OUNI, Bassem; Shafique, Muhammad",
    "title": "SSAP: A Shape-Sensitive Adversarial Patch for Comprehensive Disruption of Monocular Depth Estimation in Autonomous Navigation Applications",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1861",
    "authors": "Wu, Hang; Zhang, Zhenghao; Lin, Siyuan; Mu, Xiangru; Zhao, Qiang; Yang, Ming; Qin, Tong",
    "title": "MapLocNet: Coarse-to-Fine Visual Neural Re-Localization in Navigation Maps",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1862",
    "authors": "Shen, Qiyuan; Zhao, Hengwang; Yan, Weihao; Qin, Tong; Yang, Ming",
    "title": "Cross-Modal Visual Relocalization in Prior LiDAR Maps Utilizing Intensity Textures",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.01299v1",
    "arxiv_abstract": "Cross-modal localization has drawn increasing attention in recent years,\nwhile the visual relocalization in prior LiDAR maps is less studied. Related\nmethods usually suffer from inconsistency between the 2D texture and 3D\ngeometry, neglecting the intensity features in the LiDAR point cloud. In this\npaper, we propose a cross-modal visual relocalization system in prior LiDAR\nmaps utilizing intensity textures, which consists of three main modules: map\nprojection, coarse retrieval, and fine relocalization. In the map projection\nmodule, we construct the database of intensity channel map images leveraging\nthe dense characteristic of panoramic projection. The coarse retrieval module\nretrieves the top-K most similar map images to the query image from the\ndatabase, and retains the top-K' results by covisibility clustering. The fine\nrelocalization module applies a two-stage 2D-3D association and a covisibility\ninlier selection method to obtain robust correspondences for 6DoF pose\nestimation. The experimental results on our self-collected datasets demonstrate\nthe effectiveness in both place recognition and pose estimation tasks."
  },
  {
    "paper_no": "1866",
    "authors": "Kiatos, Marios; Koutras, Leonidas; Sarantopoulos, Iason; Doulgeri, Zoe",
    "title": "Learning a Pre-Grasp Manipulation Policy to Effectively Retrieve a Target in Dense Clutter",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1867",
    "authors": "Li, Changze; Ji, Ziheng; Qin, Tong; Yang, Ming",
    "title": "ParkingE2E: Camera-based End-to-end Parking Network, from Images to Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1868",
    "authors": "Kwon, Hyeokjin; Lee, Gunmin; Lee, Junseo; Oh, Songhwai",
    "title": "Safe CoR: A Dual-Expert Approach to Integrating Imitation Learning and Safe Reinforcement Learning through Constraint Reward",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.02245v1",
    "arxiv_abstract": "In the realm of autonomous agents, ensuring safety and reliability in complex\nand dynamic environments remains a paramount challenge. Safe reinforcement\nlearning addresses these concerns by introducing safety constraints, but still\nfaces challenges in navigating intricate environments such as complex driving\nsituations. To overcome these challenges, we present the safe constraint reward\n(Safe CoR) framework, a novel method that utilizes two types of expert\ndemonstrations$\\unicode{x2013}$reward expert demonstrations focusing on\nperformance optimization and safe expert demonstrations prioritizing safety. By\nexploiting a constraint reward (CoR), our framework guides the agent to balance\nperformance goals of reward sum with safety constraints. We test the proposed\nframework in diverse environments, including the safety gym, metadrive, and the\nreal$\\unicode{x2013}$world Jackal platform. Our proposed framework enhances the\nperformance of algorithms by $39\\%$ and reduces constraint violations by $88\\%$\non the real-world Jackal platform, demonstrating the framework's efficacy.\nThrough this innovative approach, we expect significant advancements in\nreal-world performance, leading to transformative effects in the realm of safe\nand reliable autonomous agents."
  },
  {
    "paper_no": "1869",
    "authors": "Zhou, Mengjie; Liu, Liu; Zhong, Yiran; Calway, Andrew",
    "title": "Geolocation on Cartographic Maps with Multi-Modal Fusion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1870",
    "authors": "Lee, Seungho; Lee, Hwijeong; Shim, Hyunjung",
    "title": "Learning from Spatio-temporal Correlation for Semi-Supervised LiDAR Semantic Segmentation",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.06893v1",
    "arxiv_abstract": "We address the challenges of the semi-supervised LiDAR segmentation (SSLS)\nproblem, particularly in low-budget scenarios. The two main issues in\nlow-budget SSLS are the poor-quality pseudo-labels for unlabeled data, and the\nperformance drops due to the significant imbalance between ground-truth and\npseudo-labels. This imbalance leads to a vicious training cycle. To overcome\nthese challenges, we leverage the spatio-temporal prior by recognizing the\nsubstantial overlap between temporally adjacent LiDAR scans. We propose a\nproximity-based label estimation, which generates highly accurate pseudo-labels\nfor unlabeled data by utilizing semantic consistency with adjacent labeled\ndata. Additionally, we enhance this method by progressively expanding the\npseudo-labels from the nearest unlabeled scans, which helps significantly\nreduce errors linked to dynamic classes. Additionally, we employ a dual-branch\nstructure to mitigate performance degradation caused by data imbalance.\nExperimental results demonstrate remarkable performance in low-budget settings\n(i.e., <= 5%) and meaningful improvements in normal budget settings (i.e., 5 -\n50%). Finally, our method has achieved new state-of-the-art results on\nSemanticKITTI and nuScenes in semi-supervised LiDAR segmentation. With only 5%\nlabeled data, it offers competitive results against fully-supervised\ncounterparts. Moreover, it surpasses the performance of the previous\nstate-of-the-art at 100% labeled data (75.2%) using only 20% of labeled data\n(76.0%) on nuScenes. The code is available on https://github.com/halbielee/PLE."
  },
  {
    "paper_no": "1872",
    "authors": "Wu, Bowen; Liu, Chaoran; Ishi, Carlos Toshinori; Minato, Takashi; Ishiguro, Hiroshi",
    "title": "Retargeting Human Facial Expression to Human-like Robotic Face through Neural Network Surrogate-based Optimization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1873",
    "authors": "Koga, Takayuki; Sato, Junya; Daigo, Takuya; Kimura, Kohei; Kudoh, Shunsuke",
    "title": "Fingertip Tactile Sensor for Detecting Rope Slip",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1877",
    "authors": "Xu, Wenqiang; Zheng, Dongzhe; Li, Yutong; Ren, Jieji; Lu, Cewu",
    "title": "Differentiable Fluid Physics Parameter Identification By Stirring and For Stirring",
    "arxiv_pdf": "http://arxiv.org/pdf/2311.05137v1",
    "arxiv_abstract": "Fluid interactions permeate daily human activities, with properties like\ndensity and viscosity playing pivotal roles in household tasks. While density\nestimation is straightforward through Archimedes' principle, viscosity poses a\nmore intricate challenge, especially given the varied behaviors of Newtonian\nand non-Newtonian fluids. These fluids, which differ in their stress-strain\nrelationships, are delineated by specific constitutive models such as the\nCarreau, Cross, and Herschel-Bulkley models, each possessing unique viscosity\nparameters. This study introduces a novel differentiable fitting framework,\nDiffStir, tailored to identify key physics parameters via the common daily\noperation of stirring. By employing a robotic arm for stirring and harnessing a\ndifferentiable Material Point Method (diffMPM)-based simulator, the framework\ncan determine fluid parameters by matching observations from both the simulator\nand the real world. Recognizing the distinct preferences of the aforementioned\nconstitutive models for specific fluids, an online strategy was adopted to\nadaptively select the most fitting model based on real-world data.\nAdditionally, we propose a refining neural network to bridge the sim-to-real\ngap and mitigate sensor noise-induced inaccuracies. Comprehensive experiments\nwere conducted to validate the efficacy of DiffStir, showcasing its precision\nin parameter estimation when benchmarked against reported literature values.\nMore experiments and videos can be found in the supplementary materials and on\nthe website: https://sites.google.com/view/diffstir."
  },
  {
    "paper_no": "1884",
    "authors": "Calzolari, Gabriele; Sumathy, Vidya; Kanellakis, Christoforos; Nikolakopoulos, George",
    "title": "D-MARL: A Dynamic Communication-Based Action Space Enhancement for Multi Agent Reinforcement Learning Exploration of Large Scale Unknown Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1886",
    "authors": "Cheng, Zike; Zhao, Hengwang; Shen, Qiyuan; Yan, Weihao; Wang, Chunxiang; Yang, Ming",
    "title": "MOSFormer: A Transformer-based Multi-Modal Fusion Network for Moving Object Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1887",
    "authors": "Cao, Muqing; Zhao, Jiayan; Xu, Xinhang; Xie, Lihua",
    "title": "AirCrab: A Hybrid Aerial-Ground Manipulator with An Active Wheel",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1889",
    "authors": "Bien, Seongjin; Naceri, Abdeldjallil; Figueredo, Luis; Haddadin, Sami",
    "title": "Generating Force Vectors from Projective Truncated Signed Distance Fields for Collision Avoidance and Haptic Feedback",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1890",
    "authors": "Yan, Gang; HE, Jinsong; Funabashi, Satoshi; Schmitz, Alexander; Sugano, Shigeki",
    "title": "Exploratory Motion Guided Tactile Learning for Shape-Consistent Robotic Insertion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1891",
    "authors": "Hoff, Simon Andreas; Haraldstad, Vegard; Reitan Hogstad, Bjørnar; Varagnolo, Damiano",
    "title": "Side-scan sonar based landmark detection for underwater vehicles",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1892",
    "authors": "Zheng, Xiaoji; Wu, Lixiu; Yan, Zhijie; Tang, Yuanrong; Zhao, Hao; Zhong, Chen; Chen, Bokui; Gong, Jiangtao",
    "title": "Large Language Models Powered Context-aware Motion Prediction",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.11057v3",
    "arxiv_abstract": "Motion prediction is among the most fundamental tasks in autonomous driving.\nTraditional methods of motion forecasting primarily encode vector information\nof maps and historical trajectory data of traffic participants, lacking a\ncomprehensive understanding of overall traffic semantics, which in turn affects\nthe performance of prediction tasks. In this paper, we utilized Large Language\nModels (LLMs) to enhance the global traffic context understanding for motion\nprediction tasks. We first conducted systematic prompt engineering, visualizing\ncomplex traffic environments and historical trajectory information of traffic\nparticipants into image prompts -- Transportation Context Map (TC-Map),\naccompanied by corresponding text prompts. Through this approach, we obtained\nrich traffic context information from the LLM. By integrating this information\ninto the motion prediction model, we demonstrate that such context can enhance\nthe accuracy of motion predictions. Furthermore, considering the cost\nassociated with LLMs, we propose a cost-effective deployment strategy:\nenhancing the accuracy of motion prediction tasks at scale with 0.7\\%\nLLM-augmented datasets. Our research offers valuable insights into enhancing\nthe understanding of traffic scenes of LLMs and the motion prediction\nperformance of autonomous driving. The source code is available at\n\\url{https://github.com/AIR-DISCOVER/LLM-Augmented-MTR} and\n\\url{https://aistudio.baidu.com/projectdetail/7809548}."
  },
  {
    "paper_no": "1893",
    "authors": "Yoshimura, Shunnosuke; Miki, Akihiro; Miyama, Kazuhiro; Sahara, Yuta; Kawaharazuka, Kento; Okada, Kei; Inaba, Masayuki",
    "title": "Patterned Structure Muscle : Arbitrary Shaped Wire-driven Artificial Muscle Utilizing Anisotropic Flexible Structure for Musculoskeletal Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.07682v1",
    "arxiv_abstract": "Muscles of the human body are composed of tiny actuators made up of myosin\nand actin filaments. They can exert force in various shapes such as curved or\nflat, under contact forces and deformations from the environment. On the other\nhand, muscles in musculoskeletal robots so far have faced challenges in\ngenerating force in such shapes and environments. To address this issue, we\npropose Patterned Structure Muscle (PSM), artificial muscles for\nmusculoskeletal robots. PSM utilizes patterned structures with anisotropic\ncharacteristics, wire-driven mechanisms, and is made of flexible material\nThermoplastic Polyurethane (TPU) using FDM 3D printing. This method enables the\ncreation of various shapes of muscles, such as simple 1 degree-of-freedom (DOF)\nmuscles, Multi-DOF wide area muscles, joint-covering muscles, and branched\nmuscles. We created an upper arm structure using these muscles to demonstrate\nwide range of motion, lifting heavy objects, and movements through\nenvironmental contact. These experiments show that the proposed PSM is capable\nof operating in various shapes and environments, and is suitable for the\nmuscles of musculoskeletal robots."
  },
  {
    "paper_no": "1895",
    "authors": "Eirale, Andrea; Leonetti, Matteo; Chiaberge, Marcello",
    "title": "Learning Social Cost Functions for Human-Aware Path Planning",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.10547v2",
    "arxiv_abstract": "Achieving social acceptance is one of the main goals of Social Robotic\nNavigation. Despite this topic has received increasing interest in recent\nyears, most of the research has focused on driving the robotic agent along\nobstacle-free trajectories, planning around estimates of future human motion to\nrespect personal distances and optimize navigation. However, social\ninteractions in everyday life are also dictated by norms that do not strictly\ndepend on movement, such as when standing at the end of a queue rather than\ncutting it. In this paper, we propose a novel method to recognize common social\nscenarios and modify a traditional planner's cost function to adapt to them.\nThis solution enables the robot to carry out different social navigation\nbehaviors that would not arise otherwise, maintaining the robustness of\ntraditional navigation. Our approach allows the robot to learn different social\nnorms with a single learned model, rather than having different modules for\neach task. As a proof of concept, we consider the tasks of queuing and respect\ninteraction spaces of groups of people talking to one another, but the method\ncan be extended to other human activities that do not involve motion."
  },
  {
    "paper_no": "1897",
    "authors": "Zhao, Zheyi; He, Ying; Yu, Fei; Li, Pengteng; Zhuo, Fan; Sun, Xilong",
    "title": "LLaKey: Follow My Basic Action Instructions to Your Next Key State",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1899",
    "authors": "Acerbo, Flavia Sofia; Swevers, Jan; Tuytelaars, Tinne; Tong, Son",
    "title": "Learning from Visual Demonstrations through Differentiable Nonlinear MPC for Personalized Autonomous Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1904",
    "authors": "Wang, Zhi; Wu, Xun; Wu, Xun; Dong, Li; Wenhui, Wang; Ma, Shuming; Wei, Furu",
    "title": "Kosmos-E: Learning to Follow Instruction for Robotic Grasping",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1907",
    "authors": "Luo, Xingjian; Pang, Chenglin; Wu, Xuankang; Fang, Zheng",
    "title": "ASML-VDIO: Visual-Depth-Inertial Odometry using Selected Multi-Modal Landmarks in Structural Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1908",
    "authors": "Tisnikar, Peter; Canal, Gerard; Leonetti, Matteo",
    "title": "Probabilistic Inference of Human Capabilities from Passive Observations",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1911",
    "authors": "Nakajima, Haru; Miura, Jun",
    "title": "Combining Ontological Knowledge and Large Language Model for User-Friendly Service Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.16804v1",
    "arxiv_abstract": "Lifestyle support through robotics is an increasingly promising field, with\nexpectations for robots to take over or assist with chores like floor cleaning,\ntable setting and clearing, and fetching items. The growth of AI, particularly\nfoundation models, such as large language models (LLMs) and visual language\nmodels (VLMs), is significantly shaping this sector. LLMs, by facilitating\nnatural interactions and providing vast general knowledge, are proving\ninvaluable for robotic tasks. This paper zeroes in on the benefits of LLMs for\n\"bring-me\" tasks, where robots fetch specific items for users, often based on\nvague instructions. Our previous efforts utilized an ontology extended to\nhandle environmental data to decipher such vagueness, but faced limitations\nwhen unresolvable ambiguities required user intervention for clarity. Here, we\nenhance our approach by integrating LLMs for providing additional commonsense\nknowledge, pairing it with ontological data to mitigate the issue of\nhallucinations and reduce the need for user queries, thus improving system\nusability. We present a system that merges these knowledge bases and assess its\nefficacy on \"bring-me\" tasks, aiming to provide a more seamless and efficient\nrobotic assistance experience."
  },
  {
    "paper_no": "1915",
    "authors": "Niu, Tianwei; Shuwei, Yu; Wang, Liang; Yuan, Haoyu; Wang, Shoukun; Wang, Junzheng",
    "title": "Real-time terrain assessment and Bayesian-based path planning for off-road navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1918",
    "authors": "Baumann, Nicolas; Baumgartner, Michael; Ghignone, Edoardo; Kühne, Jonas; Fischer, Tobias; Yang, Yung-Hsu; Pollefeys, Marc; Magno, Michele",
    "title": "CR3DT: Camera-RADAR Fusion for 3D Detection and Tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1919",
    "authors": "Wan, Yuxuan; zhou, kaichen; Chen, Jinhong; Dong, Hao",
    "title": "SCANet: Correcting LEGO Assembly Errors with Self-Correct Assembly Network",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1923",
    "authors": "Xie, Yihan; Lv, Weijie; Zhang, Xinyu; Chen, YiHong; Zeng, Long",
    "title": "ParametricNet+: A 6DoF Pose Estimation Network with Sparse Keypoint Recovery for Parametric Shapes in Stacked Scenarios",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1924",
    "authors": "Unger, Christoph; Hartl-Nesic, Christian; Vu, Minh Nhat; Kugi, Andreas",
    "title": "ProSIP: Probabilistic Surface Interaction Primitives for Learning of Robotic Cleaning of Edges",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1928",
    "authors": "Schwarz, Stephan Andreas; Thomas, Ulrike",
    "title": "6D Variable Virtual Fixtures for Telemanipulated Insertion Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1929",
    "authors": "Lee, Geonhyup; Lee, Joosoon; Noh, Sangjun; Ko, Minhwan; Kim, Kangmin; Lee, Kyoobin",
    "title": "PolyFit: A Peg-in-hole Assembly Framework for Unseen Polygon Shapes via Sim-to-real Adaptation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1932",
    "authors": "Naamani, Meriem Belinda; Caron, Guillaume; Morisawa, Mitsuharu; Mouaddib, El Mustapha",
    "title": "Mathematical characterization of the convergence domain for Direct Visual Servoing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1934",
    "authors": "Bezzini, Riccardo; Avizzano, Carlo Alberto; Porcini, Francesco; Filippeschi, Alessandro",
    "title": "Transparency evaluation for the Kinematic Design of the Harnesses through Human-Exoskeleton Interaction Modeling",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.18755v1",
    "arxiv_abstract": "Lower Limb Exoskeletons (LLEs) are wearable robots that provide mechanical\npower to the user. Human-exoskeleton (HE) connections must preserve the user's\nnatural behavior during the interaction, avoiding undesired forces. Therefore,\nnumerous works focus on their minimization. Given the inherent complications of\nrepeatedly prototyping and experimentally testing a device, modeling the\nexoskeleton and its physical interaction with the user emerges as a valuable\napproach for assessing the design effects. This paper proposes a novel method\nto compare different exoskeleton configurations with a flexible simulation\ntool. This approach contemplates simulating the dynamics of the device,\nincluding its interaction with the wearer, to evaluate multiple connection\nmechanism designs along with the kinematics and actuation of the LLE. This\nevaluation is based on the minimization of the interaction wrenches through an\noptimization process that includes the impedance parameters at the interfaces\nas optimization variables and the similarity of the LLE's joint variables\ntrajectories with the motion of the wearer's articulations. Exploratory tests\nare conducted using the Wearable Walker LLE in different configurations and\nmeasuring the interaction forces. Experimental data are then compared to the\noptimization outcomes, proving that the proposed method provides contact wrench\nestimations consistent with the collected measurements and previous outcomes\nfrom the literature. Copyright 2024 IEEE. Personal use of this material is\npermitted. Permission from IEEE must be obtained for all other uses, in any\ncurrent or future media, including reprinting/republishing this material for\nadvertising or promotional purposes, creating new collective works, for resale\nor redistribution to servers or lists, or reuse of any copyrighted component of\nthis work in other works."
  },
  {
    "paper_no": "1936",
    "authors": "Zhu, Keqi; Guo, Haotian; Yu, Wei; Sirag, Hassen Nigatu; Li, Tong; Dong, Huixu",
    "title": "Theoretical Modeling and Bio-inspired Trajectory Optimization of A Multiple-locomotion Origami Robot",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12471v1",
    "arxiv_abstract": "Recent research on mobile robots has focused on increasing their adaptability\nto unpredictable and unstructured environments using soft materials and\nstructures. However, the determination of key design parameters and control\nover these compliant robots are predominantly iterated through experiments,\nlacking a solid theoretical foundation. To improve their efficiency, this paper\naims to provide mathematics modeling over two locomotion, crawling and\nswimming. Specifically, a dynamic model is first devised to reveal the\ninfluence of the contact surfaces' frictional coefficients on displacements in\ndifferent motion phases. Besides, a swimming kinematics model is provided using\ncoordinate transformation, based on which, we further develop an algorithm that\nsystematically plans human-like swimming gaits, with maximum thrust obtained.\nThe proposed algorithm is highly generalizable and has the potential to be\napplied in other soft robots with multiple joints. Simulation experiments have\nbeen conducted to illustrate the effectiveness of the proposed modeling."
  },
  {
    "paper_no": "1938",
    "authors": "Radulov, Nikola; Zhang, Yuhao; Bujanca, Mihai; Ye, Ruiqi; Luján, Mikel",
    "title": "A framework for Reproducible Benchmarking and Performance Diagnosis of SLAM Systems",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.04242v1",
    "arxiv_abstract": "We propose SLAMFuse, an open-source SLAM benchmarking framework that provides\nconsistent crossplatform environments for evaluating multi-modal SLAM\nalgorithms, along with tools for data fuzzing, failure detection, and diagnosis\nacross different datasets. Our framework introduces a fuzzing mechanism to test\nthe resilience of SLAM algorithms against dataset perturbations. This enables\nthe assessment of pose estimation accuracy under varying conditions and\nidentifies critical perturbation thresholds. SLAMFuse improves diagnostics with\nfailure detection and analysis tools, examining algorithm behaviour against\ndataset characteristics. SLAMFuse uses Docker to ensure reproducible testing\nconditions across diverse datasets and systems by streamlining dependency\nmanagement. Emphasizing the importance of reproducibility and introducing\nadvanced tools for algorithm evaluation and performance diagnosis, our work\nsets a new precedent for reliable benchmarking of SLAM systems. We provide\nready-to-use docker compatible versions of the algorithms and datasets used in\nthe experiments, together with guidelines for integrating and benchmarking new\nalgorithms. Code is available at https://github.com/nikolaradulov/slamfuse"
  },
  {
    "paper_no": "1939",
    "authors": "Yokoyama, Keiko; Sueishi, Tomohiro; Inoue, Michiaki; Jin, YingJie; Hosoi, Toshinori; Ishikawa, Masatoshi",
    "title": "Toward Micro Eye Movement Detection in Practice: Stand-alone Eye Tracker with High Resolution and Wide Measurement Range",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1941",
    "authors": "Xie, Guanglei; Fu, Hao; Xue, Hanzhang; Liu, Bokai; Xu, Xin; Li, Xiaohui; Sun, Zhenping",
    "title": "M3-GMN: A Multi-environment, Multi-LiDAR, Multi-task dataset for Grid Map based Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1942",
    "authors": "Chai, Kaixin; Xu, Long; Wang, Qianhao; Xu, Chao; Gao, Fei",
    "title": "LF-3PM: a LiDAR-based Framework for Perception-aware Planning with Perturbation-induced Metric",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1943",
    "authors": "Ueda, Shiori; Hashimoto, Atsushi; Hamaya, Masashi; Tanaka, Kazutoshi; Saito, Hideo",
    "title": "Visuo-Tactile Zero-Shot Object Recognition with Vision-Language Model",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1944",
    "authors": "Li, Yulong; Zhang, Yunzhou; Zhao, Bin; Zhang, Zhiyao; Shen, You; Zhang, Tengda; Chen, Guolu",
    "title": "HSS-SLAM: Human-in-the-Loop Semantic SLAM Represented by Superquadrics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1946",
    "authors": "Xin, Shuo; Zhang, Zhen; Liu, Liang; Hou, Xiaojun; Zhu, Deye; Wang, Mengmeng; Liu, Yong",
    "title": "A Robotic-centric Paradigm for 3D Human Tracking Under Complex Environments Using Multi-modal Adaptation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1947",
    "authors": "Wu, Yuankai; Wang, Chi; Salihu, Driton; Patsch, Constantin; Zakour, Marsil; Steinbach, Eckehard",
    "title": "Rethinking 3D Geometric Object Features for Enhancing Skeleton-based Action Recognition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1948",
    "authors": "Ye, Tianyong; Xu, Wei; Cui, Yukang",
    "title": "MFCalib: Single-shot and Automatic Extrinsic Calibration for LiDAR and Camera in Targetless Environments Based on Multi-Feature Edge",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1949",
    "authors": "Dall'Alba, Diego; Naskr&#281;t, Micha&#322;; Korzeniowski, Przemyslaw; Kami&#324;ska, Sabina",
    "title": "FF-SRL: High Performance GPU-Based Surgical Simulation For Robot Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1952",
    "authors": "Yu, Jiyu; Wang, Dongqi; Chen, Zhenghan; Chen, Ci; Wu, Shuangpeng; Wang, Yue; Xiong, Rong",
    "title": "A Fast Motion and Foothold Planning Framework for Legged Robot on Discrete Terrain",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1956",
    "authors": "Valsecchi, Giorgio; Vicari, Andrea; Tischhauser, Fabian; Garabini, Manolo; Hutter, Marco",
    "title": "Accurate power consumption estimation method makes walking robots energy efficient and quiet",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1961",
    "authors": "Liu, Dingchuan; Fangfang, Yang; LIAO, Xuanhong; Lyu, Ximin",
    "title": "DIABLO: A 6-DoF Wheeled Bipedal Robot Composed Entirely of Direct-Drive Joints",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1964",
    "authors": "Boscolo Camiletto, Andrea; Bochicchio, Alfredo; Liniger, Alexander; Dai, Dengxin; Gawel, Abel Roman",
    "title": "U-BEV: Height-aware Bird's-Eye-View Segmentation and Neural Map-based Relocalization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1965",
    "authors": "Sun, Hongyang; fan, baojie; Xia, Caixia; Xu, Hongxin",
    "title": "QO-Net: Query Optimization Underwater Object Detection Network",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1966",
    "authors": "Gu, Yaru; Liu, Ze; Zou, Ting",
    "title": "Enhancing leg odometry in legged robots with learned contact bias: an LSTM recurrent neural network approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1967",
    "authors": "Hu, Jiangpeng; Yang, Fan; Nan, Fang; Hutter, Marco",
    "title": "Motion Primitives Planning For Center-Articulated Vehicles",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.17127v2",
    "arxiv_abstract": "Autonomous navigation across unstructured terrains, including forests and\nconstruction areas, faces unique challenges due to intricate obstacles and the\nelement of the unknown. Lacking pre-existing maps, these scenarios necessitate\na motion planning approach that combines agility with efficiency. Critically,\nit must also incorporate the robot's kinematic constraints to navigate more\neffectively through complex environments. This work introduces a novel planning\nmethod for center-articulated vehicles (CAV), leveraging motion primitives\nwithin a receding horizon planning framework using onboard sensing. The\napproach commences with the offline creation of motion primitives, generated\nthrough forward simulations that reflect the distinct kinematic model of\ncenter-articulated vehicles. These primitives undergo evaluation through a\nheuristic-based scoring function, facilitating the selection of the most\nsuitable path for real-time navigation. To account for disturbances, we develop\na pose-stabilizing controller, tailored to the kinematic specifications of\ncenter-articulated vehicles. During experiments, our method demonstrates a\n$67\\%$ improvement in SPL (Success Rate weighted by Path Length) performance\nover existing strategies. Furthermore, its efficacy was validated through\nreal-world experiments conducted with a tree harvester vehicle - SAHA."
  },
  {
    "paper_no": "1968",
    "authors": "Li, Jihao; Liao, Tingbo; Sirag, Hassen Nigatu; Guo, Haotian; Lu, GuoDong; Dong, Huixu",
    "title": "Under-actuated Robotic Gripper with Multiple Grasping Modes Inspired by Human Finger",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12502v1",
    "arxiv_abstract": "Under-actuated robot grippers as a pervasive tool of robots have become a\nconsiderable research focus. Despite their simplicity of mechanical design and\ncontrol strategy, they suffer from poor versatility and weak adaptability,\nmaking widespread applications limited. To better relieve relevant research\ngaps, we present a novel 3-finger linkage-based gripper that realizes\nretractable and reconfigurable multi-mode grasps driven by a single motor.\nFirstly, inspired by the changes that occurred in the contact surface with a\nhuman finger moving, we artfully design a slider-slide rail mechanism as the\nphalanx to achieve retraction of each finger, allowing for better performance\nin the enveloping grasping mode. Secondly, a reconfigurable structure is\nconstructed to broaden the grasping range of objects' dimensions for the\nproposed gripper. By adjusting the configuration and gesture of each finger,\nthe gripper can achieve five grasping modes. Thirdly, the proposed gripper is\njust actuated by a single motor, yet it can be capable of grasping and\nreconfiguring simultaneously. Finally, various experiments on grasps of\nslender, thin, and large-volume objects are implemented to evaluate the\nperformance of the proposed gripper in practical scenarios, which demonstrates\nthe excellent grasping capabilities of the gripper."
  },
  {
    "paper_no": "1969",
    "authors": "Kawano, Masaki; Uzawa, Shogo; Yamazaki, Chiaki; Nakamura, Taro",
    "title": "Development of a peristaltic flexible transfer system for&#12288;transporting feces under microgravity: Construction and validation of transport models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1973",
    "authors": "Chang, Chao-Wei; Lian, Feng-Li",
    "title": "Error-State Kalman Filter based Visual-Inertial Odometry Using Orientation Measurement on Unit Quaternion Group",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1974",
    "authors": "Wang, Yueqi; Liu, Tangyou; FENG, LICHENG; Wang, Jinze; Yang, Yang; Bao, Jianjun; Li, Binghao; Wu, Liao",
    "title": "Hardware-Based Time Synchronization for a Multi-Sensor System",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1977",
    "authors": "Chen, Zezhou; Liu, Zhaoxiang; Wang, Kai; wang, kohou; Lian, Shiguo",
    "title": "A Large Vision-Language Model based Environment Perception System for Visually Impaired People",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1978",
    "authors": "Choi, Kiyoung; Song, JunHo; Yun, WonBum; Lee, Deokjin; Oh, Sehoon",
    "title": "Identification of Flexible Joint Robot Inertia Matrix Using Frequency Response Analysis",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1979",
    "authors": "Beber, Luca; Lamon, Edoardo; Moretti, Giacomo; Fontanelli, Daniele; Saveriano, Matteo; Palopoli, Luigi",
    "title": "Towards Robotised Palpation for Cancer Detection through Online Tissue Viscoelastic Characterisation with a Collaborative Robotic Arm",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.09542v1",
    "arxiv_abstract": "This paper introduces a new method for estimating the penetration of the end\neffector and the parameters of a soft body using a collaborative robotic arm.\nThis is possible using the dimensionality reduction method that simplifies the\nHunt-Crossley model. The parameters can be found without a force sensor thanks\nto the information of the robotic arm controller. To achieve an online\nestimation, an extended Kalman filter is employed, which embeds the contact\ndynamic model. The algorithm is tested with various types of silicone,\nincluding samples with hard intrusions to simulate cancerous cells within a\nsoft tissue. The results indicate that this technique can accurately determine\nthe parameters and estimate the penetration of the end effector into the soft\nbody. These promising preliminary results demonstrate the potential for robots\nto serve as an effective tool for early-stage cancer diagnostics."
  },
  {
    "paper_no": "1983",
    "authors": "Wu, Yuwei; Tao, Yuezhan; Spasojevic, Igor; Kumar, Vijay",
    "title": "Trajectory Optimization with Global Yaw Parameterization for Field-of-View Constrained Autonomous Flight",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.17067v2",
    "arxiv_abstract": "Trajectory generation for quadrotors with limited field-of-view sensors has\nnumerous applications such as aerial exploration, coverage, inspection,\nvideography, and target tracking. Most previous works simplify the task of\noptimizing yaw trajectories by either aligning the heading of the robot with\nits velocity, or potentially restricting the feasible space of candidate\ntrajectories by using a limited yaw domain to circumvent angular singularities.\nIn this paper, we propose a novel \\textit{global} yaw parameterization method\nfor trajectory optimization that allows a 360-degree yaw variation as demanded\nby the underlying algorithm. This approach effectively bypasses inherent\nsingularities by including supplementary quadratic constraints and transforming\nthe final decision variables into the desired state representation. This method\nsignificantly reduces the needed control effort, and improves optimization\nfeasibility. Furthermore, we apply the method to several examples of different\napplications that require jointly optimizing over both the yaw and position\ntrajectories. Ultimately, we present a comprehensive numerical analysis and\nevaluation of our proposed method in both simulation and real-world\nexperiments."
  },
  {
    "paper_no": "1985",
    "authors": "de la Morena, Jesús; Redrejo López, David; Ramos, Francisco; Feliu, Vicente; Vazquez, Andres S.",
    "title": "Fractional Order Modeling and Control of Hydrogel-based Soft Pneumatic Bending Actuators",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1987",
    "authors": "Harman, Umur Ulas; Hafez, Ahmed; Duffield, Cameron; Zhao, Zihan; Dixon, Luke; Rus, Daniela; Miyashita, Shuhei",
    "title": "Wirelessly Actuated Rotation-free Magnetic Motor",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1988",
    "authors": "Yoshimitsu, Yuhei; Osa, Takayuki; Ben Amor, Heni; Ikemoto, Shuhei",
    "title": "Active Learning for Forward/Inverse Kinematics of Redundantly-driven Flexible Tensegrity Manipulator",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1989",
    "authors": "Fu, Changhong; Wang, Yiheng; Yao, Liangliang; Zheng, Guangze; Zuo, Haobo; Pan, Jia",
    "title": "TDA-Track: Prompt-Driven Temporal Domain Adaptation for Nighttime UAV Tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1990",
    "authors": "Feng, Pu; Liang, Junkang; Wang, Size; Yu, Xin; Shi, Rongye; Wu, Wenjun",
    "title": "Hierarchical Consensus-Based Multi-Agent Reinforcement Learning for Multi-Robot Cooperation Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1991",
    "authors": "Spinelli, Filippo Alberto; Egli, Pascal Arturo; Nubert, Julian; Nan, Fang; Bleumer, Thilo; Goegler, Patrick; Brockes, Stephan; Hofmann, Ferdinand; Hutter, Marco",
    "title": "Reinforcement Learning Control for Autonomous Hydraulic Material Handling Machines with Underactuated Tools",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.05093v1",
    "arxiv_abstract": "The precise and safe control of heavy material handling machines presents\nnumerous challenges due to the hard-to-model hydraulically actuated joints and\nthe need for collision-free trajectory planning with a free-swinging\nend-effector tool. In this work, we propose an RL-based controller that\ncommands the cabin joint and the arm simultaneously. It is trained in a\nsimulation combining data-driven modeling techniques with first-principles\nmodeling. On the one hand, we employ a neural network model to capture the\nhighly nonlinear dynamics of the upper carriage turn hydraulic motor,\nincorporating explicit pressure prediction to handle delays better. On the\nother hand, we model the arm as velocity-controllable and the free-swinging\nend-effector tool as a damped pendulum using first principles. This combined\nmodel enhances our simulation environment, enabling the training of RL\ncontrollers that can be directly transferred to the real machine. Designed to\nreach steady-state Cartesian targets, the RL controller learns to leverage the\nhydraulic dynamics to improve accuracy, maintain high speeds, and minimize\nend-effector tool oscillations. Our controller, tested on a mid-size prototype\nmaterial handler, is more accurate than an inexperienced operator and causes\nfewer tool oscillations. It demonstrates competitive performance even compared\nto an experienced professional driver."
  },
  {
    "paper_no": "1993",
    "authors": "Chen, Jiancheng; Yu, Chao; Wang, Huayou; Xue, Changliang; Zhan, Yifei; Liu, Kun",
    "title": "RCAL:A Lightweight Road Cognition and Automated Labeling System for Autonomous Driving Scenarios",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1995",
    "authors": "Fu, Changhong; Lei, Xiang; Zuo, Haobo; Yao, Liangliang; Zheng, Guangze; Pan, Jia",
    "title": "Progressive Representation Learning for Real-Time UAV Tracking",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.16652v1",
    "arxiv_abstract": "Visual object tracking has significantly promoted autonomous applications for\nunmanned aerial vehicles (UAVs). However, learning robust object\nrepresentations for UAV tracking is especially challenging in complex dynamic\nenvironments, when confronted with aspect ratio change and occlusion. These\nchallenges severely alter the original information of the object. To handle the\nabove issues, this work proposes a novel progressive representation learning\nframework for UAV tracking, i.e., PRL-Track. Specifically, PRL-Track is divided\ninto coarse representation learning and fine representation learning. For\ncoarse representation learning, two innovative regulators, which rely on\nappearance and semantic information, are designed to mitigate appearance\ninterference and capture semantic information. Furthermore, for fine\nrepresentation learning, a new hierarchical modeling generator is developed to\nintertwine coarse object representations. Exhaustive experiments demonstrate\nthat the proposed PRL-Track delivers exceptional performance on three\nauthoritative UAV tracking benchmarks. Real-world tests indicate that the\nproposed PRL-Track realizes superior tracking performance with 42.6 frames per\nsecond on the typical UAV platform equipped with an edge smart camera. The\ncode, model, and demo videos are available at\n\\url{https://github.com/vision4robotics/PRL-Track}."
  },
  {
    "paper_no": "1996",
    "authors": "Zhai, Shixun; Zhang, Kaige; Nan, Bo; Sun, Yanwen; fu, qianyi",
    "title": "Tube-GAN: A Novel Virtual Tube Generation Method for Unmanned Aerial Swarms Based on Generative Adversarial Network",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "1999",
    "authors": "Golani, Gautami; Turlapati, Sri Harsha; Yang, Lin; Ariffin, Mohammad; Campolo, Domenico",
    "title": "Robotic valve turning: misalignment estimation from reaction torques",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2001",
    "authors": "Zhang, Jinchang; Lu, Guoyu",
    "title": "Self-Supervised Depth Estimation Based on Camera Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2004",
    "authors": "Malka Nir, Nir; Shani, Guy; Stern, Roni",
    "title": "Online Planning for Multi Agent Path Finding in Inaccurate Maps",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2005",
    "authors": "Zuo, Haobo; Fu, Changhong; Zheng, Guangze; Yao, Liangliang; Lu, Kunhan; Pan, Jia",
    "title": "DaDiff: Domain-aware Diffusion Model for Nighttime UAV Tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2006",
    "authors": "Li, Weibing; Yang, Yang; Pan, Yongping",
    "title": "Visual Servo Control of a Conceptual Magnetically Anchored and Guided Flexible Endoscope",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2007",
    "authors": "Qiu, Tian; Zoubi, Alan; Spine, Nikolai; Cheng, Lailiang; Jiang, Yu",
    "title": "3D Branch Point Cloud Completion for Robotic Pruning in Apple Orchards",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.05953v2",
    "arxiv_abstract": "Robotic branch pruning is a significantly growing research area to cope with\nthe shortage of labor force in the context of agriculture. One fundamental\nrequirement in robotic pruning is the perception of detailed geometry and\ntopology of branches. However, the point clouds obtained in agricultural\nsettings often exhibit incompleteness due to several constraints, thereby\nrestricting the accuracy of downstream robotic pruning. In this work, we\naddressed the issue of point cloud quality through a simulation-based deep\nneural network, leveraging a Real-to-Simulation (Real2Sim) data generation\npipeline that not only eliminates the need for manual parameterization but also\nguarantees the realism of simulated data. The simulation-based neural network\nwas applied to jointly perform point cloud completion and skeletonization on\nreal-world partial branches, without additional real-world training. The\nSim2Real qualitative completion and skeletonization results showed the model's\nremarkable capability for geometry reconstruction and topology prediction.\nAdditionally, we quantitatively evaluated the Sim2Real performance by comparing\nbranch-level trait characterization errors using raw incomplete data and\ncomplete data. The Mean Absolute Error (MAE) reduced by 75% and 8% for branch\ndiameter and branch angle estimation, respectively, using the best complete\ndata, which indicates the effectiveness of the Real2Sim data in a zero-shot\ngeneralization setting. The characterization improvements contributed to the\nprecision and efficacy of robotic branch pruning."
  },
  {
    "paper_no": "2013",
    "authors": "Khorshidi, Shahram; Elnagdi, Murad; Bennewitz, Maren",
    "title": "Centroidal State Estimation based on the Koopman Embedding for Dynamic Legged Locomotion",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13366v2",
    "arxiv_abstract": "In this paper, we introduce a novel approach to centroidal state estimation,\nwhich plays a crucial role in predictive model-based control strategies for\ndynamic legged locomotion. Our approach uses the Koopman operator theory to\ntransform the robot's complex nonlinear dynamics into a linear system, by\nemploying dynamic mode decomposition and deep learning for model construction.\nWe evaluate both models on their linearization accuracy and capability to\ncapture both fast and slow dynamic system responses. We then select the most\nsuitable model for estimation purposes, and integrate it within a moving\nhorizon estimator. This estimator is formulated as a convex quadratic program\nto facilitate robust, real-time centroidal state estimation. Through extensive\nsimulation experiments on a quadruped robot executing various dynamic gaits,\nour data-driven framework outperforms conventional Extended Kalman Filtering\ntechnique based on nonlinear dynamics. Our estimator addresses challenges posed\nby force/torque measurement noise in highly dynamic motions and accurately\nrecovers the centroidal states, demonstrating the adaptability and\neffectiveness of the Koopman-based linear representation for complex locomotive\nbehaviors. Importantly, our model based on dynamic mode decomposition, trained\nwith two locomotion patterns (trot and jump), successfully estimates the\ncentroidal states for a different motion (bound) without retraining."
  },
  {
    "paper_no": "2014",
    "authors": "Wang, Yucheng; Fu, Changhong; Lu, Kunhan; Yao, Liangliang; Zuo, Haobo",
    "title": "Conditional Generative Denoiser for Nighttime UAV Tracking",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.16834v1",
    "arxiv_abstract": "State-of-the-art (SOTA) visual object tracking methods have significantly\nenhanced the autonomy of unmanned aerial vehicles (UAVs). However, in low-light\nconditions, the presence of irregular real noise from the environments severely\ndegrades the performance of these SOTA methods. Moreover, existing SOTA\ndenoising techniques often fail to meet the real-time processing requirements\nwhen deployed as plug-and-play denoisers for UAV tracking. To address this\nchallenge, this work proposes a novel conditional generative denoiser\n(CGDenoiser), which breaks free from the limitations of traditional\ndeterministic paradigms and generates the noise conditioning on the input,\nsubsequently removing it. To better align the input dimensions and accelerate\ninference, a novel nested residual Transformer conditionalizer is developed.\nFurthermore, an innovative multi-kernel conditional refiner is designed to\npertinently refine the denoised output. Extensive experiments show that\nCGDenoiser promotes the tracking precision of the SOTA tracker by 18.18\\% on\nDarkTrack2021 whereas working 5.8 times faster than the second well-performed\ndenoiser. Real-world tests with complex challenges also prove the effectiveness\nand practicality of CGDenoiser. Code, video demo and supplementary proof for\nCGDenoier are now available at:\n\\url{https://github.com/vision4robotics/CGDenoiser}."
  },
  {
    "paper_no": "2016",
    "authors": "Lenz, Christian; Menon, Rohit; Schreiber, Michael; Paul, Jacob, Melvin; Behnke, Sven; Bennewitz, Maren",
    "title": "HortiBot: An Adaptive Multi-Arm System for Robotic Horticulture of Sweet Peppers",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2018",
    "authors": "Rothfuss, Jonas; Sukhija, Bhavya; Treven, Lenart; Dorfler, Florian; Coros, Stelian; Krause, Andreas",
    "title": "Bridging the Sim-to-Real Gap with Bayesian Inference",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.16644v2",
    "arxiv_abstract": "We present SIM-FSVGD for learning robot dynamics from data. As opposed to\ntraditional methods, SIM-FSVGD leverages low-fidelity physical priors, e.g., in\nthe form of simulators, to regularize the training of neural network models.\nWhile learning accurate dynamics already in the low data regime, SIM-FSVGD\nscales and excels also when more data is available. We empirically show that\nlearning with implicit physical priors results in accurate mean model\nestimation as well as precise uncertainty quantification. We demonstrate the\neffectiveness of SIM-FSVGD in bridging the sim-to-real gap on a\nhigh-performance RC racecar system. Using model-based RL, we demonstrate a\nhighly dynamic parking maneuver with drifting, using less than half the data\ncompared to the state of the art."
  },
  {
    "paper_no": "2019",
    "authors": "Wang, Xing; Dabrowski, Joel Janek; Pinskier, Joshua; Liow, Lois; Viswanathan, VinothKumar; Scalzo, Richard; Howard, David",
    "title": "PINN-Ray: A Physics-Informed Neural Network to Model Soft Robotic Fin-Ray Fingers",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2020",
    "authors": "Xu, Zefeng; Liang, jiaqiao; Zhou, Yitong",
    "title": "Manta Ray-Inspired Soft Robotic Swimmer for High-speed and Multi-modal Swimming",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2025",
    "authors": "Jonetzko, Yannick; Naß, Theresa Alexandra Aurelia; Fiedler, Niklas; Zhang, Jianwei",
    "title": "State Estimation of an Adaptive 3-Finger Gripper using Recurrent Neural Networks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2026",
    "authors": "liu, wenjie; Shao, Yuancheng; Zhang, Yao; Chen, Zixi; Wu, Di; Chen, Yuqiao; Stefanini, Cesare; Ling, Li; Qi, Peng",
    "title": "DESectBot Design and Validation of a Novel Two-Segment Decoupled Continuum Robotic System for Endoscopic Submucosal Dissection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2027",
    "authors": "Wang, Tianyu; Lin, Haitao; Yu, Junqiu; Fu, Yanwei",
    "title": "Polaris: Open-ended Interactive Robotic Manipulation via Syn2Real Visual Grounding and Large Language Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2028",
    "authors": "Xu, Yinuo; Zhang, Xuesong",
    "title": "Depth Completion using Galerkin Attention",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2036",
    "authors": "Du, Jiayuan; Pan, Xianghui; Shen, Mengjiao; Su, Shuai; Yang, Jingwei; Liu, Chengju; Chen, Qijun",
    "title": "DVT: Decoupled Dual-Branch View Transformation for Monocular Bird's Eye View Semantic Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2038",
    "authors": "PAPATHEODOROU, ARISTOTELIS; Merkt, Wolfgang Xaver; Mitchell, Alexander Luis; Havoutis, Ioannis",
    "title": "Momentum-Aware Trajectory Optimisation using Full-Centroidal Dynamics and Implicit Inverse Kinematics",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.06074v3",
    "arxiv_abstract": "The current state-of-the-art gradient-based optimisation frameworks are able\nto produce impressive dynamic manoeuvres such as linear and rotational jumps.\nHowever, these methods, which optimise over the full rigid-body dynamics of the\nrobot, often require precise foothold locations apriori, while real-time\nperformance is not guaranteed without elaborate regularisation and tuning of\nthe cost function. In contrast, we investigate the advantages of a task-space\noptimisation framework, with special focus on acrobatic motions. Our proposed\nformulation exploits the system's high-order nonlinearities, such as the\nnonholonomy of the angular momentum, in order to produce feasible,\nhigh-acceleration manoeuvres. By leveraging the full-centroidal dynamics of the\nquadruped ANYmal C and directly optimising its footholds and contact forces,\nthe framework is capable of producing efficient motion plans with low\ncomputational overhead. Finally, we deploy our proposed framework on the ANYmal\nC platform, and demonstrate its true capabilities through real-world\nexperiments, with the successful execution of high-acceleration motions, such\nas linear and rotational jumps. Extensive analysis of these shows that the\nrobot's dynamics can be exploited to surpass its hardware limitations of having\na high mass and low-torque limits."
  },
  {
    "paper_no": "2040",
    "authors": "Wang, Shu; Han, Muzhi; Jiao, Ziyuan; Zhang, Zeyu; Wu, Ying Nian; Zhu, Song-Chun; Liu, Hangxin",
    "title": "Large Language Model-based Task and Motion Planning with Motion Failure Reasoning",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.11552v3",
    "arxiv_abstract": "Conventional Task and Motion Planning (TAMP) approaches rely on manually\ncrafted interfaces connecting symbolic task planning with continuous motion\ngeneration. These domain-specific and labor-intensive modules are limited in\naddressing emerging tasks in real-world settings. Here, we present LLM^3, a\nnovel Large Language Model (LLM)-based TAMP framework featuring a\ndomain-independent interface. Specifically, we leverage the powerful reasoning\nand planning capabilities of pre-trained LLMs to propose symbolic action\nsequences and select continuous action parameters for motion planning.\nCrucially, LLM^3 incorporates motion planning feedback through prompting,\nallowing the LLM to iteratively refine its proposals by reasoning about motion\nfailure. Consequently, LLM^3 interfaces between task planning and motion\nplanning, alleviating the intricate design process of handling domain-specific\nmessages between them. Through a series of simulations in a box-packing domain,\nwe quantitatively demonstrate the effectiveness of LLM^3 in solving TAMP\nproblems and the efficiency in selecting action parameters. Ablation studies\nunderscore the significant contribution of motion failure reasoning to the\nsuccess of LLM^3. Furthermore, we conduct qualitative experiments on a physical\nmanipulator, demonstrating the practical applicability of our approach in\nreal-world settings."
  },
  {
    "paper_no": "2042",
    "authors": "Yang, Yu Shi; fan, baojie; Jiang, yuyu; zhou, wuyang; Xu, Hongxin",
    "title": "Enhancing 3D Single Object Tracking with Efficient Point Cloud Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2047",
    "authors": "Sun, Shuo; Mielle, Malcolm; Lilienthal, Achim J.; Magnusson, Martin",
    "title": "High-Fidelity SLAM Using Gaussian Splatting with Rendering-Guided Densification and Regularized Optimization",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12535v2",
    "arxiv_abstract": "We propose a dense RGBD SLAM system based on 3D Gaussian Splatting that\nprovides metrically accurate pose tracking and visually realistic\nreconstruction. To this end, we first propose a Gaussian densification strategy\nbased on the rendering loss to map unobserved areas and refine reobserved\nareas. Second, we introduce extra regularization parameters to alleviate the\nforgetting problem in the continuous mapping problem, where parameters tend to\noverfit the latest frame and result in decreasing rendering quality for\nprevious frames. Both mapping and tracking are performed with Gaussian\nparameters by minimizing re-rendering loss in a differentiable way. Compared to\nrecent neural and concurrently developed gaussian splatting RGBD SLAM\nbaselines, our method achieves state-of-the-art results on the synthetic\ndataset Replica and competitive results on the real-world dataset TUM."
  },
  {
    "paper_no": "2053",
    "authors": "Ye, Ke; Zhou, Sanping; kang, miao; Fu, Jingwen; Zheng, Nanning",
    "title": "Vehicle Trajectory Prediction with Soft Behavior Constraints",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2056",
    "authors": "Yuan, Runze; Liu, Tao; Dai, Zijia; Zuo, Yi-Fan; Kneip, Laurent",
    "title": "EVIT: Event-based Visual-Inertial Tracking in Semi-Dense Maps Using Windowed Nonlinear Optimization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2059",
    "authors": "zhang, meiying; Peng, Weiyuan; Ding, Guangyao; Lei, Chenyang; Ji, Chunlin; HAO, QI",
    "title": "CTS: Sim-to-Real Unsupervised Domain Adaptation on 3D Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2060",
    "authors": "Yu, Haowen; Liang, Xianqi; Lyu, Ximin",
    "title": "DOB-based Wind Estimation of A UAV Using Its Onboard Sensor",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.01549v1",
    "arxiv_abstract": "Unmanned Aerial Vehicles (UAVs) play a crucial role in meteorological\nresearch, particularly in environmental wind field measurements. However,\nseveral challenges exist in current wind measurement methods using UAVs that\nneed to be addressed. Firstly, the accuracy of measurement is low, and the\nmeasurement range is limited. Secondly, the algorithms employed lack robustness\nand adaptability across different UAV platforms. Thirdly, there are limited\napproaches available for wind estimation during dynamic flight. Finally, while\nhorizontal plane measurements are feasible, vertical direction estimation is\noften missing. To tackle these challenges, we present and implement a\ncomprehensive wind estimation algorithm. Our algorithm offers several key\nfeatures, including the capability to estimate the 3-D wind vector, enabling\nwind estimation even during dynamic flight of the UAV. Furthermore, our\nalgorithm exhibits adaptability across various UAV platforms. Experimental\nresults in the wind tunnel validate the effectiveness of our algorithm,\nshowcasing improvements such as wind speed accuracy of $0.11$ m/s and wind\ndirection errors of less than $2.8^\\circ$. Additionally, our approach extends\nthe measurement range to $10$ m/s."
  },
  {
    "paper_no": "2061",
    "authors": "Cui, Bo; Cui, Rongxin; Yan, Weisheng; Wang, Y.K; zhang, shi",
    "title": "RT-RRT: Reverse Tree Guided Real-Time Path Planning/Replanning in Unpredictable Dynamic Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2062",
    "authors": "Shen, Hongming; Wu, Zhenyu; Wang, Wei; Lyu, Qiyang; Zhou, Huiqin; Wang, Danwei",
    "title": "IDF-MFL: Infrastructure-free and Drift-free Magnetic Field Localization for Mobile Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2065",
    "authors": "Hu, Yunze; Yang, Xuru; Zhou, Kangjie; Liu, Qinghang; Ding, Kang; Gao, Han; Zhu, Pingping; Liu, Chang",
    "title": "SwarmPRM: Probabilistic Roadmap Motion Planning for Large-Scale Swarm Robotic Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2067",
    "authors": "Mock, Alexander; Wiemann, Thomas; Pütz, Sebastian; Hertzberg, Joachim",
    "title": "MICP-L: Mesh-based ICP for Robot Localization using Hardware-Accelerated Ray Casting",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2071",
    "authors": "Hickert, Cameron; Yan, Zhongxia; Wu, Cathy",
    "title": "A Data-Informed Analysis of Scalable Supervision for Safety in Autonomous Vehicle Fleets",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.09500v1",
    "arxiv_abstract": "Autonomous driving is a highly anticipated approach toward eliminating\nroadway fatalities. At the same time, the bar for safety is both high and\ncostly to verify. This work considers the role of remotely-located human\noperators supervising a fleet of autonomous vehicles (AVs) for safety. Such a\n'scalable supervision' concept was previously proposed to bridge the gap\nbetween still-maturing autonomy technology and the pressure to begin commercial\nofferings of autonomous driving. The present article proposes DISCES, a\nframework for Data-Informed Safety-Critical Event Simulation, to investigate\nthe practicality of this concept from a dynamic network loading standpoint.\nWith a focus on the safety-critical context of AVs merging into mixed-autonomy\ntraffic, vehicular arrival processes at 1,097 highway merge points are modeled\nusing microscopic traffic reconstruction with historical data from interstates\nacross three California counties. Combined with a queuing theoretic model,\nthese results characterize the dynamic supervision requirements and thereby\nscalability of the teleoperation approach. Across all scenarios we find\nreductions in operator requirements greater than 99% as compared to in-vehicle\nsupervisors for the time period analyzed. The work also demonstrates two\nmethods for reducing these empirical supervision requirements: (i) the use of\ncooperative connected AVs -- which are shown to produce an average 3.67\norders-of-magnitude system reliability improvement across the scenarios studied\n-- and (ii) aggregation across larger regions."
  },
  {
    "paper_no": "2073",
    "authors": "Cheng, Hao; Cao, Jiahang; Xiao, Erjia; Sun, Mengshu; Xu, Renjing",
    "title": "Gaining the Sparse Rewards by Exploring Lottery Tickets in Spiking Neural Network",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.13302v4",
    "arxiv_abstract": "Deploying energy-efficient deep learning algorithms on computational-limited\ndevices, such as robots, is still a pressing issue for real-world applications.\nSpiking Neural Networks (SNNs), a novel brain-inspired algorithm, offer a\npromising solution due to their low-latency and low-energy properties over\ntraditional Artificial Neural Networks (ANNs). Despite their advantages, the\ndense structure of deep SNNs can still result in extra energy consumption. The\nLottery Ticket Hypothesis (LTH) posits that within dense neural networks, there\nexist winning Lottery Tickets (LTs), namely sub-networks, that can be obtained\nwithout compromising performance. Inspired by this, this paper delves into the\nspiking-based LTs (SLTs), examining their unique properties and potential for\nextreme efficiency. Then, two significant sparse \\textbf{\\textit{Rewards}} are\ngained through comprehensive explorations and meticulous experiments on SLTs\nacross various dense structures. Moreover, a sparse algorithm tailored for\nspiking transformer structure, which incorporates convolution operations into\nthe Patch Embedding Projection (ConvPEP) module, has been proposed to achieve\nMulti-level Sparsity (MultiSp). MultiSp refers to (1) Patch number sparsity;\n(2) ConvPEP weights sparsity and binarization; and (3) ConvPEP activation layer\nbinarization. Extensive experiments demonstrate that our method achieves\nextreme sparsity with only a slight performance decrease, paving the way for\ndeploying energy-efficient neural networks in robotics and beyond."
  },
  {
    "paper_no": "2076",
    "authors": "Sahara, Yuta; Miki, Akihiro; Ribayashi, Yoshimoto; Yoshimura, Shunnosuke; Kawaharazuka, Kento; Okada, Kei; Inaba, Masayuki",
    "title": "Construction of Musculoskeletal Simulation for Shoulder Complex with Ligaments and Its Validation via Model Predictive Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.05931v1",
    "arxiv_abstract": "The complex ways in which humans utilize their bodies in sports and martial\narts are remarkable, and human motion analysis is one of the most effective\ntools for robot body design and control. On the other hand, motion analysis is\nnot easy, and it is difficult to measure complex body motions in detail due to\nthe influence of numerous muscles and soft tissues, mainly ligaments. In\nresponse, various musculoskeletal simulators have been developed and applied to\nmotion analysis and robotics. However, none of them reproduce the ligaments but\nonly the muscles, nor do they focus on the shoulder complex, including the\nclavicle and scapula, which is one of the most complex parts of the body.\nTherefore, in this study, a detailed simulation model of the shoulder complex\nincluding ligaments is constructed. The model will mimic not only the skeletal\nstructure and muscle arrangement but also the ligament arrangement and maximum\nmuscle strength. Through model predictive control based on the constructed\nsimulation, we confirmed that the ligaments contribute to joint stabilization\nin the first movement and that the proper distribution of maximum muscle force\ncontributes to the equalization of the load on each muscle, demonstrating the\neffectiveness of this simulation."
  },
  {
    "paper_no": "2077",
    "authors": "Gomez Andreu, Mario Alejandro; Ploeger, Kai; Peters, Jan",
    "title": "Beyond the Cascade: Juggling Vanilla Siteswap Patterns",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.19591v1",
    "arxiv_abstract": "Being widespread in human motor behavior, dynamic movements demonstrate\nhigher efficiency and greater capacity to address a broader range of skill\ndomains compared to their quasi-static counterparts. Among the frequently\nstudied dynamic manipulation problems, robotic juggling tasks stand out due to\ntheir inherent ability to scale their difficulty levels to arbitrary extents,\nmaking them an excellent subject for investigation. In this study, we explore\njuggling patterns with mixed throw heights, following the vanilla siteswap\njuggling notation, which jugglers widely adopted to describe toss juggling\npatterns. This requires extending our previous analysis of the simpler cascade\njuggling task by a throw-height sequence planner and further constraints on the\nend effector trajectory. These are not necessary for cascade patterns but are\nvital to achieving patterns with mixed throw heights. Using a simulated\nenvironment, we demonstrate successful juggling of most common 3-9 ball\nsiteswap patterns up to 9 ball height, transitions between these patterns, and\nrandom sequences covering all possible vanilla siteswap patterns with throws\nbetween 2 and 9 ball height. https://kai-ploeger.com/beyond-cascades"
  },
  {
    "paper_no": "2079",
    "authors": "Capraru, Richard; Lupu, Emil Constantin; Demetriou, Soteris; Wang, Jian-Gang; Soong, Boon Hee",
    "title": "Rain-Reaper: Unmasking LiDAR-based Detector Vulnerabilities in Rain",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2080",
    "authors": "Bai, Ruofei; Yuan, Shenghai; Guo, Hongliang; Yin, Pengyu; Yau, Wei-Yun; Xie, Lihua",
    "title": "Collaborative Graph Exploration with Reduced Pose-SLAM Uncertainty via Submodular Optimization",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.01013v1",
    "arxiv_abstract": "This paper considers the collaborative graph exploration problem in\nGPS-denied environments, where a group of robots are required to cover a graph\nenvironment while maintaining reliable pose estimations in collaborative\nsimultaneous localization and mapping (SLAM). Considering both objectives\npresents challenges for multi-robot pathfinding, as it involves the expensive\ncovariance inference for SLAM uncertainty evaluation, especially considering\nvarious combinations of robots' paths. To reduce the computational complexity,\nwe propose an efficient two-stage strategy where exploration paths are first\ngenerated for quick coverage, and then enhanced by adding informative and\ndistance-efficient loop-closing actions, called loop edges, along the paths for\nreliable pose estimation. We formulate the latter problem as a non-monotone\nsubmodular maximization problem by relating SLAM uncertainty with pose graph\ntopology, which (1) facilitates more efficient evaluation of SLAM uncertainty\nthan covariance inference, and (2) allows the application of approximation\nalgorithms in submodular optimization to provide optimality guarantees. We\nfurther introduce the ordering heuristics to improve objective values while\npreserving the optimality bound. Simulation experiments over randomly generated\ngraph environments verify the efficiency of our methods in finding paths for\nquick coverage and enhanced pose graph reliability, and benchmark the\nperformance of the approximation algorithms and the greedy-based algorithm in\nthe loop edge selection problem. Our implementations will be open-source at\nhttps://github.com/bairuofei/CGE."
  },
  {
    "paper_no": "2081",
    "authors": "Wakamatsu, Hiroyuki; Kobayashi, Ibuki; Nagase, Yuya; Kato, Ryu; Mukai, Masaya",
    "title": "Development of five-finger hand-type robotic forceps for laparoscopic gastrointestinal surgery",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2082",
    "authors": "Wang, Peng; Guo, Zhihao; Sait, Abdul Latheef; Pham, Minh Huy",
    "title": "Robot Shape and Location Retention in Video Generation Using Diffusion Models",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.02873v1",
    "arxiv_abstract": "Diffusion models have marked a significant milestone in the enhancement of\nimage and video generation technologies. However, generating videos that\nprecisely retain the shape and location of moving objects such as robots\nremains a challenge. This paper presents diffusion models specifically tailored\nto generate videos that accurately maintain the shape and location of mobile\nrobots. This development offers substantial benefits to those working on\ndetecting dangerous interactions between humans and robots by facilitating the\ncreation of training data for collision detection models, circumventing the\nneed for collecting data from the real world, which often involves legal and\nethical issues. Our models incorporate techniques such as embedding accessible\nrobot pose information and applying semantic mask regulation within the\nConvNext backbone network. These techniques are designed to refine intermediate\noutputs, therefore improving the retention performance of shape and location.\nThrough extensive experimentation, our models have demonstrated notable\nimprovements in maintaining the shape and location of different robots, as well\nas enhancing overall video generation quality, compared to the benchmark\ndiffusion model. Codes will be opensourced at\n\\href{https://github.com/PengPaulWang/diffusion-robots}{Github}."
  },
  {
    "paper_no": "2084",
    "authors": "Bäuml, Berthold; Kasolowsky, Ulf",
    "title": "Fine Manipulation Using a Tactile Skin: Learning in Simulation and Sim-to-Real Transfer",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.12735v1",
    "arxiv_abstract": "We want to enable fine manipulation with a multi-fingered robotic hand by\nusing modern deep reinforcement learning methods. Key for fine manipulation is\na spatially resolved tactile sensor. Here, we present a novel model of a\ntactile skin that can be used together with rigid-body (hence fast) physics\nsimulators. The model considers the softness of the real fingertips such that a\ncontact can spread across multiple taxels of the sensor depending on the\ncontact geometry. We calibrate the model parameters to allow for an accurate\nsimulation of the real-world sensor. For this, we present a self-contained\ncalibration method without external tools or sensors. To demonstrate the\nvalidity of our approach, we learn two challenging fine manipulation tasks:\nRolling a marble and a bolt between two fingers. We show in simulation\nexperiments that tactile feedback is crucial for precise manipulation and\nreaching sub-taxel resolution of < 1 mm (despite a taxel spacing of 4 mm).\nMoreover, we demonstrate that all policies successfully transfer from the\nsimulation to the real robotic hand."
  },
  {
    "paper_no": "2085",
    "authors": "Wilhelm, Aaron; Wilhelm, Andrew; Calderón-Aceituno, Lydia Isabela; Napp, Nils; Petersen, Kirstin Hagelskjaer; Helbling, E. Farrell",
    "title": "Frozen Assets: Leveraging Ice, Water, and Phase Transitions in Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2090",
    "authors": "Yang, Jun; Yao, Jian; Waslander, Steven Lake",
    "title": "Active Pose Refinement for Textureless Shiny Objects using the Structured Light Camera",
    "arxiv_pdf": "http://arxiv.org/pdf/2308.14665v1",
    "arxiv_abstract": "6D pose estimation of textureless shiny objects has become an essential\nproblem in many robotic applications. Many pose estimators require high-quality\ndepth data, often measured by structured light cameras. However, when objects\nhave shiny surfaces (e.g., metal parts), these cameras fail to sense complete\ndepths from a single viewpoint due to the specular reflection, resulting in a\nsignificant drop in the final pose accuracy. To mitigate this issue, we present\na complete active vision framework for 6D object pose refinement and\nnext-best-view prediction. Specifically, we first develop an optimization-based\npose refinement module for the structured light camera. Our system then selects\nthe next best camera viewpoint to collect depth measurements by minimizing the\npredicted uncertainty of the object pose. Compared to previous approaches, we\nadditionally predict measurement uncertainties of future viewpoints by online\nrendering, which significantly improves the next-best-view prediction\nperformance. We test our approach on the challenging real-world ROBI dataset.\nThe results demonstrate that our pose refinement method outperforms the\ntraditional ICP-based approach when given the same input depth data, and our\nnext-best-view strategy can achieve high object pose accuracy with\nsignificantly fewer viewpoints than the heuristic-based policies."
  },
  {
    "paper_no": "2091",
    "authors": "Ren, Qiuyu; Yu, Huan; Dai, Jiajun; Zheng, Zhi; Meng, Jun; Xu, Li; Xu, Chao; Gao, Fei; Cao, Yanjun",
    "title": "Intention-Aware Planner for Robust and Safe Aerial Tracking",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.08854v4",
    "arxiv_abstract": "Autonomous target tracking with quadrotors has wide applications in many\nscenarios, such as cinematographic follow-up shooting or suspect chasing.\nTarget motion prediction is necessary when designing the tracking planner.\nHowever, the widely used constant velocity or constant rotation assumption can\nnot fully capture the dynamics of the target. The tracker may fail when the\ntarget happens to move aggressively, such as sudden turn or deceleration. In\nthis paper, we propose an intention-aware planner by additionally considering\nthe intention of the target to enhance safety and robustness in aerial tracking\napplications. Firstly, a designated intention prediction method is proposed,\nwhich combines a user-defined potential assessment function and a state\nobservation function. A reachable region is generated to specifically evaluate\nthe turning intentions. Then we design an intention-driven hybrid A* method to\npredict the future possible positions for the target. Finally, an\nintention-aware optimization approach is designed to generate a\nspatial-temporal optimal trajectory, allowing the tracker to perceive\nunexpected situations from the target. Benchmark comparisons and real-world\nexperiments are conducted to validate the performance of our method."
  },
  {
    "paper_no": "2093",
    "authors": "MARTIN, Claire; Duriez, Christian; Courtecuisse, Hadrien",
    "title": "High Rate Mechanical Coupling of Interacting Objects in the Context of Needle Insertion Simulation With Haptic Feedback",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2094",
    "authors": "Casseau, Benoit; Chebrolu, Nived; Mattamala, Matias; Freißmuth, Leonard; Fallon, Maurice",
    "title": "Markerless Aerial-Terrestrial Co-Registration of Forest Point Clouds using a Deformable Pose Graph",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.09896v1",
    "arxiv_abstract": "For biodiversity and forestry applications, end-users desire maps of forests\nthat are fully detailed, from the forest floor to the canopy. Terrestrial laser\nscanning and aerial laser scanning are accurate and increasingly mature methods\nfor scanning the forest. However, individually they are not able to estimate\nattributes such as tree height, trunk diameter and canopy density due to the\ninherent differences in their field-of-view and mapping processes. In this\nwork, we present a pipeline that can automatically generate a single joint\nterrestrial and aerial forest reconstruction. The novelty of the approach is a\nmarker-free registration pipeline, which estimates a set of relative\ntransformation constraints between the aerial cloud and terrestrial sub-clouds\nwithout requiring any co-registration reflective markers to be physically\nplaced in the scene. Our method then uses these constraints in a pose graph\nformulation, which enables us to finely align the respective clouds while\nrespecting spatial constraints introduced by the terrestrial SLAM scanning\nprocess. We demonstrate that our approach can produce a fine-grained and\ncomplete reconstruction of large-scale natural environments, enabling\nmulti-platform data capture for forestry applications without requiring\nexternal infrastructure."
  },
  {
    "paper_no": "2095",
    "authors": "Dong, Zhipeng; Fu, Mengyin; Liang, Hao; Zhu, Chunhui; Yang, Yi",
    "title": "DSVT: Dynamic 3D Surround View for Tractor-Trailer Vehicles Based on Real-Time Pose Estimation with Drop Model",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2099",
    "authors": "Bartsch, Alison; Car, Arvind; Avra, Charlotte; Barati Farimani, Amir",
    "title": "SculptDiff: Learning Robotic Clay Sculpting from Humans with Goal Conditioned Diffusion Policy",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2103",
    "authors": "Wen, Jiaixiao; Liu, Qiong",
    "title": "Synthetic Dataset Using Diffusion Model for Pixel-Level Dense Pose Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2104",
    "authors": "Hallgarten, Marcel; Zapata Manjarres, Julian Jose; Stoll, Martin; Renz, Katrin; Zell, Andreas",
    "title": "Can Vehicle Motion Planning Generalize to Realistic Long-tail Scenarios?",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.07569v2",
    "arxiv_abstract": "Real-world autonomous driving systems must make safe decisions in the face of\nrare and diverse traffic scenarios. Current state-of-the-art planners are\nmostly evaluated on real-world datasets like nuScenes (open-loop) or nuPlan\n(closed-loop). In particular, nuPlan seems to be an expressive evaluation\nmethod since it is based on real-world data and closed-loop, yet it mostly\ncovers basic driving scenarios. This makes it difficult to judge a planner's\ncapabilities to generalize to rarely-seen situations. Therefore, we propose a\nnovel closed-loop benchmark interPlan containing several edge cases and\nchallenging driving scenarios. We assess existing state-of-the-art planners on\nour benchmark and show that neither rule-based nor learning-based planners can\nsafely navigate the interPlan scenarios. A recently evolving direction is the\nusage of foundation models like large language models (LLM) to handle\ngeneralization. We evaluate an LLM-only planner and introduce a novel hybrid\nplanner that combines an LLM-based behavior planner with a rule-based motion\nplanner that achieves state-of-the-art performance on our benchmark."
  },
  {
    "paper_no": "2108",
    "authors": "Chandio, Yasra; Khan, Momin Ahmad; Selialia, Khotso; Garcia, Luis Antonio; DeGol, Joseph; Anwar, Fatima M",
    "title": "A Neurosymbolic Approach to Adaptive Feature Extraction in SLAM",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.06889v3",
    "arxiv_abstract": "Autonomous robots, autonomous vehicles, and humans wearing mixed-reality\nheadsets require accurate and reliable tracking services for safety-critical\napplications in dynamically changing real-world environments. However, the\nexisting tracking approaches, such as Simultaneous Localization and Mapping\n(SLAM), do not adapt well to environmental changes and boundary conditions\ndespite extensive manual tuning. On the other hand, while deep learning-based\napproaches can better adapt to environmental changes, they typically demand\nsubstantial data for training and often lack flexibility in adapting to new\ndomains. To solve this problem, we propose leveraging the neurosymbolic program\nsynthesis approach to construct adaptable SLAM pipelines that integrate the\ndomain knowledge from traditional SLAM approaches while leveraging data to\nlearn complex relationships. While the approach can synthesize end-to-end SLAM\npipelines, we focus on synthesizing the feature extraction module. We first\ndevise a domain-specific language (DSL) that can encapsulate domain knowledge\non the important attributes for feature extraction and the real-world\nperformance of various feature extractors. Our neurosymbolic architecture then\nundertakes adaptive feature extraction, optimizing parameters via learning\nwhile employing symbolic reasoning to select the most suitable feature\nextractor. Our evaluations demonstrate that our approach, neurosymbolic Feature\nEXtraction (nFEX), yields higher-quality features. It also reduces the pose\nerror observed for the state-of-the-art baseline feature extractors ORB and\nSIFT by up to 90% and up to 66%, respectively, thereby enhancing the system's\nefficiency and adaptability to novel environments."
  },
  {
    "paper_no": "2111",
    "authors": "Pathre, Pranjali; Gupta, Gunjan; Qureshi, Mohammad Nomaan; Mandyam, Brunda; Brahmbhatt, Samarth Manoj; Krishna, Madhava",
    "title": "Imagine2Servo: Intelligent Visual Servoing with Diffusion-Driven Goal Generation for Robotic Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2115",
    "authors": "xia, zihao; fan, baojie; Wang, Zhiquan; Ai, Jiajun",
    "title": "SDTrack:Spatially decoupled tracker for visual tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2116",
    "authors": "Sutoh, Masataku; Hirano, Daichi; Inazawa, Mariko; Kawai, Yuta; SAWADA, HIROTAKA",
    "title": "Mobility Performance Characterization of Transformable Nano Rover for Lunar Exploration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2117",
    "authors": "Zhang, Zhiyong; Singh, Hanumant; Jiang, Huaizu",
    "title": "NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2119",
    "authors": "Mainardi, Vanessa; Carletti, Laura; Tsiakmakis, Dimitrios; Dal Canto, Marco; Mellilo, Tommaso; Noferi, Stefano; Bagnoni, Giovanni; Rubegni, Pietro; Ciuti, Gastone",
    "title": "A non-invasive device for skin cancer diagnosis: first clinical evidence with spectroscopic data enhanced by Machine Learning algorithms",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2120",
    "authors": "Tanneberg, Daniel; Ocker, Felix; Hasler, Stephan; Deigmoeller, Joerg; Belardinelli, Anna; Wang, Chao; Wersing, Heiko; Sendhoff, Bernhard; Gienger, Michael",
    "title": "To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12533v2",
    "arxiv_abstract": "How can a robot provide unobtrusive physical support within a group of\nhumans? We present Attentive Support, a novel interaction concept for robots to\nsupport a group of humans. It combines scene perception, dialogue acquisition,\nsituation understanding, and behavior generation with the common-sense\nreasoning capabilities of Large Language Models (LLMs). In addition to\nfollowing user instructions, Attentive Support is capable of deciding when and\nhow to support the humans, and when to remain silent to not disturb the group.\nWith a diverse set of scenarios, we show and evaluate the robot's attentive\nbehavior, which supports and helps the humans when required, while not\ndisturbing if no help is needed."
  },
  {
    "paper_no": "2122",
    "authors": "Li, Qing; HU, SHAOPENG; Shimasaki, Kohei; Ishii, Idaku",
    "title": "An Ultrafast Multi-object Zooming System Based on Low-latency Stereo Correspondence",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2124",
    "authors": "Freund, Janis Eric; Phiquepal, Camille; Orthey, Andreas; Toussaint, Marc",
    "title": "Camera-Based Belief Space Planning in Discrete Partially-Observable Domains",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.10672v1",
    "arxiv_abstract": "Robots often have to operate in discrete partially observable worlds, where\nthe states of world are only observable at runtime. To react to different world\nstates, robots need contingencies. However, computing contingencies is costly\nand often non-optimal. To address this problem, we develop the improved path\ntree optimization (PTO) method. PTO computes motion contingencies by\nconstructing a tree of motion paths in belief space. This is achieved by\nconstructing a graph of configurations, then adding observation edges to extend\nthe graph to belief space. Afterwards, we use a dynamic programming step to\nextract the path tree. PTO extends prior work by adding a camera-based state\nsampler to improve the search for observation points. We also add support to\nnon-euclidean state spaces, provide an implementation in the open motion\nplanning library (OMPL), and evaluate PTO on four realistic scenarios with a\nvirtual camera in up to 10-dimensional state spaces. We compare PTO with a\ndefault and with the new camera-based state sampler. The results indicate that\nthe camera-based state sampler improves success rates in 3 out of 4 scenarios\nwhile having a significant lower memory footprint. This makes PTO an important\ncontribution to advance the state-of-the-art for discrete belief space\nplanning."
  },
  {
    "paper_no": "2126",
    "authors": "Prutsch, Alexander; Bischof, Horst; Possegger, Horst",
    "title": "Efficient Motion Prediction: A Lightweight & Accurate Trajectory Prediction Model With Fast Training and Inference Speed",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.16154v2",
    "arxiv_abstract": "For efficient and safe autonomous driving, it is essential that autonomous\nvehicles can predict the motion of other traffic agents. While highly accurate,\ncurrent motion prediction models often impose significant challenges in terms\nof training resource requirements and deployment on embedded hardware. We\npropose a new efficient motion prediction model, which achieves highly\ncompetitive benchmark results while training only a few hours on a single GPU.\nDue to our lightweight architectural choices and the focus on reducing the\nrequired training resources, our model can easily be applied to custom\ndatasets. Furthermore, its low inference latency makes it particularly suitable\nfor deployment in autonomous applications with limited computing resources."
  },
  {
    "paper_no": "2128",
    "authors": "Zhou, Zhenning; Zhou, Lei; Sun, Shengxin; Ang Jr, Marcelo H",
    "title": "A Robust and Efficient Robotic Packing Pipeline with Dissipativity-Based Adaptive Impedance-Force Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2130",
    "authors": "Rodríguez-Martínez, Sebastián; Troni, Giancarlo",
    "title": "MAGYC: A Factor Graph Based Method using Angular Rate Measurements for Full Three-Axis Magnetometer and Gyroscope Bias Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2132",
    "authors": "Wang, Wei-Ren; Do, You-Sheng; Lin, Wen-Chieh; Wang, Chieh-Chih",
    "title": "Enhancing LiDAR Scene Upsampling with Instance-aware Feature-embedding and Attention Mechanism",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2137",
    "authors": "Hu, Naiwen; Cheng, Haozhe; Xie, Yifan; Shi, Pengcheng; Zhu, Jihua",
    "title": "Hyperbolic Image-and-Pointcloud Contrastive Learning for 3D Classification",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.15810v1",
    "arxiv_abstract": "3D contrastive representation learning has exhibited remarkable efficacy\nacross various downstream tasks. However, existing contrastive learning\nparadigms based on cosine similarity fail to deeply explore the potential\nintra-modal hierarchical and cross-modal semantic correlations about\nmulti-modal data in Euclidean space. In response, we seek solutions in\nhyperbolic space and propose a hyperbolic image-and-pointcloud contrastive\nlearning method (HyperIPC). For the intra-modal branch, we rely on the\nintrinsic geometric structure to explore the hyperbolic embedding\nrepresentation of point cloud to capture invariant features. For the\ncross-modal branch, we leverage images to guide the point cloud in establishing\nstrong semantic hierarchical correlations. Empirical experiments underscore the\noutstanding classification performance of HyperIPC. Notably, HyperIPC enhances\nobject classification results by 2.8% and few-shot classification outcomes by\n5.9% on ScanObjectNN compared to the baseline. Furthermore, ablation studies\nand confirmatory testing validate the rationality of HyperIPC's parameter\nsettings and the effectiveness of its submodules."
  },
  {
    "paper_no": "2138",
    "authors": "Habekost, Jan-Gerrit; Gäde, Connor; Allgeuer, Philipp; Wermter, Stefan",
    "title": "Inverse Kinematics for Neuro-Robotic Grasping with Humanoid Embodied Agents",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.08825v2",
    "arxiv_abstract": "This paper introduces a novel zero-shot motion planning method that allows\nusers to quickly design smooth robot motions in Cartesian space. A B\\'ezier\ncurve-based Cartesian plan is transformed into a joint space trajectory by our\nneuro-inspired inverse kinematics (IK) method CycleIK, for which we enable\nplatform independence by scaling it to arbitrary robot designs. The motion\nplanner is evaluated on the physical hardware of the two humanoid robots NICO\nand NICOL in a human-in-the-loop grasping scenario. Our method is deployed with\nan embodied agent that is a large language model (LLM) at its core. We\ngeneralize the embodied agent, that was introduced for NICOL, to also embody\nNICO. The agent can execute a discrete set of physical actions and allows the\nuser to verbally instruct various different robots. We contribute a grasping\nprimitive to its action space that allows for precise manipulation of household\nobjects. The updated CycleIK method is compared to popular numerical IK solvers\nand state-of-the-art neural IK methods in simulation and is shown to be\ncompetitive with or outperform all evaluated methods when the algorithm runtime\nis very short. The grasping primitive is evaluated on both NICOL and NICO\nrobots with a reported grasp success of 72% to 82% for each robot,\nrespectively."
  },
  {
    "paper_no": "2143",
    "authors": "ZHANG, Tinghua; Yuan, Sishen; Xu, Chao; Liu, Peng; Ren, Hongliang; Yuan, Wu",
    "title": "Towards Electricity-free Pneumatic Miniature Rotation Actuator for Optical Coherence Tomography Endoscopy",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2148",
    "authors": "Khan, Mariia; QIU, YUE; Cong, Yuren; Rosenhahn, Bodo; Suter, David; Abu-Khalaf, Jumana",
    "title": "Indoor Scene Change Understanding (SCU): Segment, Describe, and Revert Any Change",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2155",
    "authors": "Semeraro, Francesco; Carberry, Jon; Leadbetter, James Hugo; Cangelosi, Angelo",
    "title": "Good Things Always Come in Threes: How Robot Responsiveness Affects Workload and Trust in Non-Dyadic Human-Robot Collaboration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2159",
    "authors": "Canzini, Ethan; Pope, Simon A.; Tiwari, Ashutosh",
    "title": "Generating Continuous Paths On Learned Constraint Manifolds Using Policy Search",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2162",
    "authors": "Du, Yipai; Zhou, Pokuang; Wang, Michael Yu; Lian, Wenzhao; She, Yu",
    "title": "Stick Roller: Precise In-hand Stick Rolling with a Sample-Efficient Tactile Model",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2166",
    "authors": "Wang, Peiyi; Feliu, Daniel; Guo, Sheng; Renda, Federico; Laschi, Cecilia",
    "title": "Strain-based Modeling of Rod-driven Soft Continuum Robots with Co-located Embedded Sensors",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2167",
    "authors": "Suppaadirek, Natchanon; Sonnic, Maximilien; Duran Jimenez, Raul Ariel; Shibata, Tomohiro",
    "title": "Design and Development of a Work Cell with a One-Handed Soldering Tool for Enhanced Human-Robot Collaboration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2168",
    "authors": "Zhou, Junbao; Mei, Jilin; Wu, Pengze; Chen, Liang; Zhao, Fangzhou; Zhao, Xijun; Hu, Yu",
    "title": "TeFF: Tracking-enhanced Forgetting-free Few-shot 3D LiDAR Semantic Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2171",
    "authors": "Mohammadi Kashani, Mahya; John, Tobias; Coffelt, Jeremy Paul; Johnsen, Einar Broch; Wasowski, Andrzej",
    "title": "Risk-Averse Planning and Plan Assessment for Marine Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.01018v1",
    "arxiv_abstract": "Autonomous Underwater Vehicles (AUVs) need to operate for days without human\nintervention and thus must be able to do efficient and reliable task planning.\nUnfortunately, efficient task planning requires deliberately abstract domain\nmodels (for scalability reasons), which in practice leads to plans that might\nbe unreliable or under performing in practice. An optimal abstract plan may\nturn out suboptimal or unreliable during physical execution. To overcome this,\nwe introduce a method that first generates a selection of diverse high-level\nplans and then assesses them in a low-level simulation to select the optimal\nand most reliable candidate. We evaluate the method using a realistic\nunderwater robot simulation, estimating the risk metrics for different\nscenarios, demonstrating feasibility and effectiveness of the approach."
  },
  {
    "paper_no": "2173",
    "authors": "Shahriari, Erfan; Peper, Kim Kristin; Hoffmann, Matej; Haddadin, Sami",
    "title": "Enhancing Robustness in Manipulability Assessment: The Pseudo-Ellipsoid Approach",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.18869v1",
    "arxiv_abstract": "Manipulability analysis is a methodology employed to assess the capacity of\nan articulated system, at a specific configuration, to produce motion or exert\nforce in diverse directions. The conventional method entails generating a\nvirtual ellipsoid using the system's configuration and model. Yet, this\napproach poses challenges when applied to systems such as the human body, where\ndirect access to such information is limited, necessitating reliance on\nestimations. Any inaccuracies in these estimations can distort the ellipsoid's\nconfiguration, potentially compromising the accuracy of the manipulability\nassessment. To address this issue, this article extends the standard approach\nby introducing the concept of the manipulability pseudo-ellipsoid. Through a\nseries of theoretical analyses, simulations, and experiments, the article\ndemonstrates that the proposed method exhibits reduced sensitivity to noise in\nsensory information, consequently enhancing the robustness of the approach."
  },
  {
    "paper_no": "2174",
    "authors": "Majd, Keyvan; Clark, Geoffrey; Fainekos, Georgios; Ben Amor, Heni",
    "title": "Repairing Neural Networks for Safety in Robotic Systems using Predictive Models",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.04408v1",
    "arxiv_abstract": "This paper introduces a new method for safety-aware robot learning, focusing\non repairing policies using predictive models. Our method combines behavioral\ncloning with neural network repair in a two-step supervised learning framework.\nIt first learns a policy from expert demonstrations and then applies repair\nsubject to predictive models to enforce safety constraints. The predictive\nmodels can encompass various aspects relevant to robot learning applications,\nsuch as proprioceptive states and collision likelihood. Our experimental\nresults demonstrate that the learned policy successfully adheres to a\npredefined set of safety constraints on two applications: mobile robot\nnavigation, and real-world lower-leg prostheses. Additionally, we have shown\nthat our method effectively reduces repeated interaction with the robot,\nleading to substantial time savings during the learning process."
  },
  {
    "paper_no": "2177",
    "authors": "Hamaoka, Rintaro; Kato, Ryu",
    "title": "Effect of Tactile and Deep Sensory Feedback Synchronized with the Manipulation of Myoelectric Hand on Body Recognition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2178",
    "authors": "Zhang, Huixin; Wang, Guangming; Wu, Xinrui; Xu, Chenfeng; Ding, Mingyu; Tomizuka, Masayoshi; Zhan, Wei; Wang, Hesheng",
    "title": "DSLO: Deep Sequence LiDAR Odometry Based on Inconsistent Spatio-temporal Propagation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2179",
    "authors": "Ezhov, Vadim; Park, Hyoungseob; Zhang, Zhaoyang; Upadhyay, Rishi; Zhang, Howard; Chandrappa, Chethan Chinder; Kadambi, Achuta; Ba, Yunhao; Dorsey, Julie; Wong, Alex",
    "title": "All-day Depth Completion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2181",
    "authors": "Xu, Pu; Bai, Zhaoqiang; Liu, Haoming; Fang, Zheng",
    "title": "PARE: A Plane-Assisted Autonomous Robot Exploration Framework in Unknown and Uneven Terrain",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2183",
    "authors": "Yao, Yue; Yan, Shengchao; Goehring, Daniel; Burgard, Wolfram; Reichardt, Joerg",
    "title": "Improving Out-of-Distribution Generalization of Trajectory Prediction for Autonomous Driving via Polynomial Representations",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.13431v2",
    "arxiv_abstract": "Robustness against Out-of-Distribution (OoD) samples is a key performance\nindicator of a trajectory prediction model. However, the development and\nranking of state-of-the-art (SotA) models are driven by their In-Distribution\n(ID) performance on individual competition datasets. We present an OoD testing\nprotocol that homogenizes datasets and prediction tasks across two large-scale\nmotion datasets. We introduce a novel prediction algorithm based on polynomial\nrepresentations for agent trajectory and road geometry on both the input and\noutput sides of the model. With a much smaller model size, training effort, and\ninference time, we reach near SotA performance for ID testing and significantly\nimprove robustness in OoD testing. Within our OoD testing protocol, we further\nstudy two augmentation strategies of SotA models and their effects on model\ngeneralization. Highlighting the contrast between ID and OoD performance, we\nsuggest adding OoD testing to the evaluation criteria of trajectory prediction\nmodels."
  },
  {
    "paper_no": "2184",
    "authors": "Ando, Daito; Turan, Bilal; Amaya, Satoshi; Ukai, Yuko; Sato, Yoshikatsu; Arai, Fumihito",
    "title": "Single Protoplasts Pickup System Combining Brightfield and Confocal Images",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2186",
    "authors": "Fiasche, Enrico; Malis, Ezio; Martinet, Philippe",
    "title": "Multi-Spectral Visual Servoing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2188",
    "authors": "Huang, Hao; Yuan, Shuaihang; Wen, Congcong; Hao, Yu; Fang, Yi",
    "title": "Weakly Scene Segmentation Using Efficient Transformer",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2189",
    "authors": "SUN, GE; Shafiee, Milad; LI, Peizhuo; Bellegarda, Guillaume; Ijspeert, Auke; Sartoretti, Guillaume Adrien",
    "title": "Learning-based Hierarchical Control: Emulating the Central Nervous System for Bio-Inspired Legged Robot Locomotion",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.17815v1",
    "arxiv_abstract": "Animals possess a remarkable ability to navigate challenging terrains,\nachieved through the interplay of various pathways between the brain, central\npattern generators (CPGs) in the spinal cord, and musculoskeletal system.\nTraditional bioinspired control frameworks often rely on a singular control\npolicy that models both higher (supraspinal) and spinal cord functions. In this\nwork, we build upon our previous research by introducing two distinct neural\nnetworks: one tasked with modulating the frequency and amplitude of CPGs to\ngenerate the basic locomotor rhythm (referred to as the spinal policy, SCP),\nand the other responsible for receiving environmental perception data and\ndirectly modulating the rhythmic output from the SCP to execute precise\nmovements on challenging terrains (referred to as the descending modulation\npolicy). This division of labor more closely mimics the hierarchical locomotor\ncontrol systems observed in legged animals, thereby enhancing the robot's\nability to navigate various uneven surfaces, including steps, high obstacles,\nand terrains with gaps. Additionally, we investigate the impact of sensorimotor\ndelays within our framework, validating several biological assumptions about\nanimal locomotion systems. Specifically, we demonstrate that spinal circuits\nplay a crucial role in generating the basic locomotor rhythm, while descending\npathways are essential for enabling appropriate gait modifications to\naccommodate uneven terrain. Notably, our findings also reveal that the\nmulti-layered control inherent in animals exhibits remarkable robustness\nagainst time delays. Through these investigations, this paper contributes to a\ndeeper understanding of the fundamental principles of interplay between spinal\nand supraspinal mechanisms in biological locomotion. It also supports the\ndevelopment of locomotion controllers in parallel to biological structures\nwhich are ..."
  },
  {
    "paper_no": "2190",
    "authors": "Henrich, Pit; Liu, Jiawei; Ge, Jiawei; Schmidgall, Samuel; Shepard, Lauren; Ghazi, Ahmed; Mathis-Ullrich, Franziska; Krieger, Axel",
    "title": "Tracking Tumors under Deformation from Partial Point Clouds using Occupancy Networks",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.02619v1",
    "arxiv_abstract": "To track tumors during surgery, information from preoperative CT scans is\nused to determine their position. However, as the surgeon operates, the tumor\nmay be deformed which presents a major hurdle for accurately resecting the\ntumor, and can lead to surgical inaccuracy, increased operation time, and\nexcessive margins. This issue is particularly pronounced in robot-assisted\npartial nephrectomy (RAPN), where the kidney undergoes significant deformations\nduring operation. Toward addressing this, we introduce a occupancy\nnetwork-based method for the localization of tumors within kidney phantoms\nundergoing deformations at interactive speeds. We validate our method by\nintroducing a 3D hydrogel kidney phantom embedded with exophytic and endophytic\nrenal tumors. It closely mimics real tissue mechanics to simulate kidney\ndeformation during in vivo surgery, providing excellent contrast and clear\ndelineation of tumor margins to enable automatic threshold-based segmentation.\nOur findings indicate that the proposed method can localize tumors in\nmoderately deforming kidneys with a margin of 6mm to 10mm, while providing\nessential volumetric 3D information at over 60Hz. This capability directly\nenables downstream tasks such as robotic resection."
  },
  {
    "paper_no": "2191",
    "authors": "Wu, Changshun; HE, Weicheng; Cheng, Chih-Hong; Huang, Xiaowei; Bensalem, Saddek",
    "title": "BAM: Box Abstraction Monitors for Real-time OoD Detection in Object Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2193",
    "authors": "Liu, Ruifan; Shin, Hyo-Sang; Tsourdos, Antonios",
    "title": "Cross-Observability Learning for Vehicle Routing Problems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2195",
    "authors": "Stavridis, Sotiris; Doulgeri, Zoe",
    "title": "Optimal view point and kinematic control for grape stem detection and cutting with an in-hand camera robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2197",
    "authors": "Liu, Tianle; Wang, Zhixiang; Zhang, Yongwei; Zhang, Yizhai; Huang, Panfeng",
    "title": "Self-reconfiguration strategies for space-distributed spacecraft",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.17137v1",
    "arxiv_abstract": "This paper proposes a distributed on-orbit spacecraft assembly algorithm,\nwhere future spacecraft can assemble modules with different functions on orbit\nto form a spacecraft structure with specific functions. This form of spacecraft\norganization has the advantages of reconfigurability, fast mission response and\neasy maintenance. Reasonable and efficient on-orbit self-reconfiguration\nalgorithms play a crucial role in realizing the benefits of distributed\nspacecraft. This paper adopts the framework of imitation learning combined with\nreinforcement learning for strategy learning of module handling order. A robot\narm motion algorithm is then designed to execute the handling sequence. We\nachieve the self-reconfiguration handling task by creating a map on the surface\nof the module, completing the path point planning of the robotic arm using A*.\nThe joint planning of the robotic arm is then accomplished through forward and\nreverse kinematics. Finally, the results are presented in Unity3D."
  },
  {
    "paper_no": "2199",
    "authors": "Liu, Chenhao; Yi, Jingang; He, Long; Zhang, Yijun; Zhang, Xiufeng; Liu, Tao",
    "title": "Foot Arch Stiffness-Based Dynamic Plantar Support Control of Human Walking Gait with Active Pneumatic Insoles",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2200",
    "authors": "Yang, Rui; Yan, Zhi; Yang, Tao; Krajník, Tomá; Ruichek, Yassine",
    "title": "Preventing Catastrophic Forgetting in Continuous Online Learning for Autonomous Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2201",
    "authors": "Yu, Wenhao; Peng, Jie; yang, huanyu; Zhang, Junrui; Duan, Yifan; Ji, Jianmin; Zhang, Yanyong",
    "title": "LDP: A Local Diffusion Planner for Efficient Robot Navigation and Collision Avoidance",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2202",
    "authors": "Pore, Ameya; Muradore, Riccardo; Dall'Alba, Diego",
    "title": "DEAR: Disentangled Environment and Agent Representations for Reinforcement Learning without Reconstruction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2204",
    "authors": "He, jiacheng; Zhao, Fangguo; Zhu, Shaohao; Li, Shuo; Xu, Jinming",
    "title": "Priority-Based Deadlock Recovery for Distributed Swarm Obstacle Avoidance in Cluttered Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2206",
    "authors": "Trombin, Edoardo; Tortora, Stefano; Menegatti, Emanuele; Tonin, Luca",
    "title": "Environment-Adaptive Gait Planning for Obstacle Avoidance in Lower-Limb Robotic Exoskeletons",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2207",
    "authors": "Ikura, Mikihiro; Le Gentil, Cedric; Müller, Marcus Gerhard; Yamashita, Atsushi; Stuerzl, Wolfgang",
    "title": "RATE: Real-time Asynchronous Feature Tracking with Event Cameras",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2208",
    "authors": "Tellaroli, Mauro; Luperto, Matteo; Antonazzi, Michele; Basilico, Nicola",
    "title": "Frontier-Based Exploration for Multi-Robot Rendezvous in Communication-Restricted Unknown Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.11617v3",
    "arxiv_abstract": "Multi-robot rendezvous and exploration are fundamental challenges in the\ndomain of mobile robotic systems. This paper addresses multi-robot rendezvous\nwithin an initially unknown environment where communication is only possible\nafter the rendezvous. Traditionally, exploration has been focused on rapidly\nmapping the environment, often leading to suboptimal rendezvous performance in\nlater stages. We adapt a standard frontier-based exploration technique to\nintegrate exploration and rendezvous into a unified strategy, with a mechanism\nthat allows robots to re-visit previously explored regions thus enhancing\nrendezvous opportunities. We validate our approach in 3D realistic simulations\nusing ROS, showcasing its effectiveness in achieving faster rendezvous times\ncompared to exploration strategies."
  },
  {
    "paper_no": "2209",
    "authors": "Lee, Sebastian; Lee, Jungpyo; Stuart, Hannah",
    "title": "Haptic Contour Following with the Smart Suction Cup",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2217",
    "authors": "Shimooka, Taiki; Kakogawa, Atsushi; Tanaka, Hiroto",
    "title": "An Agile Robotic Penguin Driven by Submersible Geared&#12288;Servomotors: Various Maneuvers by Active Feathering of the Wings",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2218",
    "authors": "Arreghini, Simone; Abbate, Gabriele; Giusti, Alessandro; Paolillo, Antonio",
    "title": "A Service Robot in the Wild: Analysis of Users Intentions,Robot Behaviors, and Their Mutual Impact",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.03287v1",
    "arxiv_abstract": "We consider a service robot that offers chocolate treats to people passing in\nits proximity: it has the capability of predicting in advance a person's\nintention to interact, and to actuate an \"offering\" gesture, subtly extending\nthe tray of chocolates towards a given target. We run the system for more than\n5 hours across 3 days and two different crowded public locations; the system\nimplements three possible behaviors that are randomly toggled every few\nminutes: passive (e.g. never performing the offering gesture); or active,\ntriggered by either a naive distance-based rule, or a smart approach that\nrelies on various behavioral cues of the user. We collect a real-world dataset\nthat includes information on 1777 users with several spontaneous human-robot\ninteractions and study the influence of robot actions on people's behavior. Our\ncomprehensive analysis suggests that users are more prone to engage with the\nrobot when it proactively starts the interaction. We release the dataset and\nprovide insights to make our work reproducible for the community. Also, we\nreport qualitative observations collected during the acquisition campaign and\nidentify future challenges and research directions in the domain of social\nhuman-robot interaction."
  },
  {
    "paper_no": "2219",
    "authors": "Wang, Han; Mascaro, Ruben; Chli, Margarita; Teixeira, Lucas",
    "title": "Real-Time Semantic Segmentation in Natural Environments with SAM-assisted Sim-to-Real Domain Transfer",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2220",
    "authors": "LIU, Peize; XU, Yang; NING, Yan; XU, Hao; Feng, Chen; Shen, Shaojie",
    "title": "OmniNxt: A Fully Open-source and Compact Aerial Robot with Omnidirectional Visual Perception",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2223",
    "authors": "Dong, Qianli; Xi, Haobo; Zhang, Shiyong; Bi, Qingchen; Li, Tianyi; Wang, Ziyu; Zhang, Xuebo",
    "title": "Fast and Communication-Efficient Multi-UAV Exploration Via Voronoi Partition on Dynamic Topological Graph",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.05808v1",
    "arxiv_abstract": "Efficient data transmission and reasonable task allocation are important to\nimprove multi-robot exploration efficiency. However, most communication data\ntypes typically contain redundant information and thus require massive\ncommunication volume. Moreover, exploration-oriented task allocation is far\nfrom trivial and becomes even more challenging for resource-limited unmanned\naerial vehicles (UAVs). In this paper, we propose a fast and\ncommunication-efficient multi-UAV exploration method for exploring large\nenvironments. We first design a multi-robot dynamic topological graph (MR-DTG)\nconsisting of nodes representing the explored and exploring regions and edges\nconnecting nodes. Supported by MR-DTG, our method achieves efficient\ncommunication by only transferring the necessary information required by\nexploration planning. To further improve the exploration efficiency, a\nhierarchical multi-UAV exploration method is devised using MR-DTG.\nSpecifically, the \\emph{graph Voronoi partition} is used to allocate MR-DTG's\nnodes to the closest UAVs, considering the actual motion cost, thus achieving\nreasonable task allocation. To our knowledge, this is the first work to address\nmulti-UAV exploration using \\emph{graph Voronoi partition}. The proposed method\nis compared with a state-of-the-art method in simulations. The results show\nthat the proposed method is able to reduce the exploration time and\ncommunication volume by up to 38.3\\% and 95.5\\%, respectively. Finally, the\neffectiveness of our method is validated in the real-world experiment with 6\nUAVs. We will release the source code to benefit the community."
  },
  {
    "paper_no": "2225",
    "authors": "Pramanick, Pradip; Rossi, Silvia",
    "title": "Multimodal Coherent Explanation Generation of Robot Failures",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.00659v1",
    "arxiv_abstract": "The explainability of a robot's actions is crucial to its acceptance in\nsocial spaces. Explaining why a robot fails to complete a given task is\nparticularly important for non-expert users to be aware of the robot's\ncapabilities and limitations. So far, research on explaining robot failures has\nonly considered generating textual explanations, even though several studies\nhave shown the benefits of multimodal ones. However, a simple combination of\nmultiple modalities may lead to semantic incoherence between the information\nacross different modalities - a problem that is not well-studied. An incoherent\nmultimodal explanation can be difficult to understand, and it may even become\ninconsistent with what the robot and the human observe and how they perform\nreasoning with the observations. Such inconsistencies may lead to wrong\nconclusions about the robot's capabilities. In this paper, we introduce an\napproach to generate coherent multimodal explanations by checking the logical\ncoherence of explanations from different modalities, followed by refinements as\nrequired. We propose a classification approach for coherence assessment, where\nwe evaluate if an explanation logically follows another. Our experiments\nsuggest that fine-tuning a neural network that was pre-trained to recognize\ntextual entailment, performs well for coherence assessment of multimodal\nexplanations. Code & data: https://pradippramanick.github.io/coherent-explain/."
  },
  {
    "paper_no": "2226",
    "authors": "HERAU, Quentin; Bennehar, Moussab; Moreau, Arthur; Piasco, Nathan; Roldao, Luis; tsishkou, dzmitry; Migniot, Cyrille; Vasseur, Pascal; Demonceaux, Cédric",
    "title": "3DGS-Calib: 3D Gaussian Splatting for Multimodal SpatioTemporal Calibration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2229",
    "authors": "Chen, Chen; Zou, Qikai; Song, Yuhang; Song, Shiji; LI, Xiang",
    "title": "Visual Attention Based Cognitive Human--Robot Collaboration for Pedicle Screw Placement in Robot-Assisted Orthopedic Surgery",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.09359v1",
    "arxiv_abstract": "Current orthopedic robotic systems largely focus on navigation, aiding\nsurgeons in positioning a guiding tube but still requiring manual drilling and\nscrew placement. The automation of this task not only demands high precision\nand safety due to the intricate physical interactions between the surgical tool\nand bone but also poses significant risks when executed without adequate human\noversight. As it involves continuous physical interaction, the robot should\ncollaborate with the surgeon, understand the human intent, and always include\nthe surgeon in the loop. To achieve this, this paper proposes a new cognitive\nhuman-robot collaboration framework, including the intuitive AR-haptic\nhuman-robot interface, the visual-attention-based surgeon model, and the shared\ninteraction control scheme for the robot. User studies on a robotic platform\nfor orthopedic surgery are presented to illustrate the performance of the\nproposed method. The results demonstrate that the proposed human-robot\ncollaboration framework outperforms full robot and full human control in terms\nof safety and ergonomics."
  },
  {
    "paper_no": "2230",
    "authors": "Antonazzi, Michele; Luperto, Matteo; Borghese, N. Alberto; Basilico, Nicola",
    "title": "R2SNet: Scalable Domain Adaptation for Object Detection in Cloud-Based Robots Ecosystems via Proposal Refinement",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2232",
    "authors": "Grieben, Raul; Sehring, Stephan; Tekülve, Jan; Spencer, John P.; Schöner, Gregor",
    "title": "ROBOVERINE: A human-inspired neural robotic process model of active visual search and scene grammar in naturalistic environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2233",
    "authors": "Qin, Jianmin; Liu, Qingchen; Ma, Qichao; Wu, Zipeng; Qin, Jiahu",
    "title": "A Non-Homogeneity Mapless Navigation Based on Hierarchical Safe Reinforcement Learning in Dynamic Complex Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2235",
    "authors": "Monguzzi, Andrea; Mantegna, Niccolò; Zanchettin, Andrea Maria; Rocco, Paolo",
    "title": "Potential Field-Based Online Path Planning for Robust Cable Routing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2236",
    "authors": "Al Saaideh, Mohammad; al-rawashdeh, Yazan; Alatawneh, Natheer; Aljanaideh, Khaled; Al Janaideh, Mohammad",
    "title": "Position Control of a Low-Energy C-Core Reluctance Actuator in a Motion System",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2237",
    "authors": "Gopinathan, Muraleekrishna; Abu-Khalaf, Jumana; Suter, David; Masek, Martin",
    "title": "StratXplore: Strategic Novelty-seeking and Instruction-aligned Exploration for Vision and Language Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2241",
    "authors": "Kalwar, Sanket; UNGARALA, SRI MIHIR DEVAPI; Jain, Shruti; Monis, Aaron; konda, Krishna; Garg, Sourav; Krishna, Madhava",
    "title": "DiffPrompter: Differentiable Implicit Visual Prompts for Semantic-Segmentation in Adverse Conditions",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2242",
    "authors": "FIGUERA MICHAL, XIYANA VEROSKA; Park, Soogeun; Ahn, Hyemin",
    "title": "Redefining Data Pairing for Motion Retargeting Leveraging a Human Body Prior",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.13208v3",
    "arxiv_abstract": "We propose MR HuBo(Motion Retargeting leveraging a HUman BOdy prior), a\ncost-effective and convenient method to collect high-quality upper body paired\n<robot, human> pose data, which is essential for data-driven motion retargeting\nmethods. Unlike existing approaches which collect <robot, human> pose data by\nconverting human MoCap poses into robot poses, our method goes in reverse. We\nfirst sample diverse random robot poses, and then convert them into human\nposes. However, since random robot poses can result in extreme and infeasible\nhuman poses, we propose an additional technique to sort out extreme poses by\nexploiting a human body prior trained from a large amount of human pose data.\nOur data collection method can be used for any humanoid robots, if one designs\nor optimizes the system's hyperparameters which include a size scale factor and\nthe joint angle ranges for sampling. In addition to this data collection\nmethod, we also present a two-stage motion retargeting neural network that can\nbe trained via supervised learning on a large amount of paired data. Compared\nto other learning-based methods trained via unsupervised learning, we found\nthat our deep neural network trained with ample high-quality paired data\nachieved notable performance. Our experiments also show that our data filtering\nmethod yields better retargeting results than training the model with raw and\nnoisy data. Our code and video results are available on\nhttps://sites.google.com/view/mr-hubo/"
  },
  {
    "paper_no": "2244",
    "authors": "Wilhelm, Nikolas Jakob; Victor, Schaack; Leisching, Annick; Micheler, Carina M.; Haddadin, Sami; Burgkart, Rainer",
    "title": "An Adaptive Robotic Exoskeleton for Comprehensive Force-Controlled Hand Rehabilitation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2246",
    "authors": "Ueno, Takahisa; Funabashi, Satoshi; Ito, Hiroshi; Schmitz, Alexander; Kulkarni, Shardul; Ogata, Tetsuya; Sugano, Shigeki",
    "title": "Multi-Fingered Dragging of Unknown Objects and Orientations Using Distributed Tactile Information Through Vision-Transformer and LSTM",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2247",
    "authors": "Bachhuber, Simon; Pawluchin, Alexander; Pal, Arka; Boblan, Ivo; Seel, Thomas",
    "title": "A Soft Robotic System Automatically Learns Precise Agile Motions Without Model Information",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.03754v3",
    "arxiv_abstract": "Many application domains, e.g., in medicine and manufacturing, can greatly\nbenefit from pneumatic Soft Robots (SRs). However, the accurate control of SRs\nhas remained a significant challenge to date, mainly due to their nonlinear\ndynamics and viscoelastic material properties. Conventional control design\nmethods often rely on either complex system modeling or time-intensive manual\ntuning, both of which require significant amounts of human expertise and thus\nlimit their practicality. In recent works, the data-driven method, Automatic\nNeural ODE Control (ANODEC) has been successfully used to -- fully\nautomatically and utilizing only input-output data -- design controllers for\nvarious nonlinear systems in silico, and without requiring prior model\nknowledge or extensive manual tuning. In this work, we successfully apply\nANODEC to automatically learn to perform agile, non-repetitive reference\ntracking motion tasks in a real-world SR and within a finite time horizon. To\nthe best of the authors' knowledge, ANODEC achieves, for the first time,\nperformant control of a SR with hysteresis effects from only 30 seconds of\ninput-output data and without any prior model knowledge. We show that for\nmultiple, qualitatively different and even out-of-training-distribution\nreference signals, a single feedback controller designed by ANODEC outperforms\na manually tuned PID baseline consistently. Overall, this contribution not only\nfurther strengthens the validity of ANODEC, but it marks an important step\ntowards more practical, easy-to-use SRs that can automatically learn to perform\nagile motions from minimal experimental interaction time."
  },
  {
    "paper_no": "2251",
    "authors": "Sakaguchi, Taichi; Taniguchi, Akira; Hagiwara, Yoshinobu; El Hafi, Lotfi; Hasegawa, Shoichi; Taniguchi, Tadahiro",
    "title": "Object Instance Retrieval in Assistive Robotics: Leveraging Fine-Tuned SimSiam with Multi-View Images Based on 3D Semantic Map",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.09647v2",
    "arxiv_abstract": "Robots that assist humans in their daily lives should be able to locate\nspecific instances of objects in an environment that match a user's desired\nobjects. This task is known as instance-specific image goal navigation\n(InstanceImageNav), which requires a model that can distinguish different\ninstances of an object within the same class. A significant challenge in\nrobotics is that when a robot observes the same object from various 3D\nviewpoints, its appearance may differ significantly, making it difficult to\nrecognize and locate accurately. In this paper, we introduce a method called\nSimView, which leverages multi-view images based on a 3D semantic map of an\nenvironment and self-supervised learning using SimSiam to train an\ninstance-identification model on-site. The effectiveness of our approach was\nvalidated using a photorealistic simulator, Habitat Matterport 3D, created by\nscanning actual home environments. Our results demonstrate a 1.7-fold\nimprovement in task accuracy compared with contrastive language-image\npre-training (CLIP), a pre-trained multimodal contrastive learning method for\nobject searching. This improvement highlights the benefits of our proposed\nfine-tuning method in enhancing the performance of assistive robots in\nInstanceImageNav tasks. The project website is\nhttps://emergentsystemlabstudent.github.io/MultiViewRetrieve/."
  },
  {
    "paper_no": "2252",
    "authors": "Pham, Phu; Bera, Aniket",
    "title": "Optimizing Crowd-Aware Multi-Agent Path Finding through Local Broadcasting with Graph Neural Networks",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.10275v3",
    "arxiv_abstract": "Multi-Agent Path Finding (MAPF) in crowded environments presents a\nchallenging problem in motion planning, aiming to find collision-free paths for\nall agents in the system. MAPF finds a wide range of applications in various\ndomains, including aerial swarms, autonomous warehouse robotics, and\nself-driving vehicles. Current approaches to MAPF generally fall into two main\ncategories: centralized and decentralized planning. Centralized planning\nsuffers from the curse of dimensionality when the number of agents or states\nincreases and thus does not scale well in large and complex environments. On\nthe other hand, decentralized planning enables agents to engage in real-time\npath planning within a partially observable environment, demonstrating implicit\ncoordination. However, they suffer from slow convergence and performance\ndegradation in dense environments. In this paper, we introduce CRAMP, a novel\ncrowd-aware decentralized reinforcement learning approach to address this\nproblem by enabling efficient local communication among agents via Graph Neural\nNetworks (GNNs), facilitating situational awareness and decision-making\ncapabilities in congested environments. We test CRAMP on simulated environments\nand demonstrate that our method outperforms the state-of-the-art decentralized\nmethods for MAPF on various metrics. CRAMP improves the solution quality up to\n59% measured in makespan and collision count, and up to 35% improvement in\nsuccess rate in comparison to previous methods."
  },
  {
    "paper_no": "2253",
    "authors": "Li, Zhuowen; Chen, Huaiyuan; Xu, Fan; Wang, Hesheng",
    "title": "An Origami-Inspired Pneumatic Continuum Module with Active Variable Stiffness",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2254",
    "authors": "Scarponi, Valentina; Lecomte, François; Duprez, Michel; Nageotte, Florent; Cotin, Stephane",
    "title": "Autonomous Guidewire Navigation in Dynamic Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2255",
    "authors": "BAIROUK, Anass; Maras, Mirjana; Herlin, Simon; Amini, Alexander; Blanchon, Marc; Hasani, Ramin; Chareyre, Patrick; Rus, Daniela",
    "title": "Exploring Latent Pathways: Enhancing the Interpretability of Autonomous Driving with a Variational Autoencoder",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.01750v1",
    "arxiv_abstract": "Autonomous driving presents a complex challenge, which is usually addressed\nwith artificial intelligence models that are end-to-end or modular in nature.\nWithin the landscape of modular approaches, a bio-inspired neural circuit\npolicy model has emerged as an innovative control module, offering a compact\nand inherently interpretable system to infer a steering wheel command from\nabstract visual features. Here, we take a leap forward by integrating a\nvariational autoencoder with the neural circuit policy controller, forming a\nsolution that directly generates steering commands from input camera images. By\nsubstituting the traditional convolutional neural network approach to feature\nextraction with a variational autoencoder, we enhance the system's\ninterpretability, enabling a more transparent and understandable\ndecision-making process.\n  In addition to the architectural shift toward a variational autoencoder, this\nstudy introduces the automatic latent perturbation tool, a novel contribution\ndesigned to probe and elucidate the latent features within the variational\nautoencoder. The automatic latent perturbation tool automates the\ninterpretability process, offering granular insights into how specific latent\nvariables influence the overall model's behavior. Through a series of numerical\nexperiments, we demonstrate the interpretative power of the variational\nautoencoder-neural circuit policy model and the utility of the automatic latent\nperturbation tool in making the inner workings of autonomous driving systems\nmore transparent."
  },
  {
    "paper_no": "2256",
    "authors": "He, Botao; Chen, Luke; Wang, Wenshan; Zhang, Ji; Fermuller, Cornelia; Aloimonos, Yiannis",
    "title": "Interactive-FAR: Interactive, Fast and Adaptable Routing for Navigation Among Movable Obstacles in Complex Unknown Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2262",
    "authors": "Abderezaei, Ava; Pasricha, Anuj; Klausenstock, Alex; Roncone, Alessandro",
    "title": "Clutter-Aware Spill-Free Liquid Transport via Learned Dynamics",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.00215v1",
    "arxiv_abstract": "In this work, we present a novel algorithm to perform spill-free handling of\nopen-top liquid-filled containers that operates in cluttered environments. By\nallowing liquid-filled containers to be tilted at higher angles and enabling\nmotion along all axes of end-effector orientation, our work extends the\nreachable space and enhances maneuverability around obstacles, broadening the\nrange of feasible scenarios. Our key contributions include: i) generating\nspill-free paths through the use of RRT* with an informed sampler that\nleverages container properties to avoid spill-inducing states (such as an\nupside-down container), ii) parameterizing the resulting path to generate\nspill-free trajectories through the implementation of a time parameterization\nalgorithm, coupled with a transformer-based machine-learning model capable of\nclassifying trajectories as spill-free or not. We validate our approach in\nreal-world, obstacle-rich task settings using containers of various shapes and\nfill levels and demonstrate an extended solution space that is at least 3x\nlarger than an existing approach."
  },
  {
    "paper_no": "2264",
    "authors": "Murphy, Kevin; Soares, João Carlos Virgolino; Yim, Justin K.; Nottage, Dustin; Soylemezoglu, Ahmet; Ramos, Joao",
    "title": "Cooperative Modular Manipulation with Numerous Cable-Driven Robots for Assistive Construction and Gap Crossing",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13124v1",
    "arxiv_abstract": "Soldiers in the field often need to cross negative obstacles, such as rivers\nor canyons, to reach goals or safety. Military gap crossing involves on-site\ntemporary bridges construction. However, this procedure is conducted with\ndangerous, time and labor intensive operations, and specialized machinery. We\nenvision a scalable robotic solution inspired by advancements in\nforce-controlled and Cable Driven Parallel Robots (CDPRs); this solution can\naddress the challenges inherent in this transportation problem, achieving fast,\nefficient, and safe deployment and field operations. We introduce the embodied\nvision in Co3MaNDR, a solution to the military gap crossing problem, a\ndistributed robot consisting of several modules simultaneously pulling on a\ncentral payload, controlling the cables' tensions to achieve complex\nobjectives, such as precise trajectory tracking or force amplification.\nHardware experiments demonstrate teleoperation of a payload, trajectory\nfollowing, and the sensing and amplification of operators' applied physical\nforces during slow operations. An operator was shown to manipulate a 27.2 kg\n(60 lb) payload with an average force utilization of 14.5\\% of its weight.\nResults indicate that the system can be scaled up to heavier payloads without\ncompromising performance or introducing superfluous complexity. This research\nlays a foundation to expand CDPR technology to uncoordinated and unstable\nmobile platforms in unknown environments."
  },
  {
    "paper_no": "2266",
    "authors": "Yang, Ruoxuan; Zhang, Xinyue; Fernandez-Laaksonen, Anais; Ding, Xin; Gong, Jiangtao",
    "title": "Driving Style Alignment for LLM-powered Driver Agent",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.11368v1",
    "arxiv_abstract": "Recently, LLM-powered driver agents have demonstrated considerable potential\nin the field of autonomous driving, showcasing human-like reasoning and\ndecision-making abilities.However, current research on aligning driver agent\nbehaviors with human driving styles remains limited, partly due to the scarcity\nof high-quality natural language data from human driving behaviors.To address\nthis research gap, we propose a multi-alignment framework designed to align\ndriver agents with human driving styles through demonstrations and feedback.\nNotably, we construct a natural language dataset of human driver behaviors\nthrough naturalistic driving experiments and post-driving interviews, offering\nhigh-quality human demonstrations for LLM alignment. The framework's\neffectiveness is validated through simulation experiments in the CARLA urban\ntraffic simulator and further corroborated by human evaluations. Our research\noffers valuable insights into designing driving agents with diverse driving\nstyles.The implementation of the framework and details of the dataset can be\nfound at the link."
  },
  {
    "paper_no": "2270",
    "authors": "Lichtenfeld, Jonathan; Daun, Kevin; von Stryk, Oskar",
    "title": "Efficient Dynamic SLAM for Mobile Robots with Structured Point Clouds",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.18443v1",
    "arxiv_abstract": "We propose a real-time dynamic LiDAR odometry pipeline for mobile robots in\nUrban Search and Rescue (USAR) scenarios. Existing approaches to dynamic object\ndetection often rely on pretrained learned networks or computationally\nexpensive volumetric maps. To enhance efficiency on computationally limited\nrobots, we reuse data between the odometry and detection module. Utilizing a\nrange image segmentation technique and a novel residual-based heuristic, our\nmethod distinguishes dynamic from static objects before integrating them into\nthe point cloud map. The approach demonstrates robust object tracking and\nimproved map accuracy in environments with numerous dynamic objects. Even\nhighly non-rigid objects, such as running humans, are accurately detected at\npoint level without prior downsampling of the point cloud and hence, without\nloss of information. Evaluation on simulated and real-world data validates its\ncomputational efficiency. Compared to a state-of-the-art volumetric method, our\napproach shows comparable detection performance at a fraction of the processing\ntime, adding only 14 ms to the odometry module for dynamic object detection and\ntracking. The implementation and a new real-world dataset are available as\nopen-source for further research."
  },
  {
    "paper_no": "2272",
    "authors": "Cho, SungJoon; Kim, Jun-Sik",
    "title": "ReLoc-Aligner : Orientation-aware Scene Descriptor for Re-Localization within a 3D Point Cloud Map",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2273",
    "authors": "Ragab, Dana; Rendon-Morales, Elizabeth; Althoefer, Kaspar; Godaba, Hareesh",
    "title": "Reconfigurable Soft Gripper Based on Eversion and Electroadhesion for Cluttered Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2274",
    "authors": "Zhang, Xiang; Lin, Hsien-Chung; Zhao, Yu; Tomizuka, Masayoshi",
    "title": "Harnessing with Twisting: Single-Arm Deformable Linear Object Manipulation for Industrial Harnessing Task",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.10729v1",
    "arxiv_abstract": "Wire-harnessing tasks pose great challenges to be automated by the robot due\nto the complex dynamics and unpredictable behavior of the deformable wire.\nTraditional methods, often reliant on dual-robot arms or tactile sensing, face\nlimitations in adaptability, cost, and scalability. This paper introduces a\nnovel single-robot wire-harnessing pipeline that leverages a robot's twisting\nmotion to generate necessary wire tension for precise insertion into clamps,\nusing only one robot arm with an integrated force/torque (F/T) sensor.\nBenefiting from this design, the single robot arm can efficiently apply tension\nfor wire routing and insertion into clamps in a narrow space. Our approach is\nstructured around four principal components: a Model Predictive Control (MPC)\nbased on the Koopman operator for tension tracking and wire following, a motion\nplanner for sequencing harnessing waypoints, a suite of insertion primitives\nfor clamp engagement, and a fix-point switching mechanism for wire constraint\nupdating. Evaluated on an industrial-level wire harnessing task, our method\ndemonstrated superior performance and reliability over conventional approaches,\nefficiently handling both single and multiple wire configurations with high\nsuccess rates."
  },
  {
    "paper_no": "2276",
    "authors": "Barlakas, Sotirios; Alexiou, Dimitrios; Tsiakas, Kosmas; Katsatos, Dimitrios; Kostavelis, Ioannis; Giakoumis, Dimitris; Gasteratos, Antonios; Tzovaras, Dimitrios",
    "title": "Robot Active Vision-Based Path Planning for Localization Improvement in Indoor Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2277",
    "authors": "Liu, Yu Tang; Nilaksh, Nilaksh; Ahmad, Aamir",
    "title": "Adaptive Reinforcement Learning for Robot Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2279",
    "authors": "Adeline, Michelle; Loo, Junn Yong; Baskaran, Vishnu Monn",
    "title": "MDHA: Multi-Scale Deformable Transformer with Hybrid Anchors for Multi-View 3D Object Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2281",
    "authors": "Henkel, Christian; Toussaint, Marc; Hoenig, Wolfgang",
    "title": "GSRM: Building Roadmaps for Query-Efficient and Near-Optimal Path Planning Using a Reaction Diffusion System",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2282",
    "authors": "Zharkov, Kirill; Chaikovskii, Mikhail; Osipov, Yefim; Alshaowa, Rahaf; Borisov, Ivan; Kolyubin, Sergey",
    "title": "Synergizing Morphological Computation and Generative Design: Automatic Synthesis of Tendon-Driven Grippers",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.07865v1",
    "arxiv_abstract": "Robots' behavior and performance are determined both by hardware and\nsoftware. The design process of robotic systems is a complex journey that\ninvolves multiple phases. Throughout this process, the aim is to tackle various\ncriteria simultaneously, even though they often contradict each other. The\nultimate goal is to uncover the optimal solution that resolves these\nconflicting factors. Generative, computation or automatic designs are the\nparadigms aimed at accelerating the whole design process. Within this paper we\npropose a design methodology to generate linkage mechanisms for robots with\nmorphological computation. We use a graph grammar and a heuristic search\nalgorithm to create robot mechanism graphs that are converted into simulation\nmodels for testing the design output. To verify the design methodology we have\napplied it to a relatively simple quasi-static problem of object grasping. We\nfound a way to automatically design an underactuated tendon-driven gripper that\ncan grasp a wide range of objects. This is possible because of its structure,\nnot because of sophisticated planning or learning."
  },
  {
    "paper_no": "2284",
    "authors": "Murphy, Dominic; Giuliani, Manuel; Bremner, Paul",
    "title": "Evaluation and Design Recommendations for a Folding Morphing-wheg Robot for Nuclear Characterisation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2287",
    "authors": "Wang, Huayou; Liu, Qingyao; Wu, Jiazheng; Liu, Kun; Ding, Chao; Xue, Changliang",
    "title": "CSR: A Lightweight Crowdsourced Road Structure Reconstruction System for Autonomous Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2288",
    "authors": "Liu, Zhi; Xu, Yongkang; Zhang, Lin; Wang, Shoukun; Wang, Junzheng",
    "title": "The control strategy for vehicle transfer robots in RO/RO terminal environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2290",
    "authors": "Song, Inpyo; Lee, Jangwon",
    "title": "SFTrack: A Robust Scale and Motion Adaptive Algorithm for Tracking Small and Fast Moving Objects",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2293",
    "authors": "Zhang, Chengjie; Wang, Jiang; Kong, He",
    "title": "Asynchronous Microphone Array Calibration using Hybrid TDOA Information",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.05791v4",
    "arxiv_abstract": "Asynchronous microphone array calibration is a prerequisite for many audition\nrobot applications. A popular solution to the above calibration problem is the\nbatch form of Simultaneous Localisation and Mapping (SLAM), using the time\ndifference of arrival measurements between two microphones (TDOA-M), and the\nrobot (which serves as a moving sound source during calibration) odometry\ninformation. In this paper, we introduce a new form of measurement for\nmicrophone array calibration, i.e. the time difference of arrival between\nadjacent sound events (TDOA-S) with respect to the microphone channels. We\npropose to use TDOA-S and TDOA-M, called hybrid TDOA, together with odometry\nmeasurements for bath SLAM-based calibration of asynchronous microphone arrays.\nExtensive simulation and real-world experiments show that our method is more\nindependent of microphone number, less sensitive to initial values (when using\noff-the-shelf algorithms such as Gauss-Newton iterations), and has better\ncalibration accuracy and robustness under various TDOA noises. Simulation\nresults also demonstrate that our method has a lower Cram\\'er-Rao lower bound\n(CRLB) for microphone parameters. To benefit the community, we open-source our\ncode and data at https://github.com/AISLAB-sustech/Hybrid-TDOA-Calib."
  },
  {
    "paper_no": "2294",
    "authors": "Shi, Guangyao; Sukhatme, Gaurav",
    "title": "Inverse Submodular Maximization with Application to Human-in-the-Loop Multi-Robot Multi-Objective Coverage Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10991v1",
    "arxiv_abstract": "We consider a new type of inverse combinatorial optimization, Inverse\nSubmodular Maximization (ISM), for human-in-the-loop multi-robot coordination.\n  Forward combinatorial optimization, defined as the process of solving a\ncombinatorial problem given the reward (cost)-related parameters, is widely\nused in multi-robot coordination. In the standard pipeline, the reward\n(cost)-related parameters are designed offline by domain experts first and then\nthese parameters are utilized for coordinating robots online. What if we need\nto change these parameters by non-expert human supervisors who watch over the\nrobots during tasks to adapt to some new requirements? We are interested in the\ncase where human supervisors can suggest what actions to take, and the robots\nneed to change the internal parameters based on such suggestions. We study such\nproblems from the perspective of inverse combinatorial optimization, i.e., the\nprocess of finding parameters given solutions to the problem. Specifically, we\npropose a new formulation for ISM, in which we aim to find a new set of\nparameters that minimally deviate from the current parameters and can make the\ngreedy algorithm output actions the same as those suggested by humans. We show\nthat such problems can be formulated as a Mixed Integer Quadratic Program\n(MIQP). However, MIQP involves exponentially many binary variables, making it\nintractable for the existing solver when the problem size is large. We propose\na new algorithm under the Branch $\\&$ Bound paradigm to solve such problems. In\nnumerical simulations, we demonstrate how to use ISM in multi-robot\nmulti-objective coverage control, and we show that the proposed algorithm\nachieves significant advantages in running time and peak memory usage compared\nto directly using an existing solver."
  },
  {
    "paper_no": "2295",
    "authors": "Chang, Haonan; Boularias, Abdeslam; Jain, Siddarth",
    "title": "Insert-One: One-Shot Robust Visual-Force Servoing for Novel Object Insertion with 6-DoF Tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2298",
    "authors": "Thomas, Annika; Kinnari, Jouko; Lusk, Parker C.; Kondo, Kota; How, Jonathan",
    "title": "SOS-Match: Segmentation for Open-Set Robust Correspondence Search and Robot Localization in Unstructured Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2303",
    "authors": "Pritzl, Vaclav; Vrba, Matous; Stasinchuk, Yurii; Kratky, Vit; Horyna, Jiri; Stepan, Petr; Saska, Martin",
    "title": "Drones Guiding Drones: Cooperative Navigation of a Less-Equipped Micro Aerial Vehicle in Cluttered Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2312.09786v2",
    "arxiv_abstract": "Reliable deployment of Unmanned Aerial Vehicles (UAVs) in cluttered unknown\nenvironments requires accurate sensors for Global Navigation Satellite System\n(GNSS)-denied localization and obstacle avoidance. Such a requirement limits\nthe usage of cheap and micro-scale vehicles with constrained payload capacity\nif industrial-grade reliability and precision are required. This paper\ninvestigates the possibility of offloading the necessity to carry heavy sensors\nto another member of the UAV team while preserving the desired capability of\nthe smaller robot intended for exploring narrow passages. A novel cooperative\nguidance framework offloading the sensing requirements from a minimalistic\nsecondary UAV to a superior primary UAV is proposed. The primary UAV constructs\na dense occupancy map of the environment and plans collision-free paths for\nboth UAVs to ensure reaching the desired secondary UAV's goals even in areas\nnot accessible by the bigger robot. The primary UAV guides the secondary UAV to\nfollow the planned path while tracking the UAV using Light Detection and\nRanging (LiDAR)-based relative localization. The proposed approach was verified\nin real-world experiments with a heterogeneous team of a 3D LiDAR-equipped\nprimary UAV and a micro-scale camera-equipped secondary UAV moving autonomously\nthrough unknown cluttered GNSS-denied environments with the proposed framework\nrunning fully on board the UAVs."
  },
  {
    "paper_no": "2304",
    "authors": "Barasuol, Victor; Turrisi, Giulio; Schulze, Lucas; Suzano Medeiros, Vivian; Semini, Claudio",
    "title": "PACC: A Passive-Arm Approach for High-Payload Collaborative Carrying with Quadruped Robots Using Model Predictive Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2306",
    "authors": "Acero, Fernando; Li, Zhibin (Alex)",
    "title": "Distilling Reinforcement Learning Policies for Interpretable Robot Locomotion: Gradient Boosting Machines and Symbolic Regression",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.14328v1",
    "arxiv_abstract": "Recent advancements in reinforcement learning (RL) have led to remarkable\nachievements in robot locomotion capabilities. However, the complexity and\n``black-box'' nature of neural network-based RL policies hinder their\ninterpretability and broader acceptance, particularly in applications demanding\nhigh levels of safety and reliability. This paper introduces a novel approach\nto distill neural RL policies into more interpretable forms using Gradient\nBoosting Machines (GBMs), Explainable Boosting Machines (EBMs) and Symbolic\nRegression. By leveraging the inherent interpretability of generalized additive\nmodels, decision trees, and analytical expressions, we transform opaque neural\nnetwork policies into more transparent ``glass-box'' models. We train expert\nneural network policies using RL and subsequently distill them into (i) GBMs,\n(ii) EBMs, and (iii) symbolic policies. To address the inherent distribution\nshift challenge of behavioral cloning, we propose to use the Dataset\nAggregation (DAgger) algorithm with a curriculum of episode-dependent\nalternation of actions between expert and distilled policies, to enable\nefficient distillation of feedback control policies. We evaluate our approach\non various robot locomotion gaits -- walking, trotting, bounding, and pacing --\nand study the importance of different observations in joint actions for\ndistilled policies using various methods. We train neural expert policies for\n205 hours of simulated experience and distill interpretable policies with only\n10 minutes of simulated interaction for each gait using the proposed method."
  },
  {
    "paper_no": "2308",
    "authors": "Zhou, Jiawei; Mascaro, Ruben; Cadena Lerma, Cesar; Chli, Margarita; Teixeira, Lucas",
    "title": "Temporal- and Viewpoint-Invariant Registration for Under-Canopy Footage using Deep-Learning-based Birds Eye View Prediction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2310",
    "authors": "Fang, Xiaolin; Kaelbling, Leslie; Lozano-Perez, Tomas",
    "title": "Embodied Uncertainty-Aware Object Segmentation",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.04760v1",
    "arxiv_abstract": "We introduce uncertainty-aware object instance segmentation (UncOS) and\ndemonstrate its usefulness for embodied interactive segmentation. To deal with\nuncertainty in robot perception, we propose a method for generating a\nhypothesis distribution of object segmentation. We obtain a set of\nregion-factored segmentation hypotheses together with confidence estimates by\nmaking multiple queries of large pre-trained models. This process can produce\nsegmentation results that achieve state-of-the-art performance on unseen object\nsegmentation problems. The output can also serve as input to a belief-driven\nprocess for selecting robot actions to perturb the scene to reduce ambiguity.\nWe demonstrate the effectiveness of this method in real-robot experiments.\nWebsite: https://sites.google.com/view/embodied-uncertain-seg"
  },
  {
    "paper_no": "2315",
    "authors": "Alberico, Ivan; Delaune, Jeff; Cioffi, Giovanni; Scaramuzza, Davide",
    "title": "Structure-Invariant Range-Visual-Inertial Odometry",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2316",
    "authors": "Valdes Saucedo, Mario Alberto; Stathoulopoulos, Nikolaos; Patel, Akash; Kanellakis, Christoforos; Nikolakopoulos, George",
    "title": "Leveraging Computation of Expectation Models for Commonsense Affordance Estimation on 3D Scene Graphs",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.05392v1",
    "arxiv_abstract": "This article studies the commonsense object affordance concept for enabling\nclose-to-human task planning and task optimization of embodied robotic agents\nin urban environments. The focus of the object affordance is on reasoning how\nto effectively identify object's inherent utility during the task execution,\nwhich in this work is enabled through the analysis of contextual relations of\nsparse information of 3D scene graphs. The proposed framework develops a\nCorrelation Information (CECI) model to learn probability distributions using a\nGraph Convolutional Network, allowing to extract the commonsense affordance for\nindividual members of a semantic class. The overall framework was\nexperimentally validated in a real-world indoor environment, showcasing the\nability of the method to level with human commonsense. For a video of the\narticle, showcasing the experimental demonstration, please refer to the\nfollowing link: https://youtu.be/BDCMVx2GiQE"
  },
  {
    "paper_no": "2318",
    "authors": "Giacomuzzo, Giulio; Terreran, Matteo; Jain, Siddarth; Romeres, Diego",
    "title": "DECAF: a Discrete-Event based Collaborative Human-Robot Framework for Furniture Assembly",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2319",
    "authors": "Michel, Nicolas; Patnaik, Ayush; Kong, Zhaodan; Lin, Xinfan",
    "title": "Energy-Optimal Planning of Waypoint-Based UAV Missions - Does Minimum Distance Mean Minimum Energy?",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2321",
    "authors": "Millan Romera, Jose Andres; Bavle, Hriday; Shaheer, Muhammad; Oswald, Martin R.; Voos, Holger; Sanchez-Lopez, Jose Luis",
    "title": "Learning High-level Semantic-Relational Concepts for SLAM",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2322",
    "authors": "Zheng, Xinlong; Zhang, Xiaozhou; Xu, Donghao",
    "title": "Speeding Up Path Planning via Reinforcement Learning in MCTS for Automated Parking",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.17234v2",
    "arxiv_abstract": "In this paper, we address a method that integrates reinforcement learning\ninto the Monte Carlo tree search to boost online path planning under fully\nobservable environments for automated parking tasks. Sampling-based planning\nmethods under high-dimensional space can be computationally expensive and\ntime-consuming. State evaluation methods are useful by leveraging the prior\nknowledge into the search steps, making the process faster in a real-time\nsystem. Given the fact that automated parking tasks are often executed under\ncomplex environments, a solid but lightweight heuristic guidance is challenging\nto compose in a traditional analytical way. To overcome this limitation, we\npropose a reinforcement learning pipeline with a Monte Carlo tree search under\nthe path planning framework. By iteratively learning the value of a state and\nthe best action among samples from its previous cycle's outcomes, we are able\nto model a value estimator and a policy generator for given states. By doing\nthat, we build up a balancing mechanism between exploration and exploitation,\nspeeding up the path planning process while maintaining its quality without\nusing human expert driver data."
  },
  {
    "paper_no": "2323",
    "authors": "Yang, Xuru; Hu, Yunze; Gao, Han; Ding, Kang; Li, Zhaoyang; Zhu, Pingping; Sun, Ying; Liu, Chang",
    "title": "Risk-Aware Non-Myopic Motion Planner for Large-Scale Robotic Swarm Using CVaR Constraints",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.16690v3",
    "arxiv_abstract": "Swarm robotics has garnered significant attention due to its ability to\naccomplish elaborate and synchronized tasks. Existing methodologies for motion\nplanning of swarm robotic systems mainly encounter difficulties in scalability\nand safety guarantee. To address these limitations, we propose a Risk-aware\nswarm mOtion planner using conditional ValuE at Risk (ROVER) that\nsystematically navigates large-scale swarms through cluttered environments\nwhile ensuring safety. ROVER formulates a finite-time model predictive control\n(FTMPC) problem predicated upon the macroscopic state of the robot swarm\nrepresented by a Gaussian Mixture Model (GMM) and integrates conditional\nvalue-at-risk (CVaR) to ensure collision avoidance. The key component of ROVER\nis imposing a CVaR constraint on the distribution of the Signed Distance\nFunction between the swarm GMM and obstacles in the FTMPC to enforce collision\navoidance. Utilizing the analytical expression of CVaR of a GMM derived in this\nwork, we develop a computationally efficient solution to solve the non-linear\nconstrained FTMPC through sequential linear programming. Simulations and\ncomparisons with representative benchmark approaches demonstrate the\neffectiveness of ROVER in flexibility, scalability, and risk mitigation."
  },
  {
    "paper_no": "2325",
    "authors": "Chen, Anthony Siming; Lopez Pulgarin, Erwin Jose; Herrmann, Guido; Lanzon, Alexander; Carrasco, Joaquin; Lennox, Barry; Carrera-Knowles, Benji; Brotherhood, John; Sakaue, Tomoki; Kaiqiang, Zhang",
    "title": "Dynamics-Based Trajectory Planning for Vibration Suppression of a Flexible Long-Reach Robotic Manipulator System",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2327",
    "authors": "Kashwani, Fatima; Hassan, Bilal; Kong, Peng-Yong; Khonji, Majid; Dias, Jorge",
    "title": "Evaluation of Predictive Display for Teleoperated Driving using CARLA Simulator",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2328",
    "authors": "Biggs, Benjamin; Stilwell, Daniel; Yetkin, Harun; McMahon, James",
    "title": "Efficient Feature Mapping Using a Collaborative Team of AUVs",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.19409v1",
    "arxiv_abstract": "We present the results of experiments performed using a team of small\nautonomous underwater vehicles (AUVs) to determine the location of an isobath.\nThe primary contributions of this work are (1) the development of a novel\nobjective function for level set estimation that utilizes a rigorous assessment\nof uncertainty, and (2) a description of the practical challenges and\ncorresponding solutions needed to implement our approach in the field using a\nteam of AUVs. We combine path planning techniques and an approach to\ndecentralization from prior work that yields theoretical performance\nguarantees. Experimentation with a team of AUVs provides empirical evidence\nthat the desirable performance guarantees can be preserved in practice even in\nthe presence of limitations that commonly arise in underwater robotics,\nincluding slow and intermittent acoustic communications and limited\ncomputational resources."
  },
  {
    "paper_no": "2333",
    "authors": "Ha, Nayoung; Ye, Ruolin; Liu, Ziang; Sinha, Shubhangi; Madan, Rishabh; Bhattacharjee, Tapomayukh",
    "title": "REPeat: A Real2Sim2Real Approach for Pre-acquisition of Soft Food Items in Robot-assisted Feeding",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2335",
    "authors": "Xiong, Ziyan; chen, bo; Huang, Shiyu; Tu, Wei-Wei; He, Zhaofeng; Gao, Yang",
    "title": "MQE: Unleashing the Power of Interaction with Multi-agent Quadruped Environment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2336",
    "authors": "Lu, Siyi; Zhong, Ping; Ye, Shuqi; Chen, Bolei; Yu, Sheng; Liu, Run",
    "title": "SocialNav-FTI: Field-Theory-Inspired Social-aware Navigation Framework based on Human Behavior and Social Norms",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2339",
    "authors": "Pohl, Christoph; Reister, Fabian; Peller-Konrad, Fabian; Asfour, Tamim",
    "title": "MAkEable: Memory-centered and Affordance-based Task Execution Framework for Transferable Mobile Manipulation Skills",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2340",
    "authors": "Dindarloo, Mohammadreza; Mirjalili, Amir Saman; Khalilpour, S. Ahmad; Khorrambakht, Rooholla; Weiss, Stephan; Taghirad, Hamid D.",
    "title": "A Graph-Based Self-Calibration Technique for Cable-Driven Robots with Sagging Cable",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2341",
    "authors": "Zhang, Tianxiang; zhang, xuanxuan; Liao, Zongbo; Xia, Xin; Li, You",
    "title": "AS-LIO: Spatial Overlap Guided Adaptive Sliding Window LiDAR-Inertial Odometry for Aggressive FOV Variation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2343",
    "authors": "Chen, Zhengqi; Versace, Elisabetta; Jamone, Lorenzo",
    "title": "3D Localization of Objects Buried within Granular Materials Using a Distributed 3-Axis Tactile Sensor",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2348",
    "authors": "Zhang, Zhitian; Li, Anjian; Lim, Angelica; Chen, Mo",
    "title": "Predicting Long-Term Human Behaviors in Discrete Representations via Physics-Guided Diffusion",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.19528v1",
    "arxiv_abstract": "Long-term human trajectory prediction is a challenging yet critical task in\nrobotics and autonomous systems. Prior work that studied how to predict\naccurate short-term human trajectories with only unimodal features often failed\nin long-term prediction. Reinforcement learning provides a good solution for\nlearning human long-term behaviors but can suffer from challenges in data\nefficiency and optimization. In this work, we propose a long-term human\ntrajectory forecasting framework that leverages a guided diffusion model to\ngenerate diverse long-term human behaviors in a high-level latent action space,\nobtained via a hierarchical action quantization scheme using a VQ-VAE to\ndiscretize continuous trajectories and the available context. The latent\nactions are predicted by our guided diffusion model, which uses\nphysics-inspired guidance at test time to constrain generated multimodal action\ndistributions. Specifically, we use reachability analysis during the reverse\ndenoising process to guide the diffusion steps toward physically feasible\nlatent actions. We evaluate our framework on two publicly available human\ntrajectory forecasting datasets: SFU-Store-Nav and JRDB, and extensive\nexperimental results show that our framework achieves superior performance in\nlong-term human trajectory forecasting."
  },
  {
    "paper_no": "2351",
    "authors": "Vanteddu, Punith Reddy; Nava, Gabriele; Bergonti, Fabio; L'Erario, Giuseppe; Paolino, Antonello; Pucci, Daniele",
    "title": "From CAD to URDF: Co-Design of a Jet-Powered Humanoid Robot Including CAD Geometry",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.07963v2",
    "arxiv_abstract": "Co-design optimization strategies usually rely on simplified robot models\nextracted from CAD. While these models are useful for optimizing geometrical\nand inertial parameters for robot control, they might overlook important\ndetails essential for prototyping the optimized mechanical design. For\ninstance, they may not account for mechanical stresses exerted on the optimized\ngeometries and the complexity of assembly-level design. In this paper, we\nintroduce a co-design framework aimed at improving both the control performance\nand mechanical design of our robot. Specifically, we identify the robot links\nthat significantly influence control performance. The geometric characteristics\nof these links are parameterized and optimized using a multi-objective\nevolutionary algorithm to achieve optimal control performance. Additionally, an\nautomated Finite Element Method (FEM) analysis is integrated into the framework\nto filter solutions not satisfying the required structural safety margin. We\nvalidate the framework by applying it to enhance the mechanical design for\nflight performance of the jet-powered humanoid robot iRonCub."
  },
  {
    "paper_no": "2352",
    "authors": "Pabon, Luis; Köhler, Johannes; Alora, John Irvin; Eberhard, Patrick Benito; Carron, Andrea; Zeilinger, Melanie N.; Pavone, Marco",
    "title": "Perfecting Periodic Trajectory Tracking: Model Predictive Control with a Periodic Observer",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.01550v2",
    "arxiv_abstract": "In Model Predictive Control (MPC), discrepancies between the actual system\nand the predictive model can lead to substantial tracking errors and\nsignificantly degrade performance and reliability. While such discrepancies can\nbe alleviated with more complex models, this often complicates controller\ndesign and implementation. By leveraging the fact that many trajectories of\ninterest are periodic, we show that perfect tracking is possible when\nincorporating a simple observer that estimates and compensates for periodic\ndisturbances. We present the design of the observer and the accompanying\ntracking MPC scheme, proving that their combination achieves zero tracking\nerror asymptotically, regardless of the complexity of the unmodelled dynamics.\nWe validate the effectiveness of our method, demonstrating asymptotically\nperfect tracking on a high-dimensional soft robot with nearly 10,000 states and\na fivefold reduction in tracking errors compared to a baseline MPC on\nsmall-scale autonomous race car experiments."
  },
  {
    "paper_no": "2354",
    "authors": "Shan, Jiwei; Li, Yirui; Feng, Qiyu; Wang, Hesheng",
    "title": "SoftNeRF: A self-modeling soft robot plugin for various tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2356",
    "authors": "Pueyo, Pablo; Montijano, Eduardo; Murillo, Ana Cristina; Schwager, Mac",
    "title": "CLIPSwarm: Generating Drone Shows from Text Prompts with Vision-Language Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2357",
    "authors": "Wang, Zihan; Li, Jianwen; Mahmoudian, Nina",
    "title": "Synergistic Reinforcement and Imitation Learning for Vision-driven Autonomous Flight of UAV Along River",
    "arxiv_pdf": "http://arxiv.org/pdf/2401.09332v2",
    "arxiv_abstract": "Vision-driven autonomous flight and obstacle avoidance of Unmanned Aerial\nVehicles (UAVs) along complex riverine environments for tasks like rescue and\nsurveillance requires a robust control policy, which is yet difficult to obtain\ndue to the shortage of trainable riverine environment simulators. To easily\nverify the vision-based navigation controller performance for the river\nfollowing task before real-world deployment, we developed a trainable\nphoto-realistic dynamics-free riverine simulation environment using Unity. In\nthis paper, we address the shortcomings that vanilla Reinforcement Learning\n(RL) algorithm encounters in learning a navigation policy within this partially\nobservable, non-Markovian environment. We propose a synergistic approach that\nintegrates RL and Imitation Learning (IL). Initially, an IL expert is trained\non manually collected demonstrations, which then guides the RL policy training\nprocess. Concurrently, experiences generated by the RL agent are utilized to\nre-train the IL expert, enhancing its ability to generalize to unseen data. By\nleveraging the strengths of both RL and IL, this framework achieves a faster\nconvergence rate and higher performance compared to pure RL, pure IL, and RL\ncombined with static IL algorithms. The results validate the efficacy of the\nproposed method in terms of both task completion and efficiency. The code and\ntrainable environments are available."
  },
  {
    "paper_no": "2362",
    "authors": "Gorodetsky, Andrey; Mironov, Konstantin; Panov, Aleksandr",
    "title": "Model-based Policy Optimization using Symbolic World Model",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.13518v1",
    "arxiv_abstract": "The application of learning-based control methods in robotics presents\nsignificant challenges. One is that model-free reinforcement learning\nalgorithms use observation data with low sample efficiency. To address this\nchallenge, a prevalent approach is model-based reinforcement learning, which\ninvolves employing an environment dynamics model. We suggest approximating\ntransition dynamics with symbolic expressions, which are generated via symbolic\nregression. Approximation of a mechanical system with a symbolic model has\nfewer parameters than approximation with neural networks, which can potentially\nlead to higher accuracy and quality of extrapolation. We use a symbolic\ndynamics model to generate trajectories in model-based policy optimization to\nimprove the sample efficiency of the learning algorithm. We evaluate our\napproach across various tasks within simulated environments. Our method\ndemonstrates superior sample efficiency in these tasks compared to model-free\nand model-based baseline methods."
  },
  {
    "paper_no": "2363",
    "authors": "Guo, Yifan; Ren, Zhongqiang; Wang, Chen",
    "title": "iMTSP: Solving Min-Max Multiple Traveling Salesman Problem with Imperative Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2364",
    "authors": "Bhattacharjee, Abhinaba; She, Yu; Anwar, Sohel; Uppuluri, Raghava",
    "title": "A visually-guided tactile exploration policy for 3D reconstruction and localization of sub-dermal tumors with surgical robotic palpation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2366",
    "authors": "Vogt, Michel Ryan; Eberlein, Maximilian; Christoph, Clemens Claudio; Baumann, Felix; Bourquin, Fabrice; Wende, Wim; Schaub, Fabio; Kazemipour, Amirhossein; Katzschmann, Robert Kevin",
    "title": "High-Frequency Capacitive Sensing for Electrohydraulic Soft Actuators",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.04071v2",
    "arxiv_abstract": "The need for compliant and proprioceptive actuators has grown more evident in\npursuing more adaptable and versatile robotic systems. Hydraulically Amplified\nSelf-Healing Electrostatic (HASEL) actuators offer distinctive advantages with\ntheir inherent softness and flexibility, making them promising candidates for\nvarious robotic tasks, including delicate interactions with humans and animals,\nbiomimetic locomotion, prosthetics, and exoskeletons. This has resulted in a\ngrowing interest in the capacitive self-sensing capabilities of HASEL actuators\nto create miniature displacement estimation circuitry that does not require\nexternal sensors. However, achieving HASEL self-sensing for actuation\nfrequencies above 1 Hz and with miniature high-voltage power supplies has\nremained limited. In this paper, we introduce the F-HASEL actuator, which adds\nan additional electrode pair used exclusively for capacitive sensing to a\nPeano-HASEL actuator. We demonstrate displacement estimation of the F-HASEL\nduring high-frequency actuation up to 20 Hz and during external loading using\nminiaturized circuitry comprised of low-cost off-the-shelf components and a\nminiature high-voltage power supply. Finally, we propose a circuitry to\nestimate the displacement of multiple F-HASELs and demonstrate it in a wearable\napplication to track joint rotations of a virtual reality user in real-time."
  },
  {
    "paper_no": "2367",
    "authors": "Cornelio, Cristina; Diab, Mohammed",
    "title": "RECOVER: A Neuro-Symbolic Framework for Failure Detection and Recovery",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2368",
    "authors": "Lin, Fangze; He, Ying; Yu, Fei",
    "title": "PP-TIL: Personalized Planning for Autonomous Driving with Instance-based Transfer Imitation Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2371",
    "authors": "Forouhar, Moein; Sadeghian, Hamid; Pérez-Suay, Daniel; Naceri, Abdeldjallil; Haddadin, Sami",
    "title": "A Tactile Lightweight Exoskeleton for Teleoperation; Design and Control Performance",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2373",
    "authors": "Herb, Markus; Navab, Nassir; Tombari, Federico",
    "title": "Neural Semantic Map-Learning for Autonomous Vehicles",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.07780v1",
    "arxiv_abstract": "Autonomous vehicles demand detailed maps to maneuver reliably through\ntraffic, which need to be kept up-to-date to ensure a safe operation. A\npromising way to adapt the maps to the ever-changing road-network is to use\ncrowd-sourced data from a fleet of vehicles. In this work, we present a mapping\nsystem that fuses local submaps gathered from a fleet of vehicles at a central\ninstance to produce a coherent map of the road environment including drivable\narea, lane markings, poles, obstacles and more as a 3D mesh. Each vehicle\ncontributes locally reconstructed submaps as lightweight meshes, making our\nmethod applicable to a wide range of reconstruction methods and sensor\nmodalities. Our method jointly aligns and merges the noisy and incomplete local\nsubmaps using a scene-specific Neural Signed Distance Field, which is\nsupervised using the submap meshes to predict a fused environment\nrepresentation. We leverage memory-efficient sparse feature-grids to scale to\nlarge areas and introduce a confidence score to model uncertainty in scene\nreconstruction. Our approach is evaluated on two datasets with different local\nmapping methods, showing improved pose alignment and reconstruction over\nexisting methods. Additionally, we demonstrate the benefit of multi-session\nmapping and examine the required amount of data to enable high-fidelity map\nlearning for autonomous vehicles."
  },
  {
    "paper_no": "2374",
    "authors": "Ramirez Montero, Mariano; Franzese, Giovanni; Kober, Jens; Della Santina, Cosimo",
    "title": "Learning Multi-Reference Frame Skills from Demonstration with Task-Parameterized Gaussian Processes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2375",
    "authors": "Narayanan, Aditya; Kasibhatla, Pranav; Choi, Minkyu; Li, Po-han; Zhao, Ruihan; Chinchali, Sandeep",
    "title": "PEERNet: An End-to-End Profiling Tool for Real-Time Networked Robotic Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2376",
    "authors": "taghavi, pardis; Pandey, Gaurav; Langari, Reza",
    "title": "SwinMTL: A Shared Architecture for Simultaneous Depth Estimation and Semantic Segmentation from Monocular Camera Images",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2377",
    "authors": "Seshasayanan, Sathyanarayanan; Sahoo, Soumya Ranjan",
    "title": "Robust Backstepping Controller with Adaptive Sliding Mode Observer for a Tilt-Augmented Quadrotor With Uncertainty Using SO(3)",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2378",
    "authors": "Jia, Yufei; Wang, Zifan; Wang, Haoyu; Li, Xueyang; Zhao, Haizhou; Zhou, Guyue; Shi, Lu; Ma, Jun; ZHOU, Jinni",
    "title": "Arm-Constrained Curriculum Learning for Loco-Manipulation of the Wheel-legged Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2379",
    "authors": "Papagiannis, Georgios; Dreczkowski, Kamil; Vosylius, Vitalis; Johns, Edward",
    "title": "Adapting Skills to Different Grasps: A Self-Supervised Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2380",
    "authors": "Agishev, Ruslan; Zimmermann, Karel; Kubelka, Vladimir; Pecka, Martin; Svoboda, Tomas",
    "title": "MonoForce: Self-supervised Learning of Physics-aware Model for Predicting Robot-terrain Interaction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2383",
    "authors": "Xie, Yue; Pinskier, Joshua; Liow, Lois; Howard, David; Iida, Fumiya",
    "title": "A 'MAP' to find high-performing soft robot designs: Traversing complex design spaces using MAP-elites and Topology Optimization",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.07591v1",
    "arxiv_abstract": "Soft robotics has emerged as the standard solution for grasping deformable\nobjects, and has proven invaluable for mobile robotic exploration in extreme\nenvironments. However, despite this growth, there are no widely adopted\ncomputational design tools that produce quality, manufacturable designs. To\nadvance beyond the diminishing returns of heuristic bio-inspiration, the field\nneeds efficient tools to explore the complex, non-linear design spaces present\nin soft robotics, and find novel high-performing designs. In this work, we\ninvestigate a hierarchical design optimization methodology which combines the\nstrengths of topology optimization and quality diversity optimization to\ngenerate diverse and high-performance soft robots by evolving the design\ndomain. The method embeds variably sized void regions within the design domain\nand evolves their size and position, to facilitating a richer exploration of\nthe design space and find a diverse set of high-performing soft robots. We\ndemonstrate its efficacy on both benchmark topology optimization problems and\nsoft robotic design problems, and show the method enhances grasp performance\nwhen applied to soft grippers. Our method provides a new framework to design\nparts in complex design domains, both soft and rigid."
  },
  {
    "paper_no": "2384",
    "authors": "Xie, Gregory; Chin, Lillian; Kim, Byungchul; Holladay, Rachel; Rus, Daniela",
    "title": "Strong Compliant Grasps Using a Cable-Driven Soft Gripper",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2385",
    "authors": "Huang, Tianle; Sontakke, Nitish Rajnish; Kannabiran, Niranjan Kumar; Essa, Irfan; Nikolaidis, Stefanos; Hong, Dennis; Ha, Sehoon",
    "title": "BayRnTune: Adaptive Bayesian Domain Randomization via Strategic Fine-tuning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2387",
    "authors": "Kirschner, Robin Jeanne; Yang, Jinyu; Elshani, Edonis; Micheler, Carina M.; Leibbrand, Tobias; Müller, Dirk; Glowalla, Claudio; Rajaei, Nader; Burgkart, Rainer; Haddadin, Sami",
    "title": "Towards Unconstrained Collision Injury Protection Data Sets: Initial Surrogate Experiments for the Human Hand",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.06175v3",
    "arxiv_abstract": "Safety for physical human-robot interaction (pHRI) is a major concern for all\napplication domains. While current standardization for industrial robot\napplications provide safety constraints that address the onset of pain in blunt\nimpacts, these impact thresholds are difficult to use on edged or pointed\nimpactors. The most severe injuries occur in constrained contact scenarios,\nwhere crushing is possible. Nevertheless, situations potentially resulting in\nconstrained contact only occur in certain areas of a workspace and design or\norganisational approaches can be used to avoid them. What remains are risks to\nthe human physical integrity caused by unconstrained accidental contacts, which\nare difficult to avoid while maintaining robot motion efficiency. Nevertheless,\nthe probability and severity of injuries occurring with edged or pointed\nimpacting objects in unconstrained collisions is hardly researched. In this\npaper, we propose an experimental setup and procedure using two pendulums\nmodeling human hands and arms and robots to understand the injury potential of\nunconstrained collisions of human hands with edged objects. Pig feet are used\nas ex vivo surrogate samples - as these closely resemble the physiological\ncharacteristics of human hands - to create an initial injury database on the\nseverity of injuries caused by unconstrained edged or pointed impacts. For the\neffective mass range of typical lightweight robots, the data obtained show low\nprobabilities of injuries such as skin cuts or bone/tendon injuries in\nunconstrained collisions when the velocity is reduced to < 0.5 m/s. The\nproposed experimental setups and procedures should be complemented by\nsufficient human modeling and will eventually lead to a complete understanding\nof the biomechanical injury potential in pHRI."
  },
  {
    "paper_no": "2388",
    "authors": "Luo, Rui; Zolotas, Mark; Moore, Drake; Padir, Taskin",
    "title": "User-customizable Shared Control for Fine Teleoperation via Virtual Reality",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13177v2",
    "arxiv_abstract": "Shared control can ease and enhance a human operator's ability to teleoperate\nrobots, particularly for intricate tasks demanding fine control over multiple\ndegrees of freedom. However, the arbitration process dictating how much\nautonomous assistance to administer in shared control can confuse novice\noperators and impede their understanding of the robot's behavior. To overcome\nthese adverse side-effects, we propose a novel formulation of shared control\nthat enables operators to tailor the arbitration to their unique capabilities\nand preferences. Unlike prior approaches to customizable shared control where\nusers could indirectly modify the latent parameters of the arbitration function\nby issuing a feedback command, we instead make these parameters observable and\ndirectly editable via a virtual reality (VR) interface. We present our\nuser-customizable shared control method for a teleoperation task in SE(3),\nknown as the buzz wire game. A user study is conducted with participants\nteleoperating a robotic arm in VR to complete the game. The experiment spanned\ntwo weeks per subject to investigate longitudinal trends. Our findings reveal\nthat users allowed to interactively tune the arbitration parameters across\ntrials generalize well to adaptations in the task, exhibiting improvements in\nprecision and fluency over direct teleoperation and conventional shared\ncontrol."
  },
  {
    "paper_no": "2390",
    "authors": "Sewlia, Mayank; Verginis, Christos; Dimarogonas, Dimos V.",
    "title": "Leader-Follower Cooperative Manipulation Under Spatio-Temporal Constraints",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2393",
    "authors": "Fusaro, Daniel; Mosco, Simone; Menegatti, Emanuele; Pretto, Alberto",
    "title": "Exploiting Local Features and Range Images for Small Data Real-Time Point Cloud Semantic Segmentation",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.10510v1",
    "arxiv_abstract": "Semantic segmentation of point clouds is an essential task for understanding\nthe environment in autonomous driving and robotics. Recent range-based works\nachieve real-time efficiency, while point- and voxel-based methods produce\nbetter results but are affected by high computational complexity. Moreover,\nhighly complex deep learning models are often not suited to efficiently learn\nfrom small datasets. Their generalization capabilities can easily be driven by\nthe abundance of data rather than the architecture design. In this paper, we\nharness the information from the three-dimensional representation to\nproficiently capture local features, while introducing the range image\nrepresentation to incorporate additional information and facilitate fast\ncomputation. A GPU-based KDTree allows for rapid building, querying, and\nenhancing projection with straightforward operations. Extensive experiments on\nSemanticKITTI and nuScenes datasets demonstrate the benefits of our\nmodification in a ``small data'' setup, in which only one sequence of the\ndataset is used to train the models, but also in the conventional setup, where\nall sequences except one are used for training. We show that a reduced version\nof our model not only demonstrates strong competitiveness against full-scale\nstate-of-the-art models but also operates in real-time, making it a viable\nchoice for real-world case applications. The code of our method is available at\nhttps://github.com/Bender97/WaffleAndRange."
  },
  {
    "paper_no": "2396",
    "authors": "Ait Bouhsain, Smail; Alami, Rachid; Simeon, Thierry",
    "title": "Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2398",
    "authors": "Zhang, Yi; Larby, Daniel; Iida, Fumiya; Forni, Fulvio",
    "title": "Virtual model control for compliant reaching under uncertainties",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2399",
    "authors": "Lin, Yue; Liu, Yang; Zhang, Pingping; CHEN, Xin; Wang, Dong; Lu, Huchuan",
    "title": "Safety-First Tracker: A Trajectory Planning Framework for Omnidirectional Robot Tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2400",
    "authors": "Eschmann, Jonas; Albani, Dario; Loianno, Giuseppe",
    "title": "Data-Driven System Identification of Quadrotors Subject to Motor Delays",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.07837v2",
    "arxiv_abstract": "Recently non-linear control methods like Model Predictive Control (MPC) and\nReinforcement Learning (RL) have attracted increased interest in the quadrotor\ncontrol community. In contrast to classic control methods like cascaded PID\ncontrollers, MPC and RL heavily rely on an accurate model of the system\ndynamics. The process of quadrotor system identification is notoriously tedious\nand is often pursued with additional equipment like a thrust stand.\nFurthermore, low-level details like motor delays which are crucial for accurate\nend-to-end control are often neglected. In this work, we introduce a\ndata-driven method to identify a quadrotor's inertia parameters, thrust curves,\ntorque coefficients, and first-order motor delay purely based on proprioceptive\ndata. The estimation of the motor delay is particularly challenging as usually,\nthe RPMs can not be measured. We derive a Maximum A Posteriori (MAP)-based\nmethod to estimate the latent time constant. Our approach only requires about a\nminute of flying data that can be collected without any additional equipment\nand usually consists of three simple maneuvers. Experimental results\ndemonstrate the ability of our method to accurately recover the parameters of\nmultiple quadrotors. It also facilitates the deployment of RL-based, end-to-end\nquadrotor control of a large quadrotor under harsh, outdoor conditions."
  },
  {
    "paper_no": "2403",
    "authors": "Tang, Chencheng; Althoff, Matthias",
    "title": "Formal and Efficient Guarantees for Robotic Contact Tasks using Reachset Conformance",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2404",
    "authors": "Jung, Sangwoo; Yang, Wooseong; Kim, Ayoung",
    "title": "Co-RaL: Complementary Radar-Leg Odometry with 4-DoF Optimization and Rolling Contact",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2408",
    "authors": "Jiang, Qingyuan; Susam, Burak; Chao, Jun-Jee; Isler, Volkan",
    "title": "Map-Aware Human Pose Prediction for Robot Follow-Ahead",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2412",
    "authors": "Heppert, Nick; Argus, Maximilian; Welschehold, Tim; Brox, Thomas; Valada, Abhinav",
    "title": "DITTO: Demonstration Imitation by Trajectory Transformation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2415",
    "authors": "Arzberger, Fabian; Nuechter, Andreas",
    "title": "On the 3D trochoidal motion model of LiDAR sensors placed off-centered inside spherical mobile mapping systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2417",
    "authors": "Mao, Xiaofeng; Giudici, Gabriele; Coppola, Claudio; Althoefer, Kaspar; Farkhatdinov, Ildar; Li, Zhibin (Alex); Jamone, Lorenzo",
    "title": "DexSkills: Skill Segmentation Using Haptic Data for Learning Autonomous Long-Horizon Robotic Manipulation Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2418",
    "authors": "Shahzad, Muhammad Zaeem; Hanif, Muhammad Abdullah; Shafique, Muhammad",
    "title": "DECADE: Towards Designing Efficient-yet-Accurate Distance Estimation Modules for Collision Avoidance in Mobile Advanced Driver Assistance Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2421",
    "authors": "Frosi, Matteo; Usuelli, Mirko; Matteucci, Matteo",
    "title": "Advancements in Radar Odometry",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.12729v2",
    "arxiv_abstract": "Radar odometry estimation has emerged as a critical technique in the field of\nautonomous navigation, providing robust and reliable motion estimation under\nvarious environmental conditions. Despite its potential, the complex nature of\nradar signals and the inherent challenges associated with processing these\nsignals have limited the widespread adoption of this technology. This paper\naims to address these challenges by proposing novel improvements to an existing\nmethod for radar odometry estimation, designed to enhance accuracy and\nreliability in diverse scenarios. Our pipeline consists of filtering, motion\ncompensation, oriented surface points computation, smoothing, one-to-many radar\nscan registration, and pose refinement. The developed method enforces local\nunderstanding of the scene, by adding additional information through smoothing\ntechniques, and alignment of consecutive scans, as a refinement posterior to\nthe one-to-many registration. We present an in-depth investigation of the\ncontribution of each improvement to the localization accuracy, and we benchmark\nour system on the sequences of the main datasets for radar understanding, i.e.,\nthe Oxford Radar RobotCar, MulRan, and Boreas datasets. The proposed pipeline\nis able to achieve superior results, on all scenarios considered and under\nharsh environmental constraints."
  },
  {
    "paper_no": "2423",
    "authors": "Schuster, Micha; Bredenbeck, Anton; Beitelschmidt, Michael; Hamaza, Salua",
    "title": "Tactile Odometry in Aerial Physical Interaction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2424",
    "authors": "Casao, Sara; Peña, Fernando; Sabater, Alberto; Castillón, Rosa; Suárez, Darío; Montijano, Eduardo; Murillo, Ana Cristina",
    "title": "SpectralWaste Dataset: Multimodal Data for Waste Sorting Automation",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.18033v1",
    "arxiv_abstract": "The increase in non-biodegradable waste is a worldwide concern. Recycling\nfacilities play a crucial role, but their automation is hindered by the complex\ncharacteristics of waste recycling lines like clutter or object deformation. In\naddition, the lack of publicly available labeled data for these environments\nmakes developing robust perception systems challenging. Our work explores the\nbenefits of multimodal perception for object segmentation in real waste\nmanagement scenarios. First, we present SpectralWaste, the first dataset\ncollected from an operational plastic waste sorting facility that provides\nsynchronized hyperspectral and conventional RGB images. This dataset contains\nlabels for several categories of objects that commonly appear in sorting plants\nand need to be detected and separated from the main trash flow for several\nreasons, such as security in the management line or reuse. Additionally, we\npropose a pipeline employing different object segmentation architectures and\nevaluate the alternatives on our dataset, conducting an extensive analysis for\nboth multimodal and unimodal alternatives. Our evaluation pays special\nattention to efficiency and suitability for real-time processing and\ndemonstrates how HSI can bring a boost to RGB-only perception in these\nrealistic industrial settings without much computational overhead."
  },
  {
    "paper_no": "2426",
    "authors": "García Cárdenas, Juan José; Hei, Xiaoxuan; Tapus, Adriana",
    "title": "Exploring Cognitive Load Dynamics in Human-Machine Interaction for Teleoperation: A User-Centric Perspective on Remote Operation System Design",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2429",
    "authors": "Imran, Navid Mohammad; Won, Myounggyu",
    "title": "SmartPathfinder: Pushing the Limits of Heuristic Solutions for Vehicle Routing Problem with Drones Using Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2430",
    "authors": "Kiefer, Benjamin; Zell, Andreas",
    "title": "Real-Time Horizon Locking on Unmanned Surface Vehicles",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2431",
    "authors": "Swaminathan, Ruphan; Korupolu, Pradyot",
    "title": "Context-Aware GAN-based Image Retrieval for Coarse Localization of Autonomous Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2434",
    "authors": "Schakkal, André; Bellegarda, Guillaume; Ijspeert, Auke",
    "title": "Dynamic Object Catching with Quadruped Robot Front Legs",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.08065v1",
    "arxiv_abstract": "This paper presents a framework for dynamic object catching using a quadruped\nrobot's front legs while it stands on its rear legs. The system integrates\ncomputer vision, trajectory prediction, and leg control to enable the quadruped\nto visually detect, track, and successfully catch a thrown object using an\nonboard camera. Leveraging a fine-tuned YOLOv8 model for object detection and a\nregression-based trajectory prediction module, the quadruped adapts its front\nleg positions iteratively to anticipate and intercept the object. The catching\nmaneuver involves identifying the optimal catching position, controlling the\nfront legs with Cartesian PD control, and closing the legs together at the\nright moment. We propose and validate three different methods for selecting the\noptimal catching position: 1) intersecting the predicted trajectory with a\nvertical plane, 2) selecting the point on the predicted trajectory with the\nminimal distance to the center of the robot's legs in their nominal position,\nand 3) selecting the point on the predicted trajectory with the highest\nlikelihood on a Gaussian Mixture Model (GMM) modelling the robot's reachable\nspace. Experimental results demonstrate robust catching capabilities across\nvarious scenarios, with the GMM method achieving the best performance, leading\nto an 80% catching success rate. A video demonstration of the system in action\ncan be found at https://youtu.be/sm7RdxRfIYg ."
  },
  {
    "paper_no": "2438",
    "authors": "Miranda Pinheiro, Pedro; Alves Neto, Armando; G. Macharet, Douglas; Drews-Jr, Paulo",
    "title": "Energy-efficient Trajectory Planning with Media Transition for a Hybrid Unmanned Aerial-Underwater Vehicle",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2441",
    "authors": "Grosse Besselmann, Marvin; Häuselmann, Ramona; Mauch, Samuel; Puck, Lennart; Schnell, Tristan; Roennau, Arne; Dillmann, Rüdiger",
    "title": "3D Global Path Planning for Walking Robots on Sparse Volumetric Maps",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2442",
    "authors": "Pellerito, Roberto; Cannici, Marco; Gehrig, Daniel; Belhadj, Joris; Dubois-Matra, Olivier; Casasco, Massimo; Scaramuzza, Davide",
    "title": "End-to-end Learned Visual Odometry with Events and Frames",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2443",
    "authors": "Zhang, Ziqiao; Chen, Shengkang; Mayberry, Scott; Zhang, Fumin",
    "title": "Opinion-based Strategy for Distributed Multi-Robot Task Allocation in Swarms of Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2447",
    "authors": "Zarras, Ioannis; Mastrogeorgiou, Athanasios; Machairas, Konstantinos; Koutsoukis, Konstantinos; Papadopoulos, Evangelos",
    "title": "Vinymap: a Vineyard Inspection and 3D Reconstruction Framework for Agricultural Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2448",
    "authors": "Pan, Tianyang; Verginis, Christos; Kavraki, Lydia",
    "title": "Robust and Safe Task-Driven Planning and Navigation for Heterogeneous Multi-Robot Teams with Uncertain Dynamics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2455",
    "authors": "Rao, Pratyaksh; Saviolo, Alessandro; Castiglione Ferrari, Tommaso; Loianno, Giuseppe",
    "title": "Learning Long-Horizon Predictions for Quadrotor Dynamics",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.12964v1",
    "arxiv_abstract": "Accurate modeling of system dynamics is crucial for achieving\nhigh-performance planning and control of robotic systems. Although existing\ndata-driven approaches represent a promising approach for modeling dynamics,\ntheir accuracy is limited to a short prediction horizon, overlooking the impact\nof compounding prediction errors over longer prediction horizons. Strategies to\nmitigate these cumulative errors remain underexplored. To bridge this gap, in\nthis paper, we study the key design choices for efficiently learning\nlong-horizon prediction dynamics for quadrotors. Specifically, we analyze the\nimpact of multiple architectures, historical data, and multi-step loss\nformulation. We show that sequential modeling techniques showcase their\nadvantage in minimizing compounding errors compared to other types of\nsolutions. Furthermore, we propose a novel decoupled dynamics learning\napproach, which further simplifies the learning process while also enhancing\nthe approach modularity. Extensive experiments and ablation studies on\nreal-world quadrotor data demonstrate the versatility and precision of the\nproposed approach. Our outcomes offer several insights and methodologies for\nenhancing long-term predictive accuracy of learned quadrotor dynamics for\nplanning and control."
  },
  {
    "paper_no": "2458",
    "authors": "Kalithasan, Namasivayam; Tuli, Arnav; Bindal, Vishal; Singh, Himanshu Gaurav; Singla, Parag; Paul, Rohan",
    "title": "Learning to Recover from Plan Execution Errors during Robot Manipulation: A Neuro-symbolic Approach",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.18948v1",
    "arxiv_abstract": "Automatically detecting and recovering from failures is an important but\nchallenging problem for autonomous robots. Most of the recent work on learning\nto plan from demonstrations lacks the ability to detect and recover from errors\nin the absence of an explicit state representation and/or a (sub-) goal check\nfunction. We propose an approach (blending learning with symbolic search) for\nautomated error discovery and recovery, without needing annotated data of\nfailures. Central to our approach is a neuro-symbolic state representation, in\nthe form of dense scene graph, structured based on the objects present within\nthe environment. This enables efficient learning of the transition function and\na discriminator that not only identifies failures but also localizes them\nfacilitating fast re-planning via computation of heuristic distance function.\nWe also present an anytime version of our algorithm, where instead of\nrecovering to the last correct state, we search for a sub-goal in the original\nplan minimizing the total distance to the goal given a re-planning budget.\nExperiments on a physics simulator with a variety of simulated failures show\nthe effectiveness of our approach compared to existing baselines, both in terms\nof efficiency as well as accuracy of our recovery mechanism."
  },
  {
    "paper_no": "2459",
    "authors": "Braun, Max; Jaquier, Noémie; Rozo, Leonel; Asfour, Tamim",
    "title": "Riemannian Flow Matching Policy for Robot Motion Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10672v2",
    "arxiv_abstract": "We introduce Riemannian Flow Matching Policies (RFMP), a novel model for\nlearning and synthesizing robot visuomotor policies. RFMP leverages the\nefficient training and inference capabilities of flow matching methods. By\ndesign, RFMP inherits the strengths of flow matching: the ability to encode\nhigh-dimensional multimodal distributions, commonly encountered in robotic\ntasks, and a very simple and fast inference process. We demonstrate the\napplicability of RFMP to both state-based and vision-conditioned robot motion\npolicies. Notably, as the robot state resides on a Riemannian manifold, RFMP\ninherently incorporates geometric awareness, which is crucial for realistic\nrobotic tasks. To evaluate RFMP, we conduct two proof-of-concept experiments,\ncomparing its performance against Diffusion Policies. Although both approaches\nsuccessfully learn the considered tasks, our results show that RFMP provides\nsmoother action trajectories with significantly lower inference times."
  },
  {
    "paper_no": "2460",
    "authors": "Zhao, Shiyao; Xu, Yucheng; Kasaei, Mohammadreza; Li, Zhibin (Alex)",
    "title": "Neural ODE-based Imitation Learning (NODE-IL): Data-Efficient Imitation Learning for Long-Horizon Multi-Skill Robot Manipulation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2461",
    "authors": "Sun, Sunan; Figueroa, Nadia",
    "title": "SE(3) Linear Parameter Varying Dynamical Systems for Globally Asymptotically Stable End-Effector Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.16366v2",
    "arxiv_abstract": "Linear Parameter Varying Dynamical Systems (LPV-DS) encode trajectories into\nan autonomous first-order DS that enables reactive responses to perturbations,\nwhile ensuring globally asymptotic stability at the target. However, the\ncurrent LPV-DS framework is established on Euclidean data only and has not been\napplicable to broader robotic applications requiring pose control. In this\npaper we present an extension to the current LPV-DS framework, named\nQuaternion-DS, which efficiently learns a DS-based motion policy for\norientation. Leveraging techniques from differential geometry and Riemannian\nstatistics, our approach properly handles the non-Euclidean orientation data in\nquaternion space, enabling the integration with positional control, namely\nSE(3) LPV-DS, so that the synergistic behaviour within the full SE(3) pose is\npreserved. Through simulation and real robot experiments, we validate our\nmethod, demonstrating its ability to efficiently and accurately reproduce the\noriginal SE(3) trajectory while exhibiting strong robustness to perturbations\nin task space."
  },
  {
    "paper_no": "2467",
    "authors": "Szpirer, Jeanne; Garzón Ramos, David; Birattari, Mauro",
    "title": "Automatic design of robot swarms that perform composite missions: an approach based on inverse reinforcement learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2468",
    "authors": "Vogt, Christian; Jost, Michael; Magno, Michele",
    "title": "SwiftEagle: An Advanced Open-Source, Miniaturized FPGA UAS Platform with Dual DVS/Frame Camera for Cutting-Edge Low-Latency Autonomous Algorithms",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2469",
    "authors": "Hu, Zechen; Shishika, Daigo; Xiao, Xuesu; Wang, Xuan",
    "title": "Bi-CL: A Reinforcement Learning Framework for Robots Coordination Through Bi-level Optimization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2471",
    "authors": "Warke, William; Ramos, J Humberto; Ganesh, Prashant; Brink, Kevin; Hale, Matthew",
    "title": "Pose Graph Optimization over Planar Unit Dual Quaternions: Improved Accuracy with Provably Convergent Riemannian Optimization",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.00010v2",
    "arxiv_abstract": "It is common in pose graph optimization (PGO) algorithms to assume that noise\nin the translations and rotations of relative pose measurements is\nuncorrelated. However, existing work shows that in practice these measurements\ncan be highly correlated, which leads to degradation in the accuracy of PGO\nsolutions that rely on this assumption. Therefore, in this paper we develop a\nnovel algorithm derived from a realistic, correlated model of relative pose\nuncertainty, and we quantify the resulting improvement in the accuracy of the\nsolutions we obtain relative to state-of-the-art PGO algorithms. Our approach\nutilizes Riemannian optimization on the planar unit dual quaternion (PUDQ)\nmanifold, and we prove that it converges to first-order stationary points of a\nLie-theoretic maximum likelihood objective. Then we show experimentally that,\ncompared to state-of-the-art PGO algorithms, this algorithm produces estimation\nerrors that are lower by 10% to 25% across several orders of magnitude of noise\nlevels and graph sizes."
  },
  {
    "paper_no": "2477",
    "authors": "Theile, Mirco; Cao, Hongpeng; Caccamo, Marco; Sangiovanni Vincentelli, Alberto",
    "title": "Equivariant Ensembles and Regularization for Reinforcement Learning in Map-based Path Planning",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12856v3",
    "arxiv_abstract": "In reinforcement learning (RL), exploiting environmental symmetries can\nsignificantly enhance efficiency, robustness, and performance. However,\nensuring that the deep RL policy and value networks are respectively\nequivariant and invariant to exploit these symmetries is a substantial\nchallenge. Related works try to design networks that are equivariant and\ninvariant by construction, limiting them to a very restricted library of\ncomponents, which in turn hampers the expressiveness of the networks. This\npaper proposes a method to construct equivariant policies and invariant value\nfunctions without specialized neural network components, which we term\nequivariant ensembles. We further add a regularization term for adding\ninductive bias during training. In a map-based path planning case study, we\nshow how equivariant ensembles and regularization benefit sample efficiency and\nperformance."
  },
  {
    "paper_no": "2484",
    "authors": "Joshi, Amogh; Ponghiran, Wachirawit; Kosta, Adarsh Kumar; Nagaraj, Manish; Roy, Kaushik",
    "title": "FEDORA: A Flying Event Dataset fOr Reactive behAvior",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2487",
    "authors": "Sochopoulos, Andreas; Gienger, Michael; Vijayakumar, Sethu",
    "title": "Learning Deep Dynamical Systems using Stable Neural ODEs",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.10622v2",
    "arxiv_abstract": "Learning complex trajectories from demonstrations in robotic tasks has been\neffectively addressed through the utilization of Dynamical Systems (DS).\nState-of-the-art DS learning methods ensure stability of the generated\ntrajectories; however, they have three shortcomings: a) the DS is assumed to\nhave a single attractor, which limits the diversity of tasks it can achieve, b)\nstate derivative information is assumed to be available in the learning process\nand c) the state of the DS is assumed to be measurable at inference time. We\npropose a class of provably stable latent DS with possibly multiple attractors,\nthat inherit the training methods of Neural Ordinary Differential Equations,\nthus, dropping the dependency on state derivative information. A diffeomorphic\nmapping for the output and a loss that captures time-invariant trajectory\nsimilarity are proposed. We validate the efficacy of our approach through\nexperiments conducted on a public dataset of handwritten shapes and within a\nsimulated object manipulation task."
  },
  {
    "paper_no": "2490",
    "authors": "von Benzon, Malte; Marley, Mathias; Sørensen, Fredrik Fogh; Liniger, Jesper; Pedersen, Simon",
    "title": "Adaptive Control Barrier Functions for Near-Structure ROV Operations",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2491",
    "authors": "Wright, Herbert; Zhi, Weiming; Johnson-Roberson, Matthew; Hermans, Tucker",
    "title": "V-PRISM: Probabilistic Mapping of Unknown Tabletop Scenes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2495",
    "authors": "Lai, Wenqiang; Gao, Yuan; Lam, Tin Lun",
    "title": "Vision-Language Model-based Physical Reasoning for Robot Liquid Perception",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.06904v1",
    "arxiv_abstract": "There is a growing interest in applying large language models (LLMs) in\nrobotic tasks, due to their remarkable reasoning ability and extensive\nknowledge learned from vast training corpora. Grounding LLMs in the physical\nworld remains an open challenge as they can only process textual input. Recent\nadvancements in large vision-language models (LVLMs) have enabled a more\ncomprehensive understanding of the physical world by incorporating visual\ninput, which provides richer contextual information than language alone. In\nthis work, we proposed a novel paradigm that leveraged GPT-4V(ision), the\nstate-of-the-art LVLM by OpenAI, to enable embodied agents to perceive liquid\nobjects via image-based environmental feedback. Specifically, we exploited the\nphysical understanding of GPT-4V to interpret the visual representation (e.g.,\ntime-series plot) of non-visual feedback (e.g., F/T sensor data), indirectly\nenabling multimodal perception beyond vision and language using images as\nproxies. We evaluated our method using 10 common household liquids with\ncontainers of various geometry and material. Without any training or\nfine-tuning, we demonstrated that our method can enable the robot to indirectly\nperceive the physical response of liquids and estimate their viscosity. We also\nshowed that by jointly reasoning over the visual and physical attributes\nlearned through interactions, our method could recognize liquid objects in the\nabsence of strong visual cues (e.g., container labels with legible text or\nsymbols), increasing the accuracy from 69.0% -- achieved by the best-performing\nvision-only variant -- to 86.0%."
  },
  {
    "paper_no": "2499",
    "authors": "Seyde, Tim Niklas; Lechner, Mathias; Rountree, Joshua; Rus, Daniela",
    "title": "Competitive Multi-Team Behavior in Dynamic Flight Scenarios",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2503",
    "authors": "Huang, Junjie; Zhang, Yunzhou; Xu, Qingdong; Wu, Song; Liu, Jun; Wang, Guiyuan; Liu, Wei",
    "title": "LA-LIO: Robust Localizability-Aware LiDAR-Inertial Odometry for Challenging Scenes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2504",
    "authors": "Abubakar, Ahmad; Zweiri, Yahya; Yakubu, Mubarak; Alhammadi, Ruqqayya; Mohiuddin, Mohammed; Haddad, Abdel Gafoor; Dias, Jorge; Seneviratne, Lakmal",
    "title": "Deep Learning-based Delay Compensation Framework For Teleoperated Wheeled Rovers on Soft Terrains",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2509",
    "authors": "Aduh, Erica; Wang, Fan; Randle, Dylan Labatt; Wang, Kaiwen; Shah, Priyesh; Mitash, Chaitanya; Nambi, Manikantan",
    "title": "Avoiding Object Damage in Robotic Manipulation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2510",
    "authors": "da Silva, Zico; Muramatsu, Naoya; Parkar, Zuhayr; Nicolls, Fred; Patel, Amir",
    "title": "Monocular 3D Reconstruction of Cheetahs in the Wild",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2512",
    "authors": "Hoque, Ryan; Mandlekar, Ajay Uday; Garrett, Caelan; Goldberg, Ken; Fox, Dieter",
    "title": "Interventional Data Generation for Robust and Data-Efficient Robot Imitation Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.01472v1",
    "arxiv_abstract": "Imitation learning is a promising paradigm for training robot control\npolicies, but these policies can suffer from distribution shift, where the\nconditions at evaluation time differ from those in the training data. A popular\napproach for increasing policy robustness to distribution shift is interactive\nimitation learning (i.e., DAgger and variants), where a human operator provides\ncorrective interventions during policy rollouts. However, collecting a\nsufficient amount of interventions to cover the distribution of policy mistakes\ncan be burdensome for human operators. We propose IntervenGen (I-Gen), a novel\ndata generation system that can autonomously produce a large set of corrective\ninterventions with rich coverage of the state space from a small number of\nhuman interventions. We apply I-Gen to 4 simulated environments and 1 physical\nenvironment with object pose estimation error and show that it can increase\npolicy robustness by up to 39x with only 10 human interventions. Videos and\nmore results are available at https://sites.google.com/view/intervengen2024."
  },
  {
    "paper_no": "2517",
    "authors": "Sonawani, Shubham; Weigend, Fabian Clemens; Ben Amor, Heni",
    "title": "SiSCo: Signal Synthesis for Effective Human-Robot Communication via Large Language Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2518",
    "authors": "Gupta, Arjun; Zhang, Michelle; Gupta, Saurabh",
    "title": "Estimating Perceptual Uncertainty to Predict Robust Motion Plans",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2521",
    "authors": "Choi, Ingu; Kim, Eunchan; Yang, Sungwook",
    "title": "A Hybrid Vision/Force Control Strategy for Handheld Robotic Devices Enhancing Probe-Based Confocal Laser Endomicroscopy",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2523",
    "authors": "Reed, Alec; Crowe, Brendan; Albin, Doncey; Achey, Lorin; Hayes, Bradley; Heckman, Christoffer",
    "title": "SceneSense: Diffusion Models for 3D Occupancy Synthesis from Partial Observation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2524",
    "authors": "Shan, Jiwei; Li, Yirui; Yang, Lujia; Feng, Qiyu; Wang, Hesheng",
    "title": "DDS-SLAM: Dense Semantic Neural SLAM for Deforming Endoscopic Scenes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2527",
    "authors": "Tyagi, Abhishek; Tyagi, Abhay; Kaur, Manpreet; Aggarwal, Richa; Soni, Kapil Dev; Sivaswamy, Jayanthi; Trikha, Anjan",
    "title": "Nerve Block Target Localization and Needle Guidance for Autonomous Robotic Ultrasound Guided Regional Anesthesia",
    "arxiv_pdf": "http://arxiv.org/pdf/2308.03717v2",
    "arxiv_abstract": "Visual servoing for the development of autonomous robotic systems capable of\nadministering UltraSound (US) guided regional anesthesia requires real-time\nsegmentation of nerves, needle tip localization and needle trajectory\nextrapolation. First, we recruited 227 patients to build a large dataset of\n41,000 anesthesiologist annotated images from US videos of brachial plexus\nnerves and developed models to localize nerves in the US images.\nGeneralizability of the best suited model was tested on the datasets\nconstructed from separate US scanners. Using these nerve segmentation\npredictions, we define automated anesthesia needle targets by fitting an\nellipse to the nerve contours. Next, we developed an image analysis tool to\nguide the needle toward their targets. For the segmentation of the needle, a\nnatural RGB pre-trained neural network was first fine-tuned on a large US\ndataset for domain transfer and then adapted for the needle using a small\ndataset. The segmented needle trajectory angle is calculated using Radon\ntransformation and the trajectory is extrapolated from the needle tip. The\nintersection of the extrapolated trajectory with the needle target guides the\nneedle navigation for drug delivery. The needle trajectory average error was\nwithin acceptable range of 5 mm as per experienced anesthesiologists. The\nentire dataset has been released publicly for further study by the research\ncommunity at https://github.com/Regional-US/"
  },
  {
    "paper_no": "2529",
    "authors": "Aliyari, Yeganeh; Afshar, Mehrnoosh; Wiebe, Ericka; Peiris, Lashan; Tavakoli, Mahdi",
    "title": "A Novel Approach for Precise Tissue Tracking in Breast Lumpectomy",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2530",
    "authors": "Shamsah, Abdulaziz; Agarwal, Krishanu; Kousik, Shreyas; Zhao, Ye",
    "title": "Real-time Model Predictive Control with Zonotope-Based Neural Networks for Bipedal Social Navigation",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.16485v1",
    "arxiv_abstract": "This study addresses the challenge of bipedal navigation in a dynamic\nhuman-crowded environment, a research area that remains largely underexplored\nin the field of legged navigation. We propose two cascaded zonotope-based\nneural networks: a Pedestrian Prediction Network (PPN) for pedestrians' future\ntrajectory prediction and an Ego-agent Social Network (ESN) for ego-agent\nsocial path planning. Representing future paths as zonotopes allows for\nefficient reachability-based planning and collision checking. The ESN is then\nintegrated with a Model Predictive Controller (ESN-MPC) for footstep planning\nfor our bipedal robot Digit designed by Agility Robotics. ESN-MPC solves for a\ncollision-free optimal trajectory by optimizing through the gradients of ESN.\nESN-MPC optimal trajectory is sent to the low-level controller for full-order\nsimulation of Digit. The overall proposed framework is validated with extensive\nsimulations on randomly generated initial settings with varying human crowd\ndensities."
  },
  {
    "paper_no": "2531",
    "authors": "Sempertegui, Miguel; Zhu, J. Jim",
    "title": "Integrated 3DOF Trajectory Tracking Control for Underactuated Marine Surface Vehicles By Trajectory Linearization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2533",
    "authors": "Putta, Pranav; Aggarwal, Gunjan; Mottaghi, Roozbeh; Batra, Dhruv; Yokoyama, Naoki; Truong, Joanne; Majumdar, Arjun",
    "title": "Embodiment Randomization for Cross Embodiment Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2534",
    "authors": "Yang, Zhelin; Bien, Seongjin; Nertinger, Simone; Naceri, Abdeldjallil; Haddadin, Sami",
    "title": "An Optimization based Scheme for Real-time Transfer of Human Arm Motion to Robot Arm",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2537",
    "authors": "Ota, Kei; Jha, Devesh; Jain, Siddarth; Yerazunis, William; Corcodel, Radu; Shukla, Yash; Bronars, Antonia; Romeres, Diego",
    "title": "Autonomous Robotic Assembly: From Part Singulation to Precise Assembly",
    "arxiv_pdf": "http://arxiv.org/pdf/2406.05331v2",
    "arxiv_abstract": "Imagine a robot that can assemble a functional product from the individual\nparts presented in any configuration to the robot. Designing such a robotic\nsystem is a complex problem which presents several open challenges. To bypass\nthese challenges, the current generation of assembly systems is built with a\nlot of system integration effort to provide the structure and precision\nnecessary for assembly. These systems are mostly responsible for part\nsingulation, part kitting, and part detection, which is accomplished by\nintelligent system design. In this paper, we present autonomous assembly of a\ngear box with minimum requirements on structure. The assembly parts are\nrandomly placed in a two-dimensional work environment for the robot. The\nproposed system makes use of several different manipulation skills such as\nsliding for grasping, in-hand manipulation, and insertion to assemble the gear\nbox. All these tasks are run in a closed-loop fashion using vision, tactile,\nand Force-Torque (F/T) sensors. We perform extensive hardware experiments to\nshow the robustness of the proposed methods as well as the overall system. See\nsupplementary video at https://www.youtube.com/watch?v=cZ9M1DQ23OI."
  },
  {
    "paper_no": "2538",
    "authors": "Li, Samuel; Bhagat, Sarthak; Campbell, Joseph; Xie, Yaqi; Kim, Woojun; Sycara, Katia; Stepputtis, Simon",
    "title": "ShapeGrasp: Zero-Shot Task-Oriented Grasping with Large Language Models through Geometric Decomposition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2539",
    "authors": "Xu, Jinxuan; Jin, Shiyu; Lei, Yutian; Zhang, Yuqian; Zhang, Liangjun",
    "title": "RT-Grasp: Reasoning Tuning Robotic Grasping via Multi-modal Large Language Model",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2540",
    "authors": "Tafuro, Alessandra; Cacciani, Luigi; Zanchettin, Andrea Maria; Rocco, Paolo",
    "title": "Towards intelligent robotic sole deburring: from burrs identification to path planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2545",
    "authors": "Jung, Roland; Santoro, Luca; Brunelli, Davide; Fontanelli, Daniele; Weiss, Stephan",
    "title": "Modular Meshed Ultra-Wideband Aided Inertial Navigation with Robust Anchor Calibration",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.14081v1",
    "arxiv_abstract": "This paper introduces a generic filter-based state estimation framework that\nsupports two state-decoupling strategies based on cross-covariance\nfactorization. These strategies reduce the computational complexity and\ninherently support true modularity -- a perquisite for handling and processing\nmeshed range measurements among a time-varying set of devices. In order to\nutilize these measurements in the estimation framework, positions of newly\ndetected stationary devices (anchors) and the pairwise biases between the\nranging devices are required. In this work an autonomous calibration procedure\nfor new anchors is presented, that utilizes range measurements from multiple\ntags as well as already known anchors. To improve the robustness, an outlier\nrejection method is introduced. After the calibration is performed, the sensor\nfusion framework obtains initial beliefs of the anchor positions and\ndictionaries of pairwise biases, in order to fuse range measurements obtained\nfrom new anchors tightly-coupled. The effectiveness of the filter and\ncalibration framework has been validated through evaluations on a recorded\ndataset and real-world experiments."
  },
  {
    "paper_no": "2546",
    "authors": "Su, Zhidong; Sheng, Weihua",
    "title": "Context-Aware Conversation Adaptation for Human-Robot Interaction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2547",
    "authors": "Law, Arion; Nimal, Nillan; Kang, Paul Hoseok; Gondokaryono, Radian; Drake, James; Van Mieghem, Tim; Looi, Thomas",
    "title": "2.23mm Diameter Continuum Tools for Suturing in Open Spina Bifida Repair",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2551",
    "authors": "Akremi, Mohamed Sanim; neji, najett; Tabia, Hedi",
    "title": "SPDAGG-TransNet: Integrating Symmetric Positive Definite Networks with Transformers for UAV-Human Action Recognition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2554",
    "authors": "Thakur, Shilpa; Diaz Armas, Nathalia; Adegite, Joseph; Pandey, Ritwik; Mead, Joey; Rao, Pratap; Onal, Cagdas",
    "title": "A Tetherless Soft Robotic Wearable Haptic Human Machine Interface for Robot Teleoperation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2555",
    "authors": "Gaspard, Clément; Passault, Grégoire; DANIEL, Mélodie; Ly, Olivier",
    "title": "FootstepNet: an Efficient Actor-Critic Method for Fast On-line Bipedal Footstep Planning and Forecasting",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2556",
    "authors": "Ha, Thuc Long; Bert, Julien; Courtecuisse, Hadrien",
    "title": "Real-time Robotic Flexible Needle Insertion In Deformable Living Organs Using Isolated Objective Constraint",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2560",
    "authors": "Huang, Kaizhen; XU, Jiajun; Zhang, Tianyi; Zhao, Mengcheng; Ji, Aihong; Song, Guoli; Li, Y.F.",
    "title": "Human-Robot Interaction Control for Multi-Mode Exosuit with Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2562",
    "authors": "Wu, Bo; Lee, Bruce; Daniilidis, Kostas; Bucher, Bernadette; Matni, Nikolai",
    "title": "Uncertainty-Aware Deployment of Pre-trained Language-Conditioned Imitation Learning Policies",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2563",
    "authors": "Ortiz-Haro, Joaquim; Hoenig, Wolfgang; Hartmann, Valentin; Toussaint, Marc; Righetti, Ludovic",
    "title": "iDb-RRT: Sampling-based Kinodynamic Motion Planning with Motion Primitives and Trajectory Optimization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2564",
    "authors": "Olkin, Jake; Parimi, Viraj; Williams, Brian",
    "title": "Multi-Agent Vulcan: An Information-Driven Multi-Agent Path Finding Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2566",
    "authors": "Zhang, Hengyuan; Paz, David; Guo, Yuliang; Das, Arun; Huang, Xinyu; Karsten, Haug; Christensen, Henrik Iskov; Ren, Liu",
    "title": "Enhancing Online Road Network Perception and Reasoning with Standard Definition Maps",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.01471v1",
    "arxiv_abstract": "Autonomous driving for urban and highway driving applications often requires\nHigh Definition (HD) maps to generate a navigation plan. Nevertheless, various\nchallenges arise when generating and maintaining HD maps at scale. While recent\nonline mapping methods have started to emerge, their performance especially for\nlonger ranges is limited by heavy occlusion in dynamic environments. With these\nconsiderations in mind, our work focuses on leveraging lightweight and scalable\npriors-Standard Definition (SD) maps-in the development of online vectorized HD\nmap representations. We first examine the integration of prototypical\nrasterized SD map representations into various online mapping architectures.\nFurthermore, to identify lightweight strategies, we extend the OpenLane-V2\ndataset with OpenStreetMaps and evaluate the benefits of graphical SD map\nrepresentations. A key finding from designing SD map integration components is\nthat SD map encoders are model agnostic and can be quickly adapted to new\narchitectures that utilize bird's eye view (BEV) encoders. Our results show\nthat making use of SD maps as priors for the online mapping task can\nsignificantly speed up convergence and boost the performance of the online\ncenterline perception task by 30% (mAP). Furthermore, we show that the\nintroduction of the SD maps leads to a reduction of the number of parameters in\nthe perception and reasoning task by leveraging SD map graphs while improving\nthe overall performance. Project Page:\nhttps://henryzhangzhy.github.io/sdhdmap/."
  },
  {
    "paper_no": "2567",
    "authors": "Bertolini, Andrea",
    "title": "The subtle line between personalization and user manipulation in a European regulatory perspective. A proposal for a technology-assessment methodology for Artificial Intelligence Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2570",
    "authors": "Werner, Lennart; Nan, Fang; Eyschen, Pol; Spinelli, Filippo Alberto; Yang, Hongyi; Hutter, Marco",
    "title": "Dynamic Throwing with Robotic Material Handling Machines",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.19001v3",
    "arxiv_abstract": "Automation of hydraulic material handling machinery is currently limited to\nsemi-static pick-and-place cycles. Dynamic throwing motions which utilize the\npassive joints, can greatly improve time efficiency as well as increase the\ndumping workspace. In this work, we use Reinforcement Learning (RL) to design\ndynamic controllers for material handlers with underactuated arms as commonly\nused in logistics. The controllers are tested both in simulation and in\nreal-world experiments on a 12-ton test platform. The method is able to exploit\nthe passive joints of the gripper to perform dynamic throwing motions. With the\nproposed controllers, the machine is able to throw individual objects to\ntargets outside the static reachability zone with good accuracy for its\npractical applications. The work demonstrates the possibility of using RL to\nperform highly dynamic tasks with heavy machinery, suggesting a potential for\nimproving the efficiency and precision of autonomous material handling tasks."
  },
  {
    "paper_no": "2571",
    "authors": "van Marum, Bart; shrestha, aayam; Duan, Helei; Dugar, Pranay; Dao, Jeremy; Fern, Alan",
    "title": "Revisiting Reward Design and Evaluation for Robust Humanoid Standing and Walking",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.19173v2",
    "arxiv_abstract": "A necessary capability for humanoid robots is the ability to stand and walk\nwhile rejecting natural disturbances. Recent progress has been made using\nsim-to-real reinforcement learning (RL) to train such locomotion controllers,\nwith approaches differing mainly in their reward functions. However, prior\nworks lack a clear method to systematically test new reward functions and\ncompare controller performance through repeatable experiments. This limits our\nunderstanding of the trade-offs between approaches and hinders progress. To\naddress this, we propose a low-cost, quantitative benchmarking method to\nevaluate and compare the real-world performance of standing and walking (SaW)\ncontrollers on metrics like command following, disturbance recovery, and energy\nefficiency. We also revisit reward function design and construct a minimally\nconstraining reward function to train SaW controllers. We experimentally verify\nthat our benchmarking framework can identify areas for improvement, which can\nbe systematically addressed to enhance the policies. We also compare our new\ncontroller to state-of-the-art controllers on the Digit humanoid robot. The\nresults provide clear quantitative trade-offs among the controllers and suggest\ndirections for future improvements to the reward functions and expansion of the\nbenchmarks."
  },
  {
    "paper_no": "2573",
    "authors": "Story, Matthew; AIT BELAID, Khaoula; Di Nuovo, Alessandro; Magistro, Daniele; Vagnetti, Roberto; Zecca, Massimiliano",
    "title": "Pilot Study for a Robot-Assisted Timed Up and Go Assessment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2574",
    "authors": "Wirth, Vanessa; Bräunig, Johanna; Khouri, Danti; Gutsche, Florian; Vossiek, Martin; Weyrich, Tim; Stamminger, Marc",
    "title": "Automatic Spatial Calibration of Near-Field MIMO Radar With Respect to Optical Sensors",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10981v2",
    "arxiv_abstract": "Despite an emerging interest in MIMO radar, the utilization of its\ncomplementary strengths in combination with optical depth sensors has so far\nbeen limited to far-field applications, due to the challenges that arise from\nmutual sensor calibration in the near field. In fact, most related approaches\nin the autonomous industry propose target-based calibration methods using\ncorner reflectors that have proven to be unsuitable for the near field. In\ncontrast, we propose a novel, joint calibration approach for optical RGB-D\nsensors and MIMO radars that is designed to operate in the radar's near-field\nrange, within decimeters from the sensors. Our pipeline consists of a bespoke\ncalibration target, allowing for automatic target detection and localization,\nfollowed by the spatial calibration of the two sensor coordinate systems\nthrough target registration. We validate our approach using two different depth\nsensing technologies from the optical domain. The experiments show the\nefficiency and accuracy of our calibration for various target displacements, as\nwell as its robustness of our localization in terms of signal ambiguities."
  },
  {
    "paper_no": "2576",
    "authors": "Turco, Enrico; Castellani, Chiara; Bo, Valerio; Pacchierotti, Claudio; Prattichizzo, Domenico; Lisini Baldi, Tommaso",
    "title": "Reducing Cognitive Load in Teleoperating Swarms of Robots through a Data-Driven Shared Control Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2578",
    "authors": "Li, Jiaxin; Wang, Zan; Di, Huijun; Li, Jian; Liang, Wei",
    "title": "Visual Loop Closure Detection with Thorough Temporal and Spatial Context Exploitation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2579",
    "authors": "Shukla, Rishabh; Yu, Zeren; Moode, Samrudh; Manyar, Omey Mohan; Wang, Fan; Mayya, Siddharth; Gupta, Satyandra K.",
    "title": "Performing Efficient and Safe Deformable Package Transport Operations Using Suction Cups",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2583",
    "authors": "Qi, Carl; Wu, Yilin; Yu, Lifan; Liu, Haoyue; Jiang, Bowen; Lin, Xingyu; Held, David",
    "title": "Learning Generalizable Tool-use Skills through Trajectory Generation",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.00156v5",
    "arxiv_abstract": "Autonomous systems that efficiently utilize tools can assist humans in\ncompleting many common tasks such as cooking and cleaning. However, current\nsystems fall short of matching human-level of intelligence in terms of adapting\nto novel tools. Prior works based on affordance often make strong assumptions\nabout the environments and cannot scale to more complex, contact-rich tasks. In\nthis work, we tackle this challenge and explore how agents can learn to use\npreviously unseen tools to manipulate deformable objects. We propose to learn a\ngenerative model of the tool-use trajectories as a sequence of tool point\nclouds, which generalizes to different tool shapes. Given any novel tool, we\nfirst generate a tool-use trajectory and then optimize the sequence of tool\nposes to align with the generated trajectory. We train a single model on four\ndifferent challenging deformable object manipulation tasks, using demonstration\ndata from only one tool per task. The model generalizes to various novel tools,\nsignificantly outperforming baselines. We further test our trained policy in\nthe real world with unseen tools, where it achieves the performance comparable\nto human. Additional materials can be found on our project website:\nhttps://sites.google.com/view/toolgen."
  },
  {
    "paper_no": "2585",
    "authors": "Okour, Mohammad; Alempijevic, Alen; Falque, Raphael",
    "title": "Sim2real Cattle Joint Estimation in 3D pointclouds",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.14419v2",
    "arxiv_abstract": "Understanding the well-being of cattle is crucial in various agricultural\ncontexts. Cattle's body shape and joint articulation carry significant\ninformation about their welfare, yet acquiring comprehensive datasets for 3D\nbody pose estimation presents a formidable challenge. This study delves into\nthe construction of such a dataset specifically tailored for cattle. Leveraging\nthe expertise of digital artists, we use a single animated 3D model to\nrepresent diverse cattle postures. To address the disparity between virtual and\nreal-world data, we augment the 3D model's shape to encompass a range of\npotential body appearances, thereby narrowing the \"sim2real\" gap. We use these\nannotated models to train a deep-learning framework capable of estimating\ninternal joints solely based on external surface curvature. Our contribution is\nspecifically the use of geodesic distance over the surface manifold, coupled\nwith multilateration to extract joints in a semantic keypoint detection\nencoder-decoder architecture. We demonstrate the robustness of joint extraction\nby comparing the link lengths extracted on real cattle mobbing and walking\nwithin a race. Furthermore, inspired by the established allometric relationship\nbetween bone length and the overall height of mammals, we utilise the estimated\njoints to predict hip height within a real cattle dataset, extending the\nutility of our approach to offer insights into improving cattle monitoring\npractices."
  },
  {
    "paper_no": "2588",
    "authors": "L'Erario, Giuseppe; Hanover, Drew; Romero, Angel; Song, Yunlong; Nava, Gabriele; Viceconte, Paolo Maria; Pucci, Daniele; Scaramuzza, Davide",
    "title": "Learning to Walk and Fly with Adversarial Motion Priors",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.12784v4",
    "arxiv_abstract": "Robot multimodal locomotion encompasses the ability to transition between\nwalking and flying, representing a significant challenge in robotics. This work\npresents an approach that enables automatic smooth transitions between legged\nand aerial locomotion. Leveraging the concept of Adversarial Motion Priors, our\nmethod allows the robot to imitate motion datasets and accomplish the desired\ntask without the need for complex reward functions. The robot learns walking\npatterns from human-like gaits and aerial locomotion patterns from motions\nobtained using trajectory optimization. Through this process, the robot adapts\nthe locomotion scheme based on environmental feedback using reinforcement\nlearning, with the spontaneous emergence of mode-switching behavior. The\nresults highlight the potential for achieving multimodal locomotion in aerial\nhumanoid robotics through automatic control of walking and flying modes, paving\nthe way for applications in diverse domains such as search and rescue,\nsurveillance, and exploration missions. This research contributes to advancing\nthe capabilities of aerial humanoid robots in terms of versatile locomotion in\nvarious environments."
  },
  {
    "paper_no": "2589",
    "authors": "Subash, Akash John; Kloeser, Daniel; Frey, Jonathan; Reiter, Rudolf; Diehl, Moritz; Bohlmann, Karsten",
    "title": "Model Predictive Control for Frenet-Cartesian Trajectory Tracking of a Tricycle Kinematic Automated Guided Vehicle",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2592",
    "authors": "Hao, Yu; Yang, Fan; Fang, Nicholas; Liu, Yu-Shen",
    "title": "EMBOSR: Embodied Spatial Reasoning for Enhanced Situated Question Answering in 3D Scenes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2593",
    "authors": "Lihong, Jin; Dong, Wei; Kaess, Michael",
    "title": "BEVRender:Vision-based Cross-view Vehicle Registration in Off-road GNSS-denied Environment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2594",
    "authors": "Wang, Jin; Laurenzi, Arturo; Tsagarakis, Nikos",
    "title": "Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.08282v1",
    "arxiv_abstract": "Enabling humanoid robots to perform autonomously loco-manipulation in\nunstructured environments is crucial and highly challenging for achieving\nembodied intelligence. This involves robots being able to plan their actions\nand behaviors in long-horizon tasks while using multi-modality to perceive\ndeviations between task execution and high-level planning. Recently, large\nlanguage models (LLMs) have demonstrated powerful planning and reasoning\ncapabilities for comprehension and processing of semantic information through\nrobot control tasks, as well as the usability of analytical judgment and\ndecision-making for multi-modal inputs. To leverage the power of LLMs towards\nhumanoid loco-manipulation, we propose a novel language-model based framework\nthat enables robots to autonomously plan behaviors and low-level execution\nunder given textual instructions, while observing and correcting failures that\nmay occur during task execution. To systematically evaluate this framework in\ngrounding LLMs, we created the robot 'action' and 'sensing' behavior library\nfor task planning, and conducted mobile manipulation tasks and experiments in\nboth simulated and real environments using the CENTAURO robot, and verified the\neffectiveness and application of this approach in robotic tasks with autonomous\nbehavioral planning."
  },
  {
    "paper_no": "2596",
    "authors": "Coffelt, Jeremy Paul; Kampmann, Peter; Wehbe, Bilal",
    "title": "SAVOR: Sonar-Aided Visual Odometry and Reconstruction for Autonomous Underwater Vehicles",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2598",
    "authors": "Hsu, Christopher D.; Chaudhari, Pratik",
    "title": "Active Scout: Multi-Target Tracking Using Neural Radiance Fields in Dense Urban Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2406.07431v2",
    "arxiv_abstract": "We study pursuit-evasion games in highly occluded urban environments, e.g.\ntall buildings in a city, where a scout (quadrotor) tracks multiple dynamic\ntargets on the ground. We show that we can build a neural radiance field (NeRF)\nrepresentation of the city -- online -- using RGB and depth images from\ndifferent vantage points. This representation is used to calculate the\ninformation gain to both explore unknown parts of the city and track the\ntargets -- thereby giving a completely first-principles approach to actively\ntracking dynamic targets. We demonstrate, using a custom-built simulator using\nOpen Street Maps data of Philadelphia and New York City, that we can explore\nand locate 20 stationary targets within 300 steps. This is slower than a greedy\nbaseline, which does not use active perception. But for dynamic targets that\nactively hide behind occlusions, we show that our approach maintains, at worst,\na tracking error of 200m; the greedy baseline can have a tracking error as\nlarge as 600m. We observe a number of interesting properties in the scout's\npolicies, e.g., it switches its attention to track a different target\nperiodically, as the quality of the NeRF representation improves over time, the\nscout also becomes better in terms of target tracking."
  },
  {
    "paper_no": "2599",
    "authors": "Cheng, Zhuoqi; Mány, Bence; Jørgensen, Kasper Balsby; An, Siheon; Jensen, Marcus Leander; Thulstrup, Richard; Frost, Habib; Savarimuthu, Thiusius Rajeeth; Huldt, Olof",
    "title": "Portable robot for needle insertion assistance to femoral artery",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2604",
    "authors": "Werner, Michal; Baca, Tomas; Stibinger, Petr; Doubravova, Daniela; Solc, Jaroslav; Rusnak, Jan; Saska, Martin",
    "title": "Autonomous localization of multiple ionizing radiation sources using miniature single-layer Compton cameras onboard a group of micro aerial vehicles",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.06693v1",
    "arxiv_abstract": "A novel method for autonomous localization of multiple sources of gamma\nradiation using a group of Micro Aerial Vehicles (MAVs) is presented in this\npaper. The method utilizes an extremely lightweight (44 g) Compton camera\nMiniPIX TPX3. The compact size of the detector allows for deployment onboard\nsafe and agile small-scale Unmanned Aerial Vehicles (UAVs). The proposed\nradiation mapping approach fuses measurements from multiple distributed Compton\ncamera sensors to accurately estimate the positions of multiple radioactive\nsources in real time. Unlike commonly used intensity-based detectors, the\nCompton camera reconstructs the set of possible directions towards a radiation\nsource from just a single ionizing particle. Therefore, the proposed approach\ncan localize radiation sources without having to estimate the gradient of a\nradiation field or contour lines, which require longer measurements. The\ninstant estimation is able to fully exploit the potential of highly mobile\nMAVs. The radiation mapping method is combined with an active search strategy,\nwhich coordinates the future actions of the MAVs in order to improve the\nquality of the estimate of the sources' positions, as well as to explore the\narea of interest faster. The proposed solution is evaluated in simulation and\nreal world experiments with multiple Cesium-137 radiation sources."
  },
  {
    "paper_no": "2605",
    "authors": "Musat, Valentina; De Martini, Daniele; Gadd, Matthew; Newman, Paul",
    "title": "NeuralFloors++: Consistent Street-Level Scene Generation From BEV Semantic Maps",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2607",
    "authors": "Rakshin, Egor; Ogureckiy, Dmitriy; Borisov, Ivan; Kolyubin, Sergey",
    "title": "Parametric Synthesis of Compliant Joints for Impact Robust Shaftless Leg Mechanisms",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2608",
    "authors": "Allegro, Davide; Terreran, Matteo; Ghidoni, Stefano",
    "title": "MEMROC: Multi-Eye to Mobile RObot Calibration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2609",
    "authors": "Wang, Zixi; Liu, Zeyi; Ouporov, Nicolas; Song, Shuran",
    "title": "ContactHandover: Contact-Guided Robot-to-Human Object Handover",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2612",
    "authors": "Bhaskar, Amisha; Liu, Rui; Sharma, Vishnu D.; Shi, Guangyao; Tokekar, Pratap",
    "title": "Long-horizon Visual Action based Food Acquisition",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12876v1",
    "arxiv_abstract": "Robotic Assisted Feeding (RAF) addresses the fundamental need for individuals\nwith mobility impairments to regain autonomy in feeding themselves. The goal of\nRAF is to use a robot arm to acquire and transfer food to individuals from the\ntable. Existing RAF methods primarily focus on solid foods, leaving a gap in\nmanipulation strategies for semi-solid and deformable foods. This study\nintroduces Long-horizon Visual Action (LAVA) based food acquisition of liquid,\nsemisolid, and deformable foods. Long-horizon refers to the goal of \"clearing\nthe bowl\" by sequentially acquiring the food from the bowl. LAVA employs a\nhierarchical policy for long-horizon food acquisition tasks. The framework uses\nhigh-level policy to determine primitives by leveraging ScoopNet. At the\nmid-level, LAVA finds parameters for primitives using vision. To carry out\nsequential plans in the real world, LAVA delegates action execution which is\ndriven by Low-level policy that uses parameters received from mid-level policy\nand behavior cloning ensuring precise trajectory execution. We validate our\napproach on complex real-world acquisition trials involving granular, liquid,\nsemisolid, and deformable food types along with fruit chunks and soup\nacquisition. Across 46 bowls, LAVA acquires much more efficiently than\nbaselines with a success rate of 89 +/- 4% and generalizes across realistic\nplate variations such as different positions, varieties, and amount of food in\nthe bowl. Code, datasets, videos, and supplementary materials can be found on\nour website."
  },
  {
    "paper_no": "2616",
    "authors": "Ginting, Muhammad Fadhil; Fan, David D; Kim, Sung-Kyun; Kochenderfer, Mykel; Agha-mohammadi, Ali-akbar",
    "title": "Semantic Belief Behavior Graph: Enabling Autonomous Robot Inspection in Unknown Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2401.17191v2",
    "arxiv_abstract": "This paper addresses the problem of autonomous robotic inspection in complex\nand unknown environments. This capability is crucial for efficient and precise\ninspections in various real-world scenarios, even when faced with perceptual\nuncertainty and lack of prior knowledge of the environment. Existing methods\nfor real-world autonomous inspections typically rely on predefined targets and\nwaypoints and often fail to adapt to dynamic or unknown settings. In this work,\nwe introduce the Semantic Belief Behavior Graph (SB2G) framework as a novel\napproach to semantic-aware autonomous robot inspection. SB2G generates a\ncontrol policy for the robot, featuring behavior nodes that encapsulate various\nsemantic-based policies designed for inspecting different classes of objects.\nWe design an active semantic search behavior to guide the robot in locating\nobjects for inspection while reducing semantic information uncertainty. The\nedges in the SB2G encode transitions between these behaviors. We validate our\napproach through simulation and real-world urban inspections using a legged\nrobotic platform. Our results show that SB2G enables a more efficient\ninspection policy, exhibiting performance comparable to human-operated\ninspections."
  },
  {
    "paper_no": "2617",
    "authors": "Mehan, Yash; Gupta, Kumaraditya; Jayanti, Rohit; Govil, Anirudh; Garg, Sourav; Krishna, Madhava",
    "title": "QueSTMaps: Queryable Semantic Topological Maps for 3D Scene Understanding",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2623",
    "authors": "Krebs, Franziska; Asfour, Tamim",
    "title": "Formalization of Temporal and Spatial Constraints of Bimanual Manipulation Categories",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2624",
    "authors": "Yan, Shengchao; König, Lukas Maximilian; Burgard, Wolfram",
    "title": "Single-Agent Actor Critic for Decentralized Cooperative Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2629",
    "authors": "Hou, Ningzhe; He, Liang; Albini, Alessandro; Halamek, Louis; Maiolino, Perla",
    "title": "The design of a sensorized laryngoscope training system for pediatric intubation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2631",
    "authors": "Sferrazza, Carmelo; Seo, Younggyo; Liu, Hao; Lee, Youngwoon; Abbeel, Pieter",
    "title": "The Power of the Senses: Generalizable Manipulation from Vision and Touch through Masked Multimodal Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2311.00924v1",
    "arxiv_abstract": "Humans rely on the synergy of their senses for most essential tasks. For\ntasks requiring object manipulation, we seamlessly and effectively exploit the\ncomplementarity of our senses of vision and touch. This paper draws inspiration\nfrom such capabilities and aims to find a systematic approach to fuse visual\nand tactile information in a reinforcement learning setting. We propose Masked\nMultimodal Learning (M3L), which jointly learns a policy and visual-tactile\nrepresentations based on masked autoencoding. The representations jointly\nlearned from vision and touch improve sample efficiency, and unlock\ngeneralization capabilities beyond those achievable through each of the senses\nseparately. Remarkably, representations learned in a multimodal setting also\nbenefit vision-only policies at test time. We evaluate M3L on three simulated\nenvironments with both visual and tactile observations: robotic insertion, door\nopening, and dexterous in-hand manipulation, demonstrating the benefits of\nlearning a multimodal policy. Code and videos of the experiments are available\nat https://sferrazza.cc/m3l_site."
  },
  {
    "paper_no": "2634",
    "authors": "Martini, Mauro; Perez-Higueras, Noe; Ostuni, Andrea; Chiaberge, Marcello; Caballero, Fernando; Merino, Luis",
    "title": "Adaptive Social Force Window Planner with Reinforcement Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.13678v1",
    "arxiv_abstract": "Human-aware navigation is a complex task for mobile robots, requiring an\nautonomous navigation system capable of achieving efficient path planning\ntogether with socially compliant behaviors. Social planners usually add costs\nor constraints to the objective function, leading to intricate tuning processes\nor tailoring the solution to the specific social scenario. Machine Learning can\nenhance planners' versatility and help them learn complex social behaviors from\ndata. This work proposes an adaptive social planner, using a Deep Reinforcement\nLearning agent to dynamically adjust the weighting parameters of the cost\nfunction used to evaluate trajectories. The resulting planner combines the\nrobustness of the classic Dynamic Window Approach, integrated with a social\ncost based on the Social Force Model, and the flexibility of learning methods\nto boost the overall performance on social navigation tasks. Our extensive\nexperimentation on different environments demonstrates the general advantage of\nthe proposed method over static cost planners."
  },
  {
    "paper_no": "2635",
    "authors": "Mizuta, Kazuki; Leung, Karen",
    "title": "CoBL-Diffusion: Diffusion-Based Conditional Robot Planning in Dynamic Environments Using Control Barrier and Lyapunov Functions",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2637",
    "authors": "Liu, Xiao; Zhou, Yifan; Weigend, Fabian Clemens; Sonawani, Shubham; Ikemoto, Shuhei; Ben Amor, Heni",
    "title": "Diff-Control: A Stateful Diffusion-based Policy for Imitation Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2639",
    "authors": "Huang, Yunqi; Alkayas, Abdulaziz Y.; Shi, Jialei; Renda, Federico; Wurdemann, Helge Arne; George Thuruthel, Thomas",
    "title": "Predicting Interaction Shape of Soft Continuum Robots using Deep Visual Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2642",
    "authors": "Thalapanane, Sandeep; Senthil Kumar, Sandip Sharan; Appiya Dilipkumar Peethambari, Guru Nandhan; Sri hari, Sourang; Zheng, Laura; Poveda, Julio; Lin, Ming C.",
    "title": "TRAVERSE: Traffic-Responsive Autonomous Vehicle Experience & Rare-event Simulation for Enhanced safety",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2643",
    "authors": "Ma, Yuliang; Liu, Jingyi; Mamaev, Ilshat; Morozov, Andrey",
    "title": "Multimodal Failure Prediction for Vision-based Manipulation Tasks with Camera Faults",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2646",
    "authors": "Vavra, Vaclav; Sattler, Torsten; Kukelova, Zuzana",
    "title": "Camera Pose Estimation from Bounding Boxes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2647",
    "authors": "Natarajan, Ramkumar; Mukherjee, Shohin; Choset, Howie; Likhachev, Maxim",
    "title": "PINSAT: Parallelized Interleaving of Graph Search and Trajectory Optimization for Kinodynamic Motion Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2648",
    "authors": "Jawaid, Mohsi; Talak, Rajat; Latif, Yasir; Carlone, Luca; Chin, Tat-Jun",
    "title": "Test-Time Certifiable Self-Supervision to Bridge the Sim2Real Gap in Event-Based Satellite Pose Estimation",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.06240v1",
    "arxiv_abstract": "Deep learning plays a critical role in vision-based satellite pose\nestimation. However, the scarcity of real data from the space environment means\nthat deep models need to be trained using synthetic data, which raises the\nSim2Real domain gap problem. A major cause of the Sim2Real gap are novel\nlighting conditions encountered during test time. Event sensors have been shown\nto provide some robustness against lighting variations in vision-based pose\nestimation. However, challenging lighting conditions due to strong directional\nlight can still cause undesirable effects in the output of commercial\noff-the-shelf event sensors, such as noisy/spurious events and inhomogeneous\nevent densities on the object. Such effects are non-trivial to simulate in\nsoftware, thus leading to Sim2Real gap in the event domain. To close the\nSim2Real gap in event-based satellite pose estimation, the paper proposes a\ntest-time self-supervision scheme with a certifier module. Self-supervision is\nenabled by an optimisation routine that aligns a dense point cloud of the\npredicted satellite pose with the event data to attempt to rectify the\ninaccurately estimated pose. The certifier attempts to verify the corrected\npose, and only certified test-time inputs are backpropagated via implicit\ndifferentiation to refine the predicted landmarks, thus improving the pose\nestimates and closing the Sim2Real gap. Results show that the our method\noutperforms established test-time adaptation schemes."
  },
  {
    "paper_no": "2655",
    "authors": "Bersier, Arnaud; Leonforte, Matteo; Vanetta, Alessio; Wotke, Sarah Lia Andrea; Nappi, Andrea; Zhou, Yifan; Oliani, Sebastiano; Kübler, Alexander M.; Katzschmann, Robert Kevin",
    "title": "Rotograb: Combining Biomimetic Hands with Industrial Grippers using a Rotating Thumb",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2657",
    "authors": "Manyar, Omey Mohan; Ye, Hantao; Sagare, Meghana; Mayya, Siddharth; Wang, Fan; Gupta, Satyandra K.",
    "title": "Simulation-Assisted Learning for Efficient Bin-Packing of Deformable Packages in a Bimanual Robotic Cell",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2662",
    "authors": "Sun, Xingpeng; Zhang, Yiran; Tang, Xindi; Bedi, Amrit Singh; Bera, Aniket",
    "title": "TrustNavGPT: Trust-Driven Audio-Guided Robot Navigation under Uncertainty with Large Language Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2663",
    "authors": "Winkelbauer, Dominik; Triebel, Rudolph; Bäuml, Berthold",
    "title": "A Learning-based Controller for Multi-Contact Grasps on Unknown Objects with a Dexterous Hand",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.12339v1",
    "arxiv_abstract": "Existing grasp controllers usually either only support finger-tip grasps or\nneed explicit configuration of the inner forces. We propose a novel grasp\ncontroller that supports arbitrary grasp types, including power grasps with\nmulti-contacts, while operating self-contained on before unseen objects. No\ndetailed contact information is needed, but only a rough 3D model, e.g.,\nreconstructed from a single depth image. First, the external wrench being\napplied to the object is estimated by using the measured torques at the joints.\nThen, the torques necessary to counteract the estimated wrench while keeping\nthe object at its initial pose are predicted. The torques are commanded via\ndesired joint angles to an underlying joint-level impedance controller. To\nreach real-time performance, we propose a learning-based approach that is based\non a wrench estimator- and a torque predictor neural network. Both networks are\ntrained in a supervised fashion using data generated via the analytical\nformulation of the controller. In an extensive simulation-based evaluation, we\nshow that our controller is able to keep 83.1% of the tested grasps stable when\napplying external wrenches with up to 10N. At the same time, we outperform the\ntwo tested baselines by being more efficient and inducing less involuntary\nobject movement. Finally, we show that the controller also works on the real\nDLR-Hand II, reaching a cycle time of 6ms."
  },
  {
    "paper_no": "2666",
    "authors": "Dreher, Christian R. G.; Asfour, Tamim",
    "title": "Learning Symbolic and Subsymbolic Temporal Task Constraints from Bimanual Human Demonstrations",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.16953v2",
    "arxiv_abstract": "Learning task models of bimanual manipulation from human demonstration and\ntheir execution on a robot should take temporal constraints between actions\ninto account. This includes constraints on (i) the symbolic level such as\nprecedence relations or temporal overlap in the execution, and (ii) the\nsubsymbolic level such as the duration of different actions, or their starting\nand end points in time. Such temporal constraints are crucial for temporal\nplanning, reasoning, and the exact timing for the execution of bimanual actions\non a bimanual robot. In our previous work, we addressed the learning of\ntemporal task constraints on the symbolic level and demonstrated how a robot\ncan leverage this knowledge to respond to failures during execution. In this\nwork, we propose a novel model-driven approach for the combined learning of\nsymbolic and subsymbolic temporal task constraints from multiple bimanual human\ndemonstrations. Our main contributions are a subsymbolic foundation of a\ntemporal task model that describes temporal nexuses of actions in the task\nbased on distributions of temporal differences between semantic action\nkeypoints, as well as a method based on fuzzy logic to derive symbolic temporal\ntask constraints from this representation. This complements our previous work\non learning comprehensive temporal task models by integrating symbolic and\nsubsymbolic information based on a subsymbolic foundation, while still\nmaintaining the symbolic expressiveness of our previous approach. We compare\nour proposed approach with our previous pure-symbolic approach and show that we\ncan reproduce and even outperform it. Additionally, we show how the subsymbolic\ntemporal task constraints can synchronize otherwise unimanual movement\nprimitives for bimanual behavior on a humanoid robot."
  },
  {
    "paper_no": "2667",
    "authors": "Jiang, Peiyang; Zhang, Dandan",
    "title": "A Digital Twin-Driven Immersive Teleoperation Framework for Robot-Assisted Microsurgery",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2668",
    "authors": "Qian, Kun; Erden, Mustafa Suphi; Kong, Xianwen",
    "title": "Scalable Network and Adaptive Refinement Module for 6D Pose Estimation of Diverse Industrial Components",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2670",
    "authors": "Dissanayaka, Didula; Wanasinghe, Thumeera Ruwansiri; Gosine, Raymond G.",
    "title": "Explainable Artificial intelligence for Autonomous UAV Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2674",
    "authors": "Yazdanshenas, Amin; Faieghi, Reza",
    "title": "Quaternion-Based Sliding Mode Control for Six Degrees of Freedom Flight Control of Quadrotors",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10934v1",
    "arxiv_abstract": "Despite extensive research on sliding mode control (SMC) design for\nquadrotors, the existing approaches suffer from certain limitations. Euler\nangle-based SMC formulations suffer from poor performance in high-pitch or\n-roll maneuvers. Quaternion-based SMC approaches have unwinding issues and\ncomplex architecture. Coordinate-free methods are slow and only almost globally\nstable. This paper presents a new six degrees of freedom SMC flight controller\nto address the above limitations. We use a cascaded architecture with a\nposition controller in the outer loop and a quaternion-based attitude\ncontroller in the inner loop. The position controller generates the desired\ntrajectory for the attitude controller using a coordinate-free approach. The\nquaternion-based attitude controller uses the natural characteristics of the\nquaternion hypersphere, featuring a simple structure while providing global\nstability and avoiding unwinding issues. We compare our controller with three\nother common control methods conducting challenging maneuvers like flip-over\nand high-speed trajectory tracking in the presence of model uncertainties and\ndisturbances. Our controller consistently outperforms the benchmark approaches\nwith less control effort and actuator saturation, offering highly effective and\nefficient flight control."
  },
  {
    "paper_no": "2676",
    "authors": "Attfield, Richard John; Croft, Elizabeth; Kulic, Dana",
    "title": "A comparison of audible, visual, and multi-modal communication for multi-robot supervision and situational awareness",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2678",
    "authors": "Demby's, Jacket; Farag, Ramy; DeSouza, Guilherme",
    "title": "Inverse Kinematics of Robotic Manipulators Using a New Learning-by-Example Method",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2679",
    "authors": "Afzal, Sayed Saad; Chen, Wei-Tung; Adib, Fadel",
    "title": "3D-BLUE: Backscatter Localization for Underwater Robotics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2680",
    "authors": "Hao, Yu; Magay, Alexey; Huang, Hao; Yuan, Shuaihang; Wen, Congcong; Fang, Yi",
    "title": "A Wearable Platform Based on the Multi-modal Foundation Model to Augment Spatial Cognition for People with Blindness and Low Vision",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2681",
    "authors": "Daudt, Guilherme; Deus, Alleff Dymytry; Kolberg, Mariana; Maffei, Renan",
    "title": "k-Robust Conflict-based Search with Continuous time for Multi-robot Coordination",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2682",
    "authors": "Caroleo, Giammarco; Giovinazzo, Francesco; Albini, Alessandro; Grella, Francesco; Cannata, Giorgio; Maiolino, Perla",
    "title": "A Proxy-Tactile Reactive Control for Robots Moving in Clutter",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2686",
    "authors": "Yu, Oscar; She, Yu",
    "title": "Feelit: Combining Compliant Shape Displays with Vision-Based Tactile Sensors for Real-Time Teletaction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2687",
    "authors": "Jawale, Neel Anand; Kaur, Navneet; Santoso, Elizabeth Amy; Chen, Xu",
    "title": "Learned Slip-Detection-Severity Framework using Tactile Deformation Field Feedback for Robotic Manipulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.07442v1",
    "arxiv_abstract": "Safely handling objects and avoiding slippage are fundamental challenges in\nrobotic manipulation, yet traditional techniques often oversimplify the issue\nby treating slippage as a binary occurrence. Our research presents a framework\nthat both identifies slip incidents and measures their severity. We introduce a\nset of features based on detailed vector field analysis of tactile deformation\ndata captured by the GelSight Mini sensor. Two distinct machine learning models\nuse these features: one focuses on slip detection, and the other evaluates the\nslip's severity, which is the slipping velocity of the object against the\nsensor surface. Our slip detection model achieves an average accuracy of 92%,\nand the slip severity estimation model exhibits a mean absolute error (MAE) of\n0.6 cm/s for unseen objects. To demonstrate the synergistic approach of this\nframework, we employ both the models in a tactile feedback-guided vertical\nsliding task. Leveraging the high accuracy of slip detection, we utilize it as\nthe foundational and corrective model and integrate the slip severity\nestimation into the feedback control loop to address slips without\novercompensating."
  },
  {
    "paper_no": "2688",
    "authors": "Pan, Sicong; Jin, Liren; Huang, Xuying; Stachniss, Cyrill; Popovic, Marija; Bennewitz, Maren",
    "title": "Exploiting Priors from 3D Diffusion Models for RGB-Based One-Shot View Planning",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.16803v2",
    "arxiv_abstract": "Object reconstruction is relevant for many autonomous robotic tasks that\nrequire interaction with the environment. A key challenge in such scenarios is\nplanning view configurations to collect informative measurements for\nreconstructing an initially unknown object. One-shot view planning enables\nefficient data collection by predicting view configurations and planning the\nglobally shortest path connecting all views at once. However, prior knowledge\nabout the object is required to conduct one-shot view planning. In this work,\nwe propose a novel one-shot view planning approach that utilizes the powerful\n3D generation capabilities of diffusion models as priors. By incorporating such\ngeometric priors into our pipeline, we achieve effective one-shot view planning\nstarting with only a single RGB image of the object to be reconstructed. Our\nplanning experiments in simulation and real-world setups indicate that our\napproach balances well between object reconstruction quality and movement cost."
  },
  {
    "paper_no": "2690",
    "authors": "Wilder-Smith, Maximum; Patil, Vaishakh; Hutter, Marco",
    "title": "Radiance Fields for Robotic Teleoperation",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.20194v1",
    "arxiv_abstract": "Radiance field methods such as Neural Radiance Fields (NeRFs) or 3D Gaussian\nSplatting (3DGS), have revolutionized graphics and novel view synthesis. Their\nability to synthesize new viewpoints with photo-realistic quality, as well as\ncapture complex volumetric and specular scenes, makes them an ideal\nvisualization for robotic teleoperation setups. Direct camera teleoperation\nprovides high-fidelity operation at the cost of maneuverability, while\nreconstruction-based approaches offer controllable scenes with lower fidelity.\nWith this in mind, we propose replacing the traditional\nreconstruction-visualization components of the robotic teleoperation pipeline\nwith online Radiance Fields, offering highly maneuverable scenes with\nphotorealistic quality. As such, there are three main contributions to state of\nthe art: (1) online training of Radiance Fields using live data from multiple\ncameras, (2) support for a variety of radiance methods including NeRF and 3DGS,\n(3) visualization suite for these methods including a virtual reality scene. To\nenable seamless integration with existing setups, these components were tested\nwith multiple robots in multiple configurations and were displayed using\ntraditional tools as well as the VR headset. The results across methods and\nrobots were compared quantitatively to a baseline of mesh reconstruction, and a\nuser study was conducted to compare the different visualization methods. For\nvideos and code, check out https://leggedrobotics.github.io/rffr.github.io/."
  },
  {
    "paper_no": "2692",
    "authors": "Louca, Joe; Zemeny, Aliz; Tzemanaki, Antonia; Charles, Romain",
    "title": "Demonstrating Trustworthiness in Model Mediated Teleoperation for Collecting Lunar Regolith Simulant",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2693",
    "authors": "Wojcik, Jagoda; Jiang, Jiaqi; Wu, Jiacheng; LUO, SHAN",
    "title": "A Case Study on Visual-Audio-Tactile Cross-Modal Retrieval",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.20709v1",
    "arxiv_abstract": "Cross-Modal Retrieval (CMR), which retrieves relevant items from one modality\n(e.g., audio) given a query in another modality (e.g., visual), has undergone\nsignificant advancements in recent years. This capability is crucial for robots\nto integrate and interpret information across diverse sensory inputs. However,\nthe retrieval space in existing robotic CMR approaches often consists of only\none modality, which limits the robot's performance. In this paper, we propose a\nnovel CMR model that incorporates three different modalities, i.e., visual,\naudio and tactile, for enhanced multi-modal object retrieval, named as VAT-CMR.\nIn this model, multi-modal representations are first fused to provide a\nholistic view of object features. To mitigate the semantic gaps between\nrepresentations of different modalities, a dominant modality is then selected\nduring the classification training phase to improve the distinctiveness of the\nrepresentations, so as to improve the retrieval performance. To evaluate our\nproposed approach, we conducted a case study and the results demonstrate that\nour VAT-CMR model surpasses competing approaches. Further, our proposed\ndominant modality selection significantly enhances cross-retrieval accuracy."
  },
  {
    "paper_no": "2694",
    "authors": "Wu, Albert; Wang, Ruocheng; Chen, Sirui; Eppner, Clemens; Liu, Karen",
    "title": "One-Shot Transfer of Long-Horizon Extrinsic Manipulation Through Contact Retargeting",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.07468v1",
    "arxiv_abstract": "Extrinsic manipulation, the use of environment contacts to achieve\nmanipulation objectives, enables strategies that are otherwise impossible with\na parallel jaw gripper. However, orchestrating a long-horizon sequence of\ncontact interactions between the robot, object, and environment is notoriously\nchallenging due to the scene diversity, large action space, and difficult\ncontact dynamics. We observe that most extrinsic manipulation are combinations\nof short-horizon primitives, each of which depend strongly on initializing from\na desirable contact configuration to succeed. Therefore, we propose to\ngeneralize one extrinsic manipulation trajectory to diverse objects and\nenvironments by retargeting contact requirements. We prepare a single library\nof robust short-horizon, goal-conditioned primitive policies, and design a\nframework to compose state constraints stemming from contacts specifications of\neach primitive. Given a test scene and a single demo prescribing the primitive\nsequence, our method enforces the state constraints on the test scene and find\nintermediate goal states using inverse kinematics. The goals are then tracked\nby the primitive policies. Using a 7+1 DoF robotic arm-gripper system, we\nachieved an overall success rate of 80.5% on hardware over 4 long-horizon\nextrinsic manipulation tasks, each with up to 4 primitives. Our experiments\ncover 10 objects and 6 environment configurations. We further show empirically\nthat our method admits a wide range of demonstrations, and that contact\nretargeting is indeed the key to successfully combining primitives for\nlong-horizon extrinsic manipulation. Code and additional details are available\nat stanford-tml.github.io/extrinsic-manipulation."
  },
  {
    "paper_no": "2695",
    "authors": "Kalantari, Arash; Brinkman, Alexander; Carpenter, Kalind; Gildner, Matthew; Jenkins, Justin; Newill-Smith, David; Seiden, Jeffrey; Umali, Allen; McCormick, Ryan",
    "title": "Design, Prototype, and Performance Assessment of an Autonomous Manipulation System for Mars Sample Recovery Helicopter",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2696",
    "authors": "Shirose, Burhanuddin; Johnson, Adam; Vundurthy, Bhaskar; Choset, Howie; Travers, Matthew",
    "title": "GESCE: Graph-based Ergodic Search in Cluttered Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2698",
    "authors": "Smith, Trevor; Rijal, Madhav; Arend Tatsch, Christopher Alexander; Butts, R. Michael; Beard, Jared; Robert Cook, Tyler; Chu, Andy; Gross, Jason; Gu, Yu",
    "title": "Design of Stickbug: a Six-Armed Precision Pollination Robot",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.03489v1",
    "arxiv_abstract": "This work presents the design of Stickbug, a six-armed, multi-agent,\nprecision pollination robot that combines the accuracy of single-agent systems\nwith swarm parallelization in greenhouses. Precision pollination robots have\noften been proposed to offset the effects of a decreasing population of natural\npollinators, but they frequently lack the required parallelization and\nscalability. Stickbug achieves this by allowing each arm and drive base to act\nas an individual agent, significantly reducing planning complexity. Stickbug\nuses a compact holonomic Kiwi drive to navigate narrow greenhouse rows, a tall\nmast to support multiple manipulators and reach plant heights, a detection\nmodel and classifier to identify Bramble flowers, and a felt-tipped\nend-effector for contact-based pollination. Initial experimental validation\ndemonstrates that Stickbug can attempt over 1.5 pollinations per minute with a\n50% success rate. Additionally, a Bramble flower perception dataset was created\nand is publicly available alongside Stickbug's software and design files."
  },
  {
    "paper_no": "2699",
    "authors": "Biswas, Sandika; Banerjee, Biplab; Rezatofighi, Hamid",
    "title": "Shape-prior Free Space-time Neural Radiance Field for 4D Semantic Reconstruction of Dynamic Scene from Sparse-View RGB Videos",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2701",
    "authors": "Zhang, Mingjie; Feng, Chen; Li, Zengzhi; Zheng, Guiyong; Luo, Yiming; Wang, Zhu; ZHOU, Jinni; Shen, Shaojie; Zhou, Boyu",
    "title": "FC-Hetero: Fast and Autonomous Aerial Reconstruction Using a LiDAR-Visual Heterogeneous Multi-UAV System",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2702",
    "authors": "Manzano, Maxime; Guegan, Sylvain; Le Breton, Ronan; Devigne, Louise; Babel, Marie",
    "title": "Force-Triggered Control Design for User Intent-Driven Assistive Upper-Limb Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2703",
    "authors": "Zhou, Shijun; Orr, Aidan; Hyun, Nak-seung Patrick",
    "title": "Importance of Translational Velocity for Bird-scale Flapping Wing Vehicles Incapable of Hovering",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2704",
    "authors": "Conway, Max; Reily, Brian; Reardon, Christopher M.",
    "title": "Learned Sensor Fusion For Robust Human Activity Recognition in Challenging Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2706",
    "authors": "SENGADU SURESH, PRASANTH; Jain, Siddarth; Doshi, Prashant; Romeres, Diego",
    "title": "Open Human-Robot Collaborations using Decentralized Inverse Reinforcement Learning",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.01790v1",
    "arxiv_abstract": "The growing interest in human-robot collaboration (HRC), where humans and\nrobots cooperate towards shared goals, has seen significant advancements over\nthe past decade. While previous research has addressed various challenges,\nseveral key issues remain unresolved. Many domains within HRC involve\nactivities that do not necessarily require human presence throughout the entire\ntask. Existing literature typically models HRC as a closed system, where all\nagents are present for the entire duration of the task. In contrast, an open\nmodel offers flexibility by allowing an agent to enter and exit the\ncollaboration as needed, enabling them to concurrently manage other tasks. In\nthis paper, we introduce a novel multiagent framework called oDec-MDP, designed\nspecifically to model open HRC scenarios where agents can join or leave tasks\nflexibly during execution. We generalize a recent multiagent inverse\nreinforcement learning method - Dec-AIRL to learn from open systems modeled\nusing the oDec-MDP. Our method is validated through experiments conducted in\nboth a simplified toy firefighting domain and a realistic dyadic human-robot\ncollaborative assembly. Results show that our framework and learning method\nimproves upon its closed system counterpart."
  },
  {
    "paper_no": "2707",
    "authors": "Lee, Kevin; Lin, Wei-Heng; Javed, Talha; Madhusudhan, Sruti; Sher, Bilal; Feng, Chen",
    "title": "Roofus: Learning-based Robotic Moisture Mapping on Flat Rooftops with Ground Penetrating Radar",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2708",
    "authors": "Beard, Jared; Butts, R. Michael; Gu, Yu",
    "title": "Feeling Optimistic? Ambiguity Attitudes for Online Decision Making",
    "arxiv_pdf": "http://arxiv.org/pdf/2303.04225v3",
    "arxiv_abstract": "Due to the complexity of many decision making problems, tree search\nalgorithms often have inadequate information to produce accurate transition\nmodels. This results in ambiguities (uncertainties for which there are multiple\nplausible models). Faced with ambiguities, robust methods have been used to\nproduce safe solutions--often by maximizing the lower bound over the set of\nplausible transition models. However, they often overlook how much the\nrepresentation of uncertainty can impact how a decision is made. This work\nintroduces the Ambiguity Attitude Graph Search (AAGS), advocating for more\ncomprehensive representations of ambiguities in decision making. Additionally,\nAAGS allows users to adjust their ambiguity attitude (or preference), promoting\nexploration and improving users' ability to control how an agent should respond\nwhen faced with a set of plausible alternatives. Simulation in a dynamic\nsailing environment shows how environments with high entropy transition models\ncan lead robust methods to fail. Results further demonstrate how adjusting\nambiguity attitudes better fulfills objectives while mitigating this failure\nmode of robust approaches. Because this approach is a generalization of the\nrobust framework, these results further demonstrate how algorithms focused on\nambiguity have applicability beyond safety-critical systems."
  },
  {
    "paper_no": "2712",
    "authors": "Jaitly, Akshay; Farzan, Siavash",
    "title": "PAAMP: Polytopic Action-Set And Motion Planning For Long Horizon Dynamic Motion Planning via Mixed Integer Linear Programming",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2713",
    "authors": "Liu, Xinhao; Gong, Moonjun; Fang, Qi; Xie, Haoyu; LI, YIMING; Zhao, Hang; Feng, Chen",
    "title": "LiDAR-based 4D Occupancy Completion and Forecasting",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.11239v2",
    "arxiv_abstract": "Scene completion and forecasting are two popular perception problems in\nresearch for mobile agents like autonomous vehicles. Existing approaches treat\nthe two problems in isolation, resulting in a separate perception of the two\naspects. In this paper, we introduce a novel LiDAR perception task of Occupancy\nCompletion and Forecasting (OCF) in the context of autonomous driving to unify\nthese aspects into a cohesive framework. This task requires new algorithms to\naddress three challenges altogether: (1) sparse-to-dense reconstruction, (2)\npartial-to-complete hallucination, and (3) 3D-to-4D prediction. To enable\nsupervision and evaluation, we curate a large-scale dataset termed OCFBench\nfrom public autonomous driving datasets. We analyze the performance of closely\nrelated existing baseline models and our own ones on our dataset. We envision\nthat this research will inspire and call for further investigation in this\nevolving and crucial area of 4D perception. Our code for data curation and\nbaseline implementation is available at https://github.com/ai4ce/Occ4cast."
  },
  {
    "paper_no": "2714",
    "authors": "Lu, Kai; Ly, Kim Tien; zhou, kaichen; Havoutis, Ioannis; Markham, Andrew",
    "title": "Learning Generalizable Manipulation Policy with Adapter-Based Parameter Fine-Tuning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2718",
    "authors": "Carvajal, Michael Angelo; Mabulu, Katiso; Lalji, Muneer; Flanagan, James; Hibbard, Sam; Luo, Rui; Chinthapatla, Tanav; Bettadpur, Rohan; Bazzi, Salah; Zolotas, Mark; Kloeckl, Kristian; Padir, Taskin",
    "title": "A Voxel-Enabled Robotic Assistant for Omnidirectional Conveyance",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2721",
    "authors": "Tam, Zachary; Dharmarajan, Karthik; Qiu, Tianshuang; Avigal, Yahav; Ichnowski, Jeffrey; Goldberg, Ken",
    "title": "BOMP: Bin-Optimized Motion Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2724",
    "authors": "Jun, Howoong; Yu, Hyeonwoo; Oh, Songhwai",
    "title": "Renderable Street View Map-based Localization: Leveraging 3D Gaussian Splatting for Street-level Positioning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2727",
    "authors": "Chandiramani, Vijay; Hauser, Helmut; Conn, Andrew",
    "title": "Improving Legged Robot Locomotion by Quantifying Morphological Computation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2729",
    "authors": "Morales, Cecilia; Srikanth, Dhruv; Good, Jack; Goswami, Mononito; Dufendach, Keith; Dubrawski, Artur",
    "title": "Bifurcation Identification for Ultrasound-driven Robotic Cannulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.06817v1",
    "arxiv_abstract": "In trauma and critical care settings, rapid and precise intravascular access\nis key to patients' survival. Our research aims at ensuring this access, even\nwhen skilled medical personnel are not readily available. Vessel bifurcations\nare anatomical landmarks that can guide the safe placement of catheters or\nneedles during medical procedures. Although ultrasound is advantageous in\nnavigating anatomical landmarks in emergency scenarios due to its portability\nand safety, to our knowledge no existing algorithm can autonomously extract\nvessel bifurcations using ultrasound images. This is primarily due to the\nlimited availability of ground truth data, in particular, data from live\nsubjects, needed for training and validating reliable models. Researchers often\nresort to using data from anatomical phantoms or simulations. We introduce\nBIFURC, Bifurcation Identification for Ultrasound-driven Robot Cannulation, a\nnovel algorithm that identifies vessel bifurcations and provides optimal needle\ninsertion sites for an autonomous robotic cannulation system. BIFURC integrates\nexpert knowledge with deep learning techniques to efficiently detect vessel\nbifurcations within the femoral region and can be trained on a limited amount\nof in-vivo data. We evaluated our algorithm using a medical phantom as well as\nreal-world experiments involving live pigs. In all cases, BIFURC consistently\nidentified bifurcation points and needle insertion locations in alignment with\nthose identified by expert clinicians."
  },
  {
    "paper_no": "2730",
    "authors": "Merida-Calvo, Luis; Haro-Olmo, Maria Isabel; Feliu, Vicente",
    "title": "Dynamic Model and Experimental Validation of a Haptic Robot based on a Flexible Antenna mounted on an Omnidirectional Platform",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2732",
    "authors": "Arul, Senthil Hariharan; Kumar, Dhruva; Sugirtharaj, Vivek; Kim, Richard; Qi, Xuewei; Madhivanan, Rajasimman; Sen, Arnab; Manocha, Dinesh",
    "title": "VLPG-Nav: Object Navigation Using Visual Language Pose Graph and Object Localization Probability Maps",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2735",
    "authors": "Samandi, Pouya; Gupta, Kamal; mehrandezh, mehran",
    "title": "Enhancing Object Grasping Efficiency with Deep Learning and Post-processing for Multi-finger Robotic Hands",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2736",
    "authors": "Ge, Wenqi; Tang, Chao; Zhang, Hong",
    "title": "Commonsense Scene Graph-based Target Localization for Object Search",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.00343v2",
    "arxiv_abstract": "Object search is a fundamental skill for household robots, yet the core\nproblem lies in the robot's ability to locate the target object accurately. The\ndynamic nature of household environments, characterized by the arbitrary\nplacement of daily objects by users, makes it challenging to perform target\nlocalization. To efficiently locate the target object, the robot needs to be\nequipped with knowledge at both the object and room level. However, existing\napproaches rely solely on one type of knowledge, leading to unsatisfactory\nobject localization performance and, consequently, inefficient object search\nprocesses. To address this problem, we propose a commonsense scene graph-based\ntarget localization, CSG-TL, to enhance target object search in the household\nenvironment. Given the pre-built map with stationary items, the robot models\nthe room-level knowledge with object-level commonsense knowledge generated by a\nlarge language model (LLM) to a commonsense scene graph (CSG), supporting both\ntypes of knowledge for CSG-TL. To demonstrate the superiority of CSG-TL on\ntarget localization, extensive experiments are performed on the real-world\nScanNet dataset and the AI2THOR simulator. Moreover, we have extended CSG-TL to\nan object search framework, CSG-OS, validated in both simulated and real-world\nenvironments. Code and videos are available at\nhttps://sites.google.com/view/csg-os."
  },
  {
    "paper_no": "2738",
    "authors": "Lee, Connor; Soedarmadji, Saraswati; Anderson, Matthew; Clark, Anthony; Chung, Soon-Jo",
    "title": "Semantics from Space: Satellite-Guided Thermal Semantic Segmentation Annotation for Aerial Field Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.14056v1",
    "arxiv_abstract": "We present a new method to automatically generate semantic segmentation\nannotations for thermal imagery captured from an aerial vehicle by utilizing\nsatellite-derived data products alongside onboard global positioning and\nattitude estimates. This new capability overcomes the challenge of developing\nthermal semantic perception algorithms for field robots due to the lack of\nannotated thermal field datasets and the time and costs of manual annotation,\nenabling precise and rapid annotation of thermal data from field collection\nefforts at a massively-parallelizable scale. By incorporating a\nthermal-conditioned refinement step with visual foundation models, our approach\ncan produce highly-precise semantic segmentation labels using low-resolution\nsatellite land cover data for little-to-no cost. It achieves 98.5% of the\nperformance from using costly high-resolution options and demonstrates between\n70-160% improvement over popular zero-shot semantic segmentation methods based\non large vision-language models currently used for generating annotations for\nRGB imagery. Code will be available at:\nhttps://github.com/connorlee77/aerial-auto-segment."
  },
  {
    "paper_no": "2739",
    "authors": "Li, Lun; Kasaei, Hamidreza",
    "title": "Single-Shot 6DoF Pose and 3D Size Estimation for Robotic Strawberry Harvesting",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.03031v1",
    "arxiv_abstract": "In this study, we introduce a deep-learning approach for determining both the\n6DoF pose and 3D size of strawberries, aiming to significantly augment robotic\nharvesting efficiency. Our model was trained on a synthetic strawberry dataset,\nwhich is automatically generated within the Ignition Gazebo simulator, with a\nspecific focus on the inherent symmetry exhibited by strawberries. By\nleveraging domain randomization techniques, the model demonstrated exceptional\nperformance, achieving an 84.77\\% average precision (AP) of 3D Intersection\nover Union (IoU) scores on the simulated dataset. Empirical evaluations,\nconducted by testing our model on real-world datasets, underscored the model's\nviability for real-world strawberry harvesting scenarios, even though its\ntraining was based on synthetic data. The model also exhibited robust occlusion\nhandling abilities, maintaining accurate detection capabilities even when\nstrawberries were obscured by other strawberries or foliage. Additionally, the\nmodel showcased remarkably swift inference speeds, reaching up to 60 frames per\nsecond (FPS)."
  },
  {
    "paper_no": "2741",
    "authors": "Sadjadpour, Tara; Yu, Justin; O'Neill, Abigail; Khfifi, Mehdi; Chen, Lawrence Yunliang; Cheng, Richard; Balakrishna, Ashwin; Kollar, Thomas; Goldberg, Ken",
    "title": "Integrating Interactive Perception into Long-Horizon Robot Manipulation Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2742",
    "authors": "Ho, Cherie; Chen, Eric; Maulimov, Mukhtar; Wang, Chen; Scherer, Sebastian",
    "title": "Learning-on-the-Drive: Self-supervised Adaptive Long-range Perception for High-speed Offroad Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2743",
    "authors": "Morton, Daniel; Cutkosky, Mark; Pavone, Marco",
    "title": "Task-Driven Manipulation with Reconfigurable Parallel Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10768v1",
    "arxiv_abstract": "ReachBot, a proposed robotic platform, employs extendable booms as limbs for\nmobility in challenging environments, such as martian caves. When attached to\nthe environment, ReachBot acts as a parallel robot, with reconfiguration driven\nby the ability to detach and re-place the booms. This ability enables\nmanipulation-focused scientific objectives: for instance, through operating\ntools, or handling and transporting samples. To achieve these capabilities, we\ndevelop a two-part solution, optimizing for robustness against task uncertainty\nand stochastic failure modes. First, we present a mixed-integer stance planner\nto determine the positioning of ReachBot's booms to maximize the task wrench\nspace about the nominal point(s). Second, we present a convex tension planner\nto determine boom tensions for the desired task wrenches, accounting for the\nprobabilistic nature of microspine grasping. We demonstrate improvements in key\nrobustness metrics from the field of dexterous manipulation, and show a large\nincrease in the volume of the manipulation workspace. Finally, we employ\nMonte-Carlo simulation to validate the robustness of these methods,\ndemonstrating good performance across a range of randomized tasks and\nenvironments, and generalization to cable-driven morphologies. We make our code\navailable at our project webpage,\nhttps://stanfordasl.github.io/reachbot_manipulation/"
  },
  {
    "paper_no": "2746",
    "authors": "Ubellacker, Wyatt; Ames, Aaron",
    "title": "Learned Regions of Attraction for Safe Motion Primitive Transitions",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2747",
    "authors": "Chi, Hyung-gun; Mercat, Jean; Barreiros, Jose; Ramani, Karthik; Kollar, Thomas",
    "title": "Multi-Modal Representation Learning with Tactile Data",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2748",
    "authors": "Brunacci, Valerio; Dionigi, Alberto; De Angelis, Alessio; Costante, Gabriele",
    "title": "Infrastructure-less UWB-based Active Relative Localization",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.12780v2",
    "arxiv_abstract": "In multi-robot systems, relative localization between platforms plays a\ncrucial role in many tasks, such as leader following, target tracking, or\ncooperative maneuvering. State of the Art (SotA) approaches either rely on\ninfrastructure-based or on infrastructure-less setups. The former typically\nachieve high localization accuracy but require fixed external structures. The\nlatter provide more flexibility, however, most of the works use cameras or\nlidars that require Line-of-Sight (LoS) to operate. Ultra Wide Band (UWB)\ndevices are emerging as a viable alternative to build infrastructure-less\nsolutions that do not require LoS. These approaches directly deploy the UWB\nsensors on the robots. However, they require that at least one of the platforms\nis static, limiting the advantages of an infrastructure-less setup. In this\nwork, we remove this constraint and introduce an active method for\ninfrastructure-less relative localization. Our approach allows the robot to\nadapt its position to minimize the relative localization error of the other\nplatform. To this aim, we first design a specialized anchor placement for the\nactive localization task. Then, we propose a novel UWB Relative Localization\nLoss that adapts the Geometric Dilution Of Precision metric to the\ninfrastructure-less scenario. Lastly, we leverage this loss function to train\nan active Deep Reinforcement Learning-based controller for UWB relative\nlocalization. An extensive simulation campaign and real-world experiments\nvalidate our method, showing up to a 60% reduction of the localization error\ncompared to current SotA approaches."
  },
  {
    "paper_no": "2749",
    "authors": "Hsu, Hao-Lun; Bozkurt, Alper Kamil; Dong, Juncheng; Gao, Qitong; Tarokh, Vahid; Pajic, Miroslav",
    "title": "Steering Decision Transformers via Temporal Difference Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2750",
    "authors": "Benham, Derek; Palacios, Ashton; Lundrigan, Philip; Mangelson, Joshua",
    "title": "Low-Cost Urban Localization with Magnetometer and LoRa Technology",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2753",
    "authors": "Pan, Lishuo; Hsu, Kevin; Ayanian, Nora",
    "title": "Hierarchical Large Scale Multirobot Path (Re)Planning",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.02777v2",
    "arxiv_abstract": "We consider a large-scale multi-robot path planning problem in a cluttered\nenvironment. Our approach achieves real-time replanning by dividing the\nworkspace into cells and utilizing a hierarchical planner. Specifically, we\npropose novel multi-commodity flow-based high-level planners that route robots\nthrough cells with reduced congestion, along with an anytime low-level planner\nthat computes collision-free paths for robots within each cell in parallel. A\nhighlight of our method is a significant improvement in computation time.\nSpecifically, we show empirical results of a 500-times speedup in computation\ntime compared to the baseline multi-agent pathfinding approach on the\nenvironments we study. We account for the robot's embodiment and support\nnon-stop execution with continuous replanning. We demonstrate the real-time\nperformance of our algorithm with up to 142 robots in simulation, and a\nrepresentative 32 physical Crazyflie nano-quadrotor experiment."
  },
  {
    "paper_no": "2755",
    "authors": "Zwane, Sicelukwanda Njabuliso Tunner; Cheney, Daniel G.; Johnson, Curtis C; Luo, Yicheng; Bekiroglu, Yasemin; Killpack, Marc; Deisenroth, Marc Peter",
    "title": "Learning Dynamic Tasks on a Large-scale Soft Robot in a Handful of Trials",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.07342v2",
    "arxiv_abstract": "Soft robots offer more flexibility, compliance, and adaptability than\ntraditional rigid robots. They are also typically lighter and cheaper to\nmanufacture. However, their use in real-world applications is limited due to\nmodeling challenges and difficulties in integrating effective proprioceptive\nsensors. Large-scale soft robots ($\\approx$ two meters in length) have greater\nmodeling complexity due to increased inertia and related effects of gravity.\nCommon efforts to ease these modeling difficulties such as assuming simple\nkinematic and dynamics models also limit the general capabilities of soft\nrobots and are not applicable in tasks requiring fast, dynamic motion like\nthrowing and hammering. To overcome these challenges, we propose a\ndata-efficient Bayesian optimization-based approach for learning control\npolicies for dynamic tasks on a large-scale soft robot. Our approach optimizes\nthe task objective function directly from commanded pressures, without\nrequiring approximate kinematics or dynamics as an intermediate step. We\ndemonstrate the effectiveness of our approach through both simulated and\nreal-world experiments."
  },
  {
    "paper_no": "2756",
    "authors": "Zhang, Dandan; Zheng, Jin",
    "title": "Towards the New Generation of Smart Home-Care with Cloud-Based Internet of Humans and Robotic Things",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2757",
    "authors": "Wang, Zhiquan; fan, baojie; Gao, Xuan; zhou, yuhan; zhang, caiyu",
    "title": "Masked Mutual Guidance Transformer Tracking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2760",
    "authors": "Amatucci, Lorenzo; Turrisi, Giulio; Bratta, Angelo; Barasuol, Victor; Semini, Claudio",
    "title": "Accelerating Model Predictive Control for Legged Robots through Distributed Optimization",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.11742v4",
    "arxiv_abstract": "This paper presents a novel approach to enhance Model Predictive Control\n(MPC) for legged robots through Distributed Optimization. Our method focuses on\ndecomposing the robot dynamics into smaller, parallelizable subsystems, and\nutilizing the Alternating Direction Method of Multipliers (ADMM) to ensure\nconsensus among them. Each subsystem is managed by its own Optimal Control\nProblem, with ADMM facilitating consistency between their optimizations. This\napproach not only decreases the computational time but also allows for\neffective scaling with more complex robot configurations, facilitating the\nintegration of additional subsystems such as articulated arms on a quadruped\nrobot. We demonstrate, through numerical evaluations, the convergence of our\napproach on two systems with increasing complexity. In addition, we showcase\nthat our approach converges towards the same solution when compared to a\nstate-of-the-art centralized whole-body MPC implementation. Moreover, we\nquantitatively compare the computational efficiency of our method to the\ncentralized approach, revealing up to a 75% reduction in computational time.\nOverall, our approach offers a promising avenue for accelerating MPC solutions\nfor legged robots, paving the way for more effective utilization of the\ncomputational performance of modern hardware."
  },
  {
    "paper_no": "2761",
    "authors": "Pittiglio, Giovanni; Donder, Abdulhamit; Dupont, Pierre",
    "title": "Continuum Robot Shape Estimation Using Magnetic Ball Chains",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.16025v1",
    "arxiv_abstract": "Shape sensing of medical continuum robots is important both for closed-loop\ncontrol as well as for enabling the clinician to visualize the robot inside the\nbody. There is a need for inexpensive, but accurate shape sensing technologies.\nThis paper proposes the use of magnetic ball chains as a means of generating\nshape-specific magnetic fields that can be detected by an external array of\nHall effect sensors. Such a ball chain, encased in a flexible polymer sleeve,\ncould be inserted inside the lumen of any continuum robot to provide real-time\nshape feedback. The sleeve could be removed, as needed, during the procedure to\nenable use of the entire lumen. To investigate this approach, a shape-sensing\nmodel for a steerable catheter tip is derived and an observability and\nsensitivity analysis are presented. Experiments show maximum estimation errors\nof 7.1% and mean of 2.9% of the tip position with respect to total length."
  },
  {
    "paper_no": "2762",
    "authors": "Abu Ajamieh, Ihab; Al Saaideh, Mohammad; Al Janaideh, Mohammad; Mills, James K.",
    "title": "Automating Trophectoderm Cells Aspiration and Separation in Embryo Biopsy at the Blastocyst Stage: A Vision-Based Control Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2763",
    "authors": "Bozzini, Chiara; Boldo, Michele; Martini, Enrico; Bombieri, Nicola",
    "title": "A Real-time Filter for Human Pose Estimation based on Denoising Diffusion Models for Edge Devices",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2764",
    "authors": "Murray, Michael; Su, Entong; Cakmak, Maya",
    "title": "Diffusion-PbD: Generalizable Robot Programming by Demonstration with Diffusion Features",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2766",
    "authors": "Shi, Moji; Chen, Gang; Serra-Gómez, Álvaro; Wu, Siyuan; Alonso-Mora, Javier",
    "title": "Evaluating Dynamic Environment Difficulty for Obstacle Avoidance Benchmarking",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.14848v1",
    "arxiv_abstract": "Dynamic obstacle avoidance is a popular research topic for autonomous\nsystems, such as micro aerial vehicles and service robots. Accurately\nevaluating the performance of dynamic obstacle avoidance methods necessitates\nthe establishment of a metric to quantify the environment's difficulty, a\ncrucial aspect that remains unexplored. In this paper, we propose four metrics\nto measure the difficulty of dynamic environments. These metrics aim to\ncomprehensively capture the influence of obstacles' number, size, velocity, and\nother factors on the difficulty. We compare the proposed metrics with existing\nstatic environment difficulty metrics and validate them through over 1.5\nmillion trials in a customized simulator. This simulator excludes the effects\nof perception and control errors and supports different motion and gaze\nplanners for obstacle avoidance. The results indicate that the survivability\nmetric outperforms and establishes a monotonic relationship between the success\nrate, with a Spearman's Rank Correlation Coefficient (SRCC) of over 0.9.\nSpecifically, for every planner, lower survivability leads to a higher success\nrate. This metric not only facilitates fair and comprehensive benchmarking but\nalso provides insights for refining collision avoidance methods, thereby\nfurthering the evolution of autonomous systems in dynamic environments."
  },
  {
    "paper_no": "2767",
    "authors": "Kim, Hyojeong; Jo, Jeong Yong; Lim, Myo-Taeg; Kim, ChangHwan",
    "title": "Efficient Target Singulation with Multi-Fingered Gripper using Propositional Logic",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2768",
    "authors": "Zhang, Zewei; Bellegarda, Guillaume; Shafiee, Milad; Ijspeert, Auke",
    "title": "Online Optimization of Central Pattern Generators for Quadruped Locomotion",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.16417v1",
    "arxiv_abstract": "Typical legged locomotion controllers are designed or trained offline. This\nis in contrast to many animals, which are able to locomote at birth, and\nrapidly improve their locomotion skills with few real-world interactions. Such\nmotor control is possible through oscillatory neural networks located in the\nspinal cord of vertebrates, known as Central Pattern Generators (CPGs). Models\nof the CPG have been widely used to generate locomotion skills in robotics, but\ncan require extensive hand-tuning or offline optimization of inter-connected\nparameters with genetic algorithms. In this paper, we present a framework for\nthe \\textit{online} optimization of the CPG parameters through Bayesian\nOptimization. We show that our framework can rapidly optimize and adapt to\nvarying velocity commands and changes in the terrain, for example to varying\ncoefficients of friction, terrain slope angles, and added mass payloads placed\non the robot. We study the effects of sensory feedback on the CPG, and find\nthat both force feedback in the phase equations, as well as posture control\n(Virtual Model Control) are both beneficial for robot stability and energy\nefficiency. In hardware experiments on the Unitree Go1, we show rapid\noptimization (in under 3 minutes) and adaptation of energy-efficient gaits to\nvarying target velocities in a variety of scenarios: varying coefficients of\nfriction, added payloads up to 15 kg, and variable slopes up to 10 degrees. See\ndemo at: https://youtu.be/4qq5leCI2AI"
  },
  {
    "paper_no": "2769",
    "authors": "Rishan Sachinthana, Wijenayaka Kankanamge; Samarakoon Mudiyanselage, Bhagya Prasangi Samarakoon; Muthugala Arachchige, Viraj Jagathpriya Muthugala; Elara, Mohan Rajesh",
    "title": "Dynamic Reconfiguration Integrated Nested A*: A Path Planner for Reconfigurable Robot to Improve Performance in Confined Spaces",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2770",
    "authors": "Chane-Sane, Elliot; Leziart, Pierre-Alexandre; Flayols, Thomas; Stasse, Olivier; Soueres, Philippe; Mansard, Nicolas",
    "title": "CaT: Constraints as Terminations for Legged Locomotion Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2772",
    "authors": "Bargmann, Daniel; Kraus, Werner; Huber, Marco F.",
    "title": "Enabling Maintainablity of Robot Programs in Assembly by Extracting Compositions of Force- and Position-Based Robot Skills from Learning-from-Demonstration Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2773",
    "authors": "Lin, Shan; Miao, Albert; Alabiad, Ali; LIU, FEI; Wang, Kaiyuan; Lu, Jingpei; Richter, Florian; Yip, Michael C.",
    "title": "SuPerPM: A Surgical Perception Framework Based on Deep Point Matching Learned from Physical Constrained Simulation Data",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2775",
    "authors": "Harms, Marvin Chayton; Kulkarni, Mihir; Khedekar, Nikhil Vijay; Jacquet, Martin; Alexis, Kostas",
    "title": "Neural Control Barrier Functions for Safe Navigation",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.19907v1",
    "arxiv_abstract": "Autonomous robot navigation can be particularly demanding, especially when\nthe surrounding environment is not known and safety of the robot is crucial.\nThis work relates to the synthesis of Control Barrier Functions (CBFs) through\ndata for safe navigation in unknown environments. A novel methodology to\njointly learn CBFs and corresponding safe controllers, in simulation, inspired\nby the State Dependent Riccati Equation (SDRE) is proposed. The CBF is used to\nobtain admissible commands from any nominal, possibly unsafe controller. An\napproach to apply the CBF inside a safety filter without the need for a\nconsistent map or position estimate is developed. Subsequently, the resulting\nreactive safety filter is deployed on a multirotor platform integrating a LiDAR\nsensor both in simulation and real-world experiments."
  },
  {
    "paper_no": "2777",
    "authors": "Fang, Xiaolin; Garrett, Caelan; Eppner, Clemens; Lozano-Perez, Tomas; Kaelbling, Leslie; Fox, Dieter",
    "title": "DiMSam: Diffusion Models as Samplers for Task and Motion Planning under Partial Observability",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2781",
    "authors": "Lorimer, Philip; Saunders, Jack; Hunter, Alan Joseph; Li, Wenbin",
    "title": "Reinforcement Learning of Dolly-In Filming Using a Ground-Based Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2782",
    "authors": "Cai, Yichen; Gao, Jianfeng; Pohl, Christoph; Asfour, Tamim",
    "title": "Visual Imitation Learning of Task-Oriented Object Grasping and Rearrangement",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.14000v1",
    "arxiv_abstract": "Task-oriented object grasping and rearrangement are critical skills for\nrobots to accomplish different real-world manipulation tasks. However, they\nremain challenging due to partial observations of the objects and shape\nvariations in categorical objects. In this paper, we propose the Multi-feature\nImplicit Model (MIMO), a novel object representation that encodes multiple\nspatial features between a point and an object in an implicit neural field.\nTraining such a model on multiple features ensures that it embeds the object\nshapes consistently in different aspects, thus improving its performance in\nobject shape reconstruction from partial observation, shape similarity measure,\nand modeling spatial relations between objects. Based on MIMO, we propose a\nframework to learn task-oriented object grasping and rearrangement from single\nor multiple human demonstration videos. The evaluations in simulation show that\nour approach outperforms the state-of-the-art methods for multi- and\nsingle-view observations. Real-world experiments demonstrate the efficacy of\nour approach in one- and few-shot imitation learning of manipulation tasks."
  },
  {
    "paper_no": "2784",
    "authors": "Yang, Yue; Ikeda, Bryce; Bertasius, Gedas; Szafir, Daniel J.",
    "title": "ARCADE: Scalable Demonstration Collection and Generation via Augmented Reality for Imitation Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2785",
    "authors": "Le Gentil, Cedric; Falque, Raphael; Vidal-Calleja, Teresa A.",
    "title": "Real-Time Truly-Coupled Lidar-Inertial Motion Correction and Spatiotemporal Dynamic Object Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2788",
    "authors": "Hoshimure, Kenya; Baba, Jun; Nakanishi, Junya; Yoshikawa, Yuichiro; Ishiguro, Hiroshi",
    "title": "Where and when should the teleoperated avatar look: Gaze Instruction Dataset for Enhanced Teleoperated Avatar Communication",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2790",
    "authors": "Soltanshah, Mohammad; eskandarpour, abolfazl; mehrandezh, mehran; Gupta, Kamal",
    "title": "Robust Partitioned Visual Servoing for Aerial Manipulation Utilizing Controllable-space Image Planning and Adaptive Image Representation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2791",
    "authors": "Di Felice, Francesco; Remus, Alberto; Gasperini, Stefano; Busam, Benjamin; Ott, Lionel; Tombari, Federico; Siegwart, Roland; Avizzano, Carlo Alberto",
    "title": "Zero123-6D: Zero-shot Novel View Synthesis for RGB Category-level 6D Pose Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2792",
    "authors": "Pei, Guanran; Stella, Francesco; Meebed, Omar Hani Mokhtar Ahmed; Bing, Zhenshan; Della Santina, Cosimo; Hughes, Josie",
    "title": "IMU Based Pose Reconstruction and Closed-loop Control for Soft Robotic Arms",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2793",
    "authors": "O'Neill, Cormac; Asada, Harry",
    "title": "Koopman Dynamic Modeling for Global and Unified Representations of Rigid Body Systems Making and Breaking Contact",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2794",
    "authors": "McGuire, Loy; Otte, Michael W.; Sofge, Donald",
    "title": "Valuing Attrition in a Fleet of Robots Used as Path-Based Sensors for Gathering Information in a Communications Restricted Environment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2795",
    "authors": "Yoshioka, Hiroki; Hiraoka, Naoki; Kojima, Kunio; Okada, Kei; Inaba, Masayuki",
    "title": "Design of Upper-Limb Exoskeleton with Distal Branching Link Mechanism for Bilateral Operation of Humanoid Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2800",
    "authors": "WANG, Sheng",
    "title": "Dragtraffic: Interactive and Controllable Traffic Scene Generation for Autonomous Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2805",
    "authors": "Ge, Jiawei; Kilmer, Ethan; Mady, Leila; Opfermann, Justin; Krieger, Axel",
    "title": "Enhancing Surgical Precision in Autonomous Robotic Incisions via Physics-Based Tissue Cutting Simulation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2806",
    "authors": "Herneth, Christopher; Ganguly, Amartya; Haddadin, Sami",
    "title": "Recommendations on joint capabilities for transhumeral prosthetics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2807",
    "authors": "Muraoka, Tomoka; Aoki, Tatsuya; Hirata, Masayuki; Taniguchi, Tadahiro; Horii, Takato; Nagai, Takayuki",
    "title": "Goal Estimation-based Adaptive Shared Control for Brain-Machine Interfaces Remote Robot Navigation",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.17936v1",
    "arxiv_abstract": "In this study, we propose a shared control method for teleoperated mobile\nrobots using brain-machine interfaces (BMI). The control commands generated\nthrough BMI for robot operation face issues of low input frequency,\ndiscreteness, and uncertainty due to noise. To address these challenges, our\nmethod estimates the user's intended goal from their commands and uses this\ngoal to generate auxiliary commands through the autonomous system that are both\nat a higher input frequency and more continuous. Furthermore, by defining the\nconfidence level of the estimation, we adaptively calculated the weights for\ncombining user and autonomous commands, thus achieving shared control."
  },
  {
    "paper_no": "2811",
    "authors": "Turrisi, Giulio; Modugno, Valerio; Amatucci, Lorenzo; Kanoulas, Dimitrios; Semini, Claudio",
    "title": "On the Benefits of GPU Sample-Based Stochastic Predictive Controllers for Legged Locomotion",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.11383v2",
    "arxiv_abstract": "Quadrupedal robots excel in mobility, navigating complex terrains with\nagility. However, their complex control systems present challenges that are\nstill far from being fully addressed. In this paper, we introduce the use of\nSample-Based Stochastic control strategies for quadrupedal robots, as an\nalternative to traditional optimal control laws. We show that Sample-Based\nStochastic methods, supported by GPU acceleration, can be effectively applied\nto real quadruped robots. In particular, in this work, we focus on achieving\ngait frequency adaptation, a notable challenge in quadrupedal locomotion for\ngradient-based methods. To validate the effectiveness of Sample-Based\nStochastic controllers we test two distinct approaches for quadrupedal robots\nand compare them against a conventional gradient-based Model Predictive Control\nsystem. Our findings, validated both in simulation and on a real 21Kg Aliengo\nquadruped, demonstrate that our method is on par with a traditional Model\nPredictive Control strategy when the robot is subject to zero or moderate\ndisturbance, while it surpasses gradient-based methods in handling sustained\nexternal disturbances, thanks to the straightforward gait adaptation strategy\nthat is possible to achieve within their formulation."
  },
  {
    "paper_no": "2814",
    "authors": "Long, Juncai; Li, Jituo; Diao, Xiaojie; Zhou, Chengdi; Lu, GuoDong; Feng, Yixiong",
    "title": "Multistable Soft Actuator for Physical Human-robot Interaction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2815",
    "authors": "Theisen, Nick; Bartsch, Robin; Paulus, Dietrich; Neubert, Peer",
    "title": "HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic Segmentation in Driving Scenarios",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2817",
    "authors": "Merz Hoffmeister, Liam; Scassellati, Brian; Rakita, Daniel",
    "title": "Sequential Discrete Action Selection via Blocking Conditions and Resolutions",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.08410v1",
    "arxiv_abstract": "In this work, we introduce a strategy that frames the sequential action\nselection problem for robots in terms of resolving \\textit{blocking\nconditions}, i.e., situations that impede progress on an action en route to a\ngoal. This strategy allows a robot to make one-at-a-time decisions that take in\npertinent contextual information and swiftly adapt and react to current\nsituations. We present a first instantiation of this strategy that combines a\nstate-transition graph and a zero-shot Large Language Model (LLM). The\nstate-transition graph tracks which previously attempted actions are currently\nblocked and which candidate actions may resolve existing blocking conditions.\nThis information from the state-transition graph is used to automatically\ngenerate a prompt for the LLM, which then uses the given context and set of\npossible actions to select a single action to try next. This selection process\nis iterative, with each chosen and executed action further refining the\nstate-transition graph, continuing until the agent either fulfills the goal or\nencounters a termination condition. We demonstrate the effectiveness of our\napproach by comparing it to various LLM and traditional task-planning methods\nin a testbed of simulation experiments. We discuss the implications of our work\nbased on our results."
  },
  {
    "paper_no": "2820",
    "authors": "Perauer, Cedric; Zhang, Haifan; Heidrich, Laurenz Adrian; Niessner, Matthias; Kornilova, Anastasiia; Artemov, Alexey",
    "title": "AutoInst: Automatic Instance-Based Segmentation of LiDAR 3D Scans",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2822",
    "authors": "Cebulla, Alexander; Asfour, Tamim; Kroeger, Torsten",
    "title": "Beyond Feasibility: Efficiently Planning Robotic Assembly Sequences That Minimize Assembly Path Lengths",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2824",
    "authors": "Docena, Amel Nestor; Quattrini Li, Alberto",
    "title": "Search-based Strategy for Spatio-Temporal Environmental Property Restoration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2825",
    "authors": "Krnjaic, Aleksandar; Steleac, Raul Dacian; Thomas, Jonathan David; Papoudakis, Georgios; Schäfer, Lukas; To, Andrew; Lao, Kuan-Ho; Cubuktepe, Murat; Haley, Matthew; Börsting, Peter; Albrecht, Stefano V.",
    "title": "Scalable Multi-Agent Reinforcement Learning for Warehouse Logistics with Robotic and Human Co-Workers",
    "arxiv_pdf": "http://arxiv.org/pdf/2212.11498v3",
    "arxiv_abstract": "We consider a warehouse in which dozens of mobile robots and human pickers\nwork together to collect and deliver items within the warehouse. The\nfundamental problem we tackle, called the order-picking problem, is how these\nworker agents must coordinate their movement and actions in the warehouse to\nmaximise performance in this task. Established industry methods using heuristic\napproaches require large engineering efforts to optimise for innately variable\nwarehouse configurations. In contrast, multi-agent reinforcement learning\n(MARL) can be flexibly applied to diverse warehouse configurations (e.g. size,\nlayout, number/types of workers, item replenishment frequency), and different\ntypes of order-picking paradigms (e.g. Goods-to-Person and Person-to-Goods), as\nthe agents can learn how to cooperate optimally through experience. We develop\nhierarchical MARL algorithms in which a manager agent assigns goals to worker\nagents, and the policies of the manager and workers are co-trained toward\nmaximising a global objective (e.g. pick rate). Our hierarchical algorithms\nachieve significant gains in sample efficiency over baseline MARL algorithms\nand overall pick rates over multiple established industry heuristics in a\ndiverse set of warehouse configurations and different order-picking paradigms."
  },
  {
    "paper_no": "2826",
    "authors": "Chang, Haonan; Gao, Kai; Boyalakuntla, Kowndinya; Lee, Alex; Huang, Baichuan; Yu, Jingjin; Boularias, Abdeslam",
    "title": "LGMCTS: Language-Guided Monte-Carlo Tree Search for Executable Semantic Object Rearrangement",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2828",
    "authors": "Ribeiro da Silva, Alysson; Chaimowicz, Luiz; Costa Silva, Thales; Hsieh, M. Ani",
    "title": "Communication-Constrained Multi-Robot Exploration with Intermittent Rendezvous",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.13494v6",
    "arxiv_abstract": "Communication constraints can significantly impact robots' ability to share\ninformation, coordinate their movements, and synchronize their actions, thus\nlimiting coordination in Multi-Robot Exploration (MRE) applications. In this\nwork, we address these challenges by modeling the MRE application as a\nDEC-POMDP and designing a joint policy that follows a rendezvous plan. This\npolicy allows robots to explore unknown environments while intermittently\nsharing maps opportunistically or at rendezvous locations without being\nconstrained by joint path optimizations. To generate the rendezvous plan,\nrobots represent the MRE task as an instance of the Job Shop Scheduling Problem\n(JSSP) and minimize JSSP metrics. They aim to reduce waiting times and increase\nconnectivity, which correlates to the DEC-POMDP rewards and time to complete\nthe task. Our simulation results suggest that our method is more efficient than\nusing relays or maintaining intermittent communication with a base station,\nbeing a suitable approach for Multi-Robot Exploration. We developed a\nproof-of-concept using the Robot Operating System (ROS) that is available at:\nhttps://github.com/multirobotplayground/ROS-Noetic-Multi-robot-Sandbox."
  },
  {
    "paper_no": "2829",
    "authors": "Sun, Qilin; Zhi, Weiming; Zhang, Tianyi; Johnson-Roberson, Matthew",
    "title": "Diagrammatic Instructions to Specify Spatial Objectives and Constraints with Applications to Mobile Base Placement",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2830",
    "authors": "Liu, Dandi; Mei, Jiahao; Zhou, Jin; Li, Shuo",
    "title": "An Observability Constrained Downward-Facing Optical-Flow-Aided Visual-Inertial Odometry",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2831",
    "authors": "Tang, Yuxuan; Wu, Qizhen; Zhu, Chunli; Chen, Lei",
    "title": "An Efficient Coverage Method for Irregularly Shaped Terrains",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2832",
    "authors": "Chignoli, Matthew; Pardis, Shayan; Kim, Sangbae",
    "title": "Probabilistic Homotopy Optimization for Dynamic Motion Planning",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.12490v1",
    "arxiv_abstract": "We present a homotopic approach to solving challenging, optimization-based\nmotion planning problems. The approach uses Homotopy Optimization, which,\nunlike standard continuation methods for solving homotopy problems, solves a\nsequence of constrained optimization problems rather than a sequence of\nnonlinear systems of equations. The insight behind our proposed algorithm is\nformulating the discovery of this sequence of optimization problems as a search\nproblem in a multidimensional homotopy parameter space. Our proposed algorithm,\nthe Probabilistic Homotopy Optimization algorithm, switches between solve and\nsample phases, using solutions to easy problems as initial guesses to more\nchallenging problems. We analyze how our algorithm performs in the presence of\ncommon challenges to homotopy methods, such as bifurcation, folding, and\ndisconnectedness of the homotopy solution manifold. Finally, we demonstrate its\nutility via a case study on two dynamic motion planning problems: the cart-pole\nand the MIT Humanoid."
  },
  {
    "paper_no": "2833",
    "authors": "Saunders, Jack; Saeedi, Sajad; Hartshorne, Adam; Xu, Binbin; &#350;im&#351;ek, Özgür; Hunter, Alan Joseph; Li, Wenbin",
    "title": "Identifying Optimal Launch Sites of High-Altitude Latex-Balloons using Bayesian Optimisation for the Task of Station-Keeping",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10784v1",
    "arxiv_abstract": "Station-keeping tasks for high-altitude balloons show promise in areas such\nas ecological surveys, atmospheric analysis, and communication relays. However,\nidentifying the optimal time and position to launch a latex high-altitude\nballoon is still a challenging and multifaceted problem. For example, tasks\nsuch as forest fire tracking place geometric constraints on the launch location\nof the balloon. Furthermore, identifying the most optimal location also heavily\ndepends on atmospheric conditions. We first illustrate how reinforcement\nlearning-based controllers, frequently used for station-keeping tasks, can\nexploit the environment. This exploitation can degrade performance on unseen\nweather patterns and affect station-keeping performance when identifying an\noptimal launch configuration. Valuing all states equally in the region, the\nagent exploits the region's geometry by flying near the edge, leading to risky\nbehaviours. We propose a modification which compensates for this exploitation\nand finds this leads to, on average, higher steps within the target region on\nunseen data. Then, we illustrate how Bayesian Optimisation (BO) can identify\nthe optimal launch location to perform station-keeping tasks, maximising the\nexpected undiscounted return from a given rollout. We show BO can find this\nlaunch location in fewer steps compared to other optimisation methods. Results\nindicate that, surprisingly, the most optimal location to launch from is not\ncommonly within the target region. Please find further information about our\nproject at https://sites.google.com/view/bo-lauch-balloon/."
  },
  {
    "paper_no": "2837",
    "authors": "Rathnayake, Darshana; Sabbella, Hemanth; Radhakrishnan, Meera; Misra, Archan",
    "title": "D2SR: Decentralized Detection, De-Synchronization, and Recovery of LiDAR Interference",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2838",
    "authors": "Sun, Lisong C.; Bhatt, Neel P.; Liu, Jonathan C.; Fan, Zhiwen; Wang, Zhangyang (Atlas); Humphreys, Todd E.; Topcu, Ufuk",
    "title": "MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.00923v1",
    "arxiv_abstract": "Simultaneous localization and mapping is essential for position tracking and\nscene understanding. 3D Gaussian-based map representations enable\nphotorealistic reconstruction and real-time rendering of scenes using multiple\nposed cameras. We show for the first time that using 3D Gaussians for map\nrepresentation with unposed camera images and inertial measurements can enable\naccurate SLAM. Our method, MM3DGS, addresses the limitations of prior neural\nradiance field-based representations by enabling faster rendering, scale\nawareness, and improved trajectory tracking. Our framework enables\nkeyframe-based mapping and tracking utilizing loss functions that incorporate\nrelative pose transformations from pre-integrated inertial measurements, depth\nestimates, and measures of photometric rendering quality. We also release a\nmulti-modal dataset, UT-MM, collected from a mobile robot equipped with a\ncamera and an inertial measurement unit. Experimental evaluation on several\nscenes from the dataset shows that MM3DGS achieves 3x improvement in tracking\nand 5% improvement in photometric rendering quality compared to the current\n3DGS SLAM state-of-the-art, while allowing real-time rendering of a\nhigh-resolution dense 3D map. Project Webpage:\nhttps://vita-group.github.io/MM3DGS-SLAM"
  },
  {
    "paper_no": "2839",
    "authors": "GAO, YIFEI; Yetkin, Harun; Stilwell, Daniel; McMahon, James",
    "title": "Prediction of Acoustic Communication Performance for AUVs using Gaussian Process Classification",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.07933v1",
    "arxiv_abstract": "Cooperating autonomous underwater vehicles (AUVs) often rely on acoustic\ncommunication to coordinate their actions effectively. However, the reliability\nof underwater acoustic communication decreases as the communication range\nbetween vehicles increases. Consequently, teams of cooperating AUVs typically\nmake conservative assumptions about the maximum range at which they can\ncommunicate reliably. To address this limitation, we propose a novel approach\nthat involves learning a map representing the probability of successful\ncommunication based on the locations of the transmitting and receiving\nvehicles. This probabilistic communication map accounts for factors such as the\nrange between vehicles, environmental noise, and multi-path effects at a given\nlocation. In pursuit of this goal, we investigate the application of Gaussian\nprocess binary classification to generate the desired communication map. We\nspecialize existing results to this specific binary classification problem and\nexplore methods to incorporate uncertainty in vehicle location into the mapping\nprocess. Furthermore, we compare the prediction performance of the probability\ncommunication map generated using binary classification with that of a\nsignal-to-noise ratio (SNR) communication map generated using Gaussian process\nregression. Our approach is experimentally validated using communication and\nnavigation data collected during trials with a pair of Virginia Tech 690 AUVs."
  },
  {
    "paper_no": "2841",
    "authors": "Gongye, Zaitian; Guo, Lianjie; Xu, Ziyi; Wang, Yingjian; Zhou, Xin; ZHOU, Jinni; Gao, Fei",
    "title": "Preserving Relative Localization of FoV-Limited Drone Swarm via Active Mutual Observation",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.01292v1",
    "arxiv_abstract": "Relative state estimation is crucial for vision-based swarms to estimate and\ncompensate for the unavoidable drift of visual odometry. For autonomous drones\nequipped with the most compact sensor setting -- a stereo camera that provides\na limited field of view (FoV), the demand for mutual observation for relative\nstate estimation conflicts with the demand for environment observation. To\nbalance the two demands for FoV limited swarms by acquiring mutual observations\nwith a safety guarantee, this paper proposes an active localization correction\nsystem, which plans camera orientations via a yaw planner during the flight.\nThe yaw planner manages the contradiction by calculating suitable timing and\nyaw angle commands based on the evaluation of localization uncertainty\nestimated by the Kalman Filter. Simulation validates the scalability of our\nalgorithm. In real-world experiments, we reduce positioning drift by up to 65%\nand managed to maintain a given formation in both indoor and outdoor GPS-denied\nflight, from which the accuracy, efficiency, and robustness of the proposed\nsystem are verified."
  },
  {
    "paper_no": "2842",
    "authors": "Ferreira Chame, Hendry; Alami, Rachid",
    "title": "AEGO: Modeling Attention for HRI in Ego-Sphere Neural Networks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2846",
    "authors": "Yokoyama, Naoki; Ramrakhya, Ram; Das, Abhishek; Batra, Dhruv; Ha, Sehoon",
    "title": "HM3D-OVON: A Dataset and Benchmark for Open-Vocabulary Object Goal Navigation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2848",
    "authors": "ZHANG, YIFENG; LI, Peizhuo; Fan, Mingfeng; Sartoretti, Guillaume Adrien",
    "title": "HeteroLight: A General and Efficient Learning Approach for Heterogeneous Traffic Signal Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2853",
    "authors": "Ondika, Patrick; Mrázek, Jan; Barnat, Jiri",
    "title": "Tree-Based Reconfiguration of Metamorphic Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2854",
    "authors": "Shore, Tavis George; Hadfield, Simon; Mendez, Oscar",
    "title": "BEV-CV: Birds-Eye-View Transform for Cross-View Geo-Localisation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2856",
    "authors": "Cai, Yuxin; He, Xiangkun; Guo, Hongliang; Yau, Wei-Yun; Lv, Chen",
    "title": "Transformer-based Multi-Agent Reinforcement Learning for Generalization of Heterogeneous Multi-Robot Cooperation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2857",
    "authors": "Gamache, Olivier; Fortin, Jean-Michel; Boxan, Matej; Vaidis, Maxime; Pomerleau, Francois; Giguère, Philippe",
    "title": "Exposing the Unseen: Exposure Time Emulation for Offline Benchmarking of Vision Algorithms",
    "arxiv_pdf": "http://arxiv.org/pdf/2309.13139v3",
    "arxiv_abstract": "Visual Odometry (VO) is one of the fundamental tasks in computer vision for\nrobotics. However, its performance is deeply affected by High Dynamic Range\n(HDR) scenes, omnipresent outdoor. While new Automatic-Exposure (AE) approaches\nto mitigate this have appeared, their comparison in a reproducible manner is\nproblematic. This stems from the fact that the behavior of AE depends on the\nenvironment, and it affects the image acquisition process. Consequently, AE has\ntraditionally only been benchmarked in an online manner, making the experiments\nnon-reproducible. To solve this, we propose a new methodology based on an\nemulator that can generate images at any exposure time. It leverages BorealHDR,\na unique multi-exposure stereo dataset collected over 10 km, on 55 trajectories\nwith challenging illumination conditions. Moreover, it includes\nlidar-inertial-based global maps with pose estimation for each image frame as\nwell as Global Navigation Satellite System (GNSS) data, for comparison. We show\nthat using these images acquired at different exposure times, we can emulate\nrealistic images, keeping a Root-Mean-Square Error (RMSE) below 1.78 % compared\nto ground truth images. To demonstrate the practicality of our approach for\noffline benchmarking, we compared three state-of-the-art AE algorithms on key\nelements of Visual Simultaneous Localization And Mapping (VSLAM) pipeline,\nagainst four baselines. Consequently, reproducible evaluation of AE is now\npossible, speeding up the development of future approaches. Our code and\ndataset are available online at this link:\nhttps://github.com/norlab-ulaval/BorealHDR"
  },
  {
    "paper_no": "2860",
    "authors": "Consumi, Vanni; Dei, Neri Niccolò; Ciuti, Gastone; Stoyanov, Danail; Stilli, Agostino",
    "title": "Miniaturisation and Evaluation of the SoftSCREEN System in Colon Phantoms",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2863",
    "authors": "Shikada, Genki; Armleder, Simon; Ito, Hiroshi; Cheng, Gordon; Ogata, Tetsuya",
    "title": "Real-time Coordinated Motion Generation: A Hierarchical Deep Predictive Learning Model for Bimanual Tasks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2864",
    "authors": "Lu, Jiaxing; Hossain, Sanzida; Sheng, Weihua; BAI, HE",
    "title": "An LSTM-based Model to Recognize Driving Style and Predict Acceleration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2865",
    "authors": "Zuo, Guoyu; Dong, Shuaifeng; Zhou, Jiyong; Yu, Shuangyue",
    "title": "A Cascaded Broad Learning System for Manipulator Motion Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2868",
    "authors": "HU, Tianshuai; JIAO, Jianhao; Xu, Yucheng; Liu, Hongji; WANG, Sheng; Liu, Ming",
    "title": "DHP-Mapping: A Dense Panoptic Mapping System with Hierarchical World Representation and Label Optimization Techniques",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2870",
    "authors": "Chen, Zheng; Duggirala, Deepak; Crandall, David; Jiang, Lei; Liu, Lantao",
    "title": "SePaint: Semantic Map Inpainting via Multinomial Diffusion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2873",
    "authors": "Rauso, Giuseppe; Caccavale, Riccardo; Finzi, Alberto",
    "title": "Incremental Learning of Robotic Manipulation Tasks through Virtual Reality Demonstrations",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2875",
    "authors": "Hulchuk, Vsevolod; Bayer, Jan; Faigl, Jan",
    "title": "LiDAR-Visual-Inertial Tightly-coupled Odometry with Adaptive Learnable Fusion Weights",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2876",
    "authors": "Jiang, Ping; Komoda, Kazuma; Han, Haifeng; Ooga, Jun'ichiro",
    "title": "MultipleCupSuctionNet: Deep Neural Network for Detecting Grasp Pose of a Vacuum Gripper with Multiple Suction Cups based on YOLO Feature Map Affine Transformation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2878",
    "authors": "Jordan, Britton; Esser, Daniel; Kim, Jeonghyeon; Cho, Brian Y; Webster III, Robert James; Kuntz, Alan",
    "title": "Exploring Modal Switch in Metamaterial-Based Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2881",
    "authors": "Ko, Dongwoo; Kim, Jonghyeok; Chung, Wan Kyun",
    "title": "Ensuring Joint Constraints of Torque-Controlled Robot Manipulators under Bounded Jerk",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2883",
    "authors": "Black, Mitchell; Fainekos, Georgios; Hoxha, Bardh; OKAMOTO, HIDEKI; Prokhorov, Danil",
    "title": "CBFkit: A Control Barrier Function Toolbox for Robotics Applications",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2886",
    "authors": "Dravid, Meghali Prashant; Oevermann, Micah; McDougall, David; Dugas, David; Ambrose, Robert",
    "title": "Design of a Soft Shell for a Spherical Exploration Robot Traversing Varying Terrain",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2887",
    "authors": "Hathaway, Jamie; Rastegarpanah, Alireza; Stolkin, Rustam",
    "title": "Imitation learning for sim-to-real adaptation of robotic cutting policies based on residual Gaussian process disturbance force model",
    "arxiv_pdf": "http://arxiv.org/pdf/2311.04096v2",
    "arxiv_abstract": "Robotic cutting, or milling, plays a significant role in applications such as\ndisassembly, decommissioning, and demolition. Planning and control of cutting\nin real-world scenarios in uncertain environments is a complex task, with the\npotential to benefit from simulated training environments. This letter focuses\non sim-to-real transfer for robotic cutting policies, addressing the need for\neffective policy transfer from simulation to practical implementation. We\nextend our previous domain generalisation approach to learning cutting tasks\nbased on a mechanistic model-based simulation framework, by proposing a hybrid\napproach for sim-to-real transfer based on a milling process force model and\nresidual Gaussian process (GP) force model, learned from either single or\nmultiple real-world cutting force examples. We demonstrate successful\nsim-to-real transfer of a robotic cutting policy without the need for\nfine-tuning on the real robot setup. The proposed approach autonomously adapts\nto materials with differing structural and mechanical properties. Furthermore,\nwe demonstrate the proposed method outperforms fine-tuning or re-training\nalone."
  },
  {
    "paper_no": "2888",
    "authors": "Hu, Zechen; Limbu, Manshi; Shishika, Daigo; Xiao, Xuesu; Wang, Xuan",
    "title": "Learning Coordinated Maneuver in Adversarial Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.09469v2",
    "arxiv_abstract": "This paper aims to solve the coordination of a team of robots traversing a\nroute in the presence of adversaries with random positions. Our goal is to\nminimize the overall cost of the team, which is determined by (i) the\naccumulated risk when robots stay in adversary-impacted zones and (ii) the\nmission completion time. During traversal, robots can reduce their speed and\nact as a `guard' (the slower, the better), which will decrease the risks\ncertain adversary incurs. This leads to a trade-off between the robots'\nguarding behaviors and their travel speeds. The formulated problem is highly\nnon-convex and cannot be efficiently solved by existing algorithms. Our\napproach includes a theoretical analysis of the robots' behaviors for the\nsingle-adversary case. As the scale of the problem expands, solving the optimal\nsolution using optimization approaches is challenging, therefore, we employ\nreinforcement learning techniques by developing new encoding and\npolicy-generating methods. Simulations demonstrate that our learning methods\ncan efficiently produce team coordination behaviors. We discuss the reasoning\nbehind these behaviors and explain why they reduce the overall team cost."
  },
  {
    "paper_no": "2890",
    "authors": "Satoh, Mineto; Takano, Rin; Oyama, Hiroyuki",
    "title": "Extensive, Long-term Task and Motion Planning with Signal Temporal Logic Specification for Autonomous Construction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2894",
    "authors": "Zhong, Zhanping; Dong, Zhuoning; Duan, Xiaoming; He, Jianping",
    "title": "Collaboration Strategies for Two Heterogeneous Pursuers in a Pursuit-evasion Game Using Deep Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2896",
    "authors": "Sung, Eunho; You, Seungbin; Moon, Seongkyeong; Kim, Juhyun; Park, Jaeheung",
    "title": "SNU-Avatar Haptic Glove: Novel Modularized Haptic Glove via Trigonometric Series Elastic Actuators",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2898",
    "authors": "Nguyen, Khang; Dang, Tuan; Huber, Manfred",
    "title": "Volumetric Mapping with Panoptic Refinement using Kernel Density Estimation for Mobile Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.11241v1",
    "arxiv_abstract": "Reconstructing three-dimensional (3D) scenes with semantic understanding is\nvital in many robotic applications. Robots need to identify which objects,\nalong with their positions and shapes, to manipulate them precisely with given\ntasks. Mobile robots, especially, usually use lightweight networks to segment\nobjects on RGB images and then localize them via depth maps; however, they\noften encounter out-of-distribution scenarios where masks over-cover the\nobjects. In this paper, we address the problem of panoptic segmentation quality\nin 3D scene reconstruction by refining segmentation errors using non-parametric\nstatistical methods. To enhance mask precision, we map the predicted masks into\na depth frame to estimate their distribution via kernel densities. The outliers\nin depth perception are then rejected without the need for additional\nparameters in an adaptive manner to out-of-distribution scenarios, followed by\n3D reconstruction using projective signed distance functions (SDFs). We\nvalidate our method on a synthetic dataset, which shows improvements in both\nquantitative and qualitative results for panoptic mapping. Through real-world\ntesting, the results furthermore show our method's capability to be deployed on\na real-robot system. Our source code is available at:\nhttps://github.com/mkhangg/refined panoptic mapping."
  },
  {
    "paper_no": "2899",
    "authors": "Ou, Zhihao; Wang, Zhibo; Hua, Yue; Dou, Jinsheng; Feng, Di; Pu, Jian",
    "title": "HP3: Hierarchical Prediction-Pretrained Planning for Unprotected Left Turn",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2900",
    "authors": "Niemann, Christopher; Lach, Luca; Leins, David Philip",
    "title": "Learning When to Stop: Efficient Active Tactile Perception with Deep Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2901",
    "authors": "Poudel, Bibek; Li, Weizi; Heaslip, Kevin",
    "title": "EnduRL: Enhancing Safety, Stability, and Efficiency of Mixed Traffic Under Real-World Perturbations Via Reinforcement Learning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2902",
    "authors": "Legittimo, Marco; Crocetti, Francesco; Fravolini, Mario Luca; Mollica, Giuseppe; Costante, Gabriele",
    "title": "LF2SLAM: Learning-based Features For visual SLAM",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2903",
    "authors": "Kruliak, Andrej; Hartvich, Jiri; Patni, Shubhan; Rustler, Lukas; Behrens, Jan Kristof; Abu-Dakka, Fares; Mikolajczyk, Krystian; Kyrki, Ville; Hoffmann, Matej",
    "title": "Interactive learning of physical object properties through robot manipulation and database of object measurements",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.07344v1",
    "arxiv_abstract": "This work presents a framework for automatically extracting physical object\nproperties, such as material composition, mass, volume, and stiffness, through\nrobot manipulation and a database of object measurements. The framework\ninvolves exploratory action selection to maximize learning about objects on a\ntable. A Bayesian network models conditional dependencies between object\nproperties, incorporating prior probability distributions and uncertainty\nassociated with measurement actions. The algorithm selects optimal exploratory\nactions based on expected information gain and updates object properties\nthrough Bayesian inference. Experimental evaluation demonstrates effective\naction selection compared to a baseline and correct termination of the\nexperiments if there is nothing more to be learned. The algorithm proved to\nbehave intelligently when presented with trick objects with material properties\nin conflict with their appearance. The robot pipeline integrates with a logging\nmodule and an online database of objects, containing over 24,000 measurements\nof 63 objects with different grippers. All code and data are publicly\navailable, facilitating automatic digitization of objects and their physical\nproperties through exploratory manipulations."
  },
  {
    "paper_no": "2904",
    "authors": "Exley, Trevor; Wijesundara Mudiyanselage, Rashmi Diviyanjali; Tan, Nathan; Sunkara, Akshay; He, Xinyu; Wang, Shuopu; Chan, Bonnie; Jain, Aditya Jain; Espinosa, Luis; Jafari, Amir",
    "title": "Agonist-Antagonist Pouch Motors: Bidirectional Soft Actuators Enhanced by Thermally Responsive Peltier Elements",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.10955v1",
    "arxiv_abstract": "In this study, we introduce a novel Mylar-based pouch motor design that\nleverages the reversible actuation capabilities of Peltier junctions to enable\nagonist-antagonist muscle mimicry in soft robotics. Addressing the limitations\nof traditional silicone-based materials, such as leakage and phase-change fluid\ndegradation, our pouch motors filled with Novec 7000 provide a durable and\nleak-proof solution for geometric modeling. The integration of flexible Peltier\njunctions offers a significant advantage over conventional Joule heating\nmethods by allowing active and reversible heating and cooling cycles. This\ninnovation not only enhances the reliability and longevity of soft robotic\napplications but also broadens the scope of design possibilities, including the\ndevelopment of agonist-antagonist artificial muscles, grippers with can\nmanipulate through flexion and extension, and an anchor-slip style simple\ncrawler design. Our findings indicate that this approach could lead to more\nefficient, versatile, and durable robotic systems, marking a significant\nadvancement in the field of soft robotics."
  },
  {
    "paper_no": "2906",
    "authors": "Kang, Minjae; Kee, Hogun; Park, Yoseph; Kim, Junseok; Jeong, Jaeyeon; Cheon, Geunje; Lee, Jaewon; Oh, Songhwai",
    "title": "Gradual Receptive Expansion Using Vision Transformer for Online 3D Bin Packing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2907",
    "authors": "Koochakzadeh, Erfan; Kargar, Alireza; Sattari, Parsa; Ravanshid, Diba; Nasiri, Rezvan",
    "title": "Seven Benefits of Using Series Elastic Actuators in Design of an Affordable, Simple Controlled, and Functional Prosthetic Hand",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2908",
    "authors": "Liang, Ziting; Chuang, Lu; Yang, Haoqian; Hashem, Ryman; Abdelaziz, Mohamed Essam Mohamed Kassem; Lindenroth, Lukas; Bandula, Steve; Stoyanov, Danail; Stilli, Agostino",
    "title": "A Novel MR Safe Double-Arch Needle Insertion Robot with Scissor-Folding Mechanism for Abdominal Interventions",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2909",
    "authors": "Jenkins, Daniel; Marshall, Joshua A.",
    "title": "This is the Way: Mitigating the Roll of an Autonomous Uncrewed Surface Vessel in Wavy Conditions Using Model Predictive Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.15349v1",
    "arxiv_abstract": "Though larger vessels may be well-equipped to deal with wavy conditions,\nsmaller vessels are often more susceptible to disturbances. This paper explores\nthe development of a nonlinear model predictive control (NMPC) system for\nUncrewed Surface Vessels (USVs) in wavy conditions to minimize average roll.\nThe NMPC is based on a prediction method that uses information about the\nvessel's dynamics and an assumed wave model. This method is able to mitigate\nthe roll of an under-actuated USV in a variety of conditions by adjusting the\nweights of the cost function. The results show a reduction of 39% of average\nroll with a tuned controller in conditions with 1.75-metre sinusoidal waves. A\ngeneral and intuitive tuning strategy is established. This preliminary work is\na proof of concept which sets the stage for the leveraging of wave prediction\nmethodologies to perform planning and control in real time for USVs in\nreal-world scenarios and field trials."
  },
  {
    "paper_no": "2910",
    "authors": "Liu, Jitian; Cohen, Zachary; Kim, Jin Seob; Armand, Mehran; Kutzer, Michael Dennis Mays",
    "title": "A Geometry-based Approach for Support-free Additive Manufacturing of Structures with Large Overhang Angles and Closed Features",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2914",
    "authors": "Zhang, Shiyao; Li, He; Zhang, Shengyu; Wang, Shuai; Ng, Derrick Wing Kwan; Xu, Chengzhong",
    "title": "Multi-Uncertainty Aware Autonomous Cooperative Planning",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.00413v1",
    "arxiv_abstract": "Autonomous cooperative planning (ACP) is a promising technique to improve the\nefficiency and safety of multi-vehicle interactions for future intelligent\ntransportation systems. However, realizing robust ACP is a challenge due to the\naggregation of perception, motion, and communication uncertainties. This paper\nproposes a novel multi-uncertainty aware ACP (MUACP) framework that\nsimultaneously accounts for multiple types of uncertainties via regularized\ncooperative model predictive control (RC-MPC). The regularizers and constraints\nfor perception, motion, and communication are constructed according to the\nconfidence levels, weather conditions, and outage probabilities, respectively.\nThe effectiveness of the proposed method is evaluated in the Car Learning to\nAct (CARLA) simulation platform. Results demonstrate that the proposed MUACP\nefficiently performs cooperative formation in real time and outperforms other\nbenchmark approaches in various scenarios under imperfect knowledge of the\nenvironment."
  },
  {
    "paper_no": "2917",
    "authors": "Tajima, Yuta; Azumi, Takuya",
    "title": "ROS-lite2: Autonomous-driving Software Platform for Clustered Many-core Processor",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2918",
    "authors": "FANG, Zhiwei; Xu, Chao; Gao, Huxin; Chan, Tat-Ming; Yuan, Wu; Ren, Hongliang",
    "title": "Head-Mounted Hydraulic Needle Driver for Targeted Interventions in Neurosurger",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2919",
    "authors": "Savvas Sadiq Ali, Farhad Nawaz; Peng, Shaoting; Lindemann, Lars; Figueroa, Nadia; Matni, Nikolai",
    "title": "Reactive Temporal Logic-based Planning and Control for Interactive Robotic Tasks",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.19594v1",
    "arxiv_abstract": "Robots interacting with humans must be safe, reactive and adapt online to\nunforeseen environmental and task changes. Achieving these requirements\nconcurrently is a challenge as interactive planners lack formal safety\nguarantees, while safe motion planners lack flexibility to adapt. To tackle\nthis, we propose a modular control architecture that generates both safe and\nreactive motion plans for human-robot interaction by integrating temporal\nlogic-based discrete task level plans with continuous Dynamical System\n(DS)-based motion plans. We formulate a reactive temporal logic formula that\nenables users to define task specifications through structured language, and\npropose a planning algorithm at the task level that generates a sequence of\ndesired robot behaviors while being adaptive to environmental changes. At the\nmotion level, we incorporate control Lyapunov functions and control barrier\nfunctions to compute stable and safe continuous motion plans for two types of\nrobot behaviors: (i) complex, possibly periodic motions given by autonomous DS\nand (ii) time-critical tasks specified by Signal Temporal Logic~(STL). Our\nmethodology is demonstrated on the Franka robot arm performing wiping tasks on\na whiteboard and a mannequin that is compliant to human interactions and\nadaptive to environmental changes."
  },
  {
    "paper_no": "2920",
    "authors": "Salagame, Adarsh; Gangaraju, Kruthika; Nallaguntla, Harin Kumar; Sihite, Eric; Schirner, Gunar; Ramezani, Alireza",
    "title": "Loco-Manipulation with Nonimpulsive Contact-Implicit Planning in a Slithering Robot",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.08174v1",
    "arxiv_abstract": "Object manipulation has been extensively studied in the context of fixed base\nand mobile manipulators. However, the overactuated locomotion modality employed\nby snake robots allows for a unique blend of object manipulation through\nlocomotion, referred to as loco-manipulation. The following work presents an\noptimization approach to solving the loco-manipulation problem based on\nnon-impulsive implicit contact path planning for our snake robot COBRA. We\npresent the mathematical framework and show high-fidelity simulation results\nand experiments to demonstrate the effectiveness of our approach."
  },
  {
    "paper_no": "2922",
    "authors": "Xie, yuting; Guo, Xianda; Wang, Cong; Kunhua, Liu; Chen, Long",
    "title": "AdvDiffuser: Generating Adversarial Safety-Critical Driving Scenarios via Guided Diffusion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2925",
    "authors": "Cheng, Jing; Alqaham, Yasser G.; Gan, Zhenyu",
    "title": "Harnessing Natural Oscillations for High-Speed, Efficient Asymmetrical Locomotion in Quadrupedal Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.17579v1",
    "arxiv_abstract": "This study explores the dynamics of asymmetrical bounding gaits in\nquadrupedal robots, focusing on the integration of torso pitching and hip\nmotion to enhance speed and stability. Traditional control strategies often\nenforce a fixed posture, minimizing natural body movements to simplify the\ncontrol problem. However, this approach may overlook the inherent dynamical\nadvantages found in natural locomotion. By considering the robot as two\ninterconnected segments, we concentrate on stance leg motion while allowing\npassive torso oscillation, drawing inspiration from natural dynamics and\nunderactuated robotics principles. Our control scheme employs Linear Inverted\nPendulum (LIP) and Spring-Loaded Inverted Pendulum (SLIP) models to govern\nfront and rear leg movements independently. This approach has been validated\nthrough extensive simulations and hardware experiments, demonstrating\nsuccessful high-speed locomotion with top speeds nearing 4 m/s and reduced\nground reaction forces, indicating a more efficient gait. Furthermore, unlike\nconventional methods, our strategy leverages natural torso oscillations to aid\nleg circulation and stride length, aligning robot dynamics more closely with\nbiological counterparts. Our findings suggest that embracing the natural\ndynamics of quadrupedal movement, particularly in asymmetrical gaits like\nbounding, can lead to more stable, efficient, and high-speed robotic\nlocomotion. This investigation lays the groundwork for future studies on\nversatile and dynamic quadrupedal gaits and their potential applications in\nscenarios demanding rapid and effective locomotion."
  },
  {
    "paper_no": "2926",
    "authors": "Sharma, Susheela; Kulkarni, Yash; Go, Sarah; Bonyun, Jeff; Amadio, Jordan P.; Rajebi, Mohammad; Khadem, Mohsen; Alambeigi, Farshid",
    "title": "Spatial Spinal Fixation: A Transformative Approach Using a Unique Robot-Assisted Steerable Drilling System and Flexible Pedicle Screw",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.17600v2",
    "arxiv_abstract": "Spinal fixation procedures are currently limited by the rigidity of the\nexisting instruments and pedicle screws leading to fixation failures and rigid\npedicle screw pull out. Leveraging our recently developed Concentric Tube\nSteerable Drilling Robot (CT-SDR) in integration with a robotic manipulator, to\naddress the aforementioned issue, here we introduce the transformative concept\nof Spatial Spinal Fixation (SSF) using a unique Flexible Pedicle Screw (FPS).\nThe proposed SSF procedure enables planar and out-of-plane placement of the FPS\nthroughout the full volume of the vertebral body. In other words, not only does\nour fixation system provide the option of drilling in-plane and out-of-plane\ntrajectories, it also enables implanting the FPS inside linear (represented by\nan I-shape) and/or non-linear (represented by J-shape) trajectories. To\nthoroughly evaluate the functionality of our proposed robotic system and the\nSSF procedure, we have performed various experiments by drilling different I-J\nand J-J drilling trajectory pairs into our custom-designed L3 vertebral\nphantoms and analyzed the accuracy of the procedure using various metrics."
  },
  {
    "paper_no": "2927",
    "authors": "Zhu, Deye; Zhu, Chengrui; Zhang, Zhen; Xin, Shuo; Liu, Yong",
    "title": "Learning Safe Locomotion for Quadrupedal Robots by Derived-Action Optimization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2930",
    "authors": "Lian, Jiaqi; Gandhi, Neeraj; Wang, Yifan; Phan, Linh Thi Xuan",
    "title": "Online Rotor Fault Detection and Isolation for Vertical Takeoff and Landing Vehicles",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2932",
    "authors": "Lin, Changyi; Liu, Xingyu; yang, Yuxiang; Niu, Yaru; Yu, Wenhao; Zhang, Tingnan; Tan, Jie; Boots, Byron; ZHAO, DING",
    "title": "LocoMan: Advancing Versatile Quadrupedal Dexterity with Lightweight Loco-Manipulators",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2935",
    "authors": "KAUR, UPINDER; Celik, Berkay; Voyles, Richard",
    "title": "RoboGuardZ: A Scalable, Lightweight Zero-Shot Learning Framework for Zero-Day Malware-Driven Controller Attack Detection in Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2936",
    "authors": "Zhong, Weiheng; Huang, Yuancan; Hong, Da; Shao, Nianfeng",
    "title": "Design and Control of an Ultra-Slender Push-Pull Multisection Continuum Manipulator for In-Situ Inspection of Aeroengine",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.03508v1",
    "arxiv_abstract": "Since the shape of industrial endoscopes is passively altered according to\nthe contact around it, manual inspection approaches of aeroengines through the\ninspection ports have unreachable areas, and it's difficult to traverse\nmultistage blades and inspect them simultaneously, which requires engine\ndisassembly or the cooperation of multiple operators, resulting in efficiency\ndecline and increased costs. To this end, this paper proposes a novel continuum\nmanipulator with push-pull multisection structure which provides a potential\nsolution for the disadvantages mentioned above due to its higher flexibility,\npassability, and controllability in confined spaces. The ultra-slender design\ncombined with a tendon-driven mechanism makes the manipulator acquire enough\nworkspace and more flexible postures while maintaining a light weight.\nConsidering the coupling between the tendons in multisection, a innovative\nkinematics decoupling control method is implemented, which can realize\nreal-time control in the case of limited computational resources. A prototype\nis built to validate the capabilities of mechatronic design and the performance\nof the control algorithm. The experimental results demonstrate the advantages\nof our continuum manipulator in the in-situ inspection of aeroengines'\nmultistage blades, which has the potential to be a replacement solution for\nindustrial endoscopes."
  },
  {
    "paper_no": "2938",
    "authors": "Lu, Liang; Gao, Xiangquan; Xiang, Ming; Yan, Zefeng; Han, Bin",
    "title": "Design of a Variable Wheel-propeller Integrated Mechanism for Amphibious Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2942",
    "authors": "Singh, Suhani; Suppa, Michael; Suarez, Raul; Rosell, Jan",
    "title": "Disp2Depth: Hybrid Stereo Dense Depth Estimation for Robotics Tasks in Industrial Automation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2944",
    "authors": "Salagame, Adarsh; Gangaraju, Kruthika; Sihite, Eric; Schirner, Gunar; Ramezani, Alireza",
    "title": "Heading Control for Obstacle Avoidance using Dynamic Posture Manipulation during Tumbling Locomotion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2948",
    "authors": "Todd, Jessica; McCammon, Seth; Girdhar, Yogesh; Roy, Nicholas; Yoerger, Dana",
    "title": "Adaptive multi-altitude search and sampling of sparsely distributed natural phenomena",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2950",
    "authors": "Lin, Fangzhou; Liu, Haotian; Zhou, Haoying; Hou, Songlin; Yamada, Kazunori; Fischer, Gregory Scott; Li, Yanhua; Zhang, Haichong; Zhang, Ziming",
    "title": "Loss Distillation via Gradient Matching for Point Cloud Completion with Weighted Chamfer Distance",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.06171v1",
    "arxiv_abstract": "3D point clouds enhanced the robot's ability to perceive the geometrical\ninformation of the environments, making it possible for many downstream tasks\nsuch as grasp pose detection and scene understanding. The performance of these\ntasks, though, heavily relies on the quality of data input, as incomplete can\nlead to poor results and failure cases. Recent training loss functions designed\nfor deep learning-based point cloud completion, such as Chamfer distance (CD)\nand its variants (\\eg HyperCD ), imply a good gradient weighting scheme can\nsignificantly boost performance. However, these CD-based loss functions usually\nrequire data-related parameter tuning, which can be time-consuming for\ndata-extensive tasks. To address this issue, we aim to find a family of\nweighted training losses ({\\em weighted CD}) that requires no parameter tuning.\nTo this end, we propose a search scheme, {\\em Loss Distillation via Gradient\nMatching}, to find good candidate loss functions by mimicking the learning\nbehavior in backpropagation between HyperCD and weighted CD. Once this is done,\nwe propose a novel bilevel optimization formula to train the backbone network\nbased on the weighted CD loss. We observe that: (1) with proper weighted\nfunctions, the weighted CD can always achieve similar performance to HyperCD,\nand (2) the Landau weighted CD, namely {\\em Landau CD}, can outperform HyperCD\nfor point cloud completion and lead to new state-of-the-art results on several\nbenchmark datasets. {\\it Our demo code is available at\n\\url{https://github.com/Zhang-VISLab/IROS2024-LossDistillationWeightedCD}.}"
  },
  {
    "paper_no": "2952",
    "authors": "Yu, Justin; Hari, Kush; Srinivas, Kishore; El-Refai, Karim; Rashid, Adam; Kim, Chung Min; Kerr, Justin; Cheng, Richard; Balakrishna, Ashwin; Kollar, Thomas; Goldberg, Ken",
    "title": "Incrementally Building Room-Scale Language-Embedded Gaussian Splats (LEGS) with a Mobile Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2953",
    "authors": "Jutras-Dube, Pascal; Zhang, Ruqi; Bera, Aniket",
    "title": "Adaptive Planning with Generative Models under Uncertainty",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.01510v1",
    "arxiv_abstract": "Planning with generative models has emerged as an effective decision-making\nparadigm across a wide range of domains, including reinforcement learning and\nautonomous navigation. While continuous replanning at each timestep might seem\nintuitive because it allows decisions to be made based on the most recent\nenvironmental observations, it results in substantial computational challenges,\nprimarily due to the complexity of the generative model's underlying deep\nlearning architecture. Our work addresses this challenge by introducing a\nsimple adaptive planning policy that leverages the generative model's ability\nto predict long-horizon state trajectories, enabling the execution of multiple\nactions consecutively without the need for immediate replanning. We propose to\nuse the predictive uncertainty derived from a Deep Ensemble of inverse dynamics\nmodels to dynamically adjust the intervals between planning sessions. In our\nexperiments conducted on locomotion tasks within the OpenAI Gym framework, we\ndemonstrate that our adaptive planning policy allows for a reduction in\nreplanning frequency to only about 10% of the steps without compromising the\nperformance. Our results underscore the potential of generative modeling as an\nefficient and effective tool for decision-making."
  },
  {
    "paper_no": "2954",
    "authors": "Boroji, Maede; Danesh, Vahid; Kao, Imin; Fakhari, Amin",
    "title": "Motion Planning for Object Manipulation by Edge-Rolling",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2955",
    "authors": "Murali, Varun; Rosman, Guy; Karaman, Sertac; Rus, Daniela",
    "title": "Learning autonomous driving from aerial imagery",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.14177v1",
    "arxiv_abstract": "In this work, we consider the problem of learning end to end perception to\ncontrol for ground vehicles solely from aerial imagery. Photogrammetric\nsimulators allow the synthesis of novel views through the transformation of\npre-generated assets into novel views.However, they have a large setup cost,\nrequire careful collection of data and often human effort to create usable\nsimulators. We use a Neural Radiance Field (NeRF) as an intermediate\nrepresentation to synthesize novel views from the point of view of a ground\nvehicle. These novel viewpoints can then be used for several downstream\nautonomous navigation applications. In this work, we demonstrate the utility of\nnovel view synthesis though the application of training a policy for end to end\nlearning from images and depth data. In a traditional real to sim to real\nframework, the collected data would be transformed into a visual simulator\nwhich could then be used to generate novel views. In contrast, using a NeRF\nallows a compact representation and the ability to optimize over the parameters\nof the visual simulator as more data is gathered in the environment. We\ndemonstrate the efficacy of our method in a custom built mini-city environment\nthrough the deployment of imitation policies on robotic cars. We additionally\nconsider the task of place localization and demonstrate that our method is able\nto relocalize the car in the real world."
  },
  {
    "paper_no": "2957",
    "authors": "Wang, Zihan; Li, Bowen; Wang, Chen; Scherer, Sebastian",
    "title": "AirShot: Efficient Few-Shot Detection for Autonomous Exploration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2960",
    "authors": "Deshpande, Mrunmayee; Majji, Manoranjan; Ramos, J Humberto",
    "title": "Magnetic Field Aided Vehicle Localization with Acceleration Correction",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.06543v1",
    "arxiv_abstract": "This paper presents a novel approach for vehicle localization by leveraging\nthe ambient magnetic field within a given environment. Our approach involves\nintroducing a global mathematical function for magnetic field mapping, combined\nwith Euclidean distance-based matching technique for accurately estimating\nvehicle position in suburban settings. The mathematical function based map\nstructure ensures efficiency and scalability of the magnetic field map, while\nthe batch processing based localization provides continuity in pose estimation.\nAdditionally, we establish a bias estimation pipeline for an onboard\naccelerometer by utilizing the updated poses obtained through magnetic field\nmatching. Our work aims to showcase the potential utility of magnetic fields as\nsupplementary aids to existing localization methods, particularly beneficial in\nscenarios where Global Positioning System (GPS) signal is restricted or where\ncost-effective navigation systems are required."
  },
  {
    "paper_no": "2961",
    "authors": "Hou, Mengqi; Li, Jie; Xu, Fengyu; HU, LeZhi",
    "title": "Design and implementation of a novel wheel-based cable inspection robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2962",
    "authors": "Veliky, Madison; Johnston, Garrison; Yildiz, Ahmet; Simaan, Nabil",
    "title": "A Feasibility Study of a Soft, Low-Cost, 6-Axis Load Cell for Haptics",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.03939v1",
    "arxiv_abstract": "Haptic devices have shown to be valuable in supplementing surgical training,\nespecially when providing haptic feedback based on user performance metrics\nsuch as wrench applied by the user on the tool. However, current 6-axis\nforce/torque sensors are prohibitively expensive. This paper presents the\ndesign and calibration of a low-cost, six-axis force/torque sensor specially\ndesigned for laparoscopic haptic training applications. The proposed design\nuses Hall-effect sensors to measure the change in the position of magnets\nembedded in a silicone layer that results from an applied wrench to the device.\nPreliminary experimental validation demonstrates that these sensors can achieve\nan accuracy of 0.45 N and 0.014 Nm, and a theoretical XY range of +/-50N, Z\nrange of +/-20N, and torque range of +/-0.2Nm. This study indicates that the\nproposed low-cost 6-axis force/torque sensor can accurately measure user force\nand provide useful feedback during laparoscopic training on a haptic device."
  },
  {
    "paper_no": "2963",
    "authors": "Somayazulu, Arjun; Majumder, Sagnik; Chen, Changan; Grauman, Kristen",
    "title": "ActiveRIR: Active Audio-Visual Exploration for Acoustic Environment Modeling",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2964",
    "authors": "Xu, Zhixuan; Gao, Chongkai; Liu, Zixuan; Yang, Gang; Tie, Chenrui; Zheng, Haozhuo; Zhou, Haoyu; Weikun, Peng; Wang, Debang; Chen, Tianyi; Yu, Zhouliang; Shao, Lin",
    "title": "ManiFoundation Model for General-Purpose Robotic Manipulation of Contact Synthesis with Arbitrary Objects and Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.06964v2",
    "arxiv_abstract": "To substantially enhance robot intelligence, there is a pressing need to\ndevelop a large model that enables general-purpose robots to proficiently\nundertake a broad spectrum of manipulation tasks, akin to the versatile\ntask-planning ability exhibited by LLMs. The vast diversity in objects, robots,\nand manipulation tasks presents huge challenges. Our work introduces a\ncomprehensive framework to develop a foundation model for general robotic\nmanipulation that formalizes a manipulation task as contact synthesis.\nSpecifically, our model takes as input object and robot manipulator point\nclouds, object physical attributes, target motions, and manipulation region\nmasks. It outputs contact points on the object and associated contact forces or\npost-contact motions for robots to achieve the desired manipulation task. We\nperform extensive experiments both in the simulation and real-world settings,\nmanipulating articulated rigid objects, rigid objects, and deformable objects\nthat vary in dimensionality, ranging from one-dimensional objects like ropes to\ntwo-dimensional objects like cloth and extending to three-dimensional objects\nsuch as plasticine. Our model achieves average success rates of around 90\\%.\nSupplementary materials and videos are available on our project website at\nhttps://manifoundationmodel.github.io/."
  },
  {
    "paper_no": "2966",
    "authors": "KAUR, UPINDER; Celik, Berkay; Voyles, Richard",
    "title": "RoboCop: A Robust Zero-Day Cyber-Physical Attack Detection Framework for Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2967",
    "authors": "Ren, Yunfan; Cai, Yixi; Zhu, Fangcheng; Liang, Siqi; Zhang, Fu",
    "title": "ROG-Map: An Efficient Robocentric Occupancy Grid Map for Large-scene and High-resolution LiDAR-based Motion Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2970",
    "authors": "Ranne, Alex; Kuang, Liming; Velikova, Yordanka; Navab, Nassir; Rodriguez y Baena, Ferdinando",
    "title": "CathFlow: Self-Supervised Segmentation of Catheters in Interventional Ultrasound Using Optical Flow and Transformers",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2971",
    "authors": "Hassan, Bilal; Abdel Madjid, Nadya; Kashwani, Fatima; Alansari, Mohamad; Khonji, Majid; Dias, Jorge",
    "title": "PathFormer: A Transformer-Based Framework for Vision-Centric Autonomous Navigation in Off-Road Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2972",
    "authors": "Wei, Yufei; Lu, Sha; Xiong, Rong; Wang, Yue",
    "title": "BEV-ODOM: Reducing Scale Drift in Monocular Visual Odometry with BEV Representation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2974",
    "authors": "Nelson, Henry J.; Papanikolopoulos, Nikos",
    "title": "Ground-Density Clustering for Approximate Agricultural Field Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2976",
    "authors": "Wolf Batista, Luis Felipe; Ro, Junghwan; Richard, Antoine; Schroepfer, Pete; Hutchinson, Seth; Pradalier, Cedric",
    "title": "Advancing ASV Autonomy for Environmental Cleanup: A Deep Reinforcement Learning Framework for Floating Waste Capture",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2977",
    "authors": "Zhao, Zhipeng; Li, Bowen; Du, Yi; Fu, Taimeng; Wang, Chen",
    "title": "PhysORD: A Neuro-Symbolic Approach for Physics-infused Motion Prediction in Off-road Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2978",
    "authors": "Pandey, Vivek; Amini, Arash; Liu, Guangyi; Topcu, Ufuk; Sun, Qiyu; Daniilidis, Kostas; Motee, Nader",
    "title": "Scalable Networked Feature Selection with Randomized Algorithm for Robot Navigation",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12279v1",
    "arxiv_abstract": "We address the problem of sparse selection of visual features for localizing\na team of robots navigating an unknown environment, where robots can exchange\nrelative position measurements with neighbors. We select a set of the most\ninformative features by anticipating their importance in robots localization by\nsimulating trajectories of robots over a prediction horizon. Through\ntheoretical proofs, we establish a crucial connection between graph Laplacian\nand the importance of features. We show that strong network connectivity\ntranslates to uniformity in feature importance, which enables uniform random\nsampling of features and reduces the overall computational complexity. We\nleverage a scalable randomized algorithm for sparse sums of positive\nsemidefinite matrices to efficiently select the set of the most informative\nfeatures and significantly improve the probabilistic performance bounds.\nFinally, we support our findings with extensive simulations."
  },
  {
    "paper_no": "2983",
    "authors": "Qu, Jinye; Gao, Zeyu; Yi, Li; Lu, Yanfeng; Qiao, Hong",
    "title": "Spike-based high energy efficiency and accuracy tracker for Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2984",
    "authors": "Dhami, Harnaik; Sharma, Vishnu D.; Tokekar, Pratap",
    "title": "MAP-NBV: Multi-agent Prediction-guided Next-Best-View Planning for Active 3D Object Reconstruction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2987",
    "authors": "Lai, Tin; Zhi, Weiming; Hermans, Tucker; Ramos, Fabio",
    "title": "Learning for Kinodynamic Tree Expansion",
    "arxiv_pdf": "http://arxiv.org/pdf/2203.00975v2",
    "arxiv_abstract": "We present the Learning for KinoDynamic Tree Expansion (L4KDE) method for\nkinodynamic planning. Tree-based planning approaches, such as rapidly exploring\nrandom tree (RRT), are the dominant approach to finding globally optimal plans\nin continuous state-space motion planning. Central to these approaches is\ntree-expansion, the procedure in which new nodes are added into an\never-expanding tree. We study the kinodynamic variants of tree-based planning,\nwhere we have known system dynamics and kinematic constraints. In the interest\nof quickly selecting nodes to connect newly sampled coordinates, existing\nmethods typically cannot optimise to find nodes that have low cost to\ntransition to sampled coordinates. Instead, they use metrics like Euclidean\ndistance between coordinates as a heuristic for selecting candidate nodes to\nconnect to the search tree. We propose L4KDE to address this issue. L4KDE uses\na neural network to predict transition costs between queried states, which can\nbe efficiently computed in batch, providing much higher quality estimates of\ntransition cost compared to commonly used heuristics while maintaining\nalmost-surely asymptotic optimality guarantee. We empirically demonstrate the\nsignificant performance improvement provided by L4KDE on a variety of\nchallenging system dynamics, with the ability to generalise across different\ninstances of the same model class, and in conjunction with a suite of modern\ntree-based motion planners."
  },
  {
    "paper_no": "2992",
    "authors": "Yang, Hsuan-Kung; Chiang, Tsung-Chih; Liu, Ting-Ru; Liu, Jou-Min; Huang, Chun-Wei; Lee, Chun-Yi",
    "title": "Visual Forecasting as a Mid-level Representation for Avoidance",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.07724v1",
    "arxiv_abstract": "The challenge of navigation in environments with dynamic objects continues to\nbe a central issue in the study of autonomous agents. While predictive methods\nhold promise, their reliance on precise state information makes them less\npractical for real-world implementation. This study presents visual forecasting\nas an innovative alternative. By introducing intuitive visual cues, this\napproach projects the future trajectories of dynamic objects to improve agent\nperception and enable anticipatory actions. Our research explores two distinct\nstrategies for conveying predictive information through visual forecasting: (1)\nsequences of bounding boxes, and (2) augmented paths. To validate the proposed\nvisual forecasting strategies, we initiate evaluations in simulated\nenvironments using the Unity engine and then extend these evaluations to\nreal-world scenarios to assess both practicality and effectiveness. The results\nconfirm the viability of visual forecasting as a promising solution for\nnavigation and obstacle avoidance in dynamic environments."
  },
  {
    "paper_no": "2994",
    "authors": "Wang, Jialiang; Gao, Zhi; LIN, Zhipeng; Zhou, Zhiyu; Wang, Xiaonan; CHENG, Jianhua; Zhang, Hao; Liu, Xinyi; Chen, Ben M.",
    "title": "Accurate and Efficient Loop Closure Detection With Deep Binary Image Descriptor and Augmented Point Cloud Registration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2995",
    "authors": "Klammer, Christopher; Kaess, Michael",
    "title": "BEVLoc: Off-Road Aerial-to-Ground Localization and Matching via Birds-Eye-View Synthesis",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2996",
    "authors": "Ionova, Marina; Behrens, Jan Kristof",
    "title": "CoBOS: Constraint-Based Online Scheduler for Human-Robot Collaboration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "2998",
    "authors": "Ma, Haitong; Ren, Zhaolin; Dai, Bo; Li, Na",
    "title": "Skill Transfer and Discovery for Sim-to-Real Learning: A Representation-Based Viewpoint",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.05051v1",
    "arxiv_abstract": "We study sim-to-real skill transfer and discovery in the context of robotics\ncontrol using representation learning. We draw inspiration from spectral\ndecomposition of Markov decision processes. The spectral decomposition brings\nabout representation that can linearly represent the state-action value\nfunction induced by any policies, thus can be regarded as skills. The skill\nrepresentations are transferable across arbitrary tasks with the same\ntransition dynamics. Moreover, to handle the sim-to-real gap in the dynamics,\nwe propose a skill discovery algorithm that learns new skills caused by the\nsim-to-real gap from real-world data. We promote the discovery of new skills by\nenforcing orthogonal constraints between the skills to learn and the skills\nfrom simulators, and then synthesize the policy using the enlarged skill sets.\nWe demonstrate our methodology by transferring quadrotor controllers from\nsimulators to Crazyflie 2.1 quadrotors. We show that we can learn the skill\nrepresentations from a single simulator task and transfer these to multiple\ndifferent real-world tasks including hovering, taking off, landing and\ntrajectory tracking. Our skill discovery approach helps narrow the sim-to-real\ngap and improve the real-world controller performance by up to 30.2%."
  },
  {
    "paper_no": "2999",
    "authors": "Mopidevi, Ajay Narasimha; Harlow, Kyle; Heckman, Christoffer",
    "title": "RMap: Millimeter-Wave Radar Mapping Through Volumetric UpSampling",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3000",
    "authors": "Blaha, Jan; Vintr, Tomas; Mikula, Jan; Janota, Ji&#345;í; Rou&#269;ek, Tomá; Ulrich, Jiri; Rekabi Bana, Fatemeh; Arvin, Farshad; Kulich, Miroslav; Krajnik, Tomas",
    "title": "Toward Perpetual Occlusion-Aware Observation of Comb States in Living Honeybee Colonies",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3001",
    "authors": "Ge, Yuhong; Zhao, Xun; Pang, Jiangmiao; Zhao, Mingguo; Lin, Dahua",
    "title": "X-neuron: Interpreting, Locating and Editing of Neurons in Reinforcement Learning Policy",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3007",
    "authors": "Wang, Yuanbo; Qu, Shanglai; Meng, Tianyu; Cui, Yan; Piao, Haiyin; Wei, Xiaopeng; Yang, Xin",
    "title": "Event-intensity Stereo with Cross-modal Fusion and Contrast",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3009",
    "authors": "Huang, Peng; Zheng, Ketong; Fettweis, Gerhard",
    "title": "Data-Driven Koopman Operator-Based Error-State Kalman Filter for Enhancing State Estimation of Quadrotors in Agile Flight",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3014",
    "authors": "Sojib, Noushad; Begum, Momotaz",
    "title": "Self Supervised Detection of Incorrect Human Demonstrations: A Path Toward Safe Imitation Learning by Robots in the Wild",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3015",
    "authors": "Li, Junnan; Chen, Lingyun; Ringwald, Johannes; Pozo Fortuni&#263;, Edmundo; Ganguly, Amartya; Haddadin, Sami",
    "title": "Identification and validation of the dynamic model of a tendon-driven anthropomorphic finger",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.13044v1",
    "arxiv_abstract": "This study addresses the absence of an identification framework to quantify a\ncomprehensive dynamic model of human and anthropomorphic tendon-driven fingers,\nwhich is necessary to investigate the physiological properties of human fingers\nand improve the control of robotic hands. First, a generalized dynamic model\nwas formulated, which takes into account the inherent properties of such a\nmechanical system. This includes rigid-body dynamics, coupling matrix, joint\nviscoelasticity, and tendon friction. Then, we propose a methodology comprising\na series of experiments, for step-wise identification and validation of this\ndynamic model. Moreover, an experimental setup was designed and constructed\nthat features actuation modules and peripheral sensors to facilitate the\nidentification process. To verify the proposed methodology, a 3D-printed\nrobotic finger based on the index finger design of the Dexmart hand was\ndeveloped, and the proposed experiments were executed to identify and validate\nits dynamic model. This study could be extended to explore the identification\nof cadaver hands, aiming for a consistent dataset from a single cadaver\nspecimen to improve the development of musculoskeletal hand models."
  },
  {
    "paper_no": "3016",
    "authors": "Han, Kyung Min; Kim, Young J.",
    "title": "Neuro-Explorer: Efficient and Scalable Exploration Planning via Learned Frontier Regions",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3018",
    "authors": "Singh, Gaurav; Kalwar, Sanket; Karim, Md Faizal; Sen, Bipasha; Govindan, Nagamanikandan; Sridhar, Srinath; Krishna, Madhava",
    "title": "Constrained 6-DoF Grasp Generation on Complex Shapes for Improved Dual-Arm Manipulation",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.04643v2",
    "arxiv_abstract": "Efficiently generating grasp poses tailored to specific regions of an object\nis vital for various robotic manipulation tasks, especially in a dual-arm\nsetup. This scenario presents a significant challenge due to the complex\ngeometries involved, requiring a deep understanding of the local geometry to\ngenerate grasps efficiently on the specified constrained regions. Existing\nmethods only explore settings involving table-top/small objects and require\naugmented datasets to train, limiting their performance on complex objects. We\npropose CGDF: Constrained Grasp Diffusion Fields, a diffusion-based grasp\ngenerative model that generalizes to objects with arbitrary geometries, as well\nas generates dense grasps on the target regions. CGDF uses a part-guided\ndiffusion approach that enables it to get high sample efficiency in constrained\ngrasping without explicitly training on massive constraint-augmented datasets.\nWe provide qualitative and quantitative comparisons using analytical metrics\nand in simulation, in both unconstrained and constrained settings to show that\nour method can generalize to generate stable grasps on complex objects,\nespecially useful for dual-arm manipulation settings, while existing methods\nstruggle to do so."
  },
  {
    "paper_no": "3020",
    "authors": "Hildebrandt, Carl; Woodlief, Trey; Elbaum, Sebastian",
    "title": "ODD-diLLMma: Driving Automation System ODD Compliance Checking using LLMs",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3021",
    "authors": "van der Brugge, Vincent Daniel; Pollefeys, Marc; Tenenbaum, Joshua; Jatavallabhula, Krishna Murthy; Tewari, Ayush",
    "title": "PickScan: Object discovery and reconstruction from handheld interactions",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3023",
    "authors": "Sivaramakrishnan, Aravind; Tangirala, Sumanth; Granados, Edgar; Carver, Noah; Bekris, Kostas E.",
    "title": "Roadmaps with Gaps over Controllers: Achieving Efficiency in Planning under Dynamics",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.03239v5",
    "arxiv_abstract": "This paper aims to improve the computational efficiency of motion planning\nfor mobile robots with non-trivial dynamics through the use of learned\ncontrollers. Offline, a system-specific controller is first trained in an empty\nenvironment. Then, for the target environment, the approach constructs a data\nstructure, a \"Roadmap with Gaps,\" to approximately learn how to solve planning\nqueries using the learned controller. The roadmap nodes correspond to local\nregions. Edges correspond to applications of the learned controller that\napproximately connect these regions. Gaps arise as the controller does not\nperfectly connect pairs of individual states along edges. Online, given a\nquery, a tree sampling-based motion planner uses the roadmap so that the tree's\nexpansion is informed towards the goal region. The tree expansion selects local\nsubgoals given a wavefront on the roadmap that guides towards the goal. When\nthe controller cannot reach a subgoal region, the planner resorts to random\nexploration to maintain probabilistic completeness and asymptotic optimality.\nThe accompanying experimental evaluation shows that the approach significantly\nimproves the computational efficiency of motion planning on various benchmarks,\nincluding physics-based vehicular models on uneven and varying friction\nterrains as well as a quadrotor under air pressure effects."
  },
  {
    "paper_no": "3024",
    "authors": "Park, Younghwa; Sloth, Christoffer",
    "title": "Differential-Algebraic Equation Control Barrier Function for Flexible Link Manipulator",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3026",
    "authors": "Martin, Rebecca; Fung, Clement; Keetha, Nikhil Varma; Bauer, Lujo; Scherer, Sebastian",
    "title": "Targeted Image Transformation for Improving Robustness in Long Range Aircraft Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3029",
    "authors": "Choy, Jae Goo; Cha, Geonho; Kee, Hogun; Oh, Songhwai",
    "title": "Unsupervised 3D Part Decomposition via Leveraged Gaussian Splatting",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3031",
    "authors": "Wang, Chenyu; Ko, Seong Young",
    "title": "A 6-DOF Double-layer Programmable Remote Center of Motion Robot for Vitreoretinal Surgery",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3034",
    "authors": "Keil, Colin; Gupta, Aniket; Kaveti, Pushyami; Singh, Hanumant",
    "title": "Towards Long Term SLAM on Thermal Imagery",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.19885v1",
    "arxiv_abstract": "Visual SLAM with thermal imagery, and other low contrast visually degraded\nenvironments such as underwater, or in areas dominated by snow and ice, remain\na difficult problem for many state of the art (SOTA) algorithms. In addition to\nchallenging front-end data association, thermal imagery presents an additional\ndifficulty for long term relocalization and map reuse. The relative\ntemperatures of objects in thermal imagery change dramatically from day to\nnight. Feature descriptors typically used for relocalization in SLAM are unable\nto maintain consistency over these diurnal changes. We show that learned\nfeature descriptors can be used within existing Bag of Word based localization\nschemes to dramatically improve place recognition across large temporal gaps in\nthermal imagery. In order to demonstrate the effectiveness of our trained\nvocabulary, we have developed a baseline SLAM system, integrating learned\nfeatures and matching into a classical SLAM algorithm. Our system demonstrates\ngood local tracking on challenging thermal imagery, and relocalization that\novercomes dramatic day to night thermal appearance changes. Our code and\ndatasets are available here:\nhttps://github.com/neufieldrobotics/IRSLAM_Baseline"
  },
  {
    "paper_no": "3037",
    "authors": "Lathrop, John; Riviere, Benjamin; Alindogan, Jedidiah; Chung, Soon-Jo",
    "title": "Model Predictive Trees: Sample-Efficient Receding-Horizon Planning with Reusable Tree Search",
    "arxiv_pdf": "http://arxiv.org/pdf/2411.15651v1",
    "arxiv_abstract": "We present Model Predictive Trees (MPT), a receding horizon tree search\nalgorithm that improves its performance by reusing information efficiently.\nWhereas existing solvers reuse only the highest-quality trajectory from the\nprevious iteration as a \"hotstart\", our method reuses the entire optimal\nsubtree, enabling the search to be simultaneously guided away from the\nlow-quality areas and towards the high-quality areas. We characterize the\nrestrictions on tree reuse by analyzing the induced tracking error under\ntime-varying dynamics, revealing a tradeoff between the search depth and the\ntimescale of the changing dynamics. In numerical studies, our algorithm\noutperforms state-of-the-art sampling-based cross-entropy methods with\nhotstarting. We demonstrate our planner on an autonomous vehicle testbed\nperforming a nonprehensile manipulation task: pushing a target object through\nan obstacle field. Code associated with this work will be made available at\nhttps://github.com/jplathrop/mpt."
  },
  {
    "paper_no": "3039",
    "authors": "Xia, Jingyuan; Lin, Zecai; Ai, Xiaojie; Gao, Anzhu",
    "title": "Embedded Sensing-Enabled External Interaction Estimation of 6-PSS Parallel Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3042",
    "authors": "Chen, Gerry; Al-Haddad, Tristan; Dellaert, Frank; Hutchinson, Seth",
    "title": "Architectural-Scale Artistic Brush Painting with a Hybrid Cable Robot",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12214v1",
    "arxiv_abstract": "Robot art presents an opportunity to both showcase and advance\nstate-of-the-art robotics through the challenging task of creating art.\nCreating large-scale artworks in particular engages the public in a way that\nsmall-scale works cannot, and the distinct qualities of brush strokes\ncontribute to an organic and human-like quality. Combining the large scale of\nmurals with the strokes of the brush medium presents an especially impactful\nresult, but also introduces unique challenges in maintaining precise, dextrous\nmotion control of the brush across such a large workspace. In this work, we\npresent the first robot to our knowledge that can paint architectural-scale\nmurals with a brush. We create a hybrid robot consisting of a cable-driven\nparallel robot and 4 degree of freedom (DoF) serial manipulator to paint a 27m\nby 3.7m mural on windows spanning 2-stories of a building. We discuss our\napproach to achieving both the scale and accuracy required for brush-painting a\nmural through a combination of novel mechanical design elements, coordinated\nplanning and control, and on-site calibration algorithms with experimental\nvalidations."
  },
  {
    "paper_no": "3043",
    "authors": "Galvan, Aldo; Majewicz Fey, Ann; Patel, Ravi",
    "title": "Learning Force-Based Control Policies via Differentiable Virtual Coupling (Diff-VC)",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3046",
    "authors": "Misra, Vihaan; Schaldenbrand, Peter; Oh, Jean",
    "title": "Robot Synesthesia: A Sound and Emotion Guided Robot Painter",
    "arxiv_pdf": "http://arxiv.org/pdf/2302.04850v2",
    "arxiv_abstract": "If a picture paints a thousand words, sound may voice a million. While recent\nrobotic painting and image synthesis methods have achieved progress in\ngenerating visuals from text inputs, the translation of sound into images is\nvastly unexplored. Generally, sound-based interfaces and sonic interactions\nhave the potential to expand accessibility and control for the user and provide\na means to convey complex emotions and the dynamic aspects of the real world.\nIn this paper, we propose an approach for using sound and speech to guide a\nrobotic painting process, known here as robot synesthesia. For general sound,\nwe encode the simulated paintings and input sounds into the same latent space.\nFor speech, we decouple speech into its transcribed text and the tone of the\nspeech. Whereas we use the text to control the content, we estimate the\nemotions from the tone to guide the mood of the painting. Our approach has been\nfully integrated with FRIDA, a robotic painting framework, adding sound and\nspeech to FRIDA's existing input modalities, such as text and style. In two\nsurveys, participants were able to correctly guess the emotion or natural sound\nused to generate a given painting more than twice as likely as random chance.\nOn our sound-guided image manipulation and music-guided paintings, we discuss\nthe results qualitatively."
  },
  {
    "paper_no": "3048",
    "authors": "Mao, Xiaofeng; Xu, Yucheng; Wen, Ruoshi; Kasaei, Mohammadreza; Yu, Wanming; Psomopoulou, Efi; Lepora, Nathan; Li, Zhibin (Alex)",
    "title": "Learning Fine Pinch-Grasp Skills using Tactile Sensing from A Few Real-world Demonstrations",
    "arxiv_pdf": "http://arxiv.org/pdf/2307.04619v2",
    "arxiv_abstract": "Imitation learning for robot dexterous manipulation, especially with a real\nrobot setup, typically requires a large number of demonstrations. In this\npaper, we present a data-efficient learning from demonstration framework which\nexploits the use of rich tactile sensing data and achieves fine bimanual pinch\ngrasping. Specifically, we employ a convolutional autoencoder network that can\neffectively extract and encode high-dimensional tactile information. Further,\nWe develop a framework that achieves efficient multi-sensor fusion for\nimitation learning, allowing the robot to learn contact-aware sensorimotor\nskills from demonstrations. Our comparision study against the framework without\nusing encoded tactile features highlighted the effectiveness of incorporating\nrich contact information, which enabled dexterous bimanual grasping with active\ncontact searching. Extensive experiments demonstrated the robustness of the\nfine pinch grasp policy directly learned from few-shot demonstration, including\ngrasping of the same object with different initial poses, generalizing to ten\nunseen new objects, robust and firm grasping against external pushes, as well\nas contact-aware and reactive re-grasping in case of dropping objects under\nvery large perturbations. Furthermore, the saliency map analysis method is used\nto describe weight distribution across various modalities during pinch\ngrasping, confirming the effectiveness of our framework at leveraging\nmultimodal information."
  },
  {
    "paper_no": "3050",
    "authors": "Makabe, Tasuku; Okada, Kei; Inaba, Masayuki",
    "title": "Abstraction of the Body Ability of the Transformer Robot System for the Transportation and Installation of Heavy Objects in Land and Underwater Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3051",
    "authors": "Kim, Taehyeon; Min, Byung-Cheol",
    "title": "Semantic Layering in Room Segmentation via LLMs",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12920v1",
    "arxiv_abstract": "In this paper, we introduce Semantic Layering in Room Segmentation via LLMs\n(SeLRoS), an advanced method for semantic room segmentation by integrating\nLarge Language Models (LLMs) with traditional 2D map-based segmentation. Unlike\nprevious approaches that solely focus on the geometric segmentation of indoor\nenvironments, our work enriches segmented maps with semantic data, including\nobject identification and spatial relationships, to enhance robotic navigation.\nBy leveraging LLMs, we provide a novel framework that interprets and organizes\ncomplex information about each segmented area, thereby improving the accuracy\nand contextual relevance of room segmentation. Furthermore, SeLRoS overcomes\nthe limitations of existing algorithms by using a semantic evaluation method to\naccurately distinguish true room divisions from those erroneously generated by\nfurniture and segmentation inaccuracies. The effectiveness of SeLRoS is\nverified through its application across 30 different 3D environments. Source\ncode and experiment videos for this work are available at:\nhttps://sites.google.com/view/selros."
  },
  {
    "paper_no": "3052",
    "authors": "Yang, Yupeng; Lyu, Yiwei; Zhang, Yanze; Gao, Ian; Luo, Wenhao",
    "title": "Integrating Online Learning and Connectivity Maintenance for Communication-Aware Multi-Robot Coordination",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.05798v1",
    "arxiv_abstract": "This paper proposes a novel data-driven control strategy for maintaining\nconnectivity in networked multi-robot systems. Existing approaches often rely\non a pre-determined communication model specifying whether pairwise robots can\ncommunicate given their relative distance to guide the connectivity-aware\ncontrol design, which may not capture real-world communication conditions. To\nrelax that assumption, we present the concept of Data-driven Connectivity\nBarrier Certificates, which utilize Control Barrier Functions (CBF) and\nGaussian Processes (GP) to characterize the admissible control space for\npairwise robots based on communication performance observed online. This allows\nrobots to maintain a satisfying level of pairwise communication quality\n(measured by the received signal strength) while in motion. Then we propose a\nData-driven Connectivity Maintenance (DCM) algorithm that combines (1) online\nlearning of the communication signal strength and (2) a bi-level\noptimization-based control framework for the robot team to enforce global\nconnectivity of the realistic multi-robot communication graph and minimally\ndeviate from their task-related motions. We provide theoretical proofs to\njustify the properties of our algorithm and demonstrate its effectiveness\nthrough simulations with up to 20 robots."
  },
  {
    "paper_no": "3053",
    "authors": "Sakamoto, Koya; Azuma, Daichi; Miyanishi, Taiki; Kurita, Shuhei; Kawanabe, Motoaki",
    "title": "Map-based Modular Approach for Zero-shot Embodied Question Answering",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.16559v2",
    "arxiv_abstract": "Embodied Question Answering (EQA) serves as a benchmark task to evaluate the\ncapability of robots to navigate within novel environments and identify objects\nin response to human queries. However, existing EQA methods often rely on\nsimulated environments and operate with limited vocabularies. This paper\npresents a map-based modular approach to EQA, enabling real-world robots to\nexplore and map unknown environments. By leveraging foundation models, our\nmethod facilitates answering a diverse range of questions using natural\nlanguage. We conducted extensive experiments in both virtual and real-world\nsettings, demonstrating the robustness of our approach in navigating and\ncomprehending queries within unknown environments."
  },
  {
    "paper_no": "3054",
    "authors": "Yao, Liangliang; Fu, Changhong; Wang, Yiheng; Zuo, Haobo; Lu, Kunhan",
    "title": "Enhancing Nighttime UAV Tracking with Light Distribution Suppression",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.16631v1",
    "arxiv_abstract": "Visual object tracking has boosted extensive intelligent applications for\nunmanned aerial vehicles (UAVs). However, the state-of-the-art (SOTA) enhancers\nfor nighttime UAV tracking always neglect the uneven light distribution in\nlow-light images, inevitably leading to excessive enhancement in scenarios with\ncomplex illumination. To address these issues, this work proposes a novel\nenhancer, i.e., LDEnhancer, enhancing nighttime UAV tracking with light\ndistribution suppression. Specifically, a novel image content refinement module\nis developed to decompose the light distribution information and image content\ninformation in the feature space, allowing for the targeted enhancement of the\nimage content information. Then this work designs a new light distribution\ngeneration module to capture light distribution effectively. The features with\nlight distribution information and image content information are fed into the\ndifferent parameter estimation modules, respectively, for the parameter map\nprediction. Finally, leveraging two parameter maps, an innovative interweave\niteration adjustment is proposed for the collaborative pixel-wise adjustment of\nlow-light images. Additionally, a challenging nighttime UAV tracking dataset\nwith uneven light distribution, namely NAT2024-2, is constructed to provide a\ncomprehensive evaluation, which contains 40 challenging sequences with over 74K\nframes in total. Experimental results on the authoritative UAV benchmarks and\nthe proposed NAT2024-2 demonstrate that LDEnhancer outperforms other SOTA\nlow-light enhancers for nighttime UAV tracking. Furthermore, real-world tests\non a typical UAV platform with an NVIDIA Orin NX confirm the practicality and\nefficiency of LDEnhancer. The code is available at\nhttps://github.com/vision4robotics/LDEnhancer."
  },
  {
    "paper_no": "3055",
    "authors": "Gandhi, Abhinav; Chiang, Shou-Shan; Onal, Cagdas; Calli, Berk",
    "title": "Grow-to-Shape Control of Variable Length Continuum Robots via Adaptive Visual Servoing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3056",
    "authors": "Goeckner, Anthony; Sui, Yueyuan; Martinet, Nicolas; Li, Xinliang; Zhu, Qi",
    "title": "Graph Neural Network-based Multi-agent Reinforcement Learning for Resilient Distributed Coordination of Multi-Robot Systems",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13093v1",
    "arxiv_abstract": "Existing multi-agent coordination techniques are often fragile and vulnerable\nto anomalies such as agent attrition and communication disturbances, which are\nquite common in the real-world deployment of systems like field robotics. To\nbetter prepare these systems for the real world, we present a graph neural\nnetwork (GNN)-based multi-agent reinforcement learning (MARL) method for\nresilient distributed coordination of a multi-robot system. Our method,\nMulti-Agent Graph Embedding-based Coordination (MAGEC), is trained using\nmulti-agent proximal policy optimization (PPO) and enables distributed\ncoordination around global objectives under agent attrition, partial\nobservability, and limited or disturbed communications. We use a multi-robot\npatrolling scenario to demonstrate our MAGEC method in a ROS 2-based simulator\nand then compare its performance with prior coordination approaches. Results\ndemonstrate that MAGEC outperforms existing methods in several experiments\ninvolving agent attrition and communication disturbance, and provides\ncompetitive results in scenarios without such anomalies."
  },
  {
    "paper_no": "3058",
    "authors": "Zhang, Jinyu; Gu, Yongchong; Gao, Jianxiong; Lin, Haitao; Sun, Qiang; Sun, Xinwei; Xue, Xiangyang; Fu, Yanwei",
    "title": "LAC-Net: Linear-Fusion Attention-Guided Convolutional Network for Accurate Robotic Grasping Under the Occlusion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3059",
    "authors": "Wei, Pengkun; Cheng, Shuo; Li, Dayou; Song, Ran; Zhang, Yipeng; Zhang, Wei",
    "title": "Coarse-to-Fine Detection of Multiple Seams for Robotic Welding",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.10710v1",
    "arxiv_abstract": "Efficiently detecting target weld seams while ensuring sub-millimeter\naccuracy has always been an important challenge in autonomous welding, which\nhas significant application in industrial practice. Previous works mostly\nfocused on recognizing and localizing welding seams one by one, leading to\ninferior efficiency in modeling the workpiece. This paper proposes a novel\nframework capable of multiple weld seams extraction using both RGB images and\n3D point clouds. The RGB image is used to obtain the region of interest by\napproximately localizing the weld seams, and the point cloud is used to achieve\nthe fine-edge extraction of the weld seams within the region of interest using\nregion growth. Our method is further accelerated by using a pre-trained deep\nlearning model to ensure both efficiency and generalization ability. The\nperformance of the proposed method has been comprehensively tested on various\nworkpieces featuring both linear and curved weld seams and in physical\nexperiment systems. The results showcase considerable potential for real-world\nindustrial applications, emphasizing the method's efficiency and effectiveness.\nVideos of the real-world experiments can be found at\nhttps://youtu.be/pq162HSP2D4."
  },
  {
    "paper_no": "3060",
    "authors": "Sun, Rundong; Fu, Mengyin; Liang, Hao; Zhu, Chunhui; Dong, Zhipeng; Yang, Yi",
    "title": "Robust Multi-Camera BEV Perception: An Image-Perceptive Approach to Counter Imprecise Camera Calibration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3061",
    "authors": "Takahashi, Yuta; Tadakuma, Kenjiro; Abe, Kazuki; Watanabe, Masahiro; Shimizu, Shoya; Tadokoro, Satoshi",
    "title": "Versatile Variable-Stiffness Scooping End-Effector: Tilting-Scooping-Transfer Mechanism for Objects with Various Properties",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3063",
    "authors": "Sathyamoorthy, Adarsh Jagan; Kulathun Mudiyanselage, Kasun Weerakoon; Elnoor, Mohamed; Zore, Anuj; Ichter, Brian; Xia, Fei; Tan, Jie; Yu, Wenhao; Manocha, Dinesh",
    "title": "CoNVOI: Context-aware Navigation using Vision Language Models in Outdoor and Indoor Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3066",
    "authors": "Koh, Youngil; Kim, WooJeong; Choi, MidEum",
    "title": "Practical Framework for Path Representation and Following Control in Mobile Industrial Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3069",
    "authors": "Tseng, Kuan-Yu; Zhang, Mengchao; Hauser, Kris; Dullerud, Geir E.",
    "title": "Adaptive Trajectory Database Learning for Nonlinear Control with Hybrid Gradient Optimization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3074",
    "authors": "Kuhn, Sebastian; Yildirim, Mehmet Can; Pozo Fortuni&#263;, Edmundo; Karacan, Kübra; Swikir, Abdalla; Haddadin, Sami",
    "title": "A Novel Variable Stiffness Suspension System for Improved Stability and Control of Tactile Mobile Manipulators",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3077",
    "authors": "Hoegerman, Joshua; Sagheb, Shahabedin; Christie, Benjamin; Losey, Dylan",
    "title": "Aligning Learning with Communication in Shared Autonomy",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.12023v1",
    "arxiv_abstract": "Assistive robot arms can help humans by partially automating their desired\ntasks. Consider an adult with motor impairments controlling an assistive robot\narm to eat dinner. The robot can reduce the number of human inputs -- and how\nprecise those inputs need to be -- by recognizing what the human wants (e.g., a\nfork) and assisting for that task (e.g., moving towards the fork). Prior\nresearch has largely focused on learning the human's task and providing\nmeaningful assistance. But as the robot learns and assists, we also need to\nensure that the human understands the robot's intent (e.g., does the human know\nthe robot is reaching for a fork?). In this paper, we study the effects of\ncommunicating learned assistance from the robot back to the human operator. We\ndo not focus on the specific interfaces used for communication. Instead, we\ndevelop experimental and theoretical models of a) how communication changes the\nway humans interact with assistive robot arms, and b) how robots can harness\nthese changes to better align with the human's intent. We first conduct online\nand in-person user studies where participants operate robots that provide\npartial assistance, and we measure how the human's inputs change with and\nwithout communication. With communication, we find that humans are more likely\nto intervene when the robot incorrectly predicts their intent, and more likely\nto release control when the robot correctly understands their task. We then use\nthese findings to modify an established robot learning algorithm so that the\nrobot can correctly interpret the human's inputs when communication is present.\nOur results from a second in-person user study suggest that this combination of\ncommunication and learning outperforms assistive systems that isolate either\nlearning or communication."
  },
  {
    "paper_no": "3079",
    "authors": "Tadakuma, Kenjiro; Sakiyama, Seiji; Takane, Eri; Tadakuma, Riichiro; Tadokoro, Satoshi",
    "title": "Enhanced Spherical Omnidirectional Wheel: Achieving Passive Rollers with High Load Capacity and Smoothness through an Offset Rotational Axis",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3081",
    "authors": "Park, Seongsu; Kim, Min Jun",
    "title": "Design of a Fully Actuated Drone With Non-Isotropic Wrench Shape",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3083",
    "authors": "Trygstad, Conor; Blankenship, Elijah; Perez-Arancibia, Nestor O",
    "title": "A New 10-mg SMA-Based Fast Bimorph Actuator for Microrobotics",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.18352v1",
    "arxiv_abstract": "We present a new millimeter-scale bimorph actuator for microrobotic\napplications, driven by feedforward controlled shape-memory alloy (SMA) wires.\nThe device weighs 10 mg, measures 14 mm in length, and occupies a volume of 4.8\nmm3, which makes it the lightest and smallest fully functional SMA-based\nbimorph actuator for microrobotics developed to date. The experimentally\nmeasured operational bandwidth is on the order of 20 Hz, and the unimorph and\nbimorph maximum low-frequency displacement outputs are on the order of 3.5 and\n7 mm, respectively. To test and demonstrate the functionality and suitability\nof the actuator for microrobotics, we developed the Fish-&-Ribbon-Inspired\nSmall Swimming Harmonic roBot (FRISSHBot). Loosely inspired by carangiformes,\nthe FRISSHBot leverages fluid-structure interaction (FSI) phenomena to propel\nitself forward, weighs 30 mg, measures 34 mm in length, operates at frequencies\nof up to 4 Hz, and swims at speeds of up to 3.06 mm/s (0.09 Bl/s). This robot\nis the lightest and smallest swimmer with onboard actuation developed to date."
  },
  {
    "paper_no": "3084",
    "authors": "Chen, Kaiyuan; Hari, Kush; Chung, Trinity; Wang, Michael; Tian, Nan; Juette, Christian; Ichnowski, Jeffrey; Ren, Liu; Kubiatowicz, John; Stoica, Ion; Goldberg, Ken",
    "title": "FogROS2-FT: Fault Tolerant Cloud Robotics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3089",
    "authors": "Balakrishnan, Anand; Atasever, Merve; Deshmukh, Jyotirmoy",
    "title": "Motion Planning for Automata-based Objectives using Efficient Gradient-based Methods",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3091",
    "authors": "Chen, Chung-Yu; Lai, Bo-Yun; Huang, Ying-Shiuan; Lin, Wen-Chieh; Wang, Chieh-Chih",
    "title": "Self-Supervised Motion Segmentation with Confidence-Aware Loss Functions for Handling Occluded Pixels and Uncertain Optical Flow Predictions",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3093",
    "authors": "Richards, Olivia; Ahronovich, Elan; Shihora, Neel; Yildiz, Ahmet; Atoum, Jumana; Wu, Jie Ying; Obstein, Keith; Simaan, Nabil",
    "title": "A Robotic Mediation Device for Skill Assessment and Training During Colonoscopy",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3094",
    "authors": "Seo, Junghyun; Jeon, Hyeonjae; Choi, Joonyoung; Kwangho, Woo; Lim, Yongseob; Jin, yongsik",
    "title": "BEV Image-based Lane Tracking Control System for Autonomous Lane Repainting Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3095",
    "authors": "Tasnim Oshim, Md Farhan; Reed, Albert; Jayasuriya, Suren; Rahman, Tauhidur",
    "title": "NeRF-enabled Analysis-Through-Synthesis for ISAR Imaging of Small Everyday Objects with Sparse and Noisy UWB Radar Data",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.10085v1",
    "arxiv_abstract": "Inverse Synthetic Aperture Radar (ISAR) imaging presents a formidable\nchallenge when it comes to small everyday objects due to their limited Radar\nCross-Section (RCS) and the inherent resolution constraints of radar systems.\nExisting ISAR reconstruction methods including backprojection (BP) often\nrequire complex setups and controlled environments, rendering them impractical\nfor many real-world noisy scenarios. In this paper, we propose a novel\nAnalysis-through-Synthesis (ATS) framework enabled by Neural Radiance Fields\n(NeRF) for high-resolution coherent ISAR imaging of small objects using sparse\nand noisy Ultra-Wideband (UWB) radar data with an inexpensive and portable\nsetup. Our end-to-end framework integrates ultra-wideband radar wave\npropagation, reflection characteristics, and scene priors, enabling efficient\n2D scene reconstruction without the need for costly anechoic chambers or\ncomplex measurement test beds. With qualitative and quantitative comparisons,\nwe demonstrate that the proposed method outperforms traditional techniques and\ngenerates ISAR images of complex scenes with multiple targets and complex\nstructures in Non-Line-of-Sight (NLOS) and noisy scenarios, particularly with\nlimited number of views and sparse UWB radar scans. This work represents a\nsignificant step towards practical, cost-effective ISAR imaging of small\neveryday objects, with broad implications for robotics and mobile sensing\napplications."
  },
  {
    "paper_no": "3100",
    "authors": "Cherian, Anoop; Jain, Siddarth; Marks, Tim K.",
    "title": "Few-shot Transparent Instance Segmentation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3101",
    "authors": "Seker, Muhammet Yunus; Kroemer, Oliver",
    "title": "Leveraging Simulation-Based Model Preconditions for Fast Action Parameter Optimization with Multiple Models",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.11313v1",
    "arxiv_abstract": "Optimizing robotic action parameters is a significant challenge for\nmanipulation tasks that demand high levels of precision and generalization.\nUsing a model-based approach, the robot must quickly reason about the outcomes\nof different actions using a predictive model to find a set of parameters that\nwill have the desired effect. The model may need to capture the behaviors of\nrigid and deformable objects, as well as objects of various shapes and sizes.\nPredictive models often need to trade-off speed for prediction accuracy and\ngeneralization. This paper proposes a framework that leverages the strengths of\nmultiple predictive models, including analytical, learned, and simulation-based\nmodels, to enhance the efficiency and accuracy of action parameter\noptimization. Our approach uses Model Deviation Estimators (MDEs) to determine\nthe most suitable predictive model for any given state-action parameters,\nallowing the robot to select models to make fast and precise predictions. We\nextend the MDE framework by not only learning sim-to-real MDEs, but also\nsim-to-sim MDEs. Our experiments show that these sim-to-sim MDEs provide\nsignificantly faster parameter optimization as well as a basis for efficiently\nlearning sim-to-real MDEs through finetuning. The ease of collecting sim-to-sim\ntraining data also allows the robot to learn MDEs based directly on visual\ninputs and local material properties."
  },
  {
    "paper_no": "3103",
    "authors": "Ikeda, Takaki; Iwaguchi, Takafumi; Thomas, Diego; Kawasaki, Hiroshi",
    "title": "Two-stage pose optimization algorithm using color information for underwater SLAM with light-sectioning-based 3D scanning method",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3105",
    "authors": "Li, Chenxi; Lu, Weining; Ma, Zhihao; Meng, Litong; Liang, Bin",
    "title": "Highly Efficient Observation Process based on FFT Filtering for Robot Swarm Collaborative Navigation in Unknown Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.07687v3",
    "arxiv_abstract": "Collaborative path planning for robot swarms in complex, unknown environments\nwithout external positioning is a challenging problem. This requires robots to\nfind safe directions based on real-time environmental observations, and to\nefficiently transfer and fuse these observations within the swarm. This study\npresents a filtering method based on Fast Fourier Transform (FFT) to address\nthese two issues. We treat sensors' environmental observations as a digital\nsampling process. Then, we design two different types of filters for safe\ndirection extraction, as well as for the compression and reconstruction of\nenvironmental data. The reconstructed data is mapped to probabilistic domain,\nachieving efficient fusion of swarm observations and planning decision. The\ncomputation time is only on the order of microseconds, and the transmission\ndata in communication systems is in bit-level. The performance of our algorithm\nin sensor data processing was validated in real world experiments, and the\neffectiveness in swarm path optimization was demonstrated through extensive\nsimulations."
  },
  {
    "paper_no": "3106",
    "authors": "Cao, Rui; Yang, Zhiqiang; Song, Ran; Meng, Ziyu; Wang, Ruifeng; Zhang, Wei",
    "title": "MPP: Multiscale Path Planning for UGV Navigationin Semi-structured Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3108",
    "authors": "Islam, Sharfin; He, Zhanpeng; Ciocarlie, Matei",
    "title": "Task-Based Design and Policy Co-Optimization for Tendon-driven Underactuated Kinematic Chains",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.14566v1",
    "arxiv_abstract": "Underactuated manipulators reduce the number of bulky motors, thereby\nenabling compact and mechanically robust designs. However, fewer actuators than\njoints means that the manipulator can only access a specific manifold within\nthe joint space, which is particular to a given hardware configuration and can\nbe low-dimensional and/or discontinuous. Determining an appropriate set of\nhardware parameters for this class of mechanisms, therefore, is difficult -\neven for traditional task-based co-optimization methods. In this paper, our\ngoal is to implement a task-based design and policy co-optimization method for\nunderactuated, tendon-driven manipulators. We first formulate a general model\nfor an underactuated, tendon-driven transmission. We then use this model to\nco-optimize a three-link, two-actuator kinematic chain using reinforcement\nlearning. We demonstrate that our optimized tendon transmission and control\npolicy can be transferred reliably to physical hardware with real-world\nreaching experiments."
  },
  {
    "paper_no": "3109",
    "authors": "Elnoor, Mohamed; Kulathun Mudiyanselage, Kasun Weerakoon; Sathyamoorthy, Adarsh Jagan; Guan, Tianrui; Rajagopal, Vignesh; Manocha, Dinesh",
    "title": "AMCO: Adaptive Multimodal Coupling of Vision and Proprioception for Quadruped Robot Navigation in Outdoor Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3114",
    "authors": "Gu, Yijun; Demiris, Yiannis",
    "title": "Learning Bimanual Manipulation Policies for Bathing Bed-bound People",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3116",
    "authors": "Cui, Li; Ding, Yang; Hartley, Richard; Xie, Zirui; Kneip, Laurent; YU, ZHENGHUA",
    "title": "NF-SLAM: Effective, Normalizing Flow-supported Neural Field representations for object-level visual SLAM in automotive applications",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3117",
    "authors": "Lee, Jaemin; Kim, Jeeseop; Ames, Aaron",
    "title": "Safety-critical Autonomous Inspection of Distillation Columns using Quadrupedal Robots Equipped with Roller Arms",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.10938v1",
    "arxiv_abstract": "This paper proposes a comprehensive framework designed for the autonomous\ninspection of complex environments, with a specific focus on multi-tiered\nsettings such as distillation column trays. Leveraging quadruped robots\nequipped with roller arms, and through the use of onboard perception, we\nintegrate essential motion components including: locomotion, safe and dynamic\ntransitions between trays, and intermediate motions that bridge a variety of\nmotion primitives. Given the slippery and confined nature of column trays, it\nis critical to ensure safety of the robot during inspection, therefore we\nemploy a safety filter and footstep re-planning based upon control barrier\nfunction representations of the environment. Our framework integrates all\nsystem components into a state machine encoding the developed safety-critical\nplanning and control elements to guarantee safety-critical autonomy, enabling\nautonomous and safe navigation and inspection of distillation columns.\nExperimental validation in an environment, consisting of industrial-grade\nchemical distillation trays, highlights the effectiveness of our multi-layered\narchitecture."
  },
  {
    "paper_no": "3118",
    "authors": "Qu, Tomson; Li, Dichen; Zakhor, Avideh; Yu, Wenhao; Zhang, Tingnan",
    "title": "Versatile Locomotion Skills for Hexapod Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2412.10628v1",
    "arxiv_abstract": "Hexapod robots are potentially suitable for carrying out tasks in cluttered\nenvironments since they are stable, compact, and light weight. They also have\nmulti-joint legs and variable height bodies that make them good candidates for\ntasks such as stairs climbing and squeezing under objects in a typical home\nenvironment or an attic. Expanding on our previous work on joist climbing in\nattics, we train a legged hexapod equipped with a depth camera and visual\ninertial odometry (VIO) to perform three tasks: climbing stairs, avoiding\nobstacles, and squeezing under obstacles such as a table. Our policies are\ntrained with simulation data only and can be deployed on lowcost hardware not\nrequiring real-time joint state feedback. We train our model in a\nteacher-student model with 2 phases: In phase 1, we use reinforcement learning\nwith access to privileged information such as height maps and joint feedback.\nIn phase 2, we use supervised learning to distill the model into one with\naccess to only onboard observations, consisting of egocentric depth images and\nrobot pose captured by a tracking VIO camera. By manipulating available\nprivileged information, constructing simulation terrains, and refining reward\nfunctions during phase 1 training, we are able to train the robots with skills\nthat are robust in non-ideal physical environments. We demonstrate successful\nsim-to-real transfer and achieve high success rates across all three tasks in\nphysical experiments."
  },
  {
    "paper_no": "3123",
    "authors": "Zhao, Lemeng; Hu, Junjie; Bi, Jianchao; Bai, Yanbing; Erick, Mas; Koshimura, Shunichi",
    "title": "Streamlining Forest Wildfire Surveillance: AI-Enhanced UAVs Utilizing the FLAME Aerial Video Dataset for Lightweight and Efficient Monitoring",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.00510v1",
    "arxiv_abstract": "In recent years, unmanned aerial vehicles (UAVs) have played an increasingly\ncrucial role in supporting disaster emergency response efforts by analyzing\naerial images. While current deep-learning models focus on improving accuracy,\nthey often overlook the limited computing resources of UAVs. This study\nrecognizes the imperative for real-time data processing in disaster response\nscenarios and introduces a lightweight and efficient approach for aerial video\nunderstanding. Our methodology identifies redundant portions within the video\nthrough policy networks and eliminates this excess information using frame\ncompression techniques. Additionally, we introduced the concept of a `station\npoint,' which leverages future information in the sequential policy network,\nthereby enhancing accuracy. To validate our method, we employed the wildfire\nFLAME dataset. Compared to the baseline, our approach reduces computation costs\nby more than 13 times while boosting accuracy by 3$\\%$. Moreover, our method\ncan intelligently select salient frames from the video, refining the dataset.\nThis feature enables sophisticated models to be effectively trained on a\nsmaller dataset, significantly reducing the time spent during the training\nprocess."
  },
  {
    "paper_no": "3124",
    "authors": "Liao, Brian Hsuan-Cheng; Cheng, Chih-Hong; Esen, Hasan; Knoll, Alois",
    "title": "EC-IoU: Orienting Safety for Object Detectors via Ego-Centric Intersection-over-Union",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3125",
    "authors": "Kannan, Shyam Sundar; Venkatesh, L.N Vishnunandan; Min, Byung-Cheol",
    "title": "SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3126",
    "authors": "Botashev, Kazii; Pyatov, Vladislav; Ferrer, Gonzalo; Lefkimmiatis, Stamatios",
    "title": "GSLoc: Visual Localization with 3D Gaussian Splatting",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3128",
    "authors": "Argenziano, Francesco; Brienza, Michele; Suriani, Vincenzo; Nardi, Daniele; Bloisi, Domenico",
    "title": "EMPOWER: Embodied Multi-role Open-vocabulary Planning with Online Grounding and Execution",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3131",
    "authors": "Mahalingam, Dasharadhan; Patankar, Aditya; Laha, Riddhiman; Lakshminarayanan, Srinivasan; Haddadin, Sami; Chakraborty, Nilanjan",
    "title": "A General Formulation for Path Constrained Time-Optimized Trajectory Planning with Environmental and Object Contacts",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.06295v1",
    "arxiv_abstract": "A typical manipulation task consists of a manipulator equipped with a gripper\nto grasp and move an object with constraints on the motion of the hand-held\nobject, which may be due to the nature of the task itself or from\nobject-environment contacts. In this paper, we study the problem of computing\njoint torques and grasping forces for time-optimal motion of an object, while\nensuring that the grasp is not lost and any constraints on the motion of the\nobject, either due to dynamics, environment contact, or no-slip requirements,\nare also satisfied. We present a second-order cone program (SOCP) formulation\nof the time-optimal trajectory planning problem that considers nonlinear\nfriction cone constraints at the hand-object and object-environment contacts.\nSince SOCPs are convex optimization problems that can be solved optimally in\npolynomial time using interior point methods, we can solve the trajectory\noptimization problem efficiently. We present simulation results on three\nexamples, including a non-prehensile manipulation task, which shows the\ngenerality and effectiveness of our approach."
  },
  {
    "paper_no": "3134",
    "authors": "Du, xinzhe; Zhang, Zhengyan; Min, Zhe; Zhang, Ang; Song, Rui; Li, Yibin; Meng, Max Q.-H.",
    "title": "OBHMR: Partial Generalized Point Set Registration with Overlap Bidirectional Hybrid Mixture Model",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3138",
    "authors": "Wu, Xuankang; Sun, Haoxiang; Wu, Rongguang; Fang, Zheng",
    "title": "EverySync: An Open Hardware Time Synchronization Sensor Suite for Common Sensors in SLAM",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3139",
    "authors": "Ying, Lance; Jha, Kunal; Aarya, Shivam; Tenenbaum, Joshua; Torralba, Antonio; Shu, Tianmin",
    "title": "GOMA: Proactive Embodied Cooperative Communication via Goal-Oriented Mental Alignment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3140",
    "authors": "Muenprasitivej, Kasdiit; Jiang, Jesse; Shamsah, Abdulaziz; Coogan, Samuel; Zhao, Ye",
    "title": "Bipedal Safe Navigation over Uncertain Rough Terrain: Unifying Terrain Mapping and Locomotion Stability",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.16356v2",
    "arxiv_abstract": "We study the problem of bipedal robot navigation in complex environments with\nuncertain and rough terrain. In particular, we consider a scenario in which the\nrobot is expected to reach a desired goal location by traversing an environment\nwith uncertain terrain elevation. Such terrain uncertainties induce not only\nuntraversable regions but also robot motion perturbations. Thus, the problems\nof terrain mapping and locomotion stability are intertwined. We evaluate three\ndifferent kernels for Gaussian process (GP) regression to learn the terrain\nelevation. We also learn the motion deviation resulting from both the terrain\nas well as the discrepancy between the reduced-order Prismatic Inverted\nPendulum Model used for planning and the full-order locomotion dynamics. We\npropose a hierarchical locomotion-dynamics-aware sampling-based navigation\nplanner. The global navigation planner plans a series of local waypoints to\nreach the desired goal locations while respecting locomotion stability\nconstraints. Then, a local navigation planner is used to generate a sequence of\ndynamically feasible footsteps to reach local waypoints. We develop a novel\ntrajectory evaluation metric to minimize motion deviation and maximize\ninformation gain of the terrain elevation map. We evaluate the efficacy of our\nplanning framework on Digit bipedal robot simulation in MuJoCo."
  },
  {
    "paper_no": "3142",
    "authors": "Zhou, Jiadong; Zeng, Yadan; Dong, Huixu; Chen, I-Ming",
    "title": "Discretizing SO(2)-Equivariant Features for Robotic Kitting",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13336v1",
    "arxiv_abstract": "Robotic kitting has attracted considerable attention in logistics and\nindustrial settings. However, existing kitting methods encounter challenges\nsuch as low precision and poor efficiency, limiting their widespread\napplications. To address these issues, we present a novel kitting framework\nthat improves both the precision and computational efficiency of complex\nkitting tasks. Firstly, our approach introduces a fine-grained orientation\nestimation technique in the picking module, significantly enhancing orientation\nprecision while effectively decoupling computational load from orientation\ngranularity. This approach combines an SO(2)-equivariant network with a group\ndiscretization operation to preciously predict discrete orientation\ndistributions. Secondly, we develop the Hand-tool Kitting Dataset (HKD) to\nevaluate the performance of different solutions in handling\norientation-sensitive kitting tasks. This dataset comprises a diverse\ncollection of hand tools and synthetically created kits, which reflects the\ncomplexities encountered in real-world kitting scenarios. Finally, a series of\nexperiments are conducted to evaluate the performance of the proposed method.\nThe results demonstrate that our approach offers remarkable precision and\nenhanced computational efficiency in robotic kitting tasks."
  },
  {
    "paper_no": "3146",
    "authors": "Moghani, Masoud; Doorenbos, Lars; Panitch, William; Huver, Sean; Azizian, Mahdi; Goldberg, Ken; Garg, Animesh",
    "title": "SuFIA: Language-Guided Augmented Dexterity for Robotic Surgical Assistants",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3148",
    "authors": "Jeong, Gowoon; Ko, Seong Young",
    "title": "A Novel Vitreoretinal Surgical Robot System to Maximize the Internal Reachable Workspace and Minimize the External Link Motion",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3152",
    "authors": "Hossain, Jumman; Faridee, Abu-Zaher; Roy, Nirmalya; Freeman, Jade; Gregory, Timothy; Trout, Theron T.",
    "title": "TopoNav: Topological Navigation for Efficient Exploration in Sparse Reward Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3156",
    "authors": "Li, Puhao; Liu, Tengyu; Li, Yuyang; Han, Muzhi; Geng, Haoran; Wang, Shu; Zhu, Yixin; Zhu, Song-Chun; Huang, Siyuan",
    "title": "Ag2Manip: Learning Novel Manipulation Skills with Agent-Agnostic Visual and Action Representations",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3160",
    "authors": "Zhou, Yuhao; Zhou, Pokuang; Wang, Shaoxiong; She, Yu",
    "title": "In-Hand Singulation and Scooping Manipulation with a 5 DOF Tactile Gripper",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.00610v1",
    "arxiv_abstract": "Manipulation tasks often require a high degree of dexterity, typically\nnecessitating grippers with multiple degrees of freedom (DoF). While a robotic\nhand equipped with multiple fingers can execute precise and intricate\nmanipulation tasks, the inherent redundancy stemming from its extensive DoF\noften adds unnecessary complexity. In this paper, we introduce the design of a\ntactile sensor-equipped gripper with two fingers and five DoF. We present a\nnovel design integrating a GelSight tactile sensor, enhancing sensing\ncapabilities and enabling finer control during specific manipulation tasks. To\nevaluate the gripper's performance, we conduct experiments involving two\nchallenging tasks: 1) retrieving, singularizing, and classification of various\nobjects embedded in granular media, and 2) executing scooping manipulations of\ncredit cards in confined environments to achieve precise insertion. Our results\ndemonstrate the efficiency of the proposed approach, with a high success rate\nfor singulation and classification tasks, particularly for spherical objects at\nhigh as 94.3%, and a 100% success rate for scooping and inserting credit cards."
  },
  {
    "paper_no": "3161",
    "authors": "Wang, Shuyuan",
    "title": "Reinforce actions with half of the dynamics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3165",
    "authors": "Arul, Senthil Hariharan; Bedi, Amrit Singh; Manocha, Dinesh",
    "title": "When, What, and with Whom to Communicate: Enhancing RL-based Multi-Robot Navigation through Selective Communication",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3167",
    "authors": "jiang, xu; Zhang, Jun; Song, Aiguo",
    "title": "An Ejecting System for Autonomous Takeoff of Flapping-Wing Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3169",
    "authors": "Yoon, Minsung; Shin, Heechan; Jeong, Jeil; Yoon, Sung-eui",
    "title": "Learning-based Adaptive Control of Quadruped Robots for Active Stabilization on Moving Platforms",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3171",
    "authors": "Yao, Hekai; Zhang, Xuetao; Sun, Gang; Liu, Yisha; Zhang, Xuebo; Zhuang, Yan",
    "title": "MUP-LIO: Mapping Uncertainty-aware Point-wise Lidar Inertial Odometry",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3173",
    "authors": "Xuan, Chice; Lu, Jiadong; Tian, Zhihao; Li, Jiacheng; Zhang, Mengke; Xie, Hanbin; Qiu, Jianxiong; Xu, Chao; Cao, Yanjun",
    "title": "Novel design of Reconfigurable Tracked Robot with Geometry-Changing Tracks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3175",
    "authors": "Schmidt, Christian; Piekenbrinck, Jens; Leibe, Bastian",
    "title": "Look Gauss, No Pose: Novel View Synthesis using Gaussian Splatting without Accurate Pose Initialization",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.08743v1",
    "arxiv_abstract": "3D Gaussian Splatting has recently emerged as a powerful tool for fast and\naccurate novel-view synthesis from a set of posed input images. However, like\nmost novel-view synthesis approaches, it relies on accurate camera pose\ninformation, limiting its applicability in real-world scenarios where acquiring\naccurate camera poses can be challenging or even impossible. We propose an\nextension to the 3D Gaussian Splatting framework by optimizing the extrinsic\ncamera parameters with respect to photometric residuals. We derive the\nanalytical gradients and integrate their computation with the existing\nhigh-performance CUDA implementation. This enables downstream tasks such as\n6-DoF camera pose estimation as well as joint reconstruction and camera\nrefinement. In particular, we achieve rapid convergence and high accuracy for\npose estimation on real-world scenes. Our method enables fast reconstruction of\n3D scenes without requiring accurate pose information by jointly optimizing\ngeometry and camera poses, while achieving state-of-the-art results in\nnovel-view synthesis. Our approach is considerably faster to optimize than most\ncompeting methods, and several times faster in rendering. We show results on\nreal-world scenes and complex trajectories through simulated environments,\nachieving state-of-the-art results on LLFF while reducing runtime by two to\nfour times compared to the most efficient competing method. Source code will be\navailable at https://github.com/Schmiddo/noposegs ."
  },
  {
    "paper_no": "3177",
    "authors": "Matsumoto, Kohei; Hyodo, Yuki; Kurazume, Ryo",
    "title": "Crowd-Aware Robot Navigation with Switching Between Learning-Based and Rule-Based Methods Using Normalizing Flows",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3179",
    "authors": "Ali, Mahmoud; Pushp, Durgakant; Chen, Zheng; Liu, Lantao",
    "title": "Visual-Geometry GP-based Navigable Space for Autonomous Navigation",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.06545v1",
    "arxiv_abstract": "Autonomous navigation in unknown environments is challenging and demands the\nconsideration of both geometric and semantic information in order to parse the\nnavigability of the environment. In this work, we propose a novel space\nmodeling framework, Visual-Geometry Sparse Gaussian Process (VG-SGP), that\nsimultaneously considers semantics and geometry of the scene. Our proposed\napproach can overcome the limitation of visual planners that fail to recognize\ngeometry associated with the semantic and the geometric planners that\ncompletely overlook the semantic information which is very critical in\nreal-world navigation. The proposed method leverages dual Sparse Gaussian\nProcesses in an integrated manner; the first is trained to forecast\ngeometrically navigable spaces while the second predicts the semantically\nnavigable areas. This integrated model is able to pinpoint the overlapping\n(geometric and semantic) navigable space. The simulation and real-world\nexperiments demonstrate that the ability of the proposed VG-SGP model, coupled\nwith our innovative navigation strategy, outperforms models solely reliant on\nvisual or geometric navigation algorithms, highlighting a superior adaptive\nbehavior."
  },
  {
    "paper_no": "3183",
    "authors": "Kim, Donghyeon; Park, Seong-Su; Lee, Kwang-Hyun; Lee, Dongheui; Ryu, Jee-Hwan",
    "title": "Is a Simulation better than Teleoperation for Acquiring Human Manipulation Data?",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3185",
    "authors": "Manoharan, Amith; Sharma, Aditya; Belsare, Himani; Pal, Kaustab; Krishna, Madhava; Singh, Arun Kumar",
    "title": "Bi-level Trajectory Optimization on Uneven Terrains with Differentiable Wheel-Terrain Interaction Model",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.03307v3",
    "arxiv_abstract": "Navigation of wheeled vehicles on uneven terrain necessitates going beyond\nthe 2D approaches for trajectory planning. Specifically, it is essential to\nincorporate the full 6dof variation of vehicle pose and its associated\nstability cost in the planning process. To this end, most recent works aim to\nlearn a neural network model to predict the vehicle evolution. However, such\napproaches are data-intensive and fraught with generalization issues. In this\npaper, we present a purely model-based approach that just requires the digital\nelevation information of the terrain. Specifically, we express the\nwheel-terrain interaction and 6dof pose prediction as a non-linear least\nsquares (NLS) problem. As a result, trajectory planning can be viewed as a\nbi-level optimization. The inner optimization layer predicts the pose on the\nterrain along a given trajectory, while the outer layer deforms the trajectory\nitself to reduce the stability and kinematic costs of the pose. We improve the\nstate-of-the-art in the following respects. First, we show that our NLS based\npose prediction closely matches the output from a high-fidelity physics engine.\nThis result coupled with the fact that we can query gradients of the NLS\nsolver, makes our pose predictor, a differentiable wheel-terrain interaction\nmodel. We further leverage this differentiability to efficiently solve the\nproposed bi-level trajectory optimization problem. Finally, we perform\nextensive experiments, and comparison with a baseline to showcase the\neffectiveness of our approach in obtaining smooth, stable trajectories."
  },
  {
    "paper_no": "3186",
    "authors": "LI, YIMING; Li, Sihang; Liu, Xinhao; Gong, Moonjun; Li, Kenan; Nuo, Chen; Wang, Zijun; Li, Zhiheng; JIANG, TAO; Yu, Fisher; WANG, YUE; Zhao, Hang; Yu, Zhiding; Feng, Chen",
    "title": "SSCBench: Monocular 3D Semantic Scene Completion Benchmark for Autonomous Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3189",
    "authors": "Ili&#263;, Stefan; Hughes, Josie",
    "title": "Self-assessment of Robotic Laboratory and Equipment Readiness Using Large Language Models and Robotic Data Capture",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3192",
    "authors": "Moon, SeongJoo; Lee, Sebin; He, Dong; Yoon, Sung-eui",
    "title": "LiDAR-camera Online Calibration by Representing Local Feature and Global Spatial Context",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3193",
    "authors": "Kim, Wooseok; Fukiage, Taiki; Oishi, Takeshi",
    "title": "REF^2-NeRF: Reflection and Refraction aware Neural Radiance Field",
    "arxiv_pdf": "http://arxiv.org/pdf/2311.17116v4",
    "arxiv_abstract": "Recently, significant progress has been made in the study of methods for 3D\nreconstruction from multiple images using implicit neural representations,\nexemplified by the neural radiance field (NeRF) method. Such methods, which are\nbased on volume rendering, can model various light phenomena, and various\nextended methods have been proposed to accommodate different scenes and\nsituations. However, when handling scenes with multiple glass objects, e.g.,\nobjects in a glass showcase, modeling the target scene accurately has been\nchallenging due to the presence of multiple reflection and refraction effects.\nThus, this paper proposes a NeRF-based modeling method for scenes containing a\nglass case. In the proposed method, refraction and reflection are modeled using\nelements that are dependent and independent of the viewer's perspective. This\napproach allows us to estimate the surfaces where refraction occurs, i.e.,\nglass surfaces, and enables the separation and modeling of both direct and\nreflected light components. The proposed method requires predetermined camera\nposes, but accurately estimating these poses in scenes with glass objects is\ndifficult. Therefore, we used a robotic arm with an attached camera to acquire\nimages with known poses. Compared to existing methods, the proposed method\nenables more accurate modeling of both glass refraction and the overall scene."
  },
  {
    "paper_no": "3194",
    "authors": "Breitfuss, Matthias; Geimer, Marcus; Gruber, Christoph Johannes",
    "title": "Long-Term Map-Maintenance in Changing Environments using Ray-Bundle-Impact-Factor Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3198",
    "authors": "Xiang, Yuxuan; Zheng, Yanqiu; Asano, Fumihiko",
    "title": "Modeling and Analysis of Passive Quadruped Walker with Compliant Torso on Low-friction Environment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3199",
    "authors": "Gursoy, Ege; Kulic, Dana; Cherubini, Andrea",
    "title": "Occlusion Handling by Pushing for Enhanced Fruit Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3201",
    "authors": "Qu, Luca; Xiong, Yijin; wu, xin; Li, Hanyu; Guo, Shichun",
    "title": "V2I-Calib: A Novel Calibration Approach for Collaborative Vehicle and Infrastructure LiDAR Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3202",
    "authors": "Tan, Derek Ming Siang; Yixiao, Ma; Liang, Jingsong; Chng, Yi Cheng; Cao, Yuhong; Sartoretti, Guillaume Adrien",
    "title": "IR2: Implicit Rendezvous for Robotic Exploration Teams under Sparse Intermittent Connectivity",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3203",
    "authors": "Csomay-Shanklin, Noel; Compton, William; Jimenez Rodriguez, Ivan Dario; Ambrose, Eric; Yue, Yisong; Ames, Aaron",
    "title": "Robust Agility via Learned Zero Dynamics Policies",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.06125v1",
    "arxiv_abstract": "We study the design of robust and agile controllers for hybrid underactuated\nsystems. Our approach breaks down the task of creating a stabilizing controller\ninto: 1) learning a mapping that is invariant under optimal control, and 2)\ndriving the actuated coordinates to the output of that mapping. This approach,\ntermed Zero Dynamics Policies, exploits the structure of underactuation by\nrestricting the inputs of the target mapping to the subset of degrees of\nfreedom that cannot be directly actuated, thereby achieving significant\ndimension reduction. Furthermore, we retain the stability and constraint\nsatisfaction of optimal control while reducing the online computational\noverhead. We prove that controllers of this type stabilize hybrid underactuated\nsystems and experimentally validate our approach on the 3D hopping platform,\nARCHER. Over the course of 3000 hops the proposed framework demonstrates robust\nagility, maintaining stable hopping while rejecting disturbances on rough\nterrain."
  },
  {
    "paper_no": "3204",
    "authors": "Nguyen, Phat; Wang, Tsun-Hsuan; Hong, Zhang-Wei; Karaman, Sertac; Rus, Daniela",
    "title": "Text-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3206",
    "authors": "Zhang, Hongjie; Billings, Gideon; Shields, Jackson; Williams, Stefan Bernard",
    "title": "Underwater Hyperspectral Imaging for Measuring Seafloor Reflectance",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3208",
    "authors": "Zhao, Jingyun; Vogel-Heuser, Birgit; Ao, Jicong; Wu, Yansong; Zhang, Liding; Fandi, Bi; Hujo, Dominik; Bing, Zhenshan; Wu, Fan; Knoll, Alois; Haddadin, Sami; Vojanec, Bernd; Markert, Timo; Kraft, André",
    "title": "Ontology Based AI Planning and Scheduling for Robotic Assembly",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3210",
    "authors": "Le, Chuong; Walunj, Pratik; Nguyen, An; Zhou, Yong; Nguyen, Thanh Binh; Nguyen, Thang; Netchaev, Anton; La, Hung",
    "title": "CAIS: Culvert Autonomous Inspection Robotic System",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3211",
    "authors": "Guan, Tianrui; Xian, Ruiqi; Wang, Xijun; Wu, Xiyang; Elnoor, Mohamed; Song, Daeun; Manocha, Dinesh",
    "title": "AGL-NET: Aerial-Ground Cross-Modal Global Localization with Varying Scales",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3212",
    "authors": "Seong, Hyunki; Shim, David Hyunchul",
    "title": "Skill Q-Network: Learning Adaptive Skill Ensemble for Mapless Navigation in Unknown Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.16664v3",
    "arxiv_abstract": "This paper focuses on the acquisition of mapless navigation skills within\nunknown environments. We introduce the Skill Q-Network (SQN), a novel\nreinforcement learning method featuring an adaptive skill ensemble mechanism.\nUnlike existing methods, our model concurrently learns a high-level skill\ndecision process alongside multiple low-level navigation skills, all without\nthe need for prior knowledge. Leveraging a tailored reward function for mapless\nnavigation, the SQN is capable of learning adaptive maneuvers that incorporate\nboth exploration and goal-directed skills, enabling effective navigation in new\nenvironments. Our experiments demonstrate that our SQN can effectively navigate\ncomplex environments, exhibiting a 40\\% higher performance compared to baseline\nmodels. Without explicit guidance, SQN discovers how to combine low-level skill\npolicies, showcasing both goal-directed navigations to reach destinations and\nexploration maneuvers to escape from local minimum regions in challenging\nscenarios. Remarkably, our adaptive skill ensemble method enables zero-shot\ntransfer to out-of-distribution domains, characterized by unseen observations\nfrom non-convex obstacles or uneven, subterranean-like environments. The\nproject page is available at https://sites.google.com/view/skill-q-net."
  },
  {
    "paper_no": "3213",
    "authors": "Niessner, Matthias; Yilmaz, Kutay; Kornilova, Anastasiia; Artemov, Alexey",
    "title": "DeepMIF: Deep Monotonic Implicit Fields for Large-Scale LiDAR 3D Mapping",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3215",
    "authors": "He, Zhengmao; Lei, Kun; Ze, Yanjie; Sreenath, Koushil; Li, Zhongyu; Xu, Huazhe",
    "title": "Learning Visual Quadrupedal Loco-Manipulation from Demonstrations",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.20328v2",
    "arxiv_abstract": "Quadruped robots are progressively being integrated into human environments.\nDespite the growing locomotion capabilities of quadrupedal robots, their\ninteraction with objects in realistic scenes is still limited. While additional\nrobotic arms on quadrupedal robots enable manipulating objects, they are\nsometimes redundant given that a quadruped robot is essentially a mobile unit\nequipped with four limbs, each possessing 3 degrees of freedom (DoFs). Hence,\nwe aim to empower a quadruped robot to execute real-world manipulation tasks\nusing only its legs. We decompose the loco-manipulation process into a\nlow-level reinforcement learning (RL)-based controller and a high-level\nBehavior Cloning (BC)-based planner. By parameterizing the manipulation\ntrajectory, we synchronize the efforts of the upper and lower layers, thereby\nleveraging the advantages of both RL and BC. Our approach is validated through\nsimulations and real-world experiments, demonstrating the robot's ability to\nperform tasks that demand mobility and high precision, such as lifting a basket\nfrom the ground while moving, closing a dishwasher, pressing a button, and\npushing a door. Project website: https://zhengmaohe.github.io/leg-manip"
  },
  {
    "paper_no": "3217",
    "authors": "Jang, Jiyun; Chang, Mincheol; Kim, Jinkyu",
    "title": "Finetuning Pre-trained Model with Limited Data for LiDAR-based 3D Object Detection by Bridging Domain Gaps",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.01319v1",
    "arxiv_abstract": "LiDAR-based 3D object detectors have been largely utilized in various\napplications, including autonomous vehicles or mobile robots. However,\nLiDAR-based detectors often fail to adapt well to target domains with different\nsensor configurations (e.g., types of sensors, spatial resolution, or FOVs) and\nlocation shifts. Collecting and annotating datasets in a new setup is commonly\nrequired to reduce such gaps, but it is often expensive and time-consuming.\nRecent studies suggest that pre-trained backbones can be learned in a\nself-supervised manner with large-scale unlabeled LiDAR frames. However,\ndespite their expressive representations, they remain challenging to generalize\nwell without substantial amounts of data from the target domain. Thus, we\npropose a novel method, called Domain Adaptive Distill-Tuning (DADT), to adapt\na pre-trained model with limited target data (approximately 100 LiDAR frames),\nretaining its representation power and preventing it from overfitting.\nSpecifically, we use regularizers to align object-level and context-level\nrepresentations between the pre-trained and finetuned models in a\nteacher-student architecture. Our experiments with driving benchmarks, i.e.,\nWaymo Open dataset and KITTI, confirm that our method effectively finetunes a\npre-trained model, achieving significant gains in accuracy."
  },
  {
    "paper_no": "3225",
    "authors": "Dong, Juan; Lu, Maobin; Deng, Fang; Chen, Jie",
    "title": "STL-SLAM: A Structured-Constrained RGB-D SLAM Approach in Texture-Limited Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3226",
    "authors": "Fatoni, Muhammad Hilman; Herneth, Christopher; Li, Junnan; Budiman, Fajar; Ganguly, Amartya; Haddadin, Sami",
    "title": "Optimizing Interaction Space: Enlarging the Capture Volume for Multiple Portable Motion Capture Devices",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.17287v1",
    "arxiv_abstract": "Markerless motion capture devices such as the Leap Motion Controller (LMC)\nhave been extensively used for tracking hand, wrist, and forearm positions as\nan alternative to Marker-based Motion Capture (MMC). However, previous studies\nhave highlighted the subpar performance of LMC in reliably recording hand\nkinematics. In this study, we employ four LMC devices to optimize their\ncollective tracking volume, aiming to enhance the accuracy and precision of\nhand kinematics. Through Monte Carlo simulation, we determine an optimized\nlayout for the four LMC devices and subsequently conduct reliability and\nvalidity experiments encompassing 1560 trials across ten subjects. The combined\ntracking volume is validated against an MMC system, particularly for kinematic\nmovements involving wrist, index, and thumb flexion. Utilizing calculation\nresources in one computer, our result of the optimized configuration has a\nbetter visibility rate with a value of 0.05 $\\pm$ 0.55 compared to the initial\nconfiguration with -0.07 $\\pm$ 0.40. Multiple Leap Motion Controllers (LMCs)\nhave proven to increase the interaction space of capture volume but are still\nunable to give agreeable measurements from dynamic movement."
  },
  {
    "paper_no": "3228",
    "authors": "Sharma, Lakshay; How, Jonathan",
    "title": "Look before you leap: Socially acceptable high-speed ground robot navigation in crowded hallways",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13284v1",
    "arxiv_abstract": "To operate safely and efficiently, autonomous warehouse/delivery robots must\nbe able to accomplish tasks while navigating in dynamic environments and\nhandling the large uncertainties associated with the motions/behaviors of other\nrobots and/or humans. A key scenario in such environments is the hallway\nproblem, where robots must operate in the same narrow corridor as human traffic\ngoing in one or both directions. Traditionally, robot planners have tended to\nfocus on socially acceptable behavior in the hallway scenario at the expense of\nperformance. This paper proposes a planner that aims to address the consequent\n\"robot freezing problem\" in hallways by allowing for \"peek-and-pass\" maneuvers.\nWe then go on to demonstrate in simulation how this planner improves robot time\nto goal without violating social norms. Finally, we show initial hardware\ndemonstrations of this planner in the real world."
  },
  {
    "paper_no": "3229",
    "authors": "Paul, Pranjal; Garg, Anant; Choudhary, Tushar; Singh, Arun Kumar; Krishna, Madhava",
    "title": "LeGo-Drive: Language-enhanced Goal-oriented Closed-Loop End-to-End Autonomous Driving",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3231",
    "authors": "Zhu, Yinglei; He, SiXiao; Qi, Zhenghao; Yong, Zhuoyuan; Qin, Yihua; Chen, Jianyu",
    "title": "Whleaper: A 10-DOF High-Performance Bipedal Wheeled Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3233",
    "authors": "Shek, Chak Lam; Wu, Xiyang; Suttle, Wesley A.; Busart, Carl; zaroukian, erin; Manocha, Dinesh; Tokekar, Pratap; Bedi, Amrit Singh",
    "title": "LANCAR: Leveraging Language for Context-Aware Robot Locomotion in Unstructured Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3235",
    "authors": "Zheng, Haokun; Rajadnya, Sidhant; Zakhor, Avideh",
    "title": "Monocular Depth Estimation for Drone Obstacle Avoidance in Indoor Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3237",
    "authors": "Ozturk, Derin; Wang, Zilin; Helbling, E. Farrell",
    "title": "Absolute Pose Estimation for a Millimeter-Scale Vision System",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3241",
    "authors": "Pushp, Durgakant; Xu, Junhong; Chen, Zheng; Liu, Lantao",
    "title": "Context-Generative Default Policy for Bounded Rational Agent",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.11604v1",
    "arxiv_abstract": "Bounded rational agents often make decisions by evaluating a finite selection\nof choices, typically derived from a reference point termed the $`$default\npolicy,' based on previous experience. However, the inherent rigidity of the\nstatic default policy presents significant challenges for agents when operating\nin unknown environment, that are not included in agent's prior knowledge. In\nthis work, we introduce a context-generative default policy that leverages the\nregion observed by the robot to predict unobserved part of the environment,\nthereby enabling the robot to adaptively adjust its default policy based on\nboth the actual observed map and the $\\textit{imagined}$ unobserved map.\nFurthermore, the adaptive nature of the bounded rationality framework enables\nthe robot to manage unreliable or incorrect imaginations by selectively\nsampling a few trajectories in the vicinity of the default policy. Our approach\nutilizes a diffusion model for map prediction and a sampling-based planning\nwith B-spline trajectory optimization to generate the default policy. Extensive\nevaluations reveal that the context-generative policy outperforms the baseline\nmethods in identifying and avoiding unseen obstacles. Additionally, real-world\nexperiments conducted with the Crazyflie drones demonstrate the adaptability of\nour proposed method, even when acting in environments outside the domain of the\ntraining distribution."
  },
  {
    "paper_no": "3244",
    "authors": "Romero, Branden; Fang, Hao-Shu; Agrawal, Pulkit; Adelson, Edward",
    "title": "EyeSight Hand: Design of a Fully-Actuated Dexterous Robot Hand with Integrated Vision-Based Tactile Sensors and Compliant Actuation",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.06265v1",
    "arxiv_abstract": "In this work, we introduce the EyeSight Hand, a novel 7 degrees of freedom\n(DoF) humanoid hand featuring integrated vision-based tactile sensors tailored\nfor enhanced whole-hand manipulation. Additionally, we introduce an actuation\nscheme centered around quasi-direct drive actuation to achieve human-like\nstrength and speed while ensuring robustness for large-scale data collection.\nWe evaluate the EyeSight Hand on three challenging tasks: bottle opening,\nplasticine cutting, and plate pick and place, which require a blend of complex\nmanipulation, tool use, and precise force application. Imitation learning\nmodels trained on these tasks, with a novel vision dropout strategy, showcase\nthe benefits of tactile feedback in enhancing task success rates. Our results\nreveal that the integration of tactile sensing dramatically improves task\nperformance, underscoring the critical role of tactile information in dexterous\nmanipulation."
  },
  {
    "paper_no": "3249",
    "authors": "Idoko, Simon; sharma, basant; Singh, Arun Kumar",
    "title": "Learning Sampling Distribution and Safety Filter for Autonomous Driving with VQ-VAE and Differentiable Optimization",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.19461v2",
    "arxiv_abstract": "Sampling trajectories from a distribution followed by ranking them based on a\nspecified cost function is a common approach in autonomous driving. Typically,\nthe sampling distribution is hand-crafted (e.g a Gaussian, or a grid).\nRecently, there have been efforts towards learning the sampling distribution\nthrough generative models such as Conditional Variational Autoencoder (CVAE).\nHowever, these approaches fail to capture the multi-modality of the driving\nbehaviour due to the Gaussian latent prior of the CVAE. Thus, in this paper, we\nre-imagine the distribution learning through vector quantized variational\nautoencoder (VQ-VAE), whose discrete latent-space is well equipped to capture\nmulti-modal sampling distribution. The VQ-VAE is trained with demonstration\ndata of optimal trajectories. We further propose a differentiable optimization\nbased safety filter to minimally correct the VQVAE sampled trajectories to\nensure collision avoidance. We use backpropagation through the optimization\nlayers in a self-supervised learning set-up to learn good initialization and\noptimal parameters of the safety filter. We perform extensive comparisons with\nstate-of-the-art CVAE-based baseline in dense and aggressive traffic scenarios\nand show a reduction of up to 12 times in collision-rate while being\ncompetitive in driving speeds."
  },
  {
    "paper_no": "3252",
    "authors": "Wang, Chenxi; Fang, Hongjie; Fang, Hao-Shu; Lu, Cewu",
    "title": "RISE: 3D Perception Makes Real-World Robot Imitation Simple and Effective",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3256",
    "authors": "Zhao, Yangheng; Xiang, Zhen; Yin, Sheng; Pang, Xianghe; Wang, Yanfeng; Chen, Siheng",
    "title": "MADE: Malicious Agent Detection for Robust Multi-Agent Collaborative Perception",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3261",
    "authors": "AGRAWAL, RAJAT; Nambiar, Karthik; Chhaglani, Bhawana; PB, Sujit; Chitre, Mandar",
    "title": "OAS-GPUCB: On-the-way Adaptive Sampling Using GPUCB for Bathymetry Mapping",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3262",
    "authors": "Han, Xingyao; Tan, Yuhong; Chen, Siyuan; Liu, Zhe; Wang, Hesheng",
    "title": "Cooperative Path Planning for Four-Way Shuttle Vehicles in Storage and Retrieval Systems: A Hierarchically Dynamic Graph Based Approach",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3264",
    "authors": "Wu, Chenyang; Duan, Yifan; Zhang, Xinran; Sheng, Yu; Ji, Jianmin; Zhang, Yanyong",
    "title": "MM-Gaussian: 3D Gaussian-based Multi-modal Fusion for Localization and Reconstruction in Unbounded Scenes",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3265",
    "authors": "Singh, Mohit; Alexis, Kostas",
    "title": "Online Refractive Camera Model Calibration in Visual Inertial Odometry",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.12074v1",
    "arxiv_abstract": "This paper presents a general refractive camera model and online\nco-estimation of odometry and the refractive index of unknown media. This\nenables operation in diverse and varying refractive fluids, given only the\ncamera calibration in air. The refractive index is estimated online as a state\nvariable of a monocular visual-inertial odometry framework in an iterative\nformulation using the proposed camera model. The method was verified on data\ncollected using an underwater robot traversing inside a pool. The evaluations\ndemonstrate convergence to the ideal refractive index for water despite\nsignificant perturbations in the initialization. Simultaneously, the approach\nenables on-par visual-inertial odometry performance in refractive media without\nprior knowledge of the refractive index or requirement of medium-specific\ncamera calibration."
  },
  {
    "paper_no": "3268",
    "authors": "Haque, A K M Nadimul; Sukkar, Fouad; Tanz, Lukas; Carmichael, Marc; Vidal-Calleja, Teresa A.",
    "title": "Constrained Bootstrapped Learning for Few-Shot Robot Skill Adaptation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3270",
    "authors": "Davis, Benjamin R.; Bray, Edward; Best, Graeme",
    "title": "Multi-Goal Path Planning in Cluttered Environments with PRM-Guided Self-Organising Maps",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3271",
    "authors": "Kuang, Zijia; Yan, Zike; Zhao, Hao; Zhou, Guyue; Zha, Hongbin",
    "title": "Active Neural Mapping at Scale",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.20276v1",
    "arxiv_abstract": "We introduce a NeRF-based active mapping system that enables efficient and\nrobust exploration of large-scale indoor environments. The key to our approach\nis the extraction of a generalized Voronoi graph (GVG) from the continually\nupdated neural map, leading to the synergistic integration of scene geometry,\nappearance, topology, and uncertainty. Anchoring uncertain areas induced by the\nneural map to the vertices of GVG allows the exploration to undergo adaptive\ngranularity along a safe path that traverses unknown areas efficiently.\nHarnessing a modern hybrid NeRF representation, the proposed system achieves\ncompetitive results in terms of reconstruction accuracy, coverage completeness,\nand exploration efficiency even when scaling up to large indoor environments.\nExtensive results at different scales validate the efficacy of the proposed\nsystem."
  },
  {
    "paper_no": "3272",
    "authors": "Saravanos, Augustinos; Balci, Isin; Bakolas, Efstathios; Theodorou, Evangelos",
    "title": "Distributed Model Predictive Covariance Steering",
    "arxiv_pdf": "http://arxiv.org/pdf/2212.00398v1",
    "arxiv_abstract": "This paper proposes Distributed Model Predictive Covariance Steering (DMPCS),\na novel method for safe multi-robot control under uncertainty. The scope of our\napproach is to blend covariance steering theory, distributed optimization and\nmodel predictive control (MPC) into a single methodology that is safe, scalable\nand decentralized. Initially, we pose a problem formulation that uses the\nWasserstein distance to steer the state distributions of a multi-robot team to\ndesired targets, and probabilistic constraints to ensure safety. We then\ntransform this problem into a finite-dimensional optimization one by utilizing\na disturbance feedback policy parametrization for covariance steering and a\ntractable approximation of the safety constraints. To solve the latter problem,\nwe derive a decentralized consensus-based algorithm using the Alternating\nDirection Method of Multipliers (ADMM). This method is then extended to a\nreceding horizon form, which yields the proposed DMPCS algorithm. Simulation\nexperiments on large-scale problems with up to hundreds of robots successfully\ndemonstrate the effectiveness and scalability of DMPCS. Its superior capability\nin achieving safety is also highlighted through a comparison against a standard\nstochastic MPC approach. A video with all simulation experiments is available\nin https://youtu.be/Hks-0BRozxA."
  },
  {
    "paper_no": "3273",
    "authors": "HE, YUETONG; Asano, Fumihiko",
    "title": "Interpretation of Legged Locomotion in Underwater Robots based on Rimless Wheel Model",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3276",
    "authors": "Kim, Jiwon; Kim, Min Jun",
    "title": "Disturbance-Aware Model Predictive Control of Underactuated Robotics Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3278",
    "authors": "Su, Zhi; Huang, Xiaoyu; Ordonez Apraez, Daniel Felipe; Li, Yunfei; Li, Zhongyu; Liao, Qiayuan; Pontil, Massimiliano; Semini, Claudio; Turrisi, Giulio; Wu, Yi; Sreenath, Koushil",
    "title": "Leveraging Symmetry in RL-based Legged Locomotion Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.17320v2",
    "arxiv_abstract": "Model-free reinforcement learning is a promising approach for autonomously\nsolving challenging robotics control problems, but faces exploration difficulty\nwithout information of the robot's kinematics and dynamics morphology. The\nunder-exploration of multiple modalities with symmetric states leads to\nbehaviors that are often unnatural and sub-optimal. This issue becomes\nparticularly pronounced in the context of robotic systems with morphological\nsymmetries, such as legged robots for which the resulting asymmetric and\naperiodic behaviors compromise performance, robustness, and transferability to\nreal hardware. To mitigate this challenge, we can leverage symmetry to guide\nand improve the exploration in policy learning via equivariance/invariance\nconstraints. In this paper, we investigate the efficacy of two approaches to\nincorporate symmetry: modifying the network architectures to be strictly\nequivariant/invariant, and leveraging data augmentation to approximate\nequivariant/invariant actor-critics. We implement the methods on challenging\nloco-manipulation and bipedal locomotion tasks and compare with an\nunconstrained baseline. We find that the strictly equivariant policy\nconsistently outperforms other methods in sample efficiency and task\nperformance in simulation. In addition, symmetry-incorporated approaches\nexhibit better gait quality, higher robustness and can be deployed zero-shot in\nreal-world experiments."
  },
  {
    "paper_no": "3279",
    "authors": "Chen, Lingyun; Yu, Haoyu; Naceri, Abdeldjallil; Swikir, Abdalla; Haddadin, Sami",
    "title": "Trajectory Planning for Non-Prehensile Object Transportation",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.16420v1",
    "arxiv_abstract": "Non-prehensile object transportation offers a way to enhance robotic\nperformance in object manipulation tasks, especially with unstable objects.\nEffective trajectory planning requires simultaneous consideration of robot\nmotion constraints and object stability. Here, we introduce a physical model\nfor object stability and propose a novel trajectory planning approach for\nnon-prehensile transportation along arbitrary straight lines in 3D space.\nValidation with a 7-DoF Franka Panda robot confirms improved transportation\nspeed via tray rotation integration while ensuring object stability and robot\nmotion constraints."
  },
  {
    "paper_no": "3280",
    "authors": "Fan, Jiping; Wang, Zhenpo; Li, Guoqiang",
    "title": "Adversarial Attack on Trajectory Prediction for Autonomous Vehicles with Generative Adversarial Networks",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3282",
    "authors": "Huang, Yunshen; He, Wenbo; Kantaros, Yiannis; Zeng, Shen",
    "title": "Spatiotemporal Co-Design Enabling Prioritized Multi-Agent Motion Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3288",
    "authors": "Jia, Fuhua; Zheng, Zihao; LI, Cheng'ao; Li, Rui; XIAO, Junlin; YANG, Xiaoying; Rushworth, Adam; Ijaz, Salman",
    "title": "Design and Validation of Soft Flexible Aerial Robot for Safe Human-Robot Interaction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3291",
    "authors": "Liu, Jason Xinyu; Shah, Ankit; Konidaris, George; Tellex, Stefanie; Paulius, David",
    "title": "Grounding Spatio-temporal Navigation Commands Using Large Language and Vision Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3293",
    "authors": "Herrera Ruiz, Alberto; Qian, Xiaobei; Fu, Li-Chen",
    "title": "Empathetic Response Generation System: Enhancing Photo Reminiscence Chatbot with Emotional Context Analysis",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3295",
    "authors": "Venkatesh, L.N Vishnunandan; Min, Byung-Cheol",
    "title": "Learning from Demonstration Framework for Multi-Robot Systems Using Interaction Keypoints and Soft Actor-Critic Methods",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.02324v1",
    "arxiv_abstract": "Learning from Demonstration (LfD) is a promising approach to enable\nMulti-Robot Systems (MRS) to acquire complex skills and behaviors. However, the\nintricate interactions and coordination challenges in MRS pose significant\nhurdles for effective LfD. In this paper, we present a novel LfD framework\nspecifically designed for MRS, which leverages visual demonstrations to capture\nand learn from robot-robot and robot-object interactions. Our framework\nintroduces the concept of Interaction Keypoints (IKs) to transform the visual\ndemonstrations into a representation that facilitates the inference of various\nskills necessary for the task. The robots then execute the task using\nsensorimotor actions and reinforcement learning (RL) policies when required. A\nkey feature of our approach is the ability to handle unseen contact-based\nskills that emerge during the demonstration. In such cases, RL is employed to\nlearn the skill using a classifier-based reward function, eliminating the need\nfor manual reward engineering and ensuring adaptability to environmental\nchanges. We evaluate our framework across a range of mobile robot tasks,\ncovering both behavior-based and contact-based domains. The results demonstrate\nthe effectiveness of our approach in enabling robots to learn complex\nmulti-robot tasks and behaviors from visual demonstrations."
  },
  {
    "paper_no": "3298",
    "authors": "Xu, Dan; Guo, Yunxiao; Wang, Chang; Long, Han",
    "title": "A Novel Variable Step-size Path Planning Framework with Step Consistent Markov Decision Process For Large Scale UAV Swarm",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3300",
    "authors": "He, Jianhui; Feng, Yiyang; Yang, Guilin; Shen, Wenjun; Chen, Silu; Zheng, Tianjiang; li, Junjie",
    "title": "A Piecewise-weighted RANSAC Method Utilizing Abandoned Hypothesis Model Information with a New Application on Robot Self-calibration",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3302",
    "authors": "Huang, Siyuan; Ponomarenko, Iaroslav; Jiang, Zhengkai; Li, Xiaoqi; HU, XIAOBIN; Gao, Peng; Li, Hongsheng; Dong, Hao",
    "title": "ManipVQA: Injecting Robotic Affordance and Physically Grounded Information into Multi-Modal Large Language Models",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3312",
    "authors": "Onishi, Yuki; Kajita, Shuuji",
    "title": "Understanding How a 3-dimensional ZMP Exactly Decouples the Horizontal and Vertical Dynamics of the CoM-ZMP Model",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3315",
    "authors": "Li, Rui; Zhao, Wentao; Deng, Tianchen; Wang, Yanbo; Wang, Jingchuan",
    "title": "PS-Loc: Robust LiDAR Localization with Prior Structural Reference",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3317",
    "authors": "Hashem, Ryman; Howison, Toby; Stilli, Agostino; Stoyanov, Danail; XU, Peter; Iida, Fumiya",
    "title": "Harnessing Symmetry Breaking in Soft Robotics: A Novel Approach for Underactuated Fingers",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3319",
    "authors": "Yang, Zonglin; Yang, Yan; Shi, Yuheng; Yang, Hao; Zhang, Ruikun; Liu, Liu; WU, Xinxiao; Pan, Liyuan",
    "title": "Event-based Few-shot Fine-grained Human Action Recognition",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3320",
    "authors": "Li, Yiheng; Zhao, Zhihao; Xu, Chenfeng; TANG, CHEN; Li, Chenran; Ding, Mingyu; Tomizuka, Masayoshi; Zhan, Wei",
    "title": "Pre-training on Synthetic Driving Data for Trajectory Prediction",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3321",
    "authors": "Liu, ZhenFei; Song, Chengqun; Cheng, Jun; Luo, Jiefu; wang, xiaoyang",
    "title": "Self-Supervised Monocular Depth Estimation with Effective Feature Fusion and Self-Distillation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3331",
    "authors": "Chen, Yang; Miao, Zhonghua; Xiong, Ya",
    "title": "Design and control of a novel multi-degree-of-freedom hybrid robotic arm",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.19826v1",
    "arxiv_abstract": "Robotic arms are key components in fruit-harvesting robots. In agricultural\nsettings, conventional serial or parallel robotic arms often fall short in\nmeeting the demands for a large workspace, rapid movement, enhanced capability\nof obstacle avoidance and affordability. This study proposes a novel hybrid\nsix-degree-of-freedom (DoF) robotic arm that combines the advantages of\nparallel and serial mechanisms. Inspired by yoga, we designed two sliders\ncapable of moving independently along a single rail, acting as two feet. These\nsliders are interconnected with linkages and a meshed-gear set, allowing the\nparallel mechanism to lower itself and perform a split to pass under obstacles.\nThis unique feature allows the arm to avoid obstacles such as pipes, tables and\nbeams typically found in greenhouses. Integrated with serially mounted joints,\nthe patented hybrid arm is able to maintain the end's pose even when it moves\nwith a mobile platform, facilitating fruit picking with the optimal pose in\ndynamic conditions. Moreover, the hybrid arm's workspace is substantially\nlarger, being almost three times the volume of UR3 serial arms and fourteen\ntimes that of the ABB IRB parallel arms. Experiments show that the\nrepeatability errors are 0.017 mm, 0.03 mm and 0.109 mm for the two sliders and\nthe arm's end, respectively, providing sufficient precision for agricultural\nrobots."
  },
  {
    "paper_no": "3333",
    "authors": "Ren, Jiming; Miller, Haris; Feigh, Karen; Coogan, Samuel; Zhao, Ye",
    "title": "LTL-D*: Incrementally Optimal Replanning for Feasible and Infeasible Tasks in Linear Temporal Logic Specifications",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3338",
    "authors": "Zakharov, Dmitriy; Iaremenko, Andrei; Kurovskii, Denis; Kurovskii, Artem; Borisov, Oleg",
    "title": "Development of a Mobile Reconfigurable Mecanum Robot with a Wheel Roller Locking Device",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3340",
    "authors": "Zhang, Lingfeng; Zhang, Qiang; WANG, Hao; Xiao, Erjia; Jiang, Zixuan; CHEN, Honglei; Xu, Renjing",
    "title": "TriHelper: Zero-Shot Object Navigation with Dynamic Assistance",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3343",
    "authors": "Groß, Sonja; Ratzel, Michael; Welte, Edgar; Hidalgo Carvajal, Diego Xavier; Chen, Lingyun; Pozo Fortuni&#263;, Edmundo; Ganguly, Amartya; Swikir, Abdalla; Haddadin, Sami",
    "title": "OPENGRASP-LITE Version 1.0: A Tactile Artificial Hand with a Compliant Linkage Mechanism",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.02293v1",
    "arxiv_abstract": "Recent research has seen notable progress in the development of linkage-based\nartificial hands. While previous designs have focused on adaptive grasping,\ndexterity and biomimetic artificial skin, only a few systems have proposed a\nlightweight, accessible solution integrating tactile sensing with a compliant\nlinkage-based mechanism. This paper introduces OPENGRASP LITE, an open-source,\nhighly integrated, tactile, and lightweight artificial hand. Leveraging\ncompliant linkage systems and MEMS barometer-based tactile sensing, it offers\nversatile grasping capabilities with six degrees of actuation. By providing\ntactile sensors and enabling soft grasping, it serves as an accessible platform\nfor further research in tactile artificial hands."
  },
  {
    "paper_no": "3345",
    "authors": "Uchiyama, Katsu; Niiyama, Ryuma",
    "title": "Pneumatic bladder links connected by joints with a wide range of motion for articulated inflatable robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3346",
    "authors": "Li, Jian; Fei, Kexin; Sun, Yi; Wang, Jie; Liu, Bokai; Zhou, Zongtan; Zheng, Yongbin; Sun, Zhenping",
    "title": "Efficient-PIP: Large-Scale Pixel-level Aligned Image Pair Generation for Cross-time Infrared-RGB Translation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3348",
    "authors": "Serpiva, Valerii; Fedoseev, Aleksey; Karaf, Sausar; Abdulkarim, Ali Alridha; Dzmitry, Tsetserukou",
    "title": "OmniRace: 6D Hand Pose Estimation for Intuitive Guidance of Racing Drone",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3349",
    "authors": "zeya, yin; Lai, Tin; Khan, Subhan; Jacob, Jayadeep; li, yong hui; Ramos, Fabio",
    "title": "Stein Movement Primitives for Adaptive Multi-Modal Trajectory Generation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3352",
    "authors": "Xie, Angchen; Qian, Yeqiang; Yan, Weihao; Wang, Chunxiang; Yang, Ming",
    "title": "Non-repetitive: A promising LiDAR scanning pattern",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3353",
    "authors": "Burgul, Chinmay; Lee, Woosik; Geneva, Patrick; Huang, Guoquan",
    "title": "Online Determination of Legged Kinematics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3355",
    "authors": "Qiu, Jiyuan; Jiang, Chen; Zhang, Pengfei; Wang, Haowen",
    "title": "EVSMap: An Efficient Volumetric-Semantic Mapping Approach for Embedded Systems",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3358",
    "authors": "La Rotta, Pedro Leandro; Xu, Jingxi; Chen, Ava; Winterbottom, Lauren; Chen, Wenxi; Nilsen, Dawn; Stein, Joel; Ciocarlie, Matei",
    "title": "Meta-Learning for Fast Adaptation in Intent Inferral on a Robotic Hand Orthosis for Stroke",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.13147v1",
    "arxiv_abstract": "We propose MetaEMG, a meta-learning approach for fast adaptation in intent\ninferral on a robotic hand orthosis for stroke. One key challenge in machine\nlearning for assistive and rehabilitative robotics with disabled-bodied\nsubjects is the difficulty of collecting labeled training data. Muscle tone and\nspasticity often vary significantly among stroke subjects, and hand function\ncan even change across different use sessions of the device for the same\nsubject. We investigate the use of meta-learning to mitigate the burden of data\ncollection needed to adapt high-capacity neural networks to a new session or\nsubject. Our experiments on real clinical data collected from five stroke\nsubjects show that MetaEMG can improve the intent inferral accuracy with a\nsmall session- or subject-specific dataset and very few fine-tuning epochs. To\nthe best of our knowledge, we are the first to formulate intent inferral on\nstroke subjects as a meta-learning problem and demonstrate fast adaptation to a\nnew session or subject for controlling a robotic hand orthosis with EMG\nsignals."
  },
  {
    "paper_no": "3359",
    "authors": "Ghansah, Adrian; Kim, Jeeseop; Li, Kejun; Ames, Aaron",
    "title": "Dynamic Walking on Highly Underactuated Point Foot Humanoids: Closing the Loop between HZD and HLIP",
    "arxiv_pdf": "http://arxiv.org/pdf/2406.13115v1",
    "arxiv_abstract": "Realizing bipedal locomotion on humanoid robots with point feet is especially\nchallenging due to their highly underactuated nature, high degrees of freedom,\nand hybrid dynamics resulting from impacts. With the goal of addressing this\nchallenging problem, this paper develops a control framework for realizing\ndynamic locomotion and implements it on a novel point foot humanoid: ADAM. To\nthis end, we close the loop between Hybrid Zero Dynamics (HZD) and Hybrid\nlinear inverted pendulum (HLIP) based step length regulation. To leverage the\nfull-order hybrid dynamics of the robot, walking gaits are first generated\noffline by utilizing HZD. These trajectories are stabilized online through the\nuse of a HLIP based regulator. Finally, the planned trajectories are mapped\ninto the full-order system using a task space controller incorporating inverse\nkinematics. The proposed method is verified through numerical simulations and\nhardware experiments on the humanoid robot ADAM marking the first humanoid\npoint foot walking. Moreover, we experimentally demonstrate the robustness of\nthe realized walking via the ability to track a desired reference speed,\nrobustness to pushes, and locomotion on uneven terrain."
  },
  {
    "paper_no": "3362",
    "authors": "Pyatov, Vladislav; Koshelev, Iaroslav; Lefkimmiatis, Stamatios",
    "title": "Robust Two-View Geometry Estimation with Implicit Differentiation",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.17983v1",
    "arxiv_abstract": "We present a novel two-view geometry estimation framework which is based on a\ndifferentiable robust loss function fitting. We propose to treat the robust\nfundamental matrix estimation as an implicit layer, which allows us to avoid\nbackpropagation through time and significantly improves the numerical\nstability. To take full advantage of the information from the feature matching\nstage we incorporate learnable weights that depend on the matching confidences.\nIn this way our solution brings together feature extraction, matching and\ntwo-view geometry estimation in a unified end-to-end trainable pipeline. We\nevaluate our approach on the camera pose estimation task in both outdoor and\nindoor scenarios. The experiments on several datasets show that the proposed\nmethod outperforms both classic and learning-based state-of-the-art methods by\na large margin. The project webpage is available at:\nhttps://github.com/VladPyatov/ihls"
  },
  {
    "paper_no": "3368",
    "authors": "Limbu, Manshi; Zhou, Yanlin; Stein, Gregory; Wang, Xuan; Shishika, Daigo; Xiao, Xuesu",
    "title": "Team Coordination on Graphs: Problem, Analysis, and Algorithms",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3374",
    "authors": "Ding, Yufei; Geng, Haoran; Xu, Chaoyi; Fang, Xiaomeng; Zhang, Jiazhao; Wei, Songlin; Zhang, Zhizheng; Wang, He",
    "title": "Open6DOR: Benchmarking Open-instruction 6-DoF Object Rearrangement and A VLM-based Baseline",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3375",
    "authors": "Li, Sihui; Schack, Matthew; Upadhyay, Aakriti; Dantam, Neil",
    "title": "A Sampling Ensemble for Asymptotically Complete Motion Planning with Volume-Reducing Workspace Constraints",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3376",
    "authors": "RafieeJavazm, Mohammad; Kiehler, Sonika; Kara, Ozdemir Can; Alambeigi, Farshid",
    "title": "Towards Design and Development of a Soft Pressure Sensing Sleeve for Performing Safe Colonoscopic Procedures",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3377",
    "authors": "Kannapiran, Shenbagaraj; Chandran, Sreenithy; Jayasuriya, Suren; Berman, Spring",
    "title": "PathFinder: Attention-Driven Dynamic Non-Line-of-Sight Tracking with a Mobile Robot",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3380",
    "authors": "Jafaripour, Masoud; Mushahwar, Vivian K.; Tavakoli, Mahdi",
    "title": "Optimal Integration of Hybrid FES-Exoskeleton for Precise Knee Trajectory Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3383",
    "authors": "Kumar, Rahul; Chipade, Vishnu S.; Yong, Sze Zheng",
    "title": "Stability of a Team of Tethered Ground Robots on Extreme Terrains",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3384",
    "authors": "Lin, Haotian; Wang, Yixiao; huo, mingxiao; Peng, Chensheng; Liu, Zhiyuan",
    "title": "Joint Pedestrian Trajectory Prediction through Posterior Sampling",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.00237v2",
    "arxiv_abstract": "Joint pedestrian trajectory prediction has long grappled with the inherent\nunpredictability of human behaviors. Recent investigations employing variants\nof conditional diffusion models in trajectory prediction have exhibited notable\nsuccess. Nevertheless, the heavy dependence on accurate historical data results\nin their vulnerability to noise disturbances and data incompleteness. To\nimprove the robustness and reliability, we introduce the Guided Full Trajectory\nDiffuser (GFTD), a novel diffusion model framework that captures the joint full\n(historical and future) trajectory distribution. By learning from the full\ntrajectory, GFTD can recover the noisy and missing data, hence improving the\nrobustness. In addition, GFTD can adapt to data imperfections without\nadditional training requirements, leveraging posterior sampling for reliable\nprediction and controllable generation. Our approach not only simplifies the\nprediction process but also enhances generalizability in scenarios with noise\nand incomplete inputs. Through rigorous experimental evaluation, GFTD exhibits\nsuperior performance in both trajectory prediction and controllable generation."
  },
  {
    "paper_no": "3387",
    "authors": "Yang, Jiaqi; Chen, Yucong; Meng, Xiangting; Yan, Chenxin; Li, Min; Cheng, Ran; Lige, Liu; Sun, Tao; Kneip, Laurent",
    "title": "MV-ROPE: Multi-view Constraints for Robust Category-level Object Pose and Size Estimation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3390",
    "authors": "Chang, Haonan; Boyalakuntla, Kowndinya; Liu, Yuhan; Zhang, Xinyu; Schramm, Liam; Boularias, Abdeslam",
    "title": "DAP: Diffusion-based Affordance Prediction for Multi-modality Storage",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3391",
    "authors": "Laouar, Zakariya; Ho, Qi Heng; Mazouz, Rayan; Becker, Tyler; Sunberg, Zachary",
    "title": "Feasibility-Guided Safety-Aware Model Predictive Control for Jump Markov Linear Systems",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.14116v2",
    "arxiv_abstract": "In this paper, we present a controller framework that synthesizes control\npolicies for Jump Markov Linear Systems subject to stochastic mode switches and\nimperfect mode estimation. Our approach builds on safe and robust methods for\nModel Predictive Control (MPC), but in contrast to existing approaches that\neither optimize without regard to feasibility or utilize soft constraints that\nincrease computational requirements, we employ a safe and robust control\napproach informed by the feasibility of the optimization problem. We formulate\nand encode finite horizon safety for multiple model systems in our MPC design\nusing Control Barrier Functions (CBFs). When subject to inaccurate hybrid state\nestimation, our feasibility-guided MPC generates a control policy that is\nmaximally robust to uncertainty in the system's modes. We evaluate our approach\non an orbital rendezvous problem and a six degree-of-freedom hexacopter under\nseveral scenarios and benchmarks to demonstrate the utility of the framework.\nResults indicate that the proposed technique of maximizing the robustness\nhorizon, and the use of CBFs for safety awareness, improve the overall safety\nand performance of MPC for Jump Markov Linear Systems."
  },
  {
    "paper_no": "3392",
    "authors": "Yoon, Hye Jung; Kim, Juno; Park, Yesol; Jun Ki, Lee; Zhang, Byoung-Tak",
    "title": "Seg2Grasp: A Robust Modular Suction Grasping in Bin Picking",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3395",
    "authors": "Li, Zhiwen; Li, Weibing; Chen, Yanjie; Pan, Yongping",
    "title": "A Unified Framework of Hybrid Vision-Force Control With Nullspace Compliance for Redundant Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3397",
    "authors": "Zarrar, Mohammed Misbah; Weng, QiTao; Yerjan, Bakhbyergyen; Soyyigit, Ahmet; Yun, Heechul",
    "title": "TinyLidarNet: 2D Lidar-based End-to-End Deep Learning Model for F1TENTH Autonomous Racing",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3399",
    "authors": "Abhyankar, Devesh; Wang, Yushi; Iwamoto, Yuhiro; Sugano, Shigeki; Kamezaki, Mitsuhiro",
    "title": "Development of Adjustable Compliance and Sensitivity Permanent Magnetic Elastomer-based Tactile Sensor",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3401",
    "authors": "Wu, Xin'ao; Yang, Chenxi; Guo, Yiyang; Zhuang, Hanyang; Wang, Chunxiang; Yang, Ming",
    "title": "Active Vehicle Re-localization Based on Non-repetitive Lidar with Gimbal Motion Strategy",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3402",
    "authors": "Zhao, Jieting; Ye, Hanjing; Zhan, Yu; Zhang, Hong",
    "title": "Human Orientation Estimation under Partial Observation",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.14139v2",
    "arxiv_abstract": "Reliable Human Orientation Estimation (HOE) from a monocular image is\ncritical for autonomous agents to understand human intention. Significant\nprogress has been made in HOE under full observation. However, the existing\nmethods easily make a wrong prediction under partial observation and give it an\nunexpectedly high confidence. To solve the above problems, this study first\ndevelops a method called Part-HOE that estimates orientation from the visible\njoints of a target person so that it is able to handle partial observation.\nSubsequently, we introduce a confidence-aware orientation estimation method,\nenabling more accurate orientation estimation and reasonable confidence\nestimation under partial observation. The effectiveness of our method is\nvalidated on both public and custom-built datasets, and it shows great accuracy\nand reliability improvement in partial observation scenarios. In particular, we\nshow in real experiments that our method can benefit the robustness and\nconsistency of the Robot Person Following (RPF) task."
  },
  {
    "paper_no": "3405",
    "authors": "Zhang, Hefei; Zhang, Xiaohu; Cheng, Jinyu; Hu, Jiangtao; Ji, Chao; Wang, Yu; Jiang, Yutong; Han, Zhen; Gao, Wei; Zhang, Shiwu",
    "title": "Torque Ripple Reduction in Quasi-Direct Drive Motors Through Angle-Based Repetitive Learning Observer and Model Predictive Torque Controller",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3407",
    "authors": "Deshpande, Abhay; Ke, Liyiming; Pfeifer, Quinn; Gupta, Abhishek; Srinivasa, Siddhartha",
    "title": "Data Efficient Behavior Cloning for Fine Manipulation via Continuity-based Corrective Labels",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.19307v3",
    "arxiv_abstract": "We consider imitation learning with access only to expert demonstrations,\nwhose real-world application is often limited by covariate shift due to\ncompounding errors during execution. We investigate the effectiveness of the\nContinuity-based Corrective Labels for Imitation Learning (CCIL) framework in\nmitigating this issue for real-world fine manipulation tasks. CCIL generates\ncorrective labels by learning a locally continuous dynamics model from\ndemonstrations to guide the agent back toward expert states. Through extensive\nexperiments on peg insertion and fine grasping, we provide the first empirical\nvalidation that CCIL can significantly improve imitation learning performance\ndespite discontinuities present in contact-rich manipulation. We find that: (1)\nreal-world manipulation exhibits sufficient local smoothness to apply CCIL, (2)\ngenerated corrective labels are most beneficial in low-data regimes, and (3)\nlabel filtering based on estimated dynamics model error enables performance\ngains. To effectively apply CCIL to robotic domains, we offer a practical\ninstantiation of the framework and insights into design choices and\nhyperparameter selection. Our work demonstrates CCIL's practicality for\nalleviating compounding errors in imitation learning on physical robots."
  },
  {
    "paper_no": "3409",
    "authors": "de Castro, Luke; Ryou, Gilhyun; OHN, HYUNGSEUK; Karaman, Sertac",
    "title": "Multi-Fidelity Reinforcement Learning for Minimum Energy Trajectory Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3414",
    "authors": "Montesino, Ignacio; Victores, Juan G.; Balaguer, Carlos; Jardon, Alberto",
    "title": "Generalized Path Impedance Control",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3415",
    "authors": "Shukla, Shubham; Srivastava, Raunak; Lima, Rolif; Bera, Titas",
    "title": "Satellite-Model-Free Deep Learning based Pose Estimation of Non-cooperative Satellite and Tracking using Navigation Filter",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3419",
    "authors": "Huang, Xiaoyu; Liao, Qiayuan; Ni, Yiming; Li, Zhongyu; Smith, Laura; Levine, Sergey; Peng, Xue Bin; Sreenath, Koushil",
    "title": "HILMA-Res: A General Hierarchical Framework via Residual RL for Combining Quadrupedal Locomotion and Manipulation",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3421",
    "authors": "Suresh, Krishna; Rauniyar, Aditya; Corah, Micah; Scherer, Sebastian",
    "title": "Greedy Perspectives: Multi-Drone View Planning for Collaborative Perception in Cluttered Environments",
    "arxiv_pdf": "http://arxiv.org/pdf/2310.10863v3",
    "arxiv_abstract": "Deployment of teams of aerial robots could enable large-scale filming of\ndynamic groups of people (actors) in complex environments for applications in\nareas such as team sports and cinematography. Toward this end, methods for\nsubmodular maximization via sequential greedy planning can enable scalable\noptimization of camera views across teams of robots but face challenges with\nefficient coordination in cluttered environments. Obstacles can produce\nocclusions and increase chances of inter-robot collision which can violate\nrequirements for near-optimality guarantees. To coordinate teams of aerial\nrobots in filming groups of people in dense environments, a more general\nview-planning approach is required. We explore how collision and occlusion\nimpact performance in filming applications through the development of a\nmulti-robot multi-actor view planner with an occlusion-aware objective for\nfilming groups of people and compare with a formation planner and a greedy\nplanner that ignores inter-robot collisions. We evaluate our approach based on\nfive test environments and complex multi-actor behaviors. Compared with a\nformation planner, our sequential planner generates 14% greater view reward for\nfilming the actors in three scenarios and comparable performance to formation\nplanning on two others. We also observe near identical view rewards for\nsequential planning both with and without inter-robot collision constraints\nwhich indicates that robots are able to avoid collisions without impairing\nperformance in the perception task. Overall, we demonstrate effective\ncoordination of teams of aerial robots in environments cluttered with obstacles\nthat may cause collisions or occlusions and for filming groups that may split,\nmerge, or spread apart."
  },
  {
    "paper_no": "3429",
    "authors": "Chen, Zhen; zhang, zongmin; GUO, WENWU; LUO, Xingjian; Bai, Long; Wu, Jinlin; Ren, Hongliang; Liu, Hongbin",
    "title": "ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3430",
    "authors": "Han, Chenrui; Yu, Xuan; Xie, Yuxuan; Liu, Yili; Mao, Sitong; ZHOU, Shunbo; Xiong, Rong; Wang, Yue",
    "title": "Scale Disparity of Instances in Interactive Point Cloud Segmentation",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.14009v1",
    "arxiv_abstract": "Interactive point cloud segmentation has become a pivotal task for\nunderstanding 3D scenes, enabling users to guide segmentation models with\nsimple interactions such as clicks, therefore significantly reducing the effort\nrequired to tailor models to diverse scenarios and new categories. However, in\nthe realm of interactive segmentation, the meaning of instance diverges from\nthat in instance segmentation, because users might desire to segment instances\nof both thing and stuff categories that vary greatly in scale. Existing methods\nhave focused on thing categories, neglecting the segmentation of stuff\ncategories and the difficulties arising from scale disparity. To bridge this\ngap, we propose ClickFormer, an innovative interactive point cloud segmentation\nmodel that accurately segments instances of both thing and stuff categories. We\npropose a query augmentation module to augment click queries by a global query\nsampling strategy, thus maintaining consistent performance across different\ninstance scales. Additionally, we employ global attention in the query-voxel\ntransformer to mitigate the risk of generating false positives, along with\nseveral other network structure improvements to further enhance the model's\nsegmentation performance. Experiments demonstrate that ClickFormer outperforms\nexisting interactive point cloud segmentation methods across both indoor and\noutdoor datasets, providing more accurate segmentation results with fewer user\nclicks in an open-world setting."
  },
  {
    "paper_no": "3431",
    "authors": "Zhao, Chunyang; Zhou, Zeyu; Liu, Haoran; Kircali, Dogan; chi, guoyi; Wang, Yuanzhe; Wang, Danwei",
    "title": "Towards Kbps-level Vehicle Teleoperation via Persistent-Transient Environment Modelling",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3434",
    "authors": "Kim, Juno; Park, Yesol; Yoon, Hye Jung; Zhang, Byoung-Tak",
    "title": "OV-MAP : Open-Vocabulary Zero-Shot 3D Instance Segmentation Map for Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3439",
    "authors": "Islam, Chashi Mahiul; Salman, Shaeke; Shams, Montasir; Liu, Xiuwen; Kumar, Piyush",
    "title": "Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems",
    "arxiv_pdf": "http://arxiv.org/pdf/2407.07392v1",
    "arxiv_abstract": "Building on the unprecedented capabilities of large language models for\ncommand understanding and zero-shot recognition of multi-modal vision-language\ntransformers, visual language navigation (VLN) has emerged as an effective way\nto address multiple fundamental challenges toward a natural language interface\nto robot navigation. However, such vision-language models are inherently\nvulnerable due to the lack of semantic meaning of the underlying embedding\nspace. Using a recently developed gradient based optimization procedure, we\ndemonstrate that images can be modified imperceptibly to match the\nrepresentation of totally different images and unrelated texts for a\nvision-language model. Building on this, we develop algorithms that can\nadversarially modify a minimal number of images so that the robot will follow a\nroute of choice for commands that require a number of landmarks. We demonstrate\nthat experimentally using a recently proposed VLN system; for a given\nnavigation command, a robot can be made to follow drastically different routes.\nWe also develop an efficient algorithm to detect such malicious modifications\nreliably based on the fact that the adversarially modified images have much\nhigher sensitivity to added Gaussian noise than the original images."
  },
  {
    "paper_no": "3440",
    "authors": "Guan, Zhongtao; Chen, YiMing; Zhu, Junlei; Hu, Yu; Bai, Weibang; Chen, Jiahao",
    "title": "Cury: A Backdrivable Leg Design using Linear Actuators",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3443",
    "authors": "Potu Surya Prakash, Nikhil; Seo, Joohwan; Sreenath, Koushil; Choi, Jongeun; HOROWITZ, Roberto",
    "title": "Deep Geometric Potential Functions for Tracking on Manifolds",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3444",
    "authors": "Schneider, Samuel; Wu, Yansong; Wu, Fan; Johannsmeier, Lars; Haddadin, Sami",
    "title": "Towards Foundation Models for tactile Robots: Designing a Scalable Platform for Robot Learning in the physical world",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3445",
    "authors": "Hanson, Nathaniel; Lvov, Gary; Rautela, Vedant; Hibbard, Sam; Holand, Ethan; DiMarzio, Charles A; Padir, Taskin",
    "title": "PROSPECT: Precision Robot Spectroscopy Exploration and Characterization Tool",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3446",
    "authors": "Shentu, Yide; Wu, Shiyao; Rajeswaran, Aravind; Abbeel, Pieter",
    "title": "From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2405.04798v2",
    "arxiv_abstract": "Hierarchical control for robotics has long been plagued by the need to have a\nwell defined interface layer to communicate between high-level task planners\nand low-level policies. With the advent of LLMs, language has been emerging as\na prospective interface layer. However, this has several limitations. Not all\ntasks can be decomposed into steps that are easily expressible in natural\nlanguage (e.g. performing a dance routine). Further, it makes end-to-end\nfinetuning on embodied data challenging due to domain shift and catastrophic\nforgetting. We introduce our method -- Learnable Latent Codes as Bridges (LCB)\n-- as an alternate architecture to overcome these limitations. \\method~uses a\nlearnable latent code to act as a bridge between LLMs and low-level policies.\nThis enables LLMs to flexibly communicate goals in the task plan without being\nentirely constrained by language limitations. Additionally, it enables\nend-to-end finetuning without destroying the embedding space of word tokens\nlearned during pre-training. Through experiments on Language Table and Calvin,\ntwo common language based benchmarks for embodied agents, we find that\n\\method~outperforms baselines (including those w/ GPT-4V) that leverage pure\nlanguage as the interface layer on tasks that require reasoning and multi-step\nbehaviors."
  },
  {
    "paper_no": "3447",
    "authors": "von Wrangel, David; Tedrake, Russ",
    "title": "Using Graphs of Convex Sets to Guide Nonconvex Trajectory Optimization",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3448",
    "authors": "Wang, Weiying; Cai, Victor; Gil, Stephanie",
    "title": "MULAN-WC: Multi-Robot Localization Uncertainty-aware Active NeRF with Wireless Coordination",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3449",
    "authors": "Kolb, Jack; Feigh, Karen",
    "title": "Inferring Belief States in Partially-Observable Human-Robot Teams",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.11955v1",
    "arxiv_abstract": "We investigate the real-time estimation of human situation awareness using\nobservations from a robot teammate with limited visibility. In human factors\nand human-autonomy teaming, it is recognized that individuals navigate their\nenvironments using an internal mental simulation, or mental model. The mental\nmodel informs cognitive processes including situation awareness, contextual\nreasoning, and task planning. In teaming domains, the mental model includes a\nteam model of each teammate's beliefs and capabilities, enabling fluent\nteamwork without the need for explicit communication. However, little work has\napplied team models to human-robot teaming. We compare the performance of two\ncurrent methods at estimating user situation awareness over varying visibility\nconditions. Our results indicate that the methods are largely resilient to\nlow-visibility conditions in our domain, however opportunities exist to improve\ntheir overall performance."
  },
  {
    "paper_no": "3450",
    "authors": "Yang, Hao; Zhou, Haoying; Fischer, Gregory Scott; Wu, Jie Ying",
    "title": "A Hybrid Model and Learning-Based Force Estimation Framework for the Surgical Robots",
    "arxiv_pdf": "http://arxiv.org/pdf/2409.19970v1",
    "arxiv_abstract": "Haptic feedback to the surgeon during robotic surgery would enable safer and\nmore immersive surgeries but estimating tissue interaction forces at the tips\nof robotically controlled surgical instruments has proven challenging. Few\nexisting surgical robots can measure interaction forces directly and the\nadditional sensor may limit the life of instruments. We present a hybrid model\nand learning-based framework for force estimation for the Patient Side\nManipulators (PSM) of a da Vinci Research Kit (dVRK). The model-based component\nidentifies the dynamic parameters of the robot and estimates free-space joint\ntorque, while the learning-based component compensates for environmental\nfactors, such as the additional torque caused by trocar interaction between the\nPSM instrument and the patient's body wall. We evaluate our method in an\nabdominal phantom and achieve an error in force estimation of under 10%\nnormalized root-mean-squared error. We show that by using a model-based method\nto perform dynamics identification, we reduce reliance on the training data\ncovering the entire workspace. Although originally developed for the dVRK, the\nproposed method is a generalizable framework for other compliant surgical\nrobots. The code is available at\nhttps://github.com/vu-maple-lab/dvrk_force_estimation."
  },
  {
    "paper_no": "3452",
    "authors": "Sato, Hiroya; Makabe, Tasuku; Yanokura, Iori; Yamaguchi, Naoya; Okada, Kei; Inaba, Masayuki",
    "title": "A Robot Kinematics Model Estimation Using Inertial Sensors for On-Site Building Robotics",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.12277v1",
    "arxiv_abstract": "In order to make robots more useful in a variety of environments, they need\nto be highly portable so that they can be transported to wherever they are\nneeded, and highly storable so that they can be stored when not in use. We\npropose \"on-site robotics\", which uses parts procured at the location where the\nrobot will be active, and propose a new solution to the problem of portability\nand storability. In this paper, as a proof of concept for on-site robotics, we\ndescribe a method for estimating the kinematic model of a robot by using\ninertial measurement units (IMU) sensor module on rigid links, estimating the\nrelative orientation between modules from angular velocity, and estimating the\nrelative position from the measurement of centrifugal force. At the end of this\npaper, as an evaluation for this method, we present an experiment in which a\nrobot made up of wooden sticks reaches a target position. In this experiment,\neven if the combination of the links is changed, the robot is able to reach the\ntarget position again immediately after estimation, showing that it can operate\neven after being reassembled. Our implementation is available on\nhttps://github.com/hiroya1224/urdf_estimation_with_imus ."
  },
  {
    "paper_no": "3454",
    "authors": "Xing, Yifan; Samano, Noe; FAN, WEN; Calway, Andrew",
    "title": "Object-based SLAM using superquadrics",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3455",
    "authors": "Ruiz Vincueria, Fernando; Arrue, Begoña C.; Ollero, Anibal",
    "title": "Thermally-Resilient Soft Gripper for On-Orbit Operations",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3456",
    "authors": "Datar, Aniket; Pan, Chenhui; Nazeri, Mohammad; Pokhrel, Anuj; Xiao, Xuesu",
    "title": "Terrain-Attentive Learning for Efficient 6-DoF Kinodynamic Modeling on Vertically Challenging Terrain",
    "arxiv_pdf": "http://arxiv.org/pdf/2403.16419v1",
    "arxiv_abstract": "Wheeled robots have recently demonstrated superior mechanical capability to\ntraverse vertically challenging terrain (e.g., extremely rugged boulders\ncomparable in size to the vehicles themselves). Negotiating such terrain\nintroduces significant variations of vehicle pose in all six Degrees-of-Freedom\n(DoFs), leading to imbalanced contact forces, varying momentum, and chassis\ndeformation due to non-rigid tires and suspensions. To autonomously navigate on\nvertically challenging terrain, all these factors need to be efficiently\nreasoned within limited onboard computation and strict real-time constraints.\nIn this paper, we propose a 6-DoF kinodynamics learning approach that is\nattentive only to the specific underlying terrain critical to the current\nvehicle-terrain interaction, so that it can be efficiently queried in real-time\nmotion planners onboard small robots. Physical experiment results show our\nTerrain-Attentive Learning demonstrates on average 51.1% reduction in model\nprediction error among all 6 DoFs compared to a state-of-the-art model for\nvertically challenging terrain."
  },
  {
    "paper_no": "3464",
    "authors": "Hosseinzadeh, Mehdi; Reid, Ian",
    "title": "BEVPose: Unveiling Scene Semantics through Self-Supervised Pose-Guided Multi-Modal BEV Alignment",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3465",
    "authors": "Fan, Qigao; Zhang, Yunrui; Liu, Yueyue",
    "title": "Design and Control of a Three-Dimensional Electromagnetic Drive System for Micro-Robots",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3467",
    "authors": "Raj, Divyanshu; Patil, Omkar; Gu, Weiwei; Baral, Chitta; Gopalan, Nakul",
    "title": "Learning Temporally Composable Task Segmentations with Language",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3469",
    "authors": "Chen, Zeyu; Tang, Jingyi; Wang, Gu; Li, Shengquan; Li, Xinghui; Ji, Xiangyang; Li, Xiu",
    "title": "UW-SDF: Exploiting Hybrid Geometric Priors for Neural SDF Reconstruction from Underwater Multi-view Monocular Images",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3470",
    "authors": "Chen, Chuheng; Chen, Xinxing; Yin, Shucong; Wang, Yuxuan; Huang, Binxin; Leng, Yuquan; Fu, Chenglong",
    "title": "Enhancing Prosthetic Safety and Environmental Adaptability: A Visual-Inertial Prosthesis Motion Estimation Approach on Uneven Terrains",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.18612v1",
    "arxiv_abstract": "Environment awareness is crucial for enhancing walking safety and stability\nof amputee wearing powered prosthesis when crossing uneven terrains such as\nstairs and obstacles. However, existing environmental perception systems for\nprosthesis only provide terrain types and corresponding parameters, which fails\nto prevent potential collisions when crossing uneven terrains and may lead to\nfalls and other severe consequences. In this paper, a visual-inertial motion\nestimation approach is proposed for prosthesis to perceive its movement and the\nchanges of spatial relationship between the prosthesis and uneven terrain when\ntraversing them. To achieve this, we estimate the knee motion by utilizing a\ndepth camera to perceive the environment and align feature points extracted\nfrom stairs and obstacles. Subsequently, an error-state Kalman filter is\nincorporated to fuse the inertial data into visual estimations to reduce the\nfeature extraction error and obtain a more robust estimation. The motion of\nprosthetic joint and toe are derived using the prosthesis model parameters.\nExperiment conducted on our collected dataset and stair walking trials with a\npowered prosthesis shows that the proposed method can accurately tracking the\nmotion of the human leg and prosthesis with an average root-mean-square error\nof toe trajectory less than 5 cm. The proposed method is expected to enable the\nenvironmental adaptive control for prosthesis, thereby enhancing amputee's\nsafety and mobility in uneven terrains."
  },
  {
    "paper_no": "3478",
    "authors": "Dube, Ayushi; Patil, Omkar; Singh, Gian; Gopalan, Nakul; VRUDHULA, SARMA",
    "title": "Hardware-Software Co-Design for Path Planning by Drones",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3480",
    "authors": "Walker, Nick; Yang, Xuning; Garg, Animesh; Cakmak, Maya; Fox, Dieter; Pérez-D'Arpino, Claudia",
    "title": "Fast Explicit-Input Assistance for Teleoperation in Clutter",
    "arxiv_pdf": "http://arxiv.org/pdf/2402.02612v3",
    "arxiv_abstract": "The performance of prediction-based assistance for robot teleoperation\ndegrades in unseen or goal-rich environments due to incorrect or\nquickly-changing intent inferences. Poor predictions can confuse operators or\ncause them to change their control input to implicitly signal their goal. We\npresent a new assistance interface for robotic manipulation where an operator\ncan explicitly communicate a manipulation goal by pointing the end-effector.\nThe pointing target specifies a region for local pose generation and\noptimization, providing interactive control over grasp and placement pose\ncandidates. We compare the explicit pointing interface to an implicit\ninference-based assistance scheme in a within-subjects user study (N=20) where\nparticipants teleoperate a simulated robot to complete a multi-step singulation\nand stacking task in cluttered environments. We find that operators prefer the\nexplicit interface, experience fewer pick failures and report lower cognitive\nworkload. Our code is available at:\nhttps://github.com/NVlabs/fast-explicit-teleop"
  },
  {
    "paper_no": "3481",
    "authors": "Korigodskii, Andrei; Kalachev, Oleg; Vasiunik, Artem; Bondar, George",
    "title": "Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3483",
    "authors": "Ta, Tung D.",
    "title": "Single Actuator Undulation Soft-bodied Robots Using A Precompressed Variable Thickness Flexible Beam",
    "arxiv_pdf": "http://arxiv.org/pdf/2410.05813v1",
    "arxiv_abstract": "Soft robots - due to their intrinsic flexibility of the body - can adaptively\nnavigate unstructured environments. One of the most popular locomotion gaits\nthat has been implemented in soft robots is undulation. The undulation motion\nin soft robots resembles the locomotion gait of stringy creatures such as\nsnakes, eels, and C. Elegans. Typically, the implementation of undulation\nlocomotion on a soft robot requires many actuators to control each segment of\nthe stringy body. The added weight of multiple actuators limits the navigating\nperformance of soft-bodied robots. In this paper, we propose a simple\ntendon-driven flexible beam with only one actuator (a DC motor) that can\ngenerate a mechanical traveling wave along the beam to support the undulation\nlocomotion of soft robots. The beam will be precompressed along its axis by\nshortening the length of the two tendons to form an S-shape, thus pretensioning\nthe tendons. The motor will wind and unwind the tendons to deform the flexible\nbeam and generate traveling waves along the body of the robot. We experiment\nwith different pre-tension to characterize the relationship between tendon\npre-tension forces and the DC-motor winding/unwinding. Our proposal enables a\nsimple implementation of undulation motion to support the locomotion of\nsoft-bodied robots."
  },
  {
    "paper_no": "3485",
    "authors": "Verzic, Nicholas; Chadaga, Abhinav; Hart, Justin",
    "title": "Recovering Missed Detections in an Elevator Button Segmentation Task",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3489",
    "authors": "Mustafa, Zaid; Turkseven, Melih",
    "title": "Design of a Pneumatically Driven 3D-Printed Under-Actuated Soft Robot with Programmable Stiffness",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3490",
    "authors": "Tarakli, Imene; Vinanzi, Samuele; Di Nuovo, Alessandro",
    "title": "Interactive Reinforcement Learning from Natural Language Feedback",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3492",
    "authors": "Xiao, Fei; Wei, Zhuoheng; Wang, Hao; Li, Jisen; ZHU, Jian",
    "title": "Embedded 3d printing of silicone for soft actuator with stiffness gradient and programmable workspace",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3498",
    "authors": "Cai, Kuanqi; Laha, Riddhiman; Gong, Yuhe; Chen, Lingyun; Zhang, Liding; Figueredo, Luis; Haddadin, Sami",
    "title": "Demonstration to Adaptation: A User-Guided Framework for Sequential and Real-Time Planning",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3501",
    "authors": "Li, Chengyang; Zhang, Yulai; Yu, Zhiqiang; Liu, Xinming; Shi, Qing",
    "title": "A Robust Visual SLAM System for Small-Scale Quadruped Robots in Dynamic Environments",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3502",
    "authors": "Hajizada, Elvin; Swaminathan, Balachandran; Sandamirskaya, Yulia",
    "title": "Continual Learning for Autonomous Robots A Prototype-based Approach",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.00418v1",
    "arxiv_abstract": "Humans and animals learn throughout their lives from limited amounts of\nsensed data, both with and without supervision. Autonomous, intelligent robots\nof the future are often expected to do the same. The existing continual\nlearning (CL) methods are usually not directly applicable to robotic settings:\nthey typically require buffering and a balanced replay of training data. A\nfew-shot online continual learning (FS-OCL) setting has been proposed to\naddress more realistic scenarios where robots must learn from a non-repeated\nsparse data stream. To enable truly autonomous life-long learning, an\nadditional challenge of detecting novelties and learning new items without\nsupervision needs to be addressed. We address this challenge with our new\nprototype-based approach called Continually Learning Prototypes (CLP). In\naddition to being capable of FS-OCL learning, CLP also detects novel objects\nand learns them without supervision. To mitigate forgetting, CLP utilizes a\nnovel metaplasticity mechanism that adapts the learning rate individually per\nprototype. CLP is rehearsal-free, hence does not require a memory buffer, and\nis compatible with neuromorphic hardware, characterized by ultra-low power\nconsumption, real-time processing abilities, and on-chip learning. Indeed, we\nhave open-sourced a simple version of CLP in the neuromorphic software\nframework Lava, targetting Intel's neuromorphic chip Loihi 2. We evaluate CLP\non a robotic vision dataset, OpenLORIS. In a low-instance FS-OCL scenario, CLP\nshows state-of-the-art results. In the open world, CLP detects novelties with\nsuperior precision and recall and learns features of the detected novel classes\nwithout supervision, achieving a strong baseline of 99% base class and 65%/76%\n(5-shot/10-shot) novel class accuracy."
  },
  {
    "paper_no": "3505",
    "authors": "Xu, Chengpeng; Sun, Xiao; Xu, Yangyang; Wang, Ruolin",
    "title": "LDIP: Real-time on-road object detection with depth estimation from a single image",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3507",
    "authors": "Zarrouki, Baha; Wang, Chenyang; Betz, Johannes",
    "title": "Adaptive Stochastic Nonlinear Model Predictive Control with Look-ahead Deep Reinforcement Learning for Autonomous Vehicle Motion Control",
    "arxiv_pdf": "http://arxiv.org/pdf/2311.04303v1",
    "arxiv_abstract": "In this paper, we present a Deep Reinforcement Learning (RL)-driven Adaptive\nStochastic Nonlinear Model Predictive Control (SNMPC) to optimize uncertainty\nhandling, constraints robustification, feasibility, and closed-loop\nperformance. To this end, we conceive an RL agent to proactively anticipate\nupcoming control tasks and to dynamically determine the most suitable\ncombination of key SNMPC parameters - foremost the robustification factor\n$\\kappa$ and the Uncertainty Propagation Horizon (UPH) $T_u$. We analyze the\ntrained RL agent's decision-making process and highlight its ability to learn\ncontext-dependent optimal parameters. One key finding is that adapting the\nconstraints robustification factor with the learned policy reduces conservatism\nand improves closed-loop performance while adapting UPH renders previously\ninfeasible SNMPC problems feasible when faced with severe disturbances. We\nshowcase the enhanced robustness and feasibility of our Adaptive SNMPC (aSNMPC)\nthrough the real-time motion control task of an autonomous passenger vehicle to\nfollow an optimal race line when confronted with significant time-variant\ndisturbances. Experimental findings demonstrate that our look-ahead RL-driven\naSNMPC outperforms its Static SNMPC (sSNMPC) counterpart in minimizing the\nlateral deviation both with accurate and inaccurate disturbance assumptions and\neven when driving in previously unexplored environments."
  },
  {
    "paper_no": "3512",
    "authors": "Huang, Yidong; Sansom, Jacob; Ma, Ziqiao; Gervits, Felix; Chai, Joyce",
    "title": "DriVLMe: Exploring Foundation Models as Autonomous Driving Agents That Perceive, Communicate and Navigate",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3513",
    "authors": "Perera, Kankanige Nisal Minula; yu, Shangqun; Marew, Daniel; Tang, Mack; Suzuki, Ken; McCormack, Aidan; Zhu, Shifan; Kim, Yong-Jae; Kim, Donghyun",
    "title": "StaccaToe: A Single-Leg Robot that Mimics the Human Leg and Toe",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3515",
    "authors": "Wang, Ziqi; Liu, Junchen; Li, Hongwu; Zhang, Qinghua; Li, Xianglong; huang, yi; Ju, Haotian; Zheng, Tianjiao; Zhao, Jie; Zhu, Yanhe",
    "title": "Using Hip Assisted Running Exoskeleton with Impact Isolation Mechanism to Improve Energy Efficiency",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3520",
    "authors": "Fan, Qigao; Hou, Zhe; Liu, Yueyue",
    "title": "Design of an Array Microrobot System and Its Application in Object Delivery",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3521",
    "authors": "Jayaraman, Suresh Kumaar; Steinfeld, Aaron; Simmons, Reid; Admoni, Henny",
    "title": "Understanding Robot Minds: Leveraging Machine Teaching for Transparent Human-Robot Collaboration Across Diverse Groups",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.15472v1",
    "arxiv_abstract": "In this work, we aim to improve transparency and efficacy in human-robot\ncollaboration by developing machine teaching algorithms suitable for groups\nwith varied learning capabilities. While previous approaches focused on\ntailored approaches for teaching individuals, our method teaches teams with\nvarious compositions of diverse learners using team belief representations to\naddress personalization challenges within groups. We investigate various group\nteaching strategies, such as focusing on individual beliefs or the group's\ncollective beliefs, and assess their impact on learning robot policies for\ndifferent team compositions. Our findings reveal that team belief strategies\nyield less variation in learning duration and better accommodate diverse teams\ncompared to individual belief strategies, suggesting their suitability in\nmixed-proficiency settings with limited resources. Conversely, individual\nbelief strategies provide a more uniform knowledge level, particularly\neffective for homogeneously inexperienced groups. Our study indicates that the\nteaching strategy's efficacy is significantly influenced by team composition\nand learner proficiency, highlighting the importance of real-time assessment of\nlearner proficiency and adapting teaching approaches based on learner\nproficiency for optimal teaching outcomes."
  },
  {
    "paper_no": "3522",
    "authors": "Sikdar, Aniruddh; Saadiyean, Qiranul; Anand, Prahlad; Sundaram, Suresh",
    "title": "SSL-RGB2IR: Semi-supervised RGB-to-IR Image-to-Image Translation for Enhancing Vision Task Training in Semantic Segmentation and Object Detection",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3523",
    "authors": "Wang, Peng; Liu, Jixiao; Qi, Dianpeng; Guo, Shijie",
    "title": "A Wearable Mechanical Pressure-Electrophysiological Bimodal Sensing System for Rehabilitation Electromechanical Device",
    "arxiv_pdf": null,
    "arxiv_abstract": null
  },
  {
    "paper_no": "3528",
    "authors": "Cheng, Yi; Han, Chenxi; Min, Yuheng; Ye, Linqi; Liu, Houde; Hang, Liu; LIANG, bin",
    "title": "Structural Optimization of Lightweight Bipedal Robot via SERL",
    "arxiv_pdf": "http://arxiv.org/pdf/2408.15632v1",
    "arxiv_abstract": "Designing a bipedal robot is a complex and challenging task, especially when\ndealing with a multitude of structural parameters. Traditional design methods\noften rely on human intuition and experience. However, such approaches are\ntime-consuming, labor-intensive, lack theoretical guidance and hard to obtain\noptimal design results within vast design spaces, thus failing to full exploit\nthe inherent performance potential of robots. In this context, this paper\nintroduces the SERL (Structure Evolution Reinforcement Learning) algorithm,\nwhich combines reinforcement learning for locomotion tasks with evolution\nalgorithms. The aim is to identify the optimal parameter combinations within a\ngiven multidimensional design space. Through the SERL algorithm, we\nsuccessfully designed a bipedal robot named Wow Orin, where the optimal leg\nlength are obtained through optimization based on body structure and motor\ntorque. We have experimentally validated the effectiveness of the SERL\nalgorithm, which is capable of optimizing the best structure within specified\ndesign space and task conditions. Additionally, to assess the performance gap\nbetween our designed robot and the current state-of-the-art robots, we compared\nWow Orin with mainstream bipedal robots Cassie and Unitree H1. A series of\nexperimental results demonstrate the Outstanding energy efficiency and\nperformance of Wow Orin, further validating the feasibility of applying the\nSERL algorithm to practical design."
  },
  {
    "paper_no": "3529",
    "authors": "Cheng, Yi; Hang, Liu; Pan, Guoping; Ye, Linqi; Liu, Houde; LIANG, bin",
    "title": "Quadruped robot traversing 3D complex environments with limited perception",
    "arxiv_pdf": "http://arxiv.org/pdf/2404.18225v3",
    "arxiv_abstract": "Traversing 3-D complex environments has always been a significant challenge\nfor legged locomotion. Existing methods typically rely on external sensors such\nas vision and lidar to preemptively react to obstacles by acquiring\nenvironmental information. However, in scenarios like nighttime or dense\nforests, external sensors often fail to function properly, necessitating robots\nto rely on proprioceptive sensors to perceive diverse obstacles in the\nenvironment and respond promptly. This task is undeniably challenging. Our\nresearch finds that methods based on collision detection can enhance a robot's\nperception of environmental obstacles. In this work, we propose an end-to-end\nlearning-based quadruped robot motion controller that relies solely on\nproprioceptive sensing. This controller can accurately detect, localize, and\nagilely respond to collisions in unknown and complex 3D environments, thereby\nimproving the robot's traversability in complex environments. We demonstrate in\nboth simulation and real-world experiments that our method enables quadruped\nrobots to successfully traverse challenging obstacles in various complex\nenvironments."
  }
]