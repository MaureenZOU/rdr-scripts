[
  {
    "paper_id": "papers_544",
    "authors": "Shiying Xiong, Zhecheng Wang, Mengdi Wang, Bo Zhu",
    "title": "A Clebsch Method for Free-surface Vortical Flow Simulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530150",
    "pdf_link": null,
    "abstract": "We propose a novel Clebsch method to simulate the free-surface vortical flow. At the center of our approach lies a level-set method enhanced by a wave-function correction scheme and a wave-function extrapolation algorithm to tackle the Clebsch method's numerical instabilities near a dynamic interface. By combining the Clebsch wave function's expressiveness in representing vortical structures and the level-set function's ability on tracking interfacial dynamics, we can model complex vortex-interface interaction problems that exhibit rich free-surface flow details on a Cartesian grid. We showcase the efficacy of our approach by simulating a wide range of new free-surface flow phenomena that were impractical for previous methods, including horseshoe vortex, sink vortex, bubble rings, and free-surface wake vortices.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_127",
    "authors": "Chuankun Zheng, Ruzhang Zheng, Rui Wang, Shuang Zhao, Hujun Bao, Chuankun Zheng",
    "title": "A Compact Representation of Measured BRDFs Using Neural Processes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3490385",
    "pdf_link": null,
    "abstract": "In this article, we introduce a compact representation for measured BRDFs by leveraging Neural Processes (NPs). Unlike prior methods that express those BRDFs as discrete high-dimensional matrices or tensors, our technique considers measured BRDFs as continuous functions and works in corresponding function spaces. Specifically, provided the evaluations of a set of BRDFs, such as ones in MERL and EPFL datasets, our method learns a low-dimensional latent space as well as a few neural networks to encode and decode these measured BRDFs or new BRDFs into and from this space in a non-linear fashion. Leveraging this latent space and the flexibility offered by the NPs formulation, our encoded BRDFs are highly compact and offer a level of accuracy better than prior methods. We demonstrate the practical usefulness of our approach via two important applications, BRDF compression and editing. Additionally, we design two alternative post-trained decoders to, respectively, achieve better compression ratio for individual BRDFs and enable importance sampling of BRDFs.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "pos_203",
    "authors": "Jong-In Lee, Paul Asente, Wolfgang Stuerzlinger",
    "title": "A Comparison of Zoom-in Transition Methods for Multiscale VR",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543237",
    "pdf_link": null,
    "abstract": "When navigating within an unfamiliar virtual environment in VR, transitions between pre-defined viewpoints are known to facilitate spatial awareness of a user. Previously, different viewpoint transition techniques had been investigated, but mainly for single-scale environments. We present a comparative study of zoom-in transition techniques, where the viewpoint of a user is being smoothly transitioned from a large level of scale (LoS) to a smaller LoS in a multiscale virtual environment (MVE) with a nested structure. We identify that orbiting first before zooming in is preferred over other alternatives when transitioning to a viewpoint at a small LoS.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_141",
    "authors": "Marian Lupașcu, Ryan Murdock, Ionuţ Mironică, Yijun Li",
    "title": "A Fast Text-driven Approach for Generating Artistic Content",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543208",
    "pdf_link": null,
    "abstract": "Finding a source of inspiration for visual art creation can be a difficult task. Even with the online search engine, it is still laborintensive because manually crawling the web is time-consuming. Therefore, a large number of artistic prototypes must be explored before an artist has a better feel of what their future creations look like structurally but also artistically. In this work, the image can be stylized according to the user’s requirements with a text prompt, a style image, or a combination of style parameters (Figure 1). The only limitation is the user’s imagination. Despite the considerable progress of generative models, there is not a common solution that allows stylization with image and text. The Conditional-driven GAN [Reed et al. 2016] first extracted visual details from the text and then synthesized the output image conditioned on these previously extracted features. The Attentiondriven GAN [Xu et al. 2018] introduced a similarity module between text features and image features. The DALLE [Ramesh et al. 2021] and StyleCLIP [Patashnik et al. 2021] are the state-of-the-art approaches of generating and manipulating images via text. However, the DALLE does not support the stylization with a style example and StyleCLIP is mainly limited in generating images from a single domain: faces, cars, etc.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_385",
    "authors": "Han Shao, Libo Huang, Dominik Michels",
    "title": "A Fast Unsmoothed Aggregation Algebraic Multigrid Framework for the Large-scale Simulation of Incompressible Flow",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530109",
    "pdf_link": null,
    "abstract": "Multigrid methods are quite efficient for solving the pressure Poisson equation in simulations of incompressible flow. However, for viscous liquids, geometric multigrid turned out to be less efficient for solving the variational viscosity equation. In this contribution, we present an Unsmoothed Aggregation Algebraic MultiGrid (UAAMG) method with a multi-color Gauss-Seidel smoother, which consistently solves the variational viscosity equation in a few iterations for various material parameters. Moreover, we augment the OpenVDB data structure with Intel SIMD intrinsic functions to perform sparse matrix-vector multiplications efficiently on all multigrid levels. Our framework is 2.0 to 14.6 times faster compared to the state-of-the-art adaptive octree solver in commercial software for the large-scale simulation of both non-viscous and viscous flow. The code is available at http://computationalsciences.org/publications/shao-2022-multigrid.html.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_261",
    "authors": "Jhamieka Greenwood, Bryan Quaife, Kevin Speer",
    "title": "A GPU-accelerated Hydrodynamics Solver for Atmosphere-fire Interactions",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543263",
    "pdf_link": null,
    "abstract": "2 METHODSFigure 1 Figure 1: Particles (green) being transported by a solution of Equation (1). There are two delta functions with centers near the middle of the domain.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_268",
    "authors": "Botao Wu, Zhendong Wang, Huamin Wang",
    "title": "A GPU-based Multilevel Additive Schwarz Preconditioner for Cloth and Deformable Body Simulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530085",
    "pdf_link": null,
    "abstract": "In this paper, we wish to push the limit of real-time cloth and deformable body simulation to a higher level with 50K to 500K vertices, based on the development of a novel GPU-based multilevel additive Schwarz (MAS) pre-conditioner. Similar to other preconditioners under the MAS framework, our preconditioner naturally adopts multilevel and domain decomposition concepts. But contrary to previous works, we advocate the use of small, non-overlapping domains that can well explore the parallel computing power on a GPU. Based on this idea, we investigate and invent a series of algorithms for our preconditioner, including multilevel domain construction using Morton codes, low-cost matrix precomputation by one-way Gauss-Jordan elimination, and conflict-free symmetric-matrix-vector multiplication in runtime preconditioning. The experiment shows that our preconditioner is effective, fast, cheap to precompute and scalable with respect to stiffness and problem size. It is compatible with many linear and nonlinear solvers used in cloth and deformable body simulation with dynamic contacts, such as PCG, accelerated gradient descent and L-BFGS. On a GPU, our preconditioner speeds up a PCG solver by approximately a factor of four, and its CPU version outperforms a number of competitors, including ILU0 and ILUT.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_635",
    "authors": "Jerry Hsu, Nghia Truong, Cem Yuksel, Kui Wu",
    "title": "A General Two-stage Initialization for Sag-free Deformable Simulations",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530165",
    "pdf_link": null,
    "abstract": "Initializing simulations of deformable objects involves setting the rest state of all internal forces at the rest shape of the object. However, often times the rest shape is not explicitly provided. In its absence, it is common to initialize by treating the given initial shape as the rest shape. This leads to sagging, the undesirable deformation under gravity as soon as the simulation begins. Prior solutions to sagging are limited to specific simulation systems and material models, most of them cannot handle frictional contact, and they require solving expensive global nonlinear optimization problems. We introduce a novel solution to the sagging problem that can be applied to a variety of simulation systems and materials. The key feature of our approach is that we avoid solving a global nonlinear optimization problem by performing the initialization in two stages. First, we use a global linear optimization for static equilibrium. Any nonlinearity of the material definition is handled in the local stage, which solves many small local problems efficiently and in parallel. Notably, our method can properly handle frictional contact orders of magnitude faster than prior work. We show that our approach can be applied to various simulation systems by presenting examples with mass-spring systems, cloth simulations, the finite element method, the material point method, and position-based dynamics.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_138",
    "authors": "Bolun Wang, Zachary Ferguson, Teseo Schneider, Xin Jiang, Marco Attene, Daniele Panozzo, Bolun Wang",
    "title": "A Large Scale Benchmark and an Inclusion-based Algorithm for Continuous Collision Detection",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3460775",
    "pdf_link": null,
    "abstract": "We introduce a large-scale benchmark for continuous collision detection (CCD) algorithms, composed of queries manually constructed to highlight challenging degenerate cases and automatically generated using existing simulators to cover common cases. We use the benchmark to evaluate the accuracy, correctness, and efficiency of state-of-the-art continuous collision detection algorithms, both with and without minimal separation. We discover that, despite the widespread use of CCD algorithms, existing algorithms are (1) …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_115",
    "authors": "Teseo Schneider, Yixin Hu, Xifeng Gao, Jérémie Dumas, Denis Zorin, Daniele Panozzo, Teseo Schneider",
    "title": "A Large-scale Comparison of Tetrahedral and Hexahedral Elements for Solving Elliptic PDEs With the Finite Element Method",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3508372",
    "pdf_link": null,
    "abstract": "The Finite Element Method (FEM) is widely used to solve discrete Partial Differential Equations (PDEs) in engineering and graphics applications. The popularity of FEM led to the development of a large family of variants, most of which require a tetrahedral or hexahedral mesh to construct the basis. While the theoretical properties of FEM basis (such as convergence rate, stability, etc.) are well understood under specific assumptions on the mesh quality, their practical performance, influenced both by the choice of the basis construction and quality of mesh generation, have not been systematically documented for large collections of automatically meshed 3D geometries. We introduce a set of benchmark problems involving most commonly solved elliptic PDEs, starting from simple cases with an analytical solution, moving to commonly used test problem setups, and using manufactured solutions for thousands of real-world, automatically meshed geometries. For all these cases, we use state-of-the-art meshing tools to create both tetrahedral and hexahedral meshes, and compare the performance of different element types for common elliptic PDEs. The goal of this benchmark is to enable comparison of complete FEM pipelines, from mesh generation to algebraic solver, and exploration of relative impact of different factors on the overall system performance. As a specific application of our geometry and benchmark dataset, we explore the question of relative advantages of unstructured (triangular/ tetrahedral) and structured (quadrilateral/hexahedral) discretizations. We observe that for Lagrange-type elements, while linear tetrahedral elements perform poorly, quadratic tetrahedral elements perform equally well or outperform hexahedral elements for our set of problems and currently available mesh generation algorithms. This observation suggests that for common problems in structural analysis, thermal analysis, and low Reynolds number flows, high-quality results can be obtained with unstructured tetrahedral meshes, which can be created robustly and automatically. We release the description of the benchmark problems, meshes, and reference implementation of our testing infrastructure to enable statistically significant comparisons between different FE methods, which we hope will be helpful in the development of new meshing and FEA techniques.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_770",
    "authors": "Ikhsanul Habibie, Mohamed Elgharib, Kripasindhu Sarkar, Ahsan Abdullah, Simbarashe Nyatsanga, Michael Neff, Christian Theobalt",
    "title": "A Motion Matching-based Framework for Controllable Gesture Synthesis From Speech",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530750",
    "pdf_link": null,
    "abstract": "Recent deep learning-based approaches have shown promising results for synthesizing plausible 3D human gestures from speech input. However, these approaches typically offer limited freedom to incorporate user control. Furthermore, training such models in a supervised manner often does not capture the multi-modal nature of the data, particularly because the same audio input can produce different gesture outputs. To address these problems, we present an approach for generating controllable 3D gestures that combines the advantage of database matching and deep generative modeling. Our method predicts 3D body motion by sequentially searching for the most plausible audio-gesture clips from a database using a k-Nearest Neighbors (k-NN) algorithm that considers the similarity to both the input audio and the previous body pose information. To further improve the synthesis quality, we propose a conditional Generative Adversarial Network (cGAN) model to provide a data-driven refinement to the k-NN result by comparing its plausibility against the ground truth audio-gesture pairs. Our novel approach enables direct and more varied control manipulation that is not possible with prior learning-based counterparts. Our experiments show that our proposed approach outperforms recent models on control-based synthesis tasks using high-level signals such as motion statistics while enabling flexible and effective user control for lower-level signals. 1",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_692",
    "authors": "Yitong Deng, Mengdi Wang, Xiangxin Kong, Shiying Xiong, Zangyueyang Xian, Bo Zhu",
    "title": "A Moving Eulerian-Lagrangian Particle Method for Thin Film and Foam Simulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530174",
    "pdf_link": null,
    "abstract": "We present the Moving Eulerian-Lagrangian Particles (MELP), a novel mesh-free method for simulating incompressible fluid on thin films and foams. Employing a bi-layer particle structure, MELP jointly simulates detailed, vigorous flow and large surface deformation at high stability and efficiency. In addition, we design multi-MELP: a mechanism that facilitates the physically-based interaction between multiple MELP systems, to simulate bubble clusters and foams with non-manifold topological evolution. We showcase the efficacy of our method with a broad range of challenging thin film phenomena, including the Rayleigh-Taylor instability across double-bubbles, foam fragmentation with rim surface tension, recovery of the Plateau borders, Newton black films, as well as cyclones on bubble clusters.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_112",
    "authors": "Qiang Chen, Tingsong Lu, Yang Tong, Guoliang Luo, Xiaogang Jin, Zhigang Deng, Qiang Chen",
    "title": "A Practical Model for Realistic Butterfly Flight Simulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3510459",
    "pdf_link": null,
    "abstract": "Butterflies are not only ubiquitous around the world but are also widely known for inspiring thrill resonance, with their elegant and peculiar flights. However, realistically modeling and simulating butterfly flights—in particular, for real-time graphics and animation applications—remains an under-explored problem. In this article, we propose an efficient and practical model to simulate butterfly flights. We first model a butterfly with parametric maneuvering functions, including wing-abdomen interaction. Then, we simulate dynamic maneuvering control of the butterfly through our force-based model, which includes both the aerodynamics force and the vortex force. Through many simulation experiments and comparisons, we demonstrate that our method can efficiently simulate realistic butterfly flight motions in various real-world settings.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_449",
    "authors": "Cyril Soler, Ronak Molazem, Kartic Subr",
    "title": "A Theoretical Analysis of Compactness of the Light Transport Operator",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530725",
    "pdf_link": null,
    "abstract": "Rendering photorealistic visuals of virtual scenes requires tractable models for the simulation of light. The rendering equation describes one such model using an integral equation, the crux of which is a continuous integral operator. A majority of rendering algorithms aim to approximate the effect of this light transport operator via discretization (using rays, particles, patches, etc.). Research spanning four decades has uncovered interesting properties and intuition surrounding this operator. In this paper we analyze …",
    "scholar_publication": "ACM SIGGRAPH 2022 Conference …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_212",
    "authors": "Yunuo Chen, Minchen Li, Lei Lan, Hao Su, Yin Yang, Chenfanfu Jiang",
    "title": "A Unified Newton Barrier Method for Multibody Dynamics",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530076",
    "pdf_link": null,
    "abstract": "We present a simulation framework for multibody dynamics via a universal variational integration. Our method naturally supports mixed rigid-deformables and mixed codimensional geometries, while providing guaranteed numerical convergence and accurate resolution of contact, friction, and a wide range of articulation constraints. We unify (1) the treatment of simulation degrees of freedom for rigid and soft bodies by formulating them both in terms of Lagrangian nodal displacements, (2) the handling of general linear equality joint constraints through an efficient change-of-variable strategy, (3) the enforcement of nonlinear articulation constraints based on novel distance potential energies, (4) the resolution of frictional contact between mixed dimensions and bodies with a variational Incremental Potential Contact formulation, and (5) the modeling of generalized restitution through semi-implicit Rayleigh damping. We conduct extensive unit tests and benchmark studies to demonstrate the efficacy of our method.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_228",
    "authors": "Yazhou Xing, Changlin Li, Xuaner Zhang, Qifeng Chen",
    "title": "A Well-aligned Dataset for Learning Image Signal Processing on Smartphones From a High-end Camera",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543252",
    "pdf_link": null,
    "abstract": "3 METHODGiven a raw image X captured by a small sensor camera, our goal is to render a high-quality RGB image . The high dynamic range of raw sensor images imposes a great challenge using a conventional CNN architecture that relies on spatially invariant convolutions, which are considered antithetical to localize edge discontinuities. Thus, directly applying standard convolution can cause apparent artifacts such as halos, which has been identified in previous non-learning-based image filtering methods [Guarnieri et al. 2011; Paris et al. 2011]. We propose a novel edge-aware conditional convolutional network architecture based on the kernel prediction method [Bako et al. 2017].",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_439",
    "authors": "Darius Rückert, Linus Franke, Marc Stamminger",
    "title": "ADOP: Approximate Differentiable One-pixel Point Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530122",
    "pdf_link": null,
    "abstract": "In this paper we present ADOP, a novel point-based, differentiable neural rendering pipeline. Like other neural renderers, our system takes as input calibrated camera images and a proxy geometry of the scene, in our case a point cloud. To generate a novel view, the point cloud is rasterized with learned feature vectors as colors and a deep neural network fills the remaining holes and shades each output pixel. The rasterizer renders points as one-pixel splats, which makes it very fast and allows us to compute gradients with respect to all relevant input parameters efficiently. Furthermore, our pipeline contains a fully differentiable physically-based photometric camera model, including exposure, white balance, and a camera response function. Following the idea of inverse rendering, we use our renderer to refine its input in order to reduce inconsistencies and optimize the quality of its output. In particular, we can optimize structural parameters like the camera pose, lens distortions, point positions and features, and a neural environment map, but also photometric parameters like camera response function, vignetting, and per-image exposure and white balance. Because our pipeline includes photometric parameters, e.g. exposure and camera response function, our system can smoothly handle input images with varying exposure and white balance, and generates high-dynamic range output. We show that due to the improved input, we can achieve high render quality, also for difficult input, e.g. with imperfect camera calibrations, inaccurate proxy geometry, or varying exposure. As a result, a simpler and thus faster deep neural network is sufficient for reconstruction. In combination with the fast point rasterization, ADOP achieves real-time rendering rates even for models with well over 100M points. https://github.com/darglein/ADOP",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_396",
    "authors": "Xue Bin Peng, Yunrong Guo, Lina Halper, Sergey Levine, Sanja Fidler",
    "title": "ASE: Large-scale Reusable Adversarial Skill Embeddings for Physically Simulated Characters",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530110",
    "pdf_link": null,
    "abstract": "The incredible feats of athleticism demonstrated by humans are made possible in part by a vast repertoire of general-purpose motor skills, acquired through years of practice and experience. These skills not only enable humans to perform complex tasks, but also provide powerful priors for guiding their behaviors when learning new tasks. This is in stark contrast to what is common practice in physics-based character animation, where control policies are most typically trained from scratch for each task. In this work, we present a large-scale data-driven framework for learning versatile and reusable skill embeddings for physically simulated characters. Our approach combines techniques from adversarial imitation learning and unsupervised reinforcement learning to develop skill embeddings that produce life-like behaviors, while also providing an easy to control representation for use on new downstream tasks. Our models can be trained using large datasets of unstructured motion clips, without requiring any task-specific annotation or segmentation of the motion data. By leveraging a massively parallel GPU-based simulator, we are able to train skill embeddings using over a decade of simulated experiences, enabling our model to learn a rich and versatile repertoire of skills. We show that a single pre-trained model can be effectively applied to perform a diverse set of new tasks. Our system also allows users to specify tasks through simple reward functions, and the skill embedding then enables the character to automatically synthesize complex and naturalistic strategies in order to achieve the task objectives.",
    "scholar_publication": "ACM Transactions On …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_689",
    "authors": "Difan Liu, Sandesh Shetty, Tobias Hinz, Matthew Fisher, Richard Zhang, Taesung Park, Evangelos Kalogerakis",
    "title": "ASSET: Autoregressive Semantic Scene Editing With Transformers at High Resolutions",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530172",
    "pdf_link": null,
    "abstract": "We present ASSET, a neural architecture for automatically modifying an input high-resolution image according to a user's edits on its semantic segmentation map. Our architecture is based on a transformer with a novel attention mechanism. Our key idea is to sparsify the transformer's attention matrix at high resolutions, guided by dense attention extracted at lower image resolutions. While previous attention mechanisms are computationally too expensive for handling high-resolution images or are overly constrained within specific image regions hampering long-range interactions, our novel attention mechanism is both computationally efficient and effective. Our sparsified attention mechanism is able to capture long-range interactions and context, leading to synthesizing interesting phenomena in scenes, such as reflections of landscapes onto water or fora consistent with the rest of the landscape, that were not possible to generate reliably with previous convnets and transformer approaches. We present qualitative and quantitative results, along with user studies, demonstrating the effectiveness of our method. Our code and dataset are available at our project page: https://github.com/DifanLiu/ASSET",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_538",
    "authors": "Dongyeon Kim, Seung-Woo Nam, Byounghyo Lee, Jong-Mo Seo, Byoungho Lee",
    "title": "Accommodative Holography: Improving Accommodation Response for Perceptually Realistic Holographic Displays",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530147",
    "pdf_link": null,
    "abstract": "Holographic displays have gained unprecedented attention as next-generation virtual and augmented reality applications with recent achievements in the realization of a high-contrast image through computer-generated holograms (CGHs). However, these holograms show a high energy concentration in a limited angular spectrum, whereas the holograms with uniformly distributed angular spectrum suffer from a severe speckle noise in the reconstructed images. In this study, we claim that these two physical phenomena attributed to the existing CGHs significantly limit the support of accommodation cues, which is known as one of the biggest advantages of holographic displays. To support the statement, we analyze and evaluate various CGH algorithms with contrast gradients - a change of contrast over the change of the focal diopter of the eye - simulated based on the optical configuration of the display system and human visual perception models. We first introduce two approaches to improve monocular accommodation response in holographic viewing experience; optical and computational approaches to provide holographic images with sufficient contrast gradients. We design and conduct user experiments with our prototype of holographic near-eye displays, validating the deficient support of accommodation cues in the existing CGH algorithms and demonstrating the feasibility of the proposed solutions with significant improvements on accommodative gains.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_147",
    "authors": "Yusuke Tokuyoshi, Atsushi Yoshimura",
    "title": "Accurate Diffuse Lighting From Spherical Gaussian Lights",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543209",
    "pdf_link": null,
    "abstract": "… Although diffuse lighting from an SG light is given by the product integral of the SG and clamped cosine, it does not have a closed-form exact solution. Therefore, efficient approximation is required for real-time applications. Pettineo and Hill [2016] fitted the irradiance from an SG … To reduce the error, we present more accurate approximations for the clamped cosine and hemispherical integral than the previous work. Our approximation is simple and easy to implement. By using our method, we are able to improve the quality of real-time SG … To improve …",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_101",
    "authors": "Stavros Diolatzis, Julien Philip, George Drettakis, Stavros Diolatzis",
    "title": "Active Exploration for Neural Global Illumination of Variable Scenes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3522735",
    "pdf_link": null,
    "abstract": "Neural rendering algorithms introduce a fundamentally new approach for photorealistic rendering, typically by learning a neural representation of illumination on large numbers of ground truth images. When training for a given variable scene, such as changing objects, materials, lights, and viewpoint, the space of possible training data instances quickly becomes unmanageable as the dimensions of variable parameters increase. We introduce a novel Active Exploration method using Markov Chain Monte Carlo, which explores , generating samples (i.e., ground truth renderings) that best help training and interleaves training and on-the-fly sample data generation. We introduce a self-tuning sample reuse strategy to minimize the expensive step of rendering training samples. We apply our approach on a neural generator that learns to render novel scene instances given an explicit parameterization of the scene configuration. Our results show that Active Exploration trains our network much more efficiently than uniformly sampling and, together with our resolution enhancement approach, achieves better quality than uniform sampling at convergence. Our method allows interactive rendering of hard light transport paths (e.g., complex caustics), which require very high samples counts to be captured, and provides dynamic scene navigation and manipulation, after training for 5 to 18 hours depending on required quality and variations.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_450",
    "authors": "Alexandre Mercier-Aubin, Alexander Winter, David Levin, Paul Kry",
    "title": "Adaptive Rigidification of Elastic Solids",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530124",
    "pdf_link": null,
    "abstract": "… With our method for on-demand elastification, physics simulation of solid geometry becomes … In what follows we detail our adaptive approach to the modeling and simulation of elastic, …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_217",
    "authors": "Arjun Teh, Ioannis Gkioulekas, Matthew O'Toole",
    "title": "Adjoint Nonlinear Ray Tracing",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530077",
    "pdf_link": null,
    "abstract": "… We use the adjoint … to nonlinear ray tracing constraints. We additionally introduce discretization schemes to numerically evaluate these equations, without the need to store nonlinear ray …",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_169",
    "authors": "Lei Lan, Danny Kaufman, Minchen Li, Chenfanfu Jiang, Yin Yang",
    "title": "Affine Body Dynamics: Fast, Stable, and Intersection-free Simulation of Stiff Materials",
    "paper_url": "https://arxiv.org/abs/2201.10022",
    "pdf_link": null,
    "abstract": "Simulating stiff materials in applications where deformations are either not significant or can safely be ignored is a pivotal task across fields. Rigid body modeling has thus long remained a fundamental tool and is, by far, the most popular simulation strategy currently employed for modeling stiff solids. At the same time, numerical models of a rigid body continue to pose a number of known challenges and trade-offs including intersections, instabilities, inaccuracies, and/or slow performances that grow with contact-problem complexity. In this paper we revisit this problem and present ABD, a simple and highly effective affine body dynamics framework, which significantly improves state-of-the-art stiff simulations. We trace the challenges in the rigid-body IPC (incremental potential contact) method to the necessity of linearizing piecewise-rigid (SE(3)) trajectories and subsequent constraints. ABD instead relaxes the unnecessary (and unrealistic) constraint that each body's motion be exactly rigid with a stiff orthogonality potential, while preserving the rigid body model's key feature of a small coordinate representation. In doing so ABD replaces piecewise linearization with piecewise linear trajectories. This, in turn, combines the best from both parties: compact coordinates ensure small, sparse system solves, while piecewise-linear trajectories enable efficient and accurate constraint (contact and joint) evaluations. Beginning with this simple foundation, ABD preserves all guarantees of the underlying IPC model e.g., solution convergence, guaranteed non-intersection, and accurate frictional contact. Over a wide range and scale of simulation problems we demonstrate that ABD brings orders of magnitude performance gains (two- to three-order on the CPU and an order more utilizing the GPU, which is 10,000x speedups) over prior IPC-based methods with a similar or higher simulation quality.",
    "scholar_publication": "arXiv preprint arXiv …, 2022 - arxiv.org"
  },
  {
    "paper_id": "papers_552",
    "authors": "Cédric Portaneri, Mael Rouxel-Labbé, David Cohen-Steiner, Michael Hemmer, Pierre Alliez",
    "title": "Alpha Wrapping With an Offset",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530152",
    "pdf_link": null,
    "abstract": "… The proposed algorithm is controlled via two user-defined parameters: alpha and offset. Alpha controls the size of cavities or holes that cannot be traversed during carving, while offset …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_679",
    "authors": "Marc Alexa",
    "title": "Alpha-functions — Piecewise-linear Approximation From Noisy and Hermite Data",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530743",
    "pdf_link": null,
    "abstract": "We introduce α-functions, providing piecewise linear approximation to given data as the difference of two convex functions. The parameter α controls the shape of a paraboloid that is probing the data and may be used to filter out noise in the data. The use of convex functions enables tools for efficient approximation to the data, adding robustness to outliers, and dealing with gradient information. It also allows using the approach in higher dimension. We show that α-functions can be efficiently computed and demonstrate their versatility at the example of surface reconstruction from noisy surface samples.",
    "scholar_publication": "ACM SIGGRAPH 2022 Conference Proceedings, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_102",
    "authors": "Yadi Cao, Yunuo Chen, Minchen Li, Yin Yang, Xinxin Zhang, Mridul Aanjaneya, Chenfanfu Jiang, Yadi Cao",
    "title": "An Efficient B-spline Lagrangian/Eulerian Method for Compressible Flow, Shock Waves, and Fracturing Solids",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3519595",
    "pdf_link": null,
    "abstract": "This study presents a new method for modeling the interaction between compressible flow, shock waves, and deformable structures, emphasizing destructive dynamics. Extending advances in time-splitting compressible flow and the Material Point Methods (MPM), we develop a hybrid Eulerian and Lagrangian/Eulerian scheme for monolithic flow-structure interactions. We adopt the second-order WENO scheme to advance the continuity equation. To stably resolve deforming boundaries with sub-cell particles, we propose a blending treatment of reflective and passable boundary conditions inspired by the theory of porous media. The strongly coupled velocity-pressure system is discretized with a new mixed-order finite element formulation employing B-spline shape functions. Shock wave propagation, temperature/density-induced buoyancy effects, and topology changes in solids are unitedly captured.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_107",
    "authors": "Yiwei Hu, Cheng'an He, Valentin Deschaintre, Julie Dorsey, Holly Rushmeier, Yiwei Hu",
    "title": "An Inverse Procedural Modeling Pipeline for SVBRDF Maps",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3502431",
    "pdf_link": null,
    "abstract": "Procedural modeling is now the de facto standard of material modeling in industry. Procedural models can be edited and are easily extended, unlike pixel-based representations of captured materials. In this article, we present a semi-automatic pipeline for general material proceduralization. Given Spatially Varying Bidirectional Reflectance Distribution Functions (SVBRDFs) represented as sets of pixel maps, our pipeline decomposes them into a tree of sub-materials whose spatial distributions are encoded by their associated mask maps. This semi-automatic decomposition of material maps progresses hierarchically, driven by our new spectrum-aware material matting and instance-based decomposition methods. Each decomposed sub-material is proceduralized by a novel multi-layer noise model to capture local variations at different scales. Spatial distributions of these sub-materials are modeled either by a by-example inverse synthesis method recovering Point Process Texture Basis Functions (PPTBF) or via random sampling. To reconstruct procedural material maps, we propose a differentiable rendering-based optimization that recomposes all generated procedures together to maximize the similarity between our procedural models and the input material pixel maps. We evaluate our pipeline on a variety of synthetic and real materials. We demonstrate our method’s capacity to process a wide range of material types, eliminating the need for artist designed material graphs required in previous work [, ]. As fully procedural models, our results expand to arbitrary resolution and enable high-level user control of appearance.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_251",
    "authors": "Yongxu Jin, Yushan Han, Zhenglin Geng, Joseph Teran, Ronald Fedkiw",
    "title": "Analytically Integratable Zero-restlength Springs for Capturing Dynamic Modes Unrepresented by Quasistatic Neural Networks",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530705",
    "pdf_link": null,
    "abstract": "We present a novel paradigm for modeling certain types of dynamic simulation in real-time with the aid of neural networks. In order to significantly reduce the requirements on data (especially time-dependent data), as well as decrease generalization error, our approach utilizes a data-driven neural network only to capture quasistatic information (instead of dynamic or time-dependent information). Subsequently, we augment our quasistatic neural network (QNN) inference with a (real-time) dynamic simulation layer. Our key insight is that the dynamic modes lost when using a QNN approximation can be captured with a quite simple (and decoupled) zero-restlength spring model, which can be integrated analytically (as opposed to numerically) and thus has no time-step stability restrictions. Additionally, we demonstrate that the spring constitutive parameters can be robustly learned from a surprisingly small amount of dynamic simulation data. Although we illustrate the efficacy of our approach by considering soft-tissue dynamics on animated human bodies, the paradigm is extensible to many different simulation frameworks.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_411",
    "authors": "Ran Yi, Zipeng Ye, Ruoyu Fan, Yezhi Shu, Yong-Jin Liu, Yu-Kun Lai, Paul Rosin",
    "title": "Animating Portrait Line Drawings From a Single Face Photo and a Speech Signal",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530720",
    "pdf_link": null,
    "abstract": "Animating a single face photo is an important research topic which receives considerable attention in computer vision and graphics. Yet line drawings for face portraits, which is a longstanding and popular art form, have not been explored much in this area. Simply concatenating a realistic talking face video generation model with a photo-to-drawing style transfer module suffers from severe inter-frame discontinuity issues. To address this new challenge, we propose a novel framework to generate artistic talking portrait-line-drawing video, given a single face photo and a speech signal. After predicting facial landmark movements from the input speech signal, we propose a novel GAN model to simultaneously handle domain transfer (from photo to drawing) and facial geometry change (according to the predicted facial landmarks). To address the inter-frame discontinuity issues, we propose two novel temporal coherence losses: one based on warping and the other based on a temporal coherence discriminator. Experiments show that our model produces high quality artistic talking portrait-line-drawing videos and outperforms baseline methods. We also show our method can be easily extended to other artistic styles and generate good results. The source code is available at https://github.com/AnimatePortrait/AnimatePortrait .",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_332",
    "authors": "Xinyue Wei, Minghua Liu, Zhan Ling, Hao Su",
    "title": "Approximate Convex Decomposition for 3D Meshes With Collision-aware Concavity and Tree Search",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530103",
    "pdf_link": null,
    "abstract": "Approximate convex decomposition aims to decompose a 3D shape into a set of almost convex components, whose convex hulls can then be used to represent the input shape. It thus enables efficient geometry processing algorithms specifically designed for convex shapes and has been widely used in game engines, physics simulations, and animation. While prior works can capture the global structure of input shapes, they may fail to preserve fine-grained details (e.g., filling a toaster's slots), which are critical for retaining the functionality of objects in interactive environments. In this paper, we propose a novel method that addresses the limitations of existing approaches from three perspectives: (a) We introduce a novel collision-aware concavity metric that examines the distance between a shape and its convex hull from both the boundary and the interior. The proposed concavity preserves collision conditions and is more robust to detect various approximation errors. (b) We decompose shapes by directly cutting meshes with 3D planes. It ensures generated convex hulls are intersection-free and avoids voxelization errors. (c) Instead of using a one-step greedy strategy, we propose employing a multi-step tree search to determine the cutting planes, which leads to a globally better solution and avoids unnecessary cuttings. Through extensive evaluation on a large-scale articulated object dataset, we show that our method generates decompositions closer to the original shape with fewer components. It thus supports delicate and efficient object interaction in downstream applications.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_276",
    "authors": "Haimin Luo, Teng Xu, Yuheng Jiang, Chenglin Zhou, Qiwei Qiu, Yingliang Zhang, Wei Yang, Lan Xu, Jingyi Yu",
    "title": "Artemis: Articulated Neural Pets With Appearance and Motion Synthesis",
    "paper_url": "https://arxiv.org/abs/2202.05628",
    "pdf_link": null,
    "abstract": "We, humans, are entering into a virtual era and indeed want to bring animals to the virtual world as well for companion. Yet, computer-generated (CGI) furry animals are limited by tedious off-line rendering, let alone interactive motion control. In this paper, we present ARTEMIS, a novel neural modeling and rendering pipeline for generating ARTiculated neural pets with appEarance and Motion synthesIS. Our ARTEMIS enables interactive motion control, real-time animation, and photo-realistic rendering of furry animals. The core of our ARTEMIS is a neural-generated (NGI) animal engine, which adopts an efficient octree-based representation for animal animation and fur rendering. The animation then becomes equivalent to voxel-level deformation based on explicit skeletal warping. We further use a fast octree indexing and efficient volumetric rendering scheme to generate appearance and density features maps. Finally, we propose a novel shading network to generate high-fidelity details of appearance and opacity under novel poses from appearance and density feature maps. For the motion control module in ARTEMIS, we combine state-of-the-art animal motion capture approach with recent neural character control scheme. We introduce an effective optimization scheme to reconstruct the skeletal motion of real animals captured by a multi-view RGB and Vicon camera array. We feed all the captured motion into a neural character control scheme to generate abstract control signals with motion styles. We further integrate ARTEMIS into existing engines that support VR headsets, providing an unprecedented immersive experience where a user can intimately interact with a variety of virtual animals with vivid movements and photo-realistic appearance. We make available our ARTEMIS model and dynamic furry animal dataset at https://haiminluo.github.io/publication/artemis/.",
    "scholar_publication": "arXiv preprint arXiv …, 2022 - arxiv.org"
  },
  {
    "paper_id": "pos_127",
    "authors": "Avirup Mandal, Parag Chaudhuri, Subhasis Chaudhuri",
    "title": "Artist Controlled Fracture Design Using Impurity Maps",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543202",
    "pdf_link": null,
    "abstract": "When an object breaks, simulating evolution of fracture as per artist control while maintaining physical realism and plausibility is a challenging problem due to different complex material properties of real world objects. In this work, we present impurity maps as a way to guide fracture paths for both brittle and ductile fracture. We develop a novel probabilistic damage mechanics to model fracture in materials with impurities, using a random graph-based formulation in conjunction with graph-based FEM. An artist created map allows us to selectively distribute the impurities in the material, to weaken the object in those specific regions where the imperfections are added. During simulation, the presence of impurities guide the cracks that develop such that the fracture pattern closely follows the impurity map. We simulate artist-controlled fractures on different materials to demonstrate the potency of our method.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_307",
    "authors": "Chrystiano Araújo, Nicholas Vining, Enrique Rosales, Giorgio Gori, Alla Sheffer",
    "title": "As-locally-uniform-as-possible Reshaping of Vector Clip Art",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530098",
    "pdf_link": null,
    "abstract": "Vector clip-art images consist of regions bounded by a network of vector curves. Users often wish to reshape, or rescale, existing clip-art images by changing the locations, proportions, or scales of different image elements. When reshaping images depicting synthetic content they seek to preserve global and local structures. These structures are best preserved when the gradient of the mapping between the original and the reshaped curve networks is locally as close as possible to a uniform scale; mappings that satisfy this property maximally …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_209",
    "authors": "Asuka Hirata, Keitaro Tanaka, Masatoshi Hamanaka, Shigeo Morishima",
    "title": "Audio-driven Violin Performance Animation With Clear Fingering and Bowing",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543240",
    "pdf_link": null,
    "abstract": "This paper presents an audio-to-animation synthesis method for violin performance. This new approach provides a fine-grained violin performance animation using information on playing procedure consisting of played string, finger number, position, and bow direction. We demonstrate that our method is capable of synthesizing natural violin performance animation with fine fingering and bowing through extensive evaluation.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_173",
    "authors": "Sandra Malpica, Ana Serrano, Julia Guerrero-Viu, Daniel Martin, Edurne Bernal, Diego Gutierrez, Belen Masia",
    "title": "Auditory Stimuli Degrade Visual Performance in Virtual Reality",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543220",
    "pdf_link": null,
    "abstract": "Humans perceive the outside world mostly by sight and hearing [Van der Stoep et al. 2016]. Although most of the extra-personal space information is perceived from sight, hearing is also a relevant",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_524",
    "authors": "Chen Cao, Tomas Simon, Jin Kyu Kim, Gabe Schwartz, Michael Zollhoefer, Shunsuke Saito, Stephen Lombardi, Shih-En Wei, Danielle Belko, Shoou-I Yu, Yaser Sheikh, Jason Saragih",
    "title": "Authentic Volumetric Avatars From a Phone Scan",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530143",
    "pdf_link": null,
    "abstract": "Creating photorealistic avatars of existing people currently requires extensive person-specific data capture, which is usually only accessible to the VFX industry and not the general public. Our work aims to address this drawback by relying only on a short mobile phone capture to obtain a drivable 3D head avatar that matches a person's likeness faithfully. In contrast to existing approaches, our architecture avoids the complex task of directly modeling the entire manifold of human appearance, aiming instead to generate an avatar model that can be specialized to novel identities using only small amounts of data. The model dispenses with low-dimensional latent spaces that are commonly employed for hallucinating novel identities, and instead, uses a conditional representation that can extract person-specific information at multiple scales from a high resolution registered neutral phone scan. We achieve high quality results through the use of a novel universal avatar prior that has been trained on high resolution multi-view video captures of facial performances of hundreds of human subjects. By fine-tuning the model using inverse rendering we achieve increased realism and personalize its range of motion. The output of our approach is not only a high-fidelity 3D head avatar that matches the person's facial shape and appearance, but one that can also be driven using a jointly discovered shared global expression space with disentangled controls for gaze direction. Via a series of experiments we demonstrate that our avatars are faithful representations of the subject's likeness. Compared to other state-of-the-art methods for lightweight avatar creation, our approach exhibits superior visual quality and animateability.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_251",
    "authors": "Jelle Vermandere, Maarten Bassier, Maarten Vergauwen",
    "title": "Automatic Alignment and Completion of Point Cloud Environments Using XR Data",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543258",
    "pdf_link": null,
    "abstract": "The AECO industry needs up-to-date and complete geo-spacial data of their facilities, ranging from construction site monitoring to immersive visualisations. Despite an enormous amount of data being captured, this goal remains a great challenge due to several factors. First, the captured data is often incomplete due to occlusions or limited sensor range. Second, captured data quickly becomes outdated, while making numerous consecutive full recordings is very time-consuming and expensive. Finally, the data coming from lower-end, cheaper capture devices is rarely used due to a lack of a proper framework to incorporate them into larger datasets. A way to combat these shortcomings is to make better use of the lower-end data. While these sensors lack range and precision, the increased recording speed and lighter data load is a big advantage",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_158",
    "authors": "Taisei Omine, Yuki Morimoto, Reiji Tsuruno",
    "title": "Automatic Generation of a 3D Braid Hair Model From a Single Image",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543216",
    "pdf_link": null,
    "abstract": "2 METHODIn our method, estimation models determine the key points, thickness, and frequency of braids, and hair flow, and an algorithm generates a hair model based on them. Note that to simplify the estimation and increase accuracy, portrait images for inputs for datasets and test workflow are limited to those in which the tips of the braids are roughly visible. The outline is as follows:",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_564",
    "authors": "Jiafeng Liu, Haoyang Shi, Siyuan Zhang, Yin Yang, Chongyang Ma, Weiwei Xu",
    "title": "Automatic Quantization for Physics-based Simulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530154",
    "pdf_link": null,
    "abstract": "Quantization has proven effective in high-resolution and large-scale simulations, which benefit from bit-level memory saving. However, identifying a quantization scheme that meets the requirement of both precision and memory efficiency requires trial and error. In this paper, we propose a novel framework to allow users to obtain a quantization scheme by simply specifying either an error bound or a memory compression rate. Based on the error propagation theory, our method takes advantage of auto-diff to estimate the contributions of each quantization operation to the total error. We formulate the task as a constrained optimization problem, which can be efficiently solved with analytical formulas derived for the linearized objective function. Our workflow extends the Taichi compiler and introduces dithering to improve the precision of quantized simulations. We demonstrate the generality and efficiency of our method via several challenging examples of physics-based simulation, which achieves up to 2.5× memory compression without noticeable degradation of visual quality in the results. Our code and data are available at https://github.com/Hanke98/AutoQantizer.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_297",
    "authors": "Fangzhou Hong, Mingyuan Zhang, Liang Pan, Zhongang Cai, Lei Yang, Ziwei Liu",
    "title": "AvatarCLIP: Zero-shot Text-driven Generation and Animation of 3D Avatars",
    "paper_url": "https://arxiv.org/abs/2205.08535",
    "pdf_link": null,
    "abstract": "3D avatar creation plays a crucial role in the digital age. However, the whole production process is prohibitively time-consuming and labor-intensive. To democratize this technology to a larger audience, we propose AvatarCLIP, a zero-shot text-driven framework for 3D avatar generation and animation. Unlike professional software that requires expert knowledge, AvatarCLIP empowers layman users to customize a 3D avatar with the desired shape and texture, and drive the avatar with the described motions using solely natural languages. Our key insight is to take advantage of the powerful vision-language model CLIP for supervising neural human generation, in terms of 3D geometry, texture and animation. Specifically, driven by natural language descriptions, we initialize 3D human geometry generation with a shape VAE network. Based on the generated 3D human shapes, a volume rendering model is utilized to further facilitate geometry sculpting and texture generation. Moreover, by leveraging the priors learned in the motion VAE, a CLIP-guided reference-based motion synthesis method is proposed for the animation of the generated 3D avatar. Extensive qualitative and quantitative experiments validate the effectiveness and generalizability of AvatarCLIP on a wide range of avatars. Remarkably, AvatarCLIP can generate unseen 3D avatars with novel animations, achieving superior zero-shot capability.",
    "scholar_publication": "arXiv preprint arXiv …, 2022 - arxiv.org"
  },
  {
    "paper_id": "papers_451",
    "authors": "Yuting Yang, Connelly Barnes, Andrew Adams, Adam Finkelstein",
    "title": "A𝛿: Autodiff for Discontinuous Programs — Applied to Shaders",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530125",
    "pdf_link": null,
    "abstract": "Over the last decade, automatic differentiation (AD) has profoundly impacted graphics and vision applications --- both broadly via deep learning and specifically for inverse rendering. Traditional AD methods ignore gradients at discontinuities, instead treating functions as continuous. Rendering algorithms intrinsically rely on discontinuities, crucial at object silhouettes and in general for any branching operation. Researchers have proposed fully-automatic differentiation approaches for handling discontinuities by restricting to affine functions, or semi-automatic processes restricted either to invertible functions or to specialized applications like vector graphics. This paper describes a compiler-based approach to extend reverse mode AD so as to accept arbitrary programs involving discontinuities. Our novel gradient rules generalize differentiation to work correctly, assuming there is a single discontinuity in a local neighborhood, by approximating the prefiltered gradient over a box kernel oriented along a 1D sampling axis. We describe when such approximation rules are first-order correct, and show that this correctness criterion applies to a relatively broad class of functions. Moreover, we show that the method is effective in practice for arbitrary programs, including features for which we cannot prove correctness. We evaluate this approach on procedural shader programs, where the task is to optimize unknown parameters in order to match a target image, and our method outperforms baselines in terms of both convergence and efficiency. Our compiler outputs gradient programs in TensorFlow, PyTorch (for quick prototypes) and Halide with an optional auto-scheduler (for efficiency). The compiler also outputs GLSL that renders the target image, allowing users to interactively modify and animate the shader, which would otherwise be cumbersome in other representations such as triangle meshes or vector art.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_611",
    "authors": "Alexander Vilesov, Pradyumna Chari, Adnan Armouti, Anirudh Bindiganavale Harish, Kimaya Kulkarni, Ananya Deoghare, Laleh Jalilian, Achuta Kadambi",
    "title": "Blending Camera and 77 GHz Radar Sensing for Equitable, Robust Plethysmography",
    "paper_url": "https://www.academia.edu/download/91210543/3528223.pdf",
    "pdf_link": null,
    "abstract": "Remote estimation of vital signs has gained growing relevance in recent years. The COVID-19 pandemic has further emphasized the need for rapid and reliable monitoring of health indicators. Remote plethysmography, the non-contact monitoring of blood volume flow in the human body, is a critical technological step in this direction. Camera-based remote plethysmography is a rapidly developing field. Most methods utilize small changes in the facial skin color as a function of dermal blood volume to capture pulse rate trends [Ahad et al. 2021; Wu et al. 2012]. Over the years, a broad range of methods have been proposed, ranging from physics-based",
    "scholar_publication": "ACM Trans …, 2022 - academia.edu"
  },
  {
    "paper_id": "pos_192",
    "authors": "Mikihito Matsuura, Koya Narumi, Toshiki Aoki, Yuta Noma, Kazutaka Nakashima, Yoshihiro Kawahara, Takeo Igarashi",
    "title": "Blow-up Print: Rapidly 3D Printing Inflatable Objects in the Compressed State",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543230",
    "pdf_link": null,
    "abstract": "3D printing is becoming a widely used technology not only for prototyping but for industrial fabrication. People have access to several types of 3D printing methods, such as fused deposition modeling (FDM), stereolithography apparatus (SLA), and selective laser sintering (SLS), to build physical objects with diverse material properties through different processes. Despite such options, we generally suffer from longer printing time, support material consumption, and/or storage space as a printed object gets bigger. Thus, researchers have recently been working on achieving 3D objects while reducing these issues. For example, Yu et al.[2017] decomposed an input 3D object into a telescopic structure that can be used for better storage and transportation. Likewise, Pop-up Print [Noma et al. 2020] 3D printed objects in the compact folded state to reduce printing time and support material consumption. However, these methods are applicable only for the tapered region of the given 3D model and the resulting design space is limited. On the other hand, pneumatically actuated inflatables have been explored to achieve deployable structures. For example, Panetta et al.[2021] achieved double-curved shape by inversely computing transformation of planar inflatable channels, which is fabricable by 2D fusing process. Also, Skouras et al.[2012] proposed the method to computationally design balloons inflatable into the target shapes. Built upon these prior works, we propose Blow-up Print, the method to print a squashed 3D model and restore the original",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_339",
    "authors": "Panayiotis Charalambous, Andreas Panayiotou, Marilena Lemonari, Yiorgos Chrysanthou, Theodoros Kyriakou",
    "title": "CCP: Configurable Crowd Profiles",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530712",
    "pdf_link": null,
    "abstract": "… We propose a curriculum-based approach to train crowds by … profiles concurrently, we can then create large-scale crowd simulations capable of exhibiting diverse behaviors (profiles) …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_745",
    "authors": "Rameen Abdal, Peihao Zhu, John Femiani, Niloy Mitra, Peter Wonka",
    "title": "CLIP2StyleGAN: Unsupervised Extraction of StyleGAN Edit Directions",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530747",
    "pdf_link": null,
    "abstract": "The success of StyleGAN has enabled unprecedented semantic editing capabilities, on both synthesized and real images. However, such editing operations are either trained with semantic supervision or annotated manually by users. In another development, the CLIP architecture has been trained with internet-scale loose image and text pairings, and has been shown to be useful in several zero-shot learning settings. In this work, we investigate how to effectively link the pretrained latent spaces of StyleGAN and CLIP, which in turn allows us to automatically extract semantically-labeled edit directions from StyleGAN, finding and naming meaningful edit operations, in a fully unsupervised setup, without additional human guidance. Technically, we propose two novel building blocks; one for discovering interesting CLIP directions and one for semantically labeling arbitrary directions in CLIP latent space. The setup does not assume any pre-determined labels and hence we do not require any additional supervised text/attributes to build the editing framework. We evaluate the effectiveness of the proposed method and demonstrate that extraction of disentangled labeled StyleGAN edit directions is indeed possible, revealing interesting and non-trivial edit directions.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_179",
    "authors": "Yael Vinker, Ehsan Pajouheshgar, Jessica Y. Bo, Roman Christian Bachmann, Amit Bermano, Daniel Cohen-Or, Amir Zamir, Ariel Shamir",
    "title": "CLIPasso: Semantically Aware Object Sketching",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530068",
    "pdf_link": null,
    "abstract": "Abstraction is at the heart of sketching due to the simple and minimal nature of line drawings. Abstraction entails identifying the essential visual properties of an object or scene, which requires semantic understanding and prior knowledge of high-level concepts. Abstract depictions are therefore challenging for artists, and even more so for machines. We present CLIPasso, an object sketching method that can achieve different levels of abstraction, guided by geometric and semantic simplifications. While sketch generation methods often rely on explicit sketch datasets for training, we utilize the remarkable ability of CLIP (Contrastive-Language-Image-Pretraining) to distill semantic concepts from sketches and images alike. We define a sketch as a set of Bézier curves and use a differentiable rasterizer to optimize the parameters of the curves directly with respect to a CLIP-based perceptual loss. The abstraction degree is controlled by varying the number of strokes. The generated sketches demonstrate multiple levels of abstraction while maintaining recognizability, underlying structure, and essential visual components of the subject drawn.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_111",
    "authors": "Seung-Hwan Baek, Noah Walsh, Ilya Chugunov, Zheng Shi, Felix Heide, Noah Walsh, Ilya Chugunov, Zheng Shi",
    "title": "Centimeter-wave Free-space Neural Time-of-flight Imaging",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3522671",
    "pdf_link": null,
    "abstract": "Depth sensors have emerged as a cornerstone sensor modality with diverse applications in personal hand-held devices, robotics, scientific imaging, autonomous vehicles, and more. In particular, correlation Time-of-Flight (ToF) sensors have found widespread adoption for meter-scale indoor applications such as object tracking and pose estimation. While they offer high depth resolution at competitive costs, the precision of these indirect ToF sensors is fundamentally limited by their modulation contrast, which is in turn limited by the effects of photo-conversion noise. In contrast, optical interferometric methods can leverage short illumination modulation wavelengths to achieve depth precision three orders of magnitude greater than ToF, but typically find their range is restricted to the sub-centimeter. In this work, we merge concepts from both correlation ToF design and interferometric imaging; a step towards bridging the gap between these methods. We propose a computational ToF imaging method that optically computes the GHz ToF correlation signal in free space before photo-conversion. To acquire a depth map, we scan a scene point-wise and computationally unwrap the collected correlation measurements. Specifically, we repurpose electro-optical modulators used in optical communication for ToF imaging with centimeter-wave signals, and achieve all-optical correlation at 7.15 GHz and 14.32 GHz modulation frequencies. While GHz modulation frequencies increase depth precision, these high modulation rates also pose a technical challenge. They result in dozens of wraps per meter which cannot be estimated robustly by existing phase unwrapping methods. We tackle this problem with a proposed segmentation-inspired phase unwrapping network, which exploits the correlation of adjacent GHz phase measurements to classify regions into their respective wrap counts. We validate this method in simulation and experimentally, and demonstrate precise depth sensing using centimeter wave modulation that is robust to surface texture and ambient light. Compared to existing analog demodulation methods, the proposed system outperforms all of them across all tested scenarios. CCS Concepts: • Computing methodologies;",
    "scholar_publication": "ACM Transactions on …, 2023 - dl.acm.org"
  },
  {
    "paper_id": "papers_150",
    "authors": "Fernando de Goes, William Sheffler, Kurt Fleischer",
    "title": "Character Articulation Through Profile Curves",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530060",
    "pdf_link": null,
    "abstract": "Computer animation relies heavily on rigging setups that articulate character surfaces through a broad range of poses. Although many deformation strategies have been proposed over the years, constructing character rigs is still a cumbersome process that involves repetitive authoring of point weights and corrective sculpts with limited and indirect shaping controls. This paper presents a new approach for character articulation that produces detail-preserving deformations fully controlled by 3D curves that profile the deforming surface. Our …",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_528",
    "authors": "Michal Piovarci, Michael Foshey, Jie Xu, Timothy Erps, Vahid Babaei, Piotr Didyk, Wojciech Matusik, Szymon Rusinkiewicz, Bernd Bickel",
    "title": "Closed-loop Control of Direct Ink Writing via Reinforcement Learning",
    "paper_url": "https://arxiv.org/abs/2201.11819",
    "pdf_link": null,
    "abstract": "Enabling additive manufacturing to employ a wide range of novel, functional materials can be a major boost to this technology. However, making such materials printable requires painstaking trial-and-error by an expert operator, as they typically tend to exhibit peculiar rheological or hysteresis properties. Even in the case of successfully finding the process parameters, there is no guarantee of print-to-print consistency due to material differences between batches. These challenges make closed-loop feedback an attractive option where …",
    "scholar_publication": "arXiv preprint arXiv …, 2022 - arxiv.org"
  },
  {
    "paper_id": "papers_164",
    "authors": "Peihan Tu, Li-Yi Wei, Matthias Zwicker",
    "title": "Clustered Vector Textures",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530062",
    "pdf_link": null,
    "abstract": "… vector patterns with diverse shapes and structured local interactions via a sample-based representation. Our main idea is adding explicit clustering as … of structured vector textures. Our …",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_114",
    "authors": "Haisen Zhao, Max Willsey, Amy Zhu, Chandrakana Nandi, Zachary Tatlock, Justin Solomon, Adriana Schulz, Amy Zhu",
    "title": "Co-optimization of Design and Fabrication Plans for Carpentry",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3508499",
    "pdf_link": null,
    "abstract": "Past work on optimizing fabrication plans given a carpentry design can provide Pareto-optimal plans trading off between material waste, fabrication time, precision, and other considerations. However, when developing fabrication plans, experts rarely restrict to a single design, instead considering families of design variations, sometimes adjusting designs to simplify fabrication. Jointly exploring the design and fabrication plan spaces for each design is intractable using current techniques. We present a new approach to jointly optimize design and fabrication plans for carpentered objects. To make this bi-level optimization tractable, we adapt recent work from program synthesis based on equality graphs (e-graphs), which encode sets of equivalent programs. Our insight is that subproblems within our bi-level problem share significant substructures. By representing both designs and fabrication plans in a new bag of parts (BOP) e-graph, we amortize the cost of optimizing design components shared among multiple candidates. Even using BOP e-graphs, the optimization space grows quickly in practice. Hence, we also show how a feedback-guided search strategy dubbed Iterative Contraction and Expansion on E-graphs (ICEE) can keep the size of the e-graph manageable and direct the search towards promising candidates. We illustrate the advantages of our pipeline through examples from the carpentry domain.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_597",
    "authors": "Amir Hossein Rabbani, Jean-Philippe Guertin, Damien Rioux-Lavoie, Arnaud Schoentgen, Kaitai Tong, Alexandre Sirois-Vigneux, Derek Nowrouzezahrai",
    "title": "Compact Poisson Filters for Fast Fluid Simulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530737",
    "pdf_link": null,
    "abstract": "Poisson equations appear in many graphics settings including, but not limited to, physics-based fluid simulation. Numerical solvers for such problems strike context-specific memory, performance, stability and accuracy trade-offs. We propose a new Poisson filter-based solver that balances between the strengths of spectral and iterative methods. We derive universal Poisson kernels for forward and inverse Poisson problems, leveraging careful adaptive filter truncation to localize their extent, all while maintaining stability and accuracy. Iterative composition of our compact filters improves solver iteration time by orders-of-magnitude compared to optimized linear methods. While motivated by spectral formulations, we overcome important limitations of spectral methods while retaining many of their desirable properties. We focus on the application of our method to high-performance and high-fidelity fluid simulation, but we also demonstrate its broader applicability. We release our source code at https://github.com/Ubisoft-LaForge/CompactPoissonFilters .",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_500",
    "authors": "Param Hanji, Rafal Mantiuk, Gabriel Eilertsen, Saghi Hajisharif, Jonas Unger",
    "title": "Comparison of Single-image HDR Reconstruction Methods — The Caveats of Quality Assessment",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530729",
    "pdf_link": null,
    "abstract": "As the problem of reconstructing high dynamic range (HDR) images from a single exposure has attracted much research effort, it is essential to provide a robust protocol and clear guidelines on how to evaluate and compare new methods. In this work, we compared six recent single image HDR reconstruction (SI-HDR) methods in a subjective image quality experiment on an HDR display. We found that only two methods produced results that are, on average, more preferred than the unprocessed single exposure images. When the same methods are evaluated using image quality metrics, as typically done in papers, the metric predictions correlate poorly with subjective quality scores. The main reason is a significant tone and color difference between the reference and reconstructed HDR images. To improve the predictions of image quality metrics, we propose correcting for the inaccuracies of the estimated camera response curve before computing quality values. We further analyze the sources of prediction noise when evaluating SI-HDR methods and demonstrate that existing metrics can reliably predict only large quality differences.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_703",
    "authors": "Kenshi Takayama",
    "title": "Compatible Intrinsic Triangulations",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530175",
    "pdf_link": null,
    "abstract": "… compatible triangulations of two polygons in order to create a smooth geometric transformation between them. Compared with existing methods, our approach creates triangulations of …",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_222",
    "authors": "Haoxiang Guo, Shilin Liu, Hao Pan, Yang Liu, Xin Tong, Baining Guo",
    "title": "ComplexGen: CAD Reconstruction by B-rep Chain Complex Generation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530078",
    "pdf_link": null,
    "abstract": "We view the reconstruction of CAD models in the boundary representation (B-Rep) as the detection of geometric primitives of different orders, i.e., vertices, edges and surface patches, and the correspondence of primitives, which are holistically modeled as a chain complex, and show that by modeling such comprehensive structures more complete and regularized reconstructions can be achieved. We solve the complex generation problem in two steps. First, we propose a novel neural framework that consists of a sparse CNN encoder for input point cloud processing and a tri-path transformer decoder for generating geometric primitives and their mutual relationships with estimated probabilities. Second, given the probabilistic structure predicted by the neural network, we recover a definite B-Rep chain complex by solving a global optimization maximizing the likelihood under structural validness constraints and applying geometric refinements. Extensive tests on large scale CAD datasets demonstrate that the modeling of B-Rep chain complex structure enables more accurate detection for learning and more constrained reconstruction for optimization, leading to structurally more faithful and complete CAD B-Rep models than previous results.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_246",
    "authors": "Mehmet Oguz Derin, Takahiro Harada, Yusuke Takeda, Yasuhiro Iba",
    "title": "Compression and Interactive Visualization of Terabyte Scale Volumetric RGBA Data With Voxel-scale Details",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543256",
    "pdf_link": null,
    "abstract": "We present a compressed volumetric data structure and traversal algorithm that interactively visualizes complete terabyte-scale scientific data. Previous methods rely on heavy approximation and do not provide individual sample-level representation when going beyond gigabytes. We develop an extensible pipeline that makes the data streamable on GPU using compact pointers and a compression algorithm based on wavelet transform. The resulting approach renders high-resolution captures under varying sampling characteristics in real-time.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_192",
    "authors": "Rulin Chen, Ziqi Wang, Peng Song, Bernd Bickel",
    "title": "Computational Design of High-level Interlocking Puzzles",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530071",
    "pdf_link": null,
    "abstract": "Interlocking puzzles are intriguing geometric games where the puzzle pieces are held together based on their geometric arrangement, preventing the puzzle from falling apart. High-level-of-difficulty, or simply high-level, interlocking puzzles are a subclass of interlocking puzzles that require multiple moves to take out the first subassembly from the puzzle. Solving a high-level interlocking puzzle is a challenging task since one has to explore many different configurations of the puzzle pieces until reaching a configuration where the first subassembly can be taken out. Designing a high-level interlocking puzzle with a user-specified level of difficulty is even harder since the puzzle pieces have to be interlocking in all the configurations before the first subassembly is taken out. In this paper, we present a computational approach to design high-level interlocking puzzles. The core idea is to represent all possible configurations of an interlocking puzzle as well as transitions among these configurations using a rooted, undirected graph called a disassembly graph and leverage this graph to find a disassembly plan that requires a minimal number of moves to take out the first subassembly from the puzzle. At the design stage, our algorithm iteratively constructs the geometry of each puzzle piece to expand the disassembly graph incrementally, aiming to achieve a user-specified level of difficulty. We show that our approach allows efficient generation of high-level interlocking puzzles of various shape complexities, including new solutions not attainable by state-of-the-art approaches.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_146",
    "authors": "Benjamin Jones, Yuxuan Mei, Haisen Zhao, Taylor Gotfrid, Jennifer Mankoff, Adriana Schulz, Benjamin Jones",
    "title": "Computational Design of Knit Templates",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3488006",
    "pdf_link": null,
    "abstract": "We present an interactive design system for knitting that allows users to create template patterns that can be fabricated using an industrial knitting machine. Our interactive design tool is novel in that it allows direct control of key knitting design axes we have identified in our formative study and does so consistently across the variations of an input parametric template geometry. This is achieved with two key technical advances. First, we present an interactive meshing tool that lets users build a coarse quadrilateral mesh that adheres to their knit design guidelines. This solution ensures consistency across the parameter space for further customization over shape variations and avoids helices, promoting knittability. Second, we lift and formalize low-level machine knitting constraints to the level of this coarse quad mesh. This enables us to not only guarantee hand- and machine-knittability, but also provides automatic design assistance through auto-completion and suggestions. We show the capabilities through a set of fabricated examples that illustrate the effectiveness of our approach in creating a wide variety of objects and interactively exploring the space of design variations.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_612",
    "authors": "Milin Kodnongbua, Ian Good, Yu Lou, Jeffrey Lipton, Adriana Schulz",
    "title": "Computational Design of Passive Grippers",
    "paper_url": "https://arxiv.org/abs/2306.03174",
    "pdf_link": null,
    "abstract": "This work proposes a novel generative design tool for passive grippers -- robot end effectors that have no additional actuation and instead leverage the existing degrees of freedom in a robotic arm to perform grasping tasks. Passive grippers are used because they offer interesting trade-offs between cost and capabilities. However, existing designs are limited in the types of shapes that can be grasped. This work proposes to use rapid-manufacturing and design optimization to expand the space of shapes that can be passively grasped. Our novel generative design algorithm takes in an object and its positioning with respect to a robotic arm and generates a 3D printable passive gripper that can stably pick the object up. To achieve this, we address the key challenge of jointly optimizing the shape and the insert trajectory to ensure a passively stable grasp. We evaluate our method on a testing suite of 22 objects (23 experiments), all of which were evaluated with physical experiments to bridge the virtual-to-real gap. Code and data are at https://homes.cs.washington.edu/~milink/passive-gripper/",
    "scholar_publication": "arXiv preprint arXiv …, 2023 - arxiv.org"
  },
  {
    "paper_id": "paperstog_113",
    "authors": "Kang Wu, Renjie Chen, Xiao-Ming Fu, Ligang Liu, Renjie Chen",
    "title": "Computational Mirror Cup and Saucer Art",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3517120",
    "pdf_link": null,
    "abstract": "In the mirror cup and saucer art created by artists Yul Cho and Sang-Ha Cho, part of the saucer is directly visible to the viewer, while the other part of the saucer is occluded and can only be seen as a reflection through a mirror cup. Thus, viewers see an image directly on the saucer and another image on the mirror cup; however, the existing art design is limited to wavelike saucers. In this work, we propose a general computational framework for mirror cup and saucer art design. As input, we take from the user one image for the direct view, one image for the reflected view, and the base shape of the saucer. Our algorithm then generates a suitable saucer shape by deforming the input shape. We formulate this problem as a constrained optimization for the saucer surface. Our framework solves for the fine geometry details on the base shape along with its texture, such that when a mirror cup is placed on the saucer, the user-specified images are observed as direct and reflected views. Through extensive experiments, we demonstrate the effectiveness of our framework and the great design flexibility that it offers to users. We further validate the produced art pieces by fabricating the colored saucers using three-dimensional printing.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_131",
    "authors": "Jian Liu, Shiqing Xin, Xifeng Gao, Kaihang Gao, Kai Xu, Baoquan Chen, Changhe Tu, Xifeng Gao",
    "title": "Computational Object-wrapping Rope Nets",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3476829",
    "pdf_link": null,
    "abstract": "Wrapping objects using ropes is a common practice in our daily life. However, it is difficult to design and tie ropes on a 3D object with complex topology and geometry features while ensuring wrapping security and easy operation. In this article, we propose to compute a rope net that can tightly wrap around various 3D shapes. Our computed rope net not only immobilizes the object but also maintains the load balance during lifting. Based on the key observation that if every knot of the net has four adjacent curve edges, then only a single rope is needed to construct the entire net. We reformulate the rope net computation problem into a constrained curve network optimization. We propose a discrete-continuous optimization approach, where the topological constraints are satisfied in the discrete phase and the geometrical goals are achieved in the continuous stage. We also develop a hoist planning to pick anchor points so that the rope net equally distributes the load during hoisting. Furthermore, we simulate the wrapping process and use it to guide the physical rope net construction process. We demonstrate the effectiveness of our method on 3D objects with varying geometric and topological complexity. In addition, we conduct physical experiments to demonstrate the practicability of our method.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_532",
    "authors": "Nico Pietroni, Corentin Dumery, Raphael Falque, Mark Liu, Teresa Vidal-Calleja, Olga Sorkine-Hornung",
    "title": "Computational Pattern Making From 3D Garment Models",
    "paper_url": "https://corentindumery.github.io/projects/computational-pattern-making-compressed.pdf",
    "pdf_link": null,
    "abstract": "In this work, we propose a method for automatically creating a sewing pattern for a given 3D model of a garment. In the fashion industry, the garment creation process starts from the 2D domain: The pattern maker creates the 2D sewing pattern using traditional, often tacit knowledge [Chen 1998], established templates and a few standard measurements, such as waist circumference, shoulder width, etc. The cut fabric pieces are then sewn together to form the garment. Designers may work with mannequins to experiment with the desired shape and draping of the fabric in the physical 3D space, but the ultimate determination of the garment shape comes from the 2D pattern. Also, in digital garment design",
    "scholar_publication": "ACM Trans …, 2022 - corentindumery.github.io"
  },
  {
    "paper_id": "papers_423",
    "authors": "Mo Li, Qing Fang, Wenqing Ouyang, Ligang Liu, Xiao-Ming Fu",
    "title": "Computing Sparse Integer-constrained Cones for Conformal Parameterizations",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530118",
    "pdf_link": null,
    "abstract": "We propose a novel method to generate sparse integer-constrained cone singularities with low distortion constraints for conformal parameterizations. Inspired by [Fang et al. 2021; Soliman et al. 2018], the cone computation is formulated as a constrained optimization problem, where the objective is the number of cones measured by the ℓ0-norm of Gaussian curvature of vertices, and the constraint is to restrict the cone angles to be multiples of π/2 and control the distortion while ensuring that the Yamabe equation holds. Besides, the holonomy angles for the non-contractible homology loops are additionally required to be multiples of π/2 for achieving rotationally seamless conformal parameterizations. The Douglas-Rachford (DR) splitting algorithm is used to solve this challenging optimization problem, and our success relies on two key components. First, replacing each integer constraint with the intersection of a box set and a sphere enables us to manage the subproblems in DR splitting update steps in the continuous domain. Second, a novel solver is developed to optimize the ℓ0-norm without any approximation. We demonstrate the effectiveness and feasibility of our algorithm on a data set containing 3885 models. Compared to state-of-the-art methods, our method achieves a better tradeoff between the number of cones and the parameterization distortion.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_123",
    "authors": "Hong Deng, Yang Liu, Beibei Wang, Jian Yang, Lei Ma, Nicolas Holzschuch, Ling-Qi Yan, Ling-Qi Yan",
    "title": "Constant-cost Spatio-angular Prefiltering of Glinty Appearance Using Tensor Decomposition",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3507915",
    "pdf_link": null,
    "abstract": "The detailed glinty appearance from complex surface microstructures enhances the level of realism but is both - and time-consuming to render, especially when viewed from far away (large spatial coverage) and/or illuminated by area lights (large angular coverage). In this article, we formulate the glinty appearance rendering process as a spatio-angular range query problem of the Normal Distribution Functions (NDFs), and introduce an efficient spatio-angular prefiltering solution to it. We start by exhaustively precomputing all possible NDFs with differently sized positional coverages. Then we compress the precomputed data using tensor rank decomposition, which enables accurate and fast angular range queries. With our spatio-angular prefiltering scheme, we are able to solve both the storage and performance issues at the same time, leading to efficient rendering of glinty appearance with both constant storage and constant performance, regardless of the range of spatio-angular queries. Finally, we demonstrate that our method easily applies to practical rendering applications that were traditionally considered difficult. For example, efficient bidirectional reflection distribution function evaluation accurate NDF importance sampling, fast global illumination between glinty objects, high-frequency preserving rendering with environment lighting, and tile-based synthesis of glinty appearance.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_775",
    "authors": "Cristian Romero, Dan Casas, Maurizio Chiaramonte, Miguel A. Otaduy",
    "title": "Contact-centric Deformation Learning",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530182",
    "pdf_link": null,
    "abstract": "… -driven deformation detail. We learn contact deformations in a contact-centric manner, … of the deformable object, and subsequently learn highly complex deformations. For this real-time …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_111",
    "authors": "Erwin Wu, Chen-Chieh Liao, Ruofan Liu, Hideki Koike",
    "title": "Context-aware Risk Degree Prediction for Smartphone Zombies",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543197",
    "pdf_link": null,
    "abstract": "Using smartphones while walking is becoming a social problem. Recent works try to support this issue by different warning systems. However, most only focus on detecting obstacles, without considering the risk to the user. In this paper, we propose a deep learning-based context-aware risk prediction system using a built-in camera on smartphones, aiming to notify ”smombies” by a risk-degree based algorithm. The proposed system both estimates the risk degree of a potential obstacle and the user’s status, which can also be used for distracted driving or visually impaired people.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_434",
    "authors": "Mohammad Sina Nabizadeh, Stephanie Wang, Ravi Ramamoorthi, Albert Chern",
    "title": "Covector Fluids",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530120",
    "pdf_link": null,
    "abstract": "… vorticity-based fluid solvers suffer from performance drawbacks. We propose a new velocity-based fluid solver derived from a reformulated Euler equation using covectors. Our method …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_594",
    "authors": "Yifang Men, Yuan Yao, Miaomiao Cui, Zhouhui Lian, Xuansong Xie",
    "title": "DCT-Net: Domain-calibrated Translation for Portrait Stylization",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530159",
    "pdf_link": null,
    "abstract": "This paper introduces DCT-Net, a novel image translation architecture for few-shot portrait stylization. Given limited style exemplars (~100), the new architecture can produce high-quality style transfer results with advanced ability to synthesize high-fidelity contents and strong generality to handle complicated scenes (e.g., occlusions and accessories). Moreover, it enables full-body image translation via one elegant evaluation network trained by partial observations (i.e., stylized heads). Few-shot learning based style transfer is challenging since the learned model can easily become overfitted in the target domain, due to the biased distribution formed by only a few training examples. This paper aims to handle the challenge by adopting the key idea of \"calibration first, translation later\" and exploring the augmented global structure with locally-focused translation. Specifically, the proposed DCT-Net consists of three modules: a content adapter borrowing the powerful prior from source photos to calibrate the content distribution of target samples; a geometry expansion module using affine transformations to release spatially semantic constraints; and a texture translation module leveraging samples produced by the calibrated distribution to learn a fine-grained conversion. Experimental results demonstrate the proposed method's superiority over the state of the art in head stylization and its effectiveness on full image translation with adaptive deformations. Our code is publicly available at https://github.com/menyifang/DCT-Net.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_505",
    "authors": "Albert Matveev, Ruslan Rakhimov, Alexey Artemov, Gleb Bobrovskikh, Vage Egiazarian, Emil Bogomolov, Daniele Panozzo, Denis Zorin, Evgeny Burnaev",
    "title": "DEF: Deep Estimation of Sharp Geometric Features in 3D Shapes",
    "paper_url": "https://par.nsf.gov/biblio/10357187",
    "pdf_link": null,
    "abstract": "We propose Deep Estimators of Features (DEFs), a learning-based framework for predicting sharp geometric features in sampled 3D shapes. Differently from existing data-driven methods, which reduce this problem to feature classification, we propose to regress a scalar field representing the distance from point samples to the closest feature line on local patches. Our approach is the first that scales to massive point clouds by fusing distance-to-feature estimates obtained on individual patches. We extensively evaluate our approach against related state-of-the-art methods on newly proposed synthetic and real-world 3D CAD model benchmarks. Our approach not only outperforms these (with improvements in Recall and False Positives Rates), but generalizes to real-world scans after training our model on synthetic data and fine-tuning it on a small dataset of scanned data. We demonstrate a downstream application, where we reconstruct an explicit representation of straight and curved sharp feature lines from range scan data. We make code, pre-trained models, and our training and evaluation datasets available at https://github.com/artonson/def.",
    "scholar_publication": "ACM Transactions on …, 2022 - par.nsf.gov"
  },
  {
    "paper_id": "paperstog_153",
    "authors": "Jie Yang, Kaichun Mo, Yu-Kun Lai, Leonidas J. Guibas, Lin Gao, Yu-Kun Lai",
    "title": "DSG-Net: Learning Disentangled Structure and Geometry for 3D Shape Generation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3526212",
    "pdf_link": null,
    "abstract": "3D shape generation is a fundamental operation in computer graphics. While significant progress has been made, especially with recent deep generative models, it remains a challenge to synthesize high-quality shapes with rich geometric details and complex structures, in a controllable manner. To tackle this, we introduce DSG-Net, a deep neural network that learns a disentangled structured & geometric mesh representation for 3D shapes, where two key aspects of shapes, geometry and structure, are encoded in a synergistic manner to ensure plausibility of the generated shapes, while also being disentangled as much as possible. This supports a range of novel shape generation applications with disentangled control, such as interpolation of structure (geometry) while keeping geometry (structure) unchanged. To achieve this, we simultaneously learn structure and geometry through variational autoencoders (VAEs) in a hierarchical manner for both, with bijective mappings at each level. In this manner, we effectively encode geometry and structure in separate latent spaces, while ensuring their compatibility: the structure is used to guide the geometry and vice versa. At the leaf level, the part geometry is represented using a conditional part VAE, to encode high-quality geometric details, guided by the structure context as the condition. Our method not only supports controllable generation applications, but also produces high-quality synthesized shapes, outperforming state-of-the-art methods.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_501",
    "authors": "Krzysztof Wolski, Fangcheng Zhong, Karol Myszkowski, Rafal Mantiuk",
    "title": "Dark Stereo: Improving Depth Perception Under Low Luminance",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530136",
    "pdf_link": null,
    "abstract": "It is often desirable or unavoidable to display Virtual Reality (VR) or stereoscopic content at low brightness. For example, a dimmer display reduces the flicker artefacts that are introduced by low-persistence VR headsets. It also saves power, prolongs battery life, and reduces the cost of a display or projection system. Additionally, stereo movies are usually displayed at relatively low luminance due to polarization filters or other optical elements necessary to separate two views. However, the binocular depth cues become less reliable at low luminance. In this paper, we propose a model of stereo constancy that predicts the precision of binocular depth cues for a given contrast and luminance. We use the model to design a novel contrast enhancement algorithm that compensates for the deteriorated depth perception to deliver good-quality stereoscopic images even for displays of very low brightness.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_398",
    "authors": "Seunghwan Lee, Jehee Lee, Phil Sik Chang",
    "title": "Deep Compliant Control",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530719",
    "pdf_link": null,
    "abstract": "… Figure 1: Our compliant controller learns dynamic interactions with environments. (Left to right) Hand-in-hand running, chicken hopping game, opening a door, and balancing a ball. …",
    "scholar_publication": "ACM SIGGRAPH 2022 conference …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_755",
    "authors": "Yucheol Jung, Wonjong Jang, Soongjin Kim, Jiaolong Yang, Xin Tong, Seungyong Lee",
    "title": "Deep Deformable 3D Caricatures With Learned Shape Control",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530748",
    "pdf_link": null,
    "abstract": "A 3D caricature is an exaggerated 3D depiction of a human face. The goal of this paper is to model the variations of 3D caricatures in a compact parameter space so that we can provide a useful data-driven toolkit for handling 3D caricature deformations. To achieve the goal, we propose an MLP-based framework for building a deformable surface model, which takes a latent code and produces a 3D surface. In the framework, a SIREN MLP models a function that takes a 3D position on a fixed template surface and returns a 3D displacement vector for the input position. We create variations of 3D surfaces by learning a hypernetwork that takes a latent code and produces the parameters of the MLP. Once learned, our deformable model provides a nice editing space for 3D caricatures, supporting label-based semantic editing and point-handle-based deformation, both of which produce highly exaggerated and natural 3D caricature shapes. We also demonstrate other applications of our deformable model, such as automatic 3D caricature creation. Our code and supplementary materials are available at https://github.com/ycjungSubhuman/DeepDeformable3DCaricatures.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_732",
    "authors": "Sebastian Starke, Ian Mason, Taku Komura",
    "title": "DeepPhase: Periodic Autoencoders for Learning Motion Phase Manifolds",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530178",
    "pdf_link": null,
    "abstract": "Learning the spatial-temporal structure of body movements is a fundamental problem for character motion synthesis. In this work, we propose a novel neural network architecture called the Periodic Autoencoder that can learn periodic features from large unstructured motion datasets in an unsupervised manner. The character movements are decomposed into multiple latent channels that capture the non-linear periodicity of different body segments while progressing forward in time. Our method extracts a multi-dimensional phase space from full-body motion data, which effectively clusters animations and produces a manifold in which computed feature distances provide a better similarity measure than in the original motion space to achieve better temporal and spatial alignment. We demonstrate that the learned periodic embedding can significantly help to improve neural motion synthesis in a number of tasks, including diverse locomotion skills, style-based movements, dance motion synthesis from music, synthesis of dribbling motions in football, and motion query for matching poses within large animation databases.",
    "scholar_publication": "ACM Transactions on Graphics (ToG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_116",
    "authors": "Feng-Lin Liu, Shu-Yu Chen, Yu-Kun Lai, Chun-Peng Li, Yue-Ren Jiang, Hongbo Fu, Lin Gao",
    "title": "DeepVideoFaceEditing: Sketch-based Deep Editing of Face Videos",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530056",
    "pdf_link": null,
    "abstract": "Sketches, which are simple and concise, have been used in recent deep image synthesis methods to allow intuitive generation and editing of facial images. However, it is nontrivial to extend such methods to video editing due to various challenges, ranging from appropriate manipulation propagation and fusion of multiple editing operations to ensure temporal coherence and visual quality. To address these issues, we propose a novel sketch-based facial video editing framework, in which we represent editing manipulations in latent space and propose specific propagation and fusion modules to generate high-quality video editing results based on StyleGAN3. Specifically, we first design an optimization approach to represent sketch editing manipulations by editing vectors, which are propagated to the whole video sequence using a proper strategy to cope with different editing needs. Specifically, input editing operations are classified into two categories: temporally consistent editing and temporally variant editing. The former (e.g., change of face shape) is applied to the whole video sequence directly, while the latter (e.g., change of facial expression or dynamics) is propagated with the guidance of expression or only affects adjacent frames in a given time window. Since users often perform different editing operations in multiple frames, we further present a region-aware fusion approach to fuse diverse editing effects. Our method supports video editing on facial structure and expression movement by sketch, which cannot be achieved by previous works. Both qualitative and quantitative evaluations show the superior editing ability of our system to existing and alternative solutions.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_643",
    "authors": "Ruben Timotheues Wiersma, Ahmad Nasikun, Elmar Eisemann, Klaus Hildebrandt",
    "title": "DeltaConv: Anisotropic Operators for Geometric Deep Learning on Point Clouds",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530166",
    "pdf_link": null,
    "abstract": "Learning from 3D point-cloud data has rapidly gained momentum, motivated by the success of deep learning on images and the increased availability of 3D data. In this paper, we aim to construct anisotropic convolution layers that work directly on the surface derived from a point cloud. This is challenging because of the lack of a global coordinate system for tangential directions on surfaces. We introduce DeltaConv, a convolution layer that combines geometric operators from vector calculus to enable the construction of anisotropic filters on point clouds. Because these operators are defined on scalar- and vector-fields, we separate the network into a scalar- and a vector-stream, which are connected by the operators. The vector stream enables the network to explicitly represent, evaluate, and process directional information. Our convolutions are robust and simple to implement and match or improve on state-of-the-art approaches on several benchmarks, while also speeding up training and inference.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_226",
    "authors": "Kadir Cenk Alpay, Ahmet Oguz Akyuz",
    "title": "Denoising and Guided Upsampling of Monte Carlo Path Traced Low Resolution Renderings",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543250",
    "pdf_link": null,
    "abstract": "Monte Carlo path tracing generates renderings by estimating the rendering equation using the Monte Carlo method. Studies focus on rendering a noisy image at the original resolution with a low sample per pixel count to decrease the rendering time. Image-space denoising is then applied to produce a visually appealing output. However, denoising process cannot handle the high variance of the noisy image accurately if the sample count is reduced harshly to finish the rendering in a shorter time. We propose a framework that renders the image at a reduced resolution to cast more samples than the harshly lowered sample count in the same time budget. The image is then robustly denoised, and the denoised result is upsampled using original resolution G-buffer of the scene as guidance.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_361",
    "authors": "Kartik Chandra, Tzu-Mao Li, Joshua Tenenbaum, Jonathan Ragan-Kelley",
    "title": "Designing Perceptual Puzzles by Differentiating Probabilistic Programs",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530715",
    "pdf_link": null,
    "abstract": "We design new visual illusions by finding “adversarial examples” for principled models of human perception — specifically, for probabilistic models, which treat vision as Bayesian inference. To perform this search efficiently, we design a differentiable probabilistic programming language, whose API exposes MCMC inference as a first-class differentiable function. We demonstrate our method by automatically creating illusions for three features of human vision: color constancy, size constancy, and face perception.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_306",
    "authors": "Jerry Yin, Chenxi Liu, Rebecca Lin, Nicholas Vining, Helge Rhodin, Alla Sheffer",
    "title": "Detecting Viewer-perceived Intended Vector Sketch Connectivity",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530097",
    "pdf_link": null,
    "abstract": "Many sketch processing applications target precise vector drawings with accurately specified stroke intersections, yet free-form artist drawn sketches are typically inexact: strokes that are intended to intersect often stop short of doing so. While human observers easily perceive the artist intended stroke connectivity, manually, or even semi-manually, correcting drawings to generate correctly connected outputs is tedious and highly time consuming. We propose a novel, robust algorithm that extracts viewer-perceived stroke connectivity from inexact free-form vector drawings by leveraging observations about local and global factors that impact human perception of inter-stroke connectivity. We employ the identified local cues to train classifiers that assess the likelihood that pairs of strokes are perceived as forming end-to-end or T- junctions based on local context. We then use these classifiers within an incremental framework that combines classifier provided likelihoods with a more global, contextual and closure-based, analysis. We demonstrate our method on over 95 diversely sourced inputs, and validate it via a series of perceptual studies; participants prefer our outputs over the closest alternative by a factor of 9 to 1.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_253",
    "authors": "Andreas Schmid, Raphael Wimmer",
    "title": "Determining the Orientation of Low Resolution Images of a De-Bruijn Tracking Pattern With a CNN",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543259",
    "pdf_link": null,
    "abstract": "Inside-out optical 2D tracking of tangible objects on a surface oftentimes uses a high-resolution pattern printed on the surface. While De-Bruijn-torus patterns offer maximum information density, their orientation must be known to decode them. Determining the orientation is challenging for patterns with very fine details; traditional algorithms, such as Hough Lines, do not work reliably. We show that a convolutional neural network can reliably determine the orientation of quasi-random bitmaps with 6 × 6 pixels per block within 36 × 36 pixel images taken by a mouse sensor. Mean error rate is below 2°. Furthermore, our model outperformed Hough Lines in a test with arbitrarily rotated low-resolution rectangles. This implies that CNN-based rotation-detection might also be applicable for more general use cases.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_117",
    "authors": "Floor Verhoeven, Amir Vaxman, Tim Hoffmann, Olga Sorkine-Hornung, Floor Verhoeven",
    "title": "Dev2PQ: Planar Quadrilateral Strip Remeshing of Developable Surfaces",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3510002",
    "pdf_link": null,
    "abstract": "We introduce an algorithm to remesh triangle meshes representing developable surfaces to planar quad dominant meshes. The output of our algorithm consists of planar quadrilateral (PQ) strips that are aligned to principal curvature directions and closely approximate the curved parts of the input developable, and planar polygons representing the flat parts of the input that connect the PQ strips. Developable PQ-strip meshes are useful in many areas of shape modeling, thanks to the simplicity of fabrication from flat sheet material. Unfortunately, they are difficult to model due to their restrictive combinatorics. Other representations of developable surfaces, such as arbitrary triangle or quad meshes, are more suitable for interactive freeform modeling but generally have non-planar faces or are not aligned to principal curvatures. Our method leverages the modeling flexibility of non-ruling-based representations of developable surfaces while still obtaining developable, curvature-aligned PQ-strip meshes. Our algorithm optimizes for a scalar function on the input mesh, such that its isolines are extrinsically straight and align well to the locally estimated ruling directions. The condition that guarantees straight isolines is non-linear of high order and numerically difficult to enforce in a straightforward manner. We devise an alternating optimization method that makes our problem tractable and practical to compute. Our method works automatically on any developable input, including multiple patches and curved folds, without explicit domain decomposition. We demonstrate the effectiveness of our approach on a variety of developable surfaces and show how our remeshing can be used alongside handle-based interactive freeform modeling of developable shapes.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_422",
    "authors": "Zheng-Yu Zhao, Qing Fang, Wenqing Ouyang, Zheng Zhang, Ligang Liu, Xiao-Ming Fu",
    "title": "Developability-driven Piecewise Approximations for Triangular Meshes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530117",
    "pdf_link": null,
    "abstract": "We propose a novel method to compute a piecewise mesh with a few developable patches and a small approximation error for an input triangular mesh. Our key observation is that a deformed mesh after enforcing discrete developability is easily partitioned into nearly developable patches. To obtain the nearly developable mesh, we present a new edge-oriented notion of discrete developability to define a developability-encouraged deformation energy, which is further optimized by the block nonlinear Gauss-Seidel method. The key to successfully applying this optimizer is three types of auxiliary variables. Then, a coarse-to-fine segmentation technique is developed to partition the deformed mesh into a small set of nearly discrete developable patches. Finally, we refine the segmented mesh to reduce the discrete Gaussian curvature while keeping the patches smooth and the approximation error small. In practice, our algorithm achieves a favorable tradeoff between the number of developable patches and the approximation error. We demonstrate the feasibility and practicability of our method over various examples, including seventeen physical manufacturing models with paper.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_222",
    "authors": "Sora Ahn, Shinji Mizuno",
    "title": "Development of 3D Projection Mapping From a Moving Vehicle to Observe From Inside and Outside of the Vehicle",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543247",
    "pdf_link": null,
    "abstract": "2 METHODSIn the proposed projection mapping system, it is necessary to properly reflect the movement of the vehicle in projected images and to be able to observe the projected images three-dimensionally from the inside or outside of the vehicle. Therefore, the image for projection is generated based on 3DCG technology using the same method as our former study [Ahn and Mizuno 2021].",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_153",
    "authors": "Hitomi Miyazaki, Wataru Kurihara, Xu Han, Saki Sakaguchi, Kumiko Kushiyama",
    "title": "Development of Exergame to Resolve Deconditioning in Children With Orthostatic Dysregulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543212",
    "pdf_link": null,
    "abstract": "In this study, we proposed an exergame to reduce resistance to exercise and maintain motivation in adolescents with orthostatic dysregulation. We created a 2D side-scrolling action game in Unity to be played on smartphones. The game is synchronized with exercises that can be done in a lying posture. We analyzed the effect of the game on the feelings of the participants. Our experiments showed that the use of the exergame has a positive effect on the participants’ emotions during exercise.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_150",
    "authors": "Yifei Li, Tao Du, Kui Wu, Jie Xu, Wojciech Matusik, Yifei Li",
    "title": "DiffCloth: Differentiable Cloth Simulation With Dry Frictional Contact",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3527660",
    "pdf_link": null,
    "abstract": "Cloth simulation has wide applications in computer animation, garment design, and robot-assisted dressing. This work presents a differentiable cloth simulator whose additional gradient information facilitates cloth-related applications. Our differentiable simulator extends a state-of-the-art cloth simulator based on Projective Dynamics (PD) and with dry frictional contact [Ly et al. ]. We draw inspiration from previous work [Du et al. ] to propose a fast and novel method for deriving gradients in PD-based cloth simulation with dry frictional contact. Furthermore, we conduct a comprehensive analysis and evaluation of the usefulness of gradients in contact-rich cloth simulation. Finally, we demonstrate the efficacy of our simulator in a number of downstream applications, including system identification, trajectory optimization for assisted dressing, closed-loop control, inverse design, and real-to-sim transfer. We observe a substantial speedup obtained from using our gradient information in solving most of these applications.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_136",
    "authors": "Tao Du, Kui Wu, Pingchuan Ma, Sebastien Wah, Andrew Spielberg, Daniela Rus, Wojciech Matusik, Kui Wu",
    "title": "DiffPD: Differentiable Projective Dynamics",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3490168",
    "pdf_link": null,
    "abstract": "… In this work, we present DiffPD, an efficient differentiable softbody simulator that implements … DiffPD with both explicit and implicit differentiable FEM simulations and observe DiffPD’s …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_667",
    "authors": "Ziang Cheng, Hongdong Li, Richard Hartley, Yinqiang Zheng, Imari Sato",
    "title": "Diffeomorphic Neural Surface Parameterization for 3D and Reflectance Recovery",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530741",
    "pdf_link": null,
    "abstract": "This paper proposes a simple method which solves the problem of multi-view 3D reconstruction for objects with unknown and generic surface materials, imaged by a freely moving camera and lit by a freely moving point light source. The object can have arbitrary (diffuse or specular) and spatially-varying surface reflectances. Our solution consists of two small-sized neural networks (dubbed the ‘Shape-Net’ and ‘BRDF-Net’), used to parameterize the unknown shape and material map as functions on a canonical surface (e.g. unit sphere). Key to our method is a velocity field shape representation that drives the canonical surface to target shape through time. We show this parameterization can be implemented as a recurrent residual network that is guaranteed to be diffeomorphic and orientation-preserving. Our method yields an exceptionally clean formulation that can be optimized by standard gradient descent without initialization, and works with both near-field and distant light source. Synthetic and real experiments demonstrate the reliability and accuracy of our reconstructions, with extensions including novel-view-synthesis, relighting and material retouching done with ease. Our source codes are available at https://github.com/za-cheng/DNS.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_504",
    "authors": "Delio Vicini, Sébastien Speierer, Wenzel Jakob",
    "title": "Differentiable Signed Distance Function Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530139",
    "pdf_link": null,
    "abstract": "Physically-based differentiable rendering has recently emerged as an attractive new technique for solving inverse problems that recover complete 3D scene representations from images. The inversion of shape parameters is of particular interest but also poses severe challenges: shapes are intertwined with visibility, whose discontinuous nature introduces severe bias in computed derivatives unless costly precautions are taken. Shape representations like triangle meshes suffer from additional difficulties, since the continuous optimization of mesh parameters cannot introduce topological changes. One common solution to these difficulties entails representing shapes using signed distance functions (SDFs) and gradually adapting their zero level set during optimization. Previous differentiable rendering of SDFs did not fully account for visibility gradients and required the use of mask or silhouette supervision, or discretization into a triangle mesh. In this article, we show how to extend the commonly used sphere tracing algorithm so that it additionally outputs a reparameterization that provides the means to compute accurate shape parameter derivatives. At a high level, this resembles techniques for differentiable mesh rendering, though we show that the SDF representation admits a particularly efficient reparameterization that outperforms prior work. Our experiments demonstrate the reconstruction of (synthetic) objects without complex regularization or priors, using only a per-pixel RGB loss.",
    "scholar_publication": "ACM Transactions on Graphics (ToG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_118",
    "authors": "Nicholas Sharp, Souhaib Attaiki, Keenan Crane, Maks Ovsjanikov, Nicholas Sharp",
    "title": "DiffusionNet: Discretization Agnostic Learning on Surfaces",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3507905",
    "pdf_link": null,
    "abstract": "We introduce a new general-purpose approach to deep learning on three-dimensional surfaces based on the insight that a simple diffusion layer is highly effective for spatial communication. The resulting networks are automatically robust to changes in resolution and sampling of a surface—a basic property that is crucial for practical applications. Our networks can be discretized on various geometric representations, such as triangle meshes or point clouds, and can even be trained on one representation and then applied to another. We optimize the spatial support of diffusion as a continuous network parameter ranging from purely local to totally global, removing the burden of manually choosing neighborhood sizes. The only other ingredients in the method are a multi-layer perceptron applied independently at each point and spatial gradient features to support directional filters. The resulting networks are simple, robust, and efficient. Here, we focus primarily on triangle mesh surfaces and demonstrate state-of-the-art results for a variety of tasks, including surface classification, segmentation, and non-rigid correspondence.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_677",
    "authors": "Erik Härkönen, Miika Aittala, Tuomas Kynkäänniemi, Samuli Laine, Timo Aila, Jaakko Lehtinen",
    "title": "Disentangling Random and Cyclic Effects in Time-lapse Sequences",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530170",
    "pdf_link": null,
    "abstract": "Time-lapse image sequences offer visually compelling insights into dynamic processes that are too slow to observe in real time. However, playing a long time-lapse sequence back as a video often results in distracting flicker due to random effects, such as weather, as well as cyclic effects, such as the day-night cycle. We introduce the problem of disentangling time-lapse sequences in a way that allows separate, after-the-fact control of overall trends, cyclic effects, and random effects in the images, and describe a technique based on data-driven generative models that achieves this goal. This enables us to \"re-render\" the sequences in ways that would not be possible with the input images alone. For example, we can stabilize a long sequence to focus on plant growth over many months, under selectable, consistent weather. Our approach is based on Generative Adversarial Networks (GAN) that are conditioned with the time coordinate of the time-lapse sequence. Our architecture and training procedure are designed so that the networks learn to model random variations, such as weather, using the GAN's latent space, and to disentangle overall trends and cyclic variations by feeding the conditioning time label to the model using Fourier features with specific frequencies. We show that our models are robust to defects in the training data, enabling us to amend some of the practical difficulties in capturing long time-lapse sequences, such as temporary occlusions, uneven frame spacing, and missing frames.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_196",
    "authors": "Jacob Justice, Alex Adkins, Tommy Dong, Sophie Jörg",
    "title": "Do We Measure What We Perceive? Comparison of Perceptual and Computed Differences Between Hand Animations",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543233",
    "pdf_link": null,
    "abstract": "An increased interest in public motion capture data has allowed for the use of data-driven animation algorithms through neural networks. While motion capture data is increasingly accessible, data sets have become too large to sort through manually. Similarity metrics quantify how different two motions are and can be used to search databases much faster when compared to manual searches as well as to train neural networks. However, the most popular similarity metrics are not informed by human perception, resulting in the potential for data that is not perceptually similar being labeled as such by these metrics. We conducted an experiment with hand motions to identify how large the differences between human perception and common similarity metrics are. In this study, participants watched two animations of hand motions, one altered and the other unaltered, and scored their similarity on a 7-point Likert scale. In our comparisons, we found that none of the tested similarity metrics correlated with human judged scores of similarity.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_593",
    "authors": "Yuxin Zhang, Fan Tang, Weiming Dong, Haibin Huang, Chongyang Ma, Tong-Yee Lee, Changsheng Xu",
    "title": "Domain Enhanced Arbitrary Image Style Transfer via Contrastive Learning",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530736",
    "pdf_link": null,
    "abstract": "In this work, we tackle the challenging problem of arbitrary image style transfer using a novel style feature representation learning method. A suitable style representation, as a key component in image stylization tasks, is essential to achieve satisfactory results. Existing deep neural network based approaches achieve reasonable results with the guidance from second-order statistics such as Gram matrix of content features. However, they do not leverage sufficient style information, which results in artifacts such as local distortions and style inconsistency. To address these issues, we propose to learn style representation directly from image features instead of their second-order statistics, by analyzing the similarities and differences between multiple styles and considering the style distribution. Specifically, we present Contrastive Arbitrary Style Transfer (CAST), which is a new style representation learning and style transfer method via contrastive learning. Our framework consists of three key components, i.e., a multi-layer style projector for style code encoding, a domain enhancement module for effective learning of style distribution, and a generative network for image style transfer. We conduct qualitative and quantitative evaluations comprehensively to demonstrate that our approach achieves significantly better results compared to those obtained via state-of-the-art methods. Code and models are available at https://github.com/zyxElsa/CAST_pytorch.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_308",
    "authors": "Wenzel Jakob, Sébastien Speierer, Nicolas Roussel, Delio Vicini",
    "title": "Dr.Jit: A Just-in-time Compiler for Differentiable Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530099",
    "pdf_link": null,
    "abstract": "DR.JIT is a new just-in-time compiler for physically based rendering and its derivative. DR.JIT expedites research on these topics in two ways: first, it traces high-level simulation code (e.g., written in Python) and aggressively simplifies and specializes the resulting program representation, producing data-parallel kernels with state-of-the-art performance on CPUs and GPUs. Second, it simplifies the development of differentiable rendering algorithms. Efficient methods in this area turn the derivative of a simulation into a simulation of the derivative. DR.JIT provides fine-grained control over the process of automatic differentiation to help with this transformation. Specialization is particularly helpful in the context of differentiation, since large parts of the simulation ultimately do not influence the computed gradients. DR.JIT tracks data dependencies globally to find and remove redundant computation.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_651",
    "authors": "Edoardo Remelli, Timur Bagautdinov, Shunsuke Saito, Chenglei Wu, Tomas Simon, Shih-En Wei, Kaiwen Guo, Zhe Cao, Fabian Prada, Jason Saragih, Yaser Sheikh",
    "title": "Drivable Volumetric Avatars Using Texel-aligned Features",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530740",
    "pdf_link": null,
    "abstract": "Photorealistic telepresence requires both high-fidelity body modeling and faithful driving to enable dynamically synthesized appearance that is indistinguishable from reality. In this work, we propose an end-to-end framework that addresses two core challenges in modeling and driving full-body avatars of real people. One challenge is driving an avatar while staying faithful to details and dynamics that cannot be captured by a global low-dimensional parameterization such as body pose. Our approach supports driving of clothed avatars with wrinkles and motion that a real driving performer exhibits beyond the training corpus. Unlike existing global state representations or non-parametric screen-space approaches, we introduce texel-aligned features—a localised representation which can leverage both the structural prior of a skeleton-based parametric model and observed sparse image signals at the same time. Another challenge is modeling a temporally coherent clothed avatar, which typically requires precise surface tracking. To circumvent this, we propose a novel volumetric avatar representation by extending mixtures of volumetric primitives to articulated objects. By explicitly incorporating articulation, our approach naturally generalizes to unseen poses. We also introduce a localized viewpoint conditioning, which leads to a large improvement in generalization of view-dependent appearance. The proposed volumetric representation does not require high-quality mesh tracking as a prerequisite and brings significant quality improvements compared to mesh-based counterparts. In our experiments, we carefully examine our design choices and demonstrate the efficacy of our approach, outperforming the state-of-the-art methods on challenging driving scenarios.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_278",
    "authors": "Peng-Shuai Wang, Yang Liu, Xin Tong",
    "title": "Dual Octree Graph Networks for Learning Adaptive Volumetric Shape Representations",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530087",
    "pdf_link": null,
    "abstract": "We present an adaptive deep representation of volumetric fields of 3D shapes and an efficient approach to learn this deep representation for high-quality 3D shape reconstruction and auto-encoding. Our method encodes the volumetric field of a 3D shape with an adaptive feature volume organized by an octree and applies a compact multilayer perceptron network for mapping the features to the field value at each 3D position. An encoder-decoder network is designed to learn the adaptive feature volume based on the graph convolutions over the dual graph of octree nodes. The core of our network is a new graph convolution operator defined over a regular grid of features fused from irregular neighboring octree nodes at different levels, which not only reduces the computational and memory cost of the convolutions over irregular neighboring octree nodes, but also improves the performance of feature learning. Our method effectively encodes shape details, enables fast 3D shape reconstruction, and exhibits good generality for modeling 3D shapes out of training categories. We evaluate our method on a set of reconstruction tasks of 3D shapes and scenes and validate its superiority over other existing approaches. Our code, data, and trained models are available at https://wang-ps.github.io/dualocnn.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_183",
    "authors": "Xin Sun, Nathan Carr, Sumit Dhingra, Vineet Batra, Ankit Phogat",
    "title": "Dual-layer Light Source With Textured Lighting Gel",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543227",
    "pdf_link": null,
    "abstract": "We propose a new light source representation to intuitively model complicated lighting effects with simple user interactions. Our representation uses two layers; an emissive layer which is a traditional diffuse area light source with a constant emission, and a lighting gel layer which introduces variations to the emission. The lighting gel layer is mapped with a texture for colored shadows without modeling a 3D scene. The two layers are transformed independently to cast the texture with different effects. To cast lighting on a planar canvas in …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_205",
    "authors": "Gerardo Gandeaga, Denys Iliash, Chris Careaga, Yağız Aksoy",
    "title": "DynaPix: Normal Map Pixelization for Dynamic Lighting",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543238",
    "pdf_link": null,
    "abstract": "This work introduces DynaPix, a Krita extension that automatically generates pixelated images and surface normals from an input image. DynaPix is a tool that aids pixel artists and game developers more efficiently develop 8-bit style games and bring them to life with dynamic lighting through normal maps that can be used in modern game engines such as Unity. The extension offers artists a degree of flexibility as well as allows for further refinements to generated artwork. Powered by out of the box solutions, DynaPix is a tool that seamlessly integrates in the artistic workflow.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_407",
    "authors": "Sang-Bin Jeon, Soon-Uk Kwon, June-Young Hwang, Yong-Hun Cho, Hayeon Kim, Jinhyung Park, In-Kwon Lee",
    "title": "Dynamic Optimal Space Partitioning for Redirected Walking in Multi-user Environment",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530113",
    "pdf_link": null,
    "abstract": "In multi-user Redirected Walking (RDW), the space subdivision method divides a shared physical space into sub-spaces and allocates a sub-space to each user. While this approach has the advantage of precluding any collisions between users, the conventional space subdivision method suffers from frequent boundary resets due to the reduction of available space per user. To address this challenge, in this study, we propose a space subdivision method called Optimal Space Partitioning (OSP) that dynamically divides the shared physical space in real-time. By exploiting spatial information of the physical and virtual environment, OSP predicts the movement of users and divides the shared physical space into optimal sub-spaces separated with shutters. Our OSP framework is trained using deep reinforcement learning to allocate optimal sub-space to each user and provide optimal steering. Our experiments demonstrate that OSP provides higher sense of immersion to users by minimizing the total number of reset counts, while preserving the advantage of the existing space subdivision strategy: ensuring better safety to users by completely eliminating the possibility of any collisions between users beforehand. Our project is available at https://github.com/AppleParfait/OSP-Archive.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_163",
    "authors": "Jonathan Merrin, Michael Shah",
    "title": "Dynamic Vertex Hierarchies for View-dependent Progressive Meshes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543217",
    "pdf_link": null,
    "abstract": "Triangles are one way we measure the complexity in a synthesized image. There often exists a trade-off between how realistic the synthesized image is based on the number of triangles and the overall rendering time. In real time applications, this trade-off becomes more important as we need to render detailed scenes at a fixed frame rate without sacrificing image quality. We propose a new view-dependent method that creates a more dynamic structure and is easy to parallelize. We also propose an amortized rebalancing operation to reduce long dependency lines in our data structure, prevent worst-case behavior, and in some instances improve the average case. Our implementation is still in-progress, but our new method is provably consistent and has potential to reduce the amount of storage needed for view-dependent methods and remove more geometry at higher fidelity, along with other performance improvements.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_738",
    "authors": "Xinya Ji, Hang Zhou, Kaisiyuan Wang, Qianyi Wu, Wayne Wu, Feng Xu, Xun Cao",
    "title": "EAMM: One-Shot Emotional Talking Face via Audio-based Emotion-Aware Motion Model",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530745",
    "pdf_link": null,
    "abstract": "Although significant progress has been made to audio-driven talking face generation, existing methods either neglect facial emotion or cannot be applied to arbitrary subjects. In this paper, we propose the Emotion-Aware Motion Model (EAMM) to generate one-shot emotional talking faces by involving an emotion source video. Specifically, we first propose an Audio2Facial-Dynamics module, which renders talking faces from audio-driven unsupervised zero- and first-order key-points motion. Then through exploring the motion model’s properties, we further propose an Implicit Emotion Displacement Learner to represent emotion-related facial dynamics as linearly additive displacements to the previously acquired motion representations. Comprehensive experiments demonstrate that by incorporating the results from both modules, our method can generate satisfactory talking face results on arbitrary subjects with realistic emotion patterns.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_668",
    "authors": "Alexander Rath, Pascal Grittmann, Sebastian Herholz, Philippe Weier, Philipp Slusallek",
    "title": "EARS: Efficiency-aware Russian Roulette and Splitting",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530168",
    "pdf_link": null,
    "abstract": "Russian roulette and splitting are widely used techniques to increase the efficiency of Monte Carlo estimators. But, despite their popularity, there is little work on how to best apply them. Most existing approaches rely on simple heuristics based on, e.g., surface albedo and roughness. Their efficiency often hinges on user-controlled parameters. We instead iteratively learn optimal Russian roulette and splitting factors during rendering, using a simple and lightweight data structure. Given perfect estimates of variance and cost, our fixed-point iteration provably converges to the optimal Russian roulette and splitting factors that maximize the rendering efficiency. In our application to unidirectional path tracing, we achieve consistent and significant speed-ups over the state of the art.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_768",
    "authors": "Philip Trettner, Julius Nehring-Wirxel, Leif Kobbelt",
    "title": "EMBER: Exact Mesh Booleans via Efficient and Robust Local Arrangements",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530181",
    "pdf_link": null,
    "abstract": "Boolean operators are an essential tool in a wide range of geometry processing and CAD/CAM tasks. We present a novel method, EMBER, to compute Boolean operations on polygon meshes which is exact, reliable, and highly performant at the same time. Exactness is guaranteed by using a plane-based representation for the input meshes along with recently introduced homogeneous integer coordinates. Reliability and robustness emerge from a formulation of the algorithm via generalized winding numbers and mesh arrangements. High performance is achieved by avoiding the (pre-)construction of a global acceleration structure. Instead, our algorithm performs an adaptive recursive subdivision of the scene's bounding box while generating and tracking all required data on the fly. By leveraging a number of early-out termination criteria, we can avoid the generation and inspection of regions that do not contribute to the output. With a careful implementation and a work-stealing multi-threading architecture, we are able to compute Boolean operations between meshes with millions of triangles at interactive rates. We run an extensive evaluation on the Thingi10K dataset to demonstrate that our method outperforms state-of-the-art algorithms, even inexact ones like QuickCSG, by orders of magnitude.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_149",
    "authors": "Seitaro Inagaki, Kenji Funahashi",
    "title": "Easy Rearward Visibility by the Control of Eye Direction in Viewing Panoramic Images With HMD",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543210",
    "pdf_link": null,
    "abstract": "The development of home-use HMDs has made it possible for many people to enjoy VR in the comfort of their own homes. Most VR services that allow users to view 360-degree images are used in a seated position. However, it is difficult for users to look rearward while rotating the necks and hips in a seated position [K. Yonemoto and T. Kondo 1995]. Sitting in a swivel chair makes it easier to look rearward, but it has been reported that when viewing 360-degree images with an HMD, the rotation of the seat surface amplifies the user’s body movements, resulting in a larger sensory discrepancy [Y. Banchi and T. Kawai 2018]. In this paper, we propose a new method that enables rearward viewing while sitting in a chair. The direction in which the user looks is called the eye direction. By presenting a rearward view on the HMD that is different from the actual viewing direction, the user can have a rearward view without",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_534",
    "authors": "Wojtek Palubicki, Milosz Makowski, Weronika Gajda, Torsten Hädrich, Dominik L. Michels, Sören Pirk",
    "title": "Ecoclimates: Climate-response Modeling of Vegetation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530146",
    "pdf_link": null,
    "abstract": "One of the greatest challenges to mankind is understanding the underlying principles of climate change. Over the last years, the role of forests in climate change has received increased attention. This is due to the observation that not only the atmosphere has a principal impact on vegetation growth but also that vegetation is contributing to local variations of weather resulting in diverse microclimates. The interconnection of plant ecosystems and weather is described and studied as ecoclimates. In this work we take steps …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_452",
    "authors": "Pascal Grittmann, Ömercan Yazici, Iliyan Georgiev, Philipp Slusallek",
    "title": "Efficiency-aware Multiple Importance Sampling for Bidirectional Rendering Algorithms",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530126",
    "pdf_link": null,
    "abstract": "Multiple importance sampling (MIS) is an indispensable tool in light-transport simulation. It enables robust Monte Carlo integration by combining samples from several techniques. However, it is well understood that such a combination is not always more efficient than using a single sampling technique. Thus a major criticism of complex combined estimators, such as bidirectional path tracing, is that they can be significantly less efficient on common scenes than simpler algorithms like forward path tracing. We propose a general method to improve MIS efficiency: By cheaply estimating the efficiencies of various technique and sample-count combinations, we can pick the best one. The key ingredient is a numerically robust and efficient scheme that uses the samples of one MIS combination to compute the efficiency of multiple other combinations. For example, we can run forward path tracing and use its samples to decide which subset of VCM to enable, and at what sampling rates. The sample count for each technique can be controlled per-pixel or globally. Applied to VCM, our approach enables robust rendering of complex scenes with caustics, without compromising efficiency on simpler scenes.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_238",
    "authors": "Kai Yan, Christoph Lassner, Brian Budge, Zhao Dong, Shuang Zhao",
    "title": "Efficient Estimation of Boundary Integrals for Path-space Differentiable Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530080",
    "pdf_link": null,
    "abstract": "Boundary integrals are unique to physics-based differentiable rendering and crucial for differentiating with respect to object geometry. Under the differential path integral framework---which has enabled the development of sophisticated differentiable rendering algorithms---the boundary components are themselves path integrals. Previously, although the mathematical formulation of boundary path integrals have been established, efficient estimation of these integrals remains challenging. In this paper, we introduce a new technique to efficiently estimate boundary path integrals. A key component of our technique is a primary-sample-space guiding step for importance sampling of boundary segments. Additionally, we show multiple importance sampling can be used to combine multiple guided samplings. Lastly, we introduce an optional edge sorting step to further improve the runtime performance. We evaluate the effectiveness of our method using several differentiable-rendering and inverse-rendering examples and provide comparisons with existing methods for reconstruction as well as gradient quality.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_477",
    "authors": "Wei Li, Yihui Ma, Xiaopei Liu, Mathieu Desbrun",
    "title": "Efficient Kinetic Simulation of Two-Phase Flows",
    "paper_url": "https://hal.science/hal-03828392/",
    "pdf_link": null,
    "abstract": "Real-life multiphase flows exhibit a number of complex and visually appealing behaviors, involving bubbling, wetting, splashing, and glugging. However, most state-of-the-art simulation techniques in graphics can only demonstrate a limited range of multiphase flow phenomena, due to their inability to handle the real water-air density ratio and to the large amount of numerical viscosity introduced in the flow simulation and its coupling with the interface. Recently, kinetic-based methods have achieved success in simulating large density ratios and high Reynolds numbers efficiently; but their memory overhead, limited stability, and numerically-intensive treatment of coupling with immersed solids remain enduring obstacles to their adoption in movie productions. In this paper, we propose a new kinetic solver to couple the incompressible Navier-Stokes equations with a conservative phase-field equation which remedies these major practical hurdles. The resulting two-phase immiscible fluid solver is shown to be efficient due to its massively-parallel nature and GPU implementation, as well as very versatile and reliable because of its enhanced stability to large density ratios, high Reynolds numbers, and complex solid boundaries. We highlight the advantages of our solver through various challenging simulation results that capture intricate and turbulent air-water interaction, including comparisons to previous work and real footage.",
    "scholar_publication": "ACM Transactions on Graphics, 2022 - hal.science"
  },
  {
    "paper_id": "papers_205",
    "authors": "Hyeonjoong Jang, Andréas Meuleman, Dahyun Kang, Donggun Kim, Christian Richardt, Min H. Kim",
    "title": "Egocentric Scene Reconstruction From an Omnidirectional Video",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530074",
    "pdf_link": null,
    "abstract": "Omnidirectional videos capture environmental scenes effectively, but they have rarely been used for geometry reconstruction. In this work, we propose an egocentric 3D reconstruction method that can acquire scene geometry with high accuracy from a short egocentric omnidirectional video. To this end, we first estimate per-frame depth using a spherical disparity network. We then fuse per-frame depth estimates into a novel spherical binoctree data structure that is specifically designed to tolerate spherical depth estimation errors. By subdividing the spherical space into binary tree and octree nodes that represent spherical frustums adaptively, the spherical binoctree effectively enables egocentric surface geometry reconstruction for environmental scenes while simultaneously assigning high-resolution nodes for closely observed surfaces. This allows to reconstruct an entire scene from a short video captured with a small camera trajectory. Experimental results validate the effectiveness and accuracy of our approach for reconstructing the 3D geometry of environmental scenes from short egocentric omnidirectional video inputs. We further demonstrate various applications using a conventional omnidirectional camera, including novel-view synthesis, object insertion, and relighting of scenes using reconstructed 3D models with texture.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_272",
    "authors": "Mojtaba Bemana, Karol Myszkowski, Jeppe Revall Frisvad, Hans-Peter Seidel, Tobias Ritschel",
    "title": "Eikonal Fields for Refractive Novel-view Synthesis",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530706",
    "pdf_link": null,
    "abstract": "We tackle the problem of generating novel-view images from collections of 2D images showing refractive and reflective objects. Current solutions assume opaque or transparent light transport along straight paths following the emission-absorption model. Instead, we optimize for a field of 3D-varying index of refraction (IoR) and trace light through it that bends toward the spatial gradients of said IoR according to the laws of eikonal light transport.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_196",
    "authors": "Xuan Li, Minchen Li, Chenfanfu Jiang",
    "title": "Energetically Consistent Inelasticity for Optimization Time Integration",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530072",
    "pdf_link": null,
    "abstract": "In this paper, we propose Energetically Consistent Inelasticity (ECI), a new formulation for modeling and discretizing finite strain elastoplasticity/viscoelasticity in a way that is compatible with optimization-based time integrators. We provide an in-depth analysis for allowing plasticity to be implicitly integrated through an augmented strain energy density function. We develop ECI on the associative von-Mises J2 plasticity, the non-associative Drucker-Prager plasticity, and the finite strain viscoelasticity. We demonstrate the resulting scheme on both the Finite Element Method (FEM) and the Material Point Method (MPM). Combined with a custom Newton-type optimization integration scheme, our method enables simulating stiff and large-deformation inelastic dynamics of metal, sand, snow, and foam with larger time steps, improved stability, higher efficiency, and better accuracy than existing approaches.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_142",
    "authors": "Thomas Bashford-Rogers, Luis Paulo Santos, Demetris Marnerides, Kurt Debattista, Thomas Bashford-Rogers",
    "title": "Ensemble Metropolis Light Transport",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3472294",
    "pdf_link": null,
    "abstract": "… of ensembles of light transport paths, which are distributed according to the lighting in the … We show how this can be implemented efficiently by organizing the paths in each ensemble …",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_128",
    "authors": "Yuichi Nagata, Shinji Imahori, Yuichi Nagata",
    "title": "Escherization With Large Deformations Based on As-rigid-as-possible Shape Modeling",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3487017",
    "pdf_link": null,
    "abstract": "Escher tiling is well known as a tiling that consists of one or a few recognizable figures, such as animals. The Escherization problem involves finding the most similar shape to a given goal figure that can tile the plane. However, it is easy to imagine that there is no similar tile shape for complex goal shapes. This article devises a method for finding a satisfactory tile shape in such a situation. To obtain a satisfactory tile shape, the tile shape is generated by deforming the goal shape to a considerable extent while retaining the characteristics of the original shape. To achieve this, both goal and tile shapes are represented as triangular meshes to consider not only the contours but also the internal similarity of the shapes. To measure the naturalness of the deformation, energy functions based on traditional as-rigid-as-possible shape modeling are incorporated into a recently developed framework of the exhaustive search of the templates for the Escherization problem. The developed algorithms find satisfactory tile shapes with natural deformations for fairly complex goal shapes.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_646",
    "authors": "Georg Sperl, Rosa M. Sánchez-Banderas, Manwen Li, Chris Wojtan, Miguel A. Otaduy",
    "title": "Estimation of Yarn-level Simulation Models for Production Fabrics",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530167",
    "pdf_link": null,
    "abstract": "This paper introduces a methodology for inverse-modeling of yarn-level mechanics of cloth, based on the mechanical response of fabrics in the real world. We compiled a database from physical tests of several different knitted fabrics used in the textile industry. These data span different types of complex knit patterns, yarn compositions, and fabric finishes, and the results demonstrate diverse physical properties like stiffness, nonlinearity, and anisotropy. We then develop a system for approximating these mechanical responses with yarn-level cloth simulation. To do so, we introduce an efficient pipeline for converting between fabric-level data and yarn-level simulation, including a novel swatch-level approximation for speeding up computation, and some small-but-necessary extensions to yarn-level models used in computer graphics. The dataset used for this paper can be found at http://mslab.es/projects/YarnLevelFabrics.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_185",
    "authors": "Antoine Maiorca, Youngwoo Yoon, Thierry Dutoit",
    "title": "Evaluating the Quality of a Synthesized Motion With the Fréchet Motion Distance",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543228",
    "pdf_link": null,
    "abstract": "Motion synthesis is an active research topic in the Deep Learning community. It has various fields of application including character animation, humanoid robots and embodied conversational agents. Designing such algorithm is not a straightforward task and must ensure that the output motion are natural. It is however necessary to assess the quality of a synthesized animation to be able to compare algorithms’ performance. Although that evaluations relying on subjective survey give satisfying estimation on the quality of the animation, gathering such group of people with defined requirements (level of expertise of subjects, eg) is expensive, time consuming, and having low reproducibility, which hinders fast development iterations. In this sense, a quantitative evaluation with",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_473",
    "authors": "Gengyan Li, Abhimitra Meka, Franziska Mueller, Marcel Buehler, Otmar Hilliges, Thabo Beeler",
    "title": "EyeNeRF: A Hybrid Representation for Photorealistic Synthesis, Animation, and Relighting of Human Eyes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530130",
    "pdf_link": null,
    "abstract": "A unique challenge in creating high-quality animatable and relightable 3D avatars of real people is modeling human eyes, particularly in conjunction with the surrounding periocular face region. The challenge of synthesizing eyes is multifold as it requires 1) appropriate representations for the various components of the eye and the periocular region for coherent viewpoint synthesis, capable of representing diffuse, refractive and highly reflective surfaces, 2) disentangling skin and eye appearance from environmental illumination such that it may be rendered under novel lighting conditions, and 3) capturing eyeball motion and the deformation of the surrounding skin to enable re-gazing. These challenges have traditionally necessitated the use of expensive and cumbersome capture setups to obtain high-quality results, and even then, modeling of the full eye region holistically has remained elusive. We present a novel geometry and appearance representation that enables high-fidelity capture and photorealistic animation, view synthesis and relighting of the eye region using only a sparse set of lights and cameras. Our hybrid representation combines an explicit parametric surface model for the eyeball surface with implicit deformable volumetric representations for the periocular region and the interior of the eye. This novel hybrid model has been designed specifically to address the various parts of that exceptionally challenging facial area - the explicit eyeball surface allows modeling refraction and high frequency specular reflection at the cornea, whereas the implicit representation is well suited to model lower frequency skin reflection via spherical harmonics and can represent non-surface structures such as hair (i.e. eyebrows) or highly diffuse volumetric bodies (i.e. sclera), both of which are a challenge for explicit surface models. Tightly integrating the two representations in a joint framework allows controlled photoreal image synthesis and joint optimization of both the geometry parameters of the eyeball and the implicit neural network in continuous 3D space. We show that for high-resolution close-ups of the human eye, our model can synthesize high-fidelity animated gaze from novel views under unseen illumination conditions, allowing to generate visually rich eye imagery.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_475",
    "authors": "Wei-Sheng Lai, YiChang Shih, Lun-Cheng Chu, Xiaotong Wu, Sung-fang Tsai, Michael Krainin, Deqing Sun, Chia-Kai Liang",
    "title": "Face Deblurring Using Dual Camera Fusion on Mobile Phones",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530131",
    "pdf_link": null,
    "abstract": "Motion blur of fast-moving subjects is a longstanding problem in photography and very common on mobile phones due to limited light collection efficiency, particularly in low-light conditions. While we have witnessed great progress in image deblurring in recent years, most methods require significant computational power and have limitations in processing high-resolution photos with severe local motions. To this end, we develop a novel face deblurring system based on the dual camera fusion technique for mobile phones. The system detects subject motion to dynamically enable a reference camera, e.g., ultrawide angle camera commonly available on recent premium phones, and captures an auxiliary photo with faster shutter settings. While the main shot is low noise but blurry (Figure 1(a)), the reference shot is sharp but noisy (Figure 1(b)). We learn ML models to align and fuse these two shots and output a clear photo without motion blur (Figure 1(c)). Our algorithm runs efficiently on Google Pixel 6, which takes 463 ms overhead per shot. Our experiments demonstrate the advantage and robustness of our system against alternative single-image, multi-frame, face-specific, and video deblurring algorithms as well as commercial products. To the best of our knowledge, our work is the first mobile solution for face motion deblurring that works reliably and robustly over thousands of images in diverse motion and lighting conditions.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_809",
    "authors": "Karran Pandey, J. Andreas Bærentzen, Karan Singh",
    "title": "Face Extrusion Quad Meshes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530754",
    "pdf_link": null,
    "abstract": "… face-loops in design, we propose, Face Extrusion Quad FEQ meshes, a 3D object representation built on atomic face… capture the properties of artist designed face-loops. Specifically, we …",
    "scholar_publication": "ACM SIGGRAPH 2022 Conference …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_418",
    "authors": "Sebastian Winberg, Gaspard Zoss, Prashanth Chandran, Paulo Gotardo, Derek Bradley",
    "title": "Facial Hair Tracking for High Fidelity Performance Capture",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530116",
    "pdf_link": null,
    "abstract": "Facial hair is a largely overlooked topic in facial performance capture. Most production pipelines in the entertainment industry do not have a way to automatically capture facial hair or track the skin underneath it. Thus, actors are asked to shave clean before face capture, which is very often undesirable. Capturing the geometry of individual facial hairs is very challenging, and their presence makes it harder to capture the deforming shape of the underlying skin surface. Some attempts have already been made at automating this task, but only for static faces with relatively sparse 3D hair reconstructions. In particular, current methods lack the temporal correspondence needed when capturing a sequence of video frames depicting facial performance. The problem of robustly tracking the skin underneath also remains unaddressed. In this paper, we propose the first multiview reconstruction pipeline that tracks both the dense 3D facial hair, as well as the underlying 3D skin for entire performances. Our method operates with standard setups for face photogrammetry, without requiring dense camera arrays. For a given capture subject, our algorithm first reconstructs a dense, high-quality neutral 3D facial hairstyle by registering sparser hair reconstructions over multiple frames that depict a neutral face under quasi-rigid motion. This custom-built, reference facial hairstyle is then tracked throughout a variety of changing facial expressions in a captured performance, and the result is used to constrain the tracking of the 3D skin surface underneath. We demonstrate the proposed capture pipeline on a variety of different facial hairstyles and lengths, ranging from sparse and short to dense full-beards.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_294",
    "authors": "Abhishek Madan, David Levin",
    "title": "Fast Evaluation of Smooth Distance Constraints on Co-dimensional Geometry",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530093",
    "pdf_link": null,
    "abstract": "We present a new method for computing a smooth minimum distance function based on the LogSumExp function for point clouds, edge meshes, triangle meshes, and combinations of all three. We derive blending weights and a modified Barnes-Hut acceleration approach that ensure our method approximates the true distance, and is conservative (points outside the zero isosurface are guaranteed to be outside the surface) and efficient to evaluate for all the above data types. This, in combination with its ability to smooth sparsely sampled and noisy data, like point clouds, shortens the gap between data acquisition and simulation, and thereby enables new applications such as direct, co-dimensional rigid body simulation using unprocessed lidar data.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_329",
    "authors": "Marcel Padilla, Oliver Gross, Felix Knöppel, Albert Chern, Ulrich Pinkall, Peter Schröder",
    "title": "Filament Based Plasma",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530102",
    "pdf_link": null,
    "abstract": "… filaments whose shape is governed by the magnetohydrostatic equation. The magnetic filaments provide … Subsequently, the shape of the filaments is determined based on a variational …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_132",
    "authors": "Zhen Chen, Hsiao-yu Chen, Danny Kaufman, Melina Skouras, Etienne Vouga, Zhen Chen",
    "title": "Fine Wrinkling on Coarsely Meshed Thin Shells",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3462758",
    "pdf_link": null,
    "abstract": "We propose a new model and algorithm to capture the high-definition statics of thin shells via coarse meshes. This model predicts global, fine-scale wrinkling at frequencies much higher than the resolution of the coarse mesh; moreover, it is grounded in the geometric analysis of elasticity, and does not require manual guidance, a corpus of training examples, nor tuning of ad hoc parameters. We first approximate the coarse shape of the shell using tension field theory, in which material forces do not resist compression. We then augment this base mesh with wrinkles, parameterized by an amplitude and phase field that we solve for over the base mesh, which together characterize the geometry of the wrinkles. We validate our approach against both physical experiments and numerical simulations, and we show that our algorithm produces wrinkles qualitatively similar to those predicted by traditional shell solvers requiring orders of magnitude more degrees of freedom.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_133",
    "authors": "Julien Philip, Sébastien Morgenthaler, Michaël Gharbi, George Drettakis, Julien Philip",
    "title": "Free-viewpoint Indoor Neural Relighting from Multi-view Stereo",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3469842",
    "pdf_link": null,
    "abstract": "We introduce a neural relighting algorithm for captured indoors scenes, that allows interactive free-viewpoint navigation. Our method allows illumination to be changed synthetically, while coherently rendering cast shadows and complex glossy materials. We start with multiple images of the scene and a three-dimensional mesh obtained by multi-view stereo (MVS) reconstruction. We assume that lighting is well explained as the sum of a view-independent diffuse component and a view-dependent glossy term concentrated around the mirror reflection direction. We design a convolutional network around input feature maps that facilitate learning of an implicit representation of scene materials and illumination, enabling both relighting and free-viewpoint navigation. We generate these input maps by exploiting the best elements of both image-based and physically based rendering. We sample the input views to estimate diffuse scene irradiance, and compute the new illumination caused by user-specified light sources using path tracing. To facilitate the network's understanding of materials and synthesize plausible glossy reflections, we reproject the views and compute mirror images. We train the network on a synthetic dataset where each scene is also reconstructed with MVS. We show results of our algorithm relighting real indoor scenes and performing free-viewpoint navigation with complex and realistic glossy reflections, which so far remained out of reach for view-synthesis techniques.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_480",
    "authors": "Changjian Li, Hao Pan, Adrien Bousseau, Niloy Mitra",
    "title": "Free2CAD: Parsing Freehand Drawings Into CAD Commands",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530133",
    "pdf_link": null,
    "abstract": "CAD modeling, despite being the industry-standard, remains restricted to usage by skilled practitioners due to two key barriers. First, the user must be able to mentally parse a final shape into a valid sequence of supported CAD commands; and second, the user must be sufficiently conversant with CAD software packages to be able to execute the corresponding CAD commands. As a step towards addressing both these challenges, we present Free2CAD wherein the user can simply sketch the final shape and our system parses the input strokes into a sequence of commands expressed in a simplified CAD language. When executed, these commands reproduce the sketched object. Technically, we cast sketch-based CAD modeling as a sequence-to-sequence translation problem, for which we leverage the powerful Transformers neural network architecture. Given the sequence of pen strokes as input, we introduce the new task of grouping strokes that correspond to individual CAD operations. We combine stroke grouping with geometric fitting of the operation parameters, such that intermediate groups are geometrically corrected before being reused, as context, for subsequent steps in the sequence inference. Although trained on synthetically-generated data, we demonstrate that Free2CAD generalizes to sketches created from real-world CAD models as well as to sketches drawn by novice users. Code and data are at https://github.com/Enigma-li/Free2CAD.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_119",
    "authors": "Alain Lioret, Nicolas Ruche, Etienne Gibiat, Cédric Chopin",
    "title": "GAN Applied to Wave Function Collapse for Procedural Map Generation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543198",
    "pdf_link": null,
    "abstract": "This paper describes the use of Generative Adversarial Network (GAN) applied to the Wave Function Collapse (WFC) algorithm for procedural content generation. The goal of this system is to enable level designers to generate coherent 3D worlds with brand new meshes generated by the GAN.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_577",
    "authors": "Peizhuo Li, Kfir Aberman, Zihan Zhang, Rana Hanocka, Olga Sorkine-Hornung",
    "title": "GANimator: Neural Motion Synthesis From a Single Sequence",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530157",
    "pdf_link": null,
    "abstract": "We present GANimator, a generative model that learns to synthesize novel motions from a single, short motion sequence. GANimator generates motions that resemble the core elements of the original motion, while simultaneously synthesizing novel and diverse movements. Existing data-driven techniques for motion synthesis require a large motion dataset which contains the desired and specific skeletal structure. By contrast, GANimator only requires training on a single motion sequence, enabling novel motion synthesis for a variety of skeletal structures e.g., bipeds, quadropeds, hexapeds, and more. Our framework contains a series of generative and adversarial neural networks, each responsible for generating motions in a specific frame rate. The framework progressively learns to synthesize motion from random noise, enabling hierarchical control over the generated motion content across varying levels of detail. We show a number of applications, including crowd simulation, key-frame editing, style transfer, and interactive control, which all learn from a single input sequence. Code and data for this paper are at https://peizhuoli.github.io/ganimator.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_526",
    "authors": "Zhenyu Tang, Rohith Aralikatti, Anton Ratnarajah, Dinesh Manocha",
    "title": "GWA: A Large Geometric-wave Acoustic Dataset for Audio Deep Learning",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530731",
    "pdf_link": null,
    "abstract": "… Geometric-Wave Acoustic (GWA) dataset, a largescale audio … the benefits of GWA on audio deep learning tasks such as … This dataset is the first data with accurate wave acoustic simu…",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_584",
    "authors": "Daqi Lin, Markus Kettunen, Benedikt Bitterli, Jacopo Pantaleoni, Cem Yuksel, Chris Wyman",
    "title": "Generalized Resampled Importance Sampling: Foundations of ReSTIR",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530158",
    "pdf_link": null,
    "abstract": "As scenes become ever more complex and real-time applications embrace ray tracing, path sampling algorithms that maximize quality at low sample counts become vital. Recent resampling algorithms building on Talbot et al.'s [2005] resampled importance sampling (RIS) reuse paths spatiotemporally to render surprisingly complex light transport with a few samples per pixel. These reservoir-based spatiotemporal importance resamplers (ReSTIR) and their underlying RIS theory make various assumptions, including sample independence. But sample reuse introduces correlation, so ReSTIR-style iterative reuse loses most convergence guarantees that RIS theoretically provides. We introduce generalized resampled importance sampling (GRIS) to extend the theory, allowing RIS on correlated samples, with unknown PDFs and taken from varied domains. This solidifies the theoretical foundation, allowing us to derive variance bounds and convergence conditions in ReSTIR-based samplers. It also guides practical algorithm design and enables advanced path reuse between pixels via complex shift mappings. We show a path-traced resampler (ReSTIR PT) running interactively on complex scenes, capturing many-bounce diffuse and specular lighting while shading just one path per pixel. With our new theoretical foundation, we can also modify the algorithm to guarantee convergence for offline renderers.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_135",
    "authors": "Sihun Cha, Kwanggyoon Seo, Amirsaman Ashtari, Junyong Noh",
    "title": "Generating 3D Human Texture From a Single Image With Sampling and Refinement",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543204",
    "pdf_link": null,
    "abstract": "Generating the texture map for a 3D human mesh from a single image is challenging. To generate a plausible texture map, the invisible parts of the texture need to be synthesized with relevance to the visible part and the texture should semantically align to the UV space of the template mesh. To overcome such challenges, we propose a novel method that incorporates SamplerNet and RefineNet. SamplerNet predicts a sampling grid that enables sampling from the given visible texture information, and RefineNet refines the sampled texture to maintain spatial alignment.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_217",
    "authors": "Ya-Chuan Hsu, Stefanos Nikolaidis",
    "title": "Generating Diverse Indoor Furniture Arrangements",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543244",
    "pdf_link": null,
    "abstract": "We present a method for generating arrangements of indoor furniture from human-designed furniture layout data. Our method creates arrangements that target specified diversity, such as the total price of all furniture in the room and the number of pieces placed. To generate realistic furniture arrangement, we train a generative adversarial network (GAN) on human-designed layouts. To target specific diversity in the arrangements, we optimize the latent space of the GAN via a quality diversity algorithm to generate a diverse arrangement collection. Experiments show our approach discovers a set of arrangements that are similar to human-designed layouts but varies in price and number of furniture pieces.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_175",
    "authors": "Asahi Adachi, Lana Sinapayen, Jun Rekimoto",
    "title": "Generation of Traditional Japanese Patterns From Natural Patterns With StyleGAN",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543221",
    "pdf_link": null,
    "abstract": "3 METHODSWe used the StyleGAN2 architecture 1 [Karras et al. 2020] and the layer swapping technique [Pinkney and Adler 2020]. Firstly, we trained StyleGAN2 on the source dataset (DTD) with default parameters, and then transfer learning to the target dataset (wagara) created a new StyleGAN2 generator model. Lastly, we split the StyleGAN generator into three levels: coarse, medium, and fine, according to [Karras et al. 2019; 2020]. We combined the parameters and created a new generator following the layer swapping method proposed in [Pinkney and Adler 2020]. At the coarse and medium levels, we used parameters learned on the source dataset; at the fine level, we used parameters learned on the target dataset.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_377",
    "authors": "Jungnam Park, Sehee Min, Phil Sik Chang, Jaedong Lee, Moon Seok Park, Jehee Lee",
    "title": "Generative GaitNet",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530717",
    "pdf_link": null,
    "abstract": "Understanding the relation between anatomy and gait is key to successful predictive gait simulation. In this paper, we present Generative GaitNet, which is a novel network architecture …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_476",
    "authors": "Jiong Chen, Mathieu Desbrun",
    "title": "Go Green: General Regularized Green's Functions for Elasticity",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530726",
    "pdf_link": null,
    "abstract": "The fundamental solutions (Green's functions) of linear elasticity for an infinite and isotropic media are ubiquitous in interactive graphics applications that cannot afford the computational costs of volumetric meshing and finite-element simulation. For instance, the recent work of de Goes and James [2017] leveraged these Green's functions to formulate sculpting tools capturing in real-time broad and physically-plausible deformations more intuitively and realistically than traditional editing brushes. In this paper, we extend this …",
    "scholar_publication": "ACM SIGGRAPH 2022 Conference Proceedings, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_165",
    "authors": "Yu-Yen Chen, Yi-Jie Lu, Ping-Hsuan Han",
    "title": "GravityPack: Exploring a Wearable Gravity Display for Immersive Interaction Using Liquid-based System",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543218",
    "pdf_link": null,
    "abstract": "Previous works have done several kinds of haptic techniques for simulating the touching experience of the virtual object. However, the feedback on the object’s weight has less been explored. This paper presents GravityPack, a wearable gravity display to simulate grabbing, holding, and releasing the virtual object in the virtual world using the liquid-based system consisting of pumps, pipes, valves, a water tank, and water packs. This system can provide a wide weight range from 110g to 1.8 kg in 40 seconds. Additionally, we design and investigate the visual feedback of weight transition for the delay time of liquid transfer to understand the feasibility of visualization by a user study. With the revealing of design consideration and implementation, the paper also shows the potential use of the liquid-based system and its possibility of the visualization technique to simulate the weight sensations.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_485",
    "authors": "Rohan Sawhney, Dario Seyb, Wojciech Jarosz, Keenan Crane",
    "title": "Grid-free Monte Carlo for PDEs With Spatially Varying Coefficients",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530134",
    "pdf_link": null,
    "abstract": "… FC---AD Solvers for Variable-Coefficient PDEs We present fast, spatially dispersionless and … -order solvers for partial differential equations (PDEs) with variable coefficients in general …",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_148",
    "authors": "Joel Wretborn, Sean Flynn, Alexey Stomakhin",
    "title": "Guided Bubbles and Wet Foam for Realistic Whitewater Simulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530059",
    "pdf_link": null,
    "abstract": "We present a method for enhancing fluid simulations with realistic bubble and foam detail. We treat bubbles as discrete air particles, two-way coupled with a sparse volumetric Euler flow, as first suggested in [Stomakhin et al. 2020]. We elaborate further on their scheme and introduce a bubble inertia correction term for improved convergence. We also show how one can add bubbles to an already existing fluid simulation using our novel guiding technique, which performs local re-simulation of fluid to achieve more interesting bubble dynamics through coupling. As bubbles reach the surface, they are converted into foam and simulated separately. Our foam is discretized with smoothed particle hydrodynamics (SPH), and we replace forces normal to the fluid surface with a fluid surface manifold advection constraint to achieve more robust and stable results. The SPH forces are derived through proper constitutive modeling of an incompressible viscous liquid, and we explain why this choice is appropriate for \"wet\" types of foam. This allows us to produce believable dynamics from close-up scenarios to large oceans, with just a few parameters that work intuitively across a variety of scales. Additionally, we present relevant research on air entrainment metrics and bubble distributions that have been used in this work.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_215",
    "authors": "Paul Debevec, Chloe LeGendre",
    "title": "HDR Lighting Dilation for Dynamic Range Reduction on Virtual Production Stages",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543243",
    "pdf_link": null,
    "abstract": "We present a technique to reduce the dynamic range of an HDRI lighting environment map in an efficient, energy-preserving manner by spreading out the light of concentrated light sources. This allows us to display a reasonable approximation of the illumination of an HDRI map in a lighting reproduction system with limited dynamic range such as virtual production LED Stage. The technique identifies regions of the HDRI map above a given pixel threshold, dilates these regions until the average pixel value within each is below the threshold, and finally replaces each dilated region’s pixels with the region’s average pixel value. The new HDRI map contains the same energy as the original, spreads the light as little as possible, and avoids chromatic fringing.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_129",
    "authors": "Yabin Xu, Liangliang Nan, Laishui Zhou, Jun Wang, Charlie C.L. Wang, Yabin Xu",
    "title": "HRBF-Fusion: Accurate 3D Reconstruction From RGB-D Data Using On-the-fly Implicits",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3516521",
    "pdf_link": null,
    "abstract": "Reconstruction of high-fidelity 3D objects or scenes is a fundamental research problem. Recent advances in RGB-D fusion have demonstrated the potential of producing 3D models from consumer-level RGB-D cameras. However, due to the discrete nature and limited resolution of their surface representations (e.g., point or voxel based), existing approaches suffer from the accumulation of errors in camera tracking and distortion in the reconstruction, which leads to an unsatisfactory 3D reconstruction. In this article, we present a method using on-the-fly implicits of Hermite Radial Basis Functions (HRBFs) as a continuous surface representation for camera tracking in an existing RGB-D fusion framework. Furthermore, curvature estimation and confidence evaluation are coherently derived from the inherent surface properties of the on-the-fly HRBF implicits, which are devoted to a data fusion with better quality. We argue that our continuous but on-the-fly surface representation can effectively mitigate the impact of noise with its robustness and constrain the reconstruction with inherent surface smoothness when being compared with discrete representations. Experimental results on various real-world and synthetic datasets demonstrate that our HRBF-fusion outperforms the state-of-the-art approaches in terms of tracking robustness and reconstruction accuracy.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_208",
    "authors": "Jose Barreiros, Tianshu Liu, Maurizio Chiaramonte, Kristy Jost, Yigit Menguc, Nicholas Colonnese, Priyanshu Agarwal",
    "title": "HYFAR: A Textile Soft Actuator for Haptic Clothing Interfaces",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543239",
    "pdf_link": null,
    "abstract": "Haptic feedback is important in augmented and virtual reality (AR/VR) because it closes the loop of touch sensation and provides physical realism to what is being rendered in the virtual world [Sodhi et al. 2013]. In this context, clothing is an appealing substrate for haptic interfaces because it is in direct contact with the user’s skin and provides a large space for delivering haptic feedback. Most haptic garments are based on rigid devices (eg electromagnetic vibrotactors) which tamper the softness of clothing",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_182",
    "authors": "Jiahao Weng, Chao Zhang, Xi Yang, Haoran Xie",
    "title": "HiVideo: Hierarchical Browsing Interface for Educational Videos",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543226",
    "pdf_link": null,
    "abstract": "Online academic conferences and massive open online courses (MOOCs) are becoming increasingly popular. However, it is difficult to properly retrieve and select the required video material. Current video retrieval systems [Kim et al. 2014; Yadav et al. 2016] may require more interactivity and summarization features to meet",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_191",
    "authors": "Lizhou Cao, Chao Peng",
    "title": "Hierarchical Cross-parameterization for the Morphing of Deforming Meshes",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543229",
    "pdf_link": null,
    "abstract": "Deforming meshes with animations are common geometric data used in film, gaming, simulation, digital training, and scientific visualization. A deforming mesh usually consists of two parts: a mesh with topology presenting the shape and a hierarchical set of joints (a skeleton) that deforms mesh regions. Understanding deforming meshes and reusing them to produce new characters is crucial in asset creation. Traditional methods require specific types of input and labor-intensive effort to create character variations in order to enhance the visual diversity in a realistic environment. For example, to create animated and morphologically varied characters for a crowd simulation, sets of interchangeable body parts have to be built manually. The blend-shape technique is an automated method to create morphable mesh sequences, but it requires input meshes must be isomorphic, which means the input meshes must have the same number of vertices and the same topology with a one-to-one mapping of all vertices. The goal to automate the generation of morphologically varied characters from non-isomorphic inputs has led to the use of crossparameterization techniques [Kwok et al. 2011; Peng and Timalsena 2016]. Here, cross-parameterization is able to form a one-to-one vertex mapping for input meshes into a common representation on",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_757",
    "authors": "Bruno Lecouat, Thomas Eboli, Jean Ponce, Julien Mairal",
    "title": "High Dynamic Range and Super-resolution From Raw Image Bursts",
    "paper_url": "https://arxiv.org/abs/2207.14671",
    "pdf_link": null,
    "abstract": "Photographs captured by smartphones and mid-range cameras have limited spatial resolution and dynamic range, with noisy response in underexposed regions and color artefacts in saturated areas. This paper introduces the first approach (to the best of our knowledge) to the reconstruction of high-resolution, high-dynamic range color images from raw photographic bursts captured by a handheld camera with exposure bracketing. This method uses a physically-accurate model of image formation to combine an iterative optimization algorithm for solving the corresponding inverse problem with a learned image representation for robust alignment and a learned natural image prior. The proposed algorithm is fast, with low memory requirements compared to state-of-the-art learning-based approaches to image restoration, and features that are learned end to end from synthetic yet realistic data. Extensive experiments demonstrate its excellent performance with super-resolution factors of up to on real photographs taken in the wild with hand-held cameras, and high robustness to low-light conditions, noise, camera shake, and moderate object motion.",
    "scholar_publication": "arXiv preprint arXiv:2207.14671, 2022 - arxiv.org"
  },
  {
    "paper_id": "pos_181",
    "authors": "Wakasa Noguchi, Hiroki Nishino",
    "title": "High-low Tech Ombro-Cinéma",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543225",
    "pdf_link": null,
    "abstract": "… Ombro-Cinéma by reproducing it usingthe high-low tech approach. Regardless of its technical simplicity, the high-low tech … in extending the narrative of Ombro-Cinéma, here with sound …",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_109",
    "authors": "Praneeth Chakravarthula, Ethan Tseng, Henry Fuchs, Felix Heide, Praneeth Chakravarthula",
    "title": "Hogel-free Holography",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3516428",
    "pdf_link": null,
    "abstract": "… We study the parallax and occlusion efects produced by holograms optimized using hogel-free holography. To capture these view-dependent efects, an aperture is placed on a …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_640",
    "authors": "Jonghyun Kim, Manu Gopakumar, Suyeon Choi, Yifan Peng, Ward Lopes, Gordon Wetzstein",
    "title": "Holographic Glasses for Virtual Reality",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530739",
    "pdf_link": null,
    "abstract": "We present Holographic Glasses, a holographic near-eye display system with an eyeglasses-like form factor for virtual reality. Holographic Glasses are composed of a pupil-replicating waveguide, a spatial light modulator, and a geometric phase lens to create holographic images in a lightweight and thin form factor. The proposed design can deliver full-color 3D holographic images using an optical stack of 2.5 mm thickness. A novel pupil-high-order gradient descent algorithm is presented for the correct phase calculation with the user’s varying pupil size. We implement benchtop and wearable prototypes for testing. Our binocular wearable prototype supports 3D focus cues and provides a diagonal field of view of 22.8° with a 2.3 mm static eye box and additional capabilities of dynamic eye box with beam steering, while weighing only 60 g excluding the driving board.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_122",
    "authors": "Alain Lioret, Lior Diler, Sami Dalil, Marion Mota",
    "title": "Hybrid Prediction for Games’ Rollback Netcode",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543199",
    "pdf_link": null,
    "abstract": "The online implementation for fighting games has evolved greatly recently. The fighting game genre needs efficient netcode implementation, because inputs are very precise and even a latency of a few frames will affect gameplay significantly. Of the two major netcode implementations on the market, one is of particular interest. Rollback Netcode, a recent invention and currently the most popular implementation, can be seen as the future for online fighting games. This technique attempts to emulate a more pleasant experience by not delaying the inputs of the players. Instead, when the connectivity is lost for one of the combatants, the netcode tries to naively predict the inputs of the momentarily disconnected player by assuming that the missing inputs are the same as the last received actual player input, as shown in the figure below.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_728",
    "authors": "Honghua Chen, Zeyong Wei, Yabin Xu, Mingqiang Wei, Jun Wang",
    "title": "ImLoveNet: Misaligned Image-supported Registration Network for Low-overlap Point Cloud Pairs",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530744",
    "pdf_link": null,
    "abstract": "Low-overlap regions between paired point clouds make the captured features very low-confidence, leading cutting edge models to point cloud registration with poor quality. Beyond the traditional wisdom, we raise an intriguing question: Is it possible to exploit an intermediate yet misaligned image between two low-overlap point clouds to enhance the performance of cutting-edge registration models? To answer it, we propose a misaligned image supported registration network for low-overlap point cloud pairs, dubbed ImLoveNet. ImLoveNet first learns triple deep features across different modalities and then exports these features to a two-stage classifier, for progressively obtaining the high-confidence overlap region between the two point clouds. Therefore, soft correspondences are well established on the predicted overlap region, resulting in accurate rigid transformations for registration. ImLoveNet is simple to implement yet effective, since 1) the misaligned image provides clearer overlap information for the two low-overlap point clouds to better locate overlap parts; 2) it contains certain geometry knowledge to extract better deep features; and 3) it does not require the extrinsic parameters of the imaging device with respect to the reference frame of the 3D point cloud. Extensive qualitative and quantitative evaluations on different kinds of benchmarks demonstrate the effectiveness and superiority of our ImLoveNet over state-of-the-art approaches.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_103",
    "authors": "Budmonde Duinkharjav, Praneeth Chakravarthula, Rachel Brown, Anjul Patney, Qi Sun",
    "title": "Image Features Influence Reaction Time: A Learned Probabilistic Perceptual Model for Saccade Latency",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530055",
    "pdf_link": null,
    "abstract": "We aim to ask and answer an essential question \"how quickly do we react after observing a displayed visual target?\" To this end, we present psychophysical studies that characterize the remarkable disconnect between human saccadic behaviors and spatial visual acuity. Building on the results of our studies, we develop a perceptual model to predict temporal gaze behavior, particularly saccadic latency, as a function of the statistics of a displayed image. Specifically, we implement a neurologically-inspired probabilistic model that mimics the accumulation of confidence that leads to a perceptual decision. We validate our model with a series of objective measurements and user studies using an eye-tracked VR display. The results demonstrate that our model prediction is in statistical alignment with real-world human behavior. Further, we establish that many sub-threshold image modifications commonly introduced in graphics pipelines may significantly alter human reaction timing, even if the differences are visually undetectable. Finally, we show that our model can serve as a metric to predict and alter reaction latency of users in interactive computer graphics applications, thus may improve gaze-contingent rendering, design of virtual experiences, and player performance in e-sports. We illustrate this with two examples: estimating competition fairness in a video game with two different team colors, and tuning display viewing distance to minimize player reaction time.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_225",
    "authors": "Achref Doula, Tobias Güdelhöfer, Andrii Mativiienko, Max Mühlhäuser, Alejandro Sanchez Guinea",
    "title": "Immersive-Labeler: Immersive Annotation of Large-scale 3D Point Clouds in Virtual Reality",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543249",
    "pdf_link": null,
    "abstract": "We present Immersive-Labeler, an environment for the annotation of large-scale 3D point cloud scenes of urban environments. Our concept is based on the full immersion of the user in a VR-based environment that represents the 3D point cloud scene while offering adapted visual aids and intuitive interaction and navigation modalities. Through a user-centric design, we aim to improve the annotation experience and thus reduce its costs. For the preliminary evaluation of our environment, we conduct a user study (N=20) to quantify the effect of higher levels of immersion in combination with the visual aids we implemented on the annotation process. Our findings reveal that higher levels of immersion combined with object-based visual aids lead to a faster and more engaging annotation process.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_576",
    "authors": "LINGCHEN YANG, Byungsoo Kim, Gaspard Zoss, Baran Gözcü, Markus Gross, Barbara Solenthaler",
    "title": "Implicit Neural Representation for Physics-driven Actuated Soft Bodies",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530156",
    "pdf_link": null,
    "abstract": "Active soft bodies can affect their shape through an internal actuation mechanism that induces a deformation. Similar to recent work, this paper utilizes a differentiable, quasi-static, and physics-based simulation layer to optimize for actuation signals parameterized by neural networks. Our key contribution is a general and implicit formulation to control active soft bodies by defining a function that enables a continuous mapping from a spatial point in the material space to the actuation value. This property allows us to capture the signal's dominant frequencies, making the method discretization agnostic and widely applicable. We extend our implicit model to mandible kinematics for the particular case of facial animation and show that we can reliably reproduce facial expressions captured with high-quality capture systems. We apply the method to volumetric soft bodies, human poses, and facial expressions, demonstrating artist-friendly properties, such as simple control over the latent space and resolution invariance at test time.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_248",
    "authors": "Florent Nauleau, Benjamin Fovet, Fabien Vivodtzev",
    "title": "In Situ Segmentation of Turbulent Flow With Topological Data Analysis",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543257",
    "pdf_link": null,
    "abstract": "The design of complex vehicles for atmospheric reentry requires running massive 3D calculations generating a set of important and complex data that must be analyzed to understand the physical phenomena involved. We focus on turbulent hydrodynamic flows in 2D, and viscous flows in 3D in order to study the areas of influence of the most important vortices. Topological data analysis methods",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_125",
    "authors": "Michelle Ma",
    "title": "Inclusive Character Creator: A Showcase of Inclusive Design for 3D Character Creators",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543201",
    "pdf_link": null,
    "abstract": "Inclusive Character Creator is a speculative design research project that seeks to address some of the long-standing issues of sexism, racism, ableism, and sizeism prevalent in most 3D character creators in interactive media. This project focuses on stylized and expressive features rather than hyperrealism. It seeks to redefine what it means to start a character from a “default body,” a definition that usually results in creating a biased system that relies on media norms. A version 1.0 has been built, encapsulating fundamental principles resulting from research.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_463",
    "authors": "Thomas Müller, Alex Evans, Christoph Schied, Alexander Keller",
    "title": "Instant Neural Graphics Primitives With a Multiresolution Hash Encoding",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530127",
    "pdf_link": null,
    "abstract": "Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920×1080.",
    "scholar_publication": "ACM transactions on graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_151",
    "authors": "Changyang Li, Wanwan Li, Haikun Huang, Lap-Fai Yu",
    "title": "Interactive Augmented Reality Storytelling Guided by Scene Semantics",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530061",
    "pdf_link": null,
    "abstract": "We present a novel interactive augmented reality (AR) storytelling approach guided by indoor scene semantics. Our approach automatically populates virtual contents in real-world environments to deliver AR stories, which match both the story plots and scene semantics. During the storytelling process, a player can participate as a character in the story. Meanwhile, the behaviors of the virtual characters and the placement of the virtual items adapt to the player's actions. An input raw story is represented as a sequence of events, which contain high-level descriptions of the characters' states, and is converted into a graph representation with automatically supplemented low-level spatial details. Our hierarchical story sampling approach samples realistic character behaviors that fit the story contexts through optimizations; and an animator, which estimates and prioritizes the player's actions, animates the virtual characters to tell the story in AR. Through experiments and a user study, we validated the effectiveness of our approach for AR storytelling in different environments.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_199",
    "authors": "Obumneme Stanley Dukor, S. Mahdi H. Miangoleh, Mahesh Kumar Krishna Reddy, Long Mai, Yağız Aksoy",
    "title": "Interactive Editing of Monocular Depth",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543235",
    "pdf_link": null,
    "abstract": "Recent advances in computer vision have made 3D structure-aware editing of still photographs a reality. Such computational photography applications use a depth map that is automatically generated by monocular depth estimation methods to represent the scene structure. In this work, we present a lightweight, web-based interactive depth editing and visualization tool that adapts low-level conventional image editing operations for geometric manipulation to enable artistic control in the 3D photography workflow. Our tool provides real-time feedback on the geometry through a 3D scene visualization to make the depth map editing process more intuitive for artists. Our web-based tool is open-source1 and platform-independent to support wider adoption of 3D photography techniques in everyday digital photography.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_304",
    "authors": "Fei Hou, Chiyu Wang, Wencheng Wang, Hong Qin, Chen Qian, Ying He",
    "title": "Iterative Poisson Surface Reconstruction (iPSR) for Unoriented Points",
    "paper_url": "https://arxiv.org/abs/2209.09510",
    "pdf_link": null,
    "abstract": "Poisson surface reconstruction (PSR) remains a popular technique for reconstructing watertight surfaces from 3D point samples thanks to its efficiency, simplicity, and robustness. Yet, the existing PSR method and subsequent variants work only for oriented points. This paper intends to validate that an improved PSR, called iPSR, can completely eliminate the requirement of point normals and proceed in an iterative manner. In each iteration, iPSR takes as input point samples with normals directly computed from the surface obtained in the preceding iteration, and then generates a new surface with better quality. Extensive quantitative evaluation confirms that the new iPSR algorithm converges in 5-30 iterations even with randomly initialized normals. If initialized with a simple visibility based heuristic, iPSR can further reduce the number of iterations. We conduct comprehensive comparisons with PSR and other powerful implicit-function based methods. Finally, we confirm iPSR's effectiveness and scalability on the AIM@SHAPE dataset and challenging (indoor and outdoor) scenes. Code and data for this paper are at https://github.com/houfei0801/ipsr.",
    "scholar_publication": "arXiv preprint arXiv …, 2022 - arxiv.org"
  },
  {
    "paper_id": "papers_190",
    "authors": "Yujie Wang, Praneeth Chakravarthula, Qi Sun, Baoquan Chen",
    "title": "Joint Neural Phase Retrieval and Compression for Energy- and Computation-efficient Holography on the Edge",
    "paper_url": "https://par.nsf.gov/biblio/10465404",
    "pdf_link": null,
    "abstract": "Recent deep learning approaches have shown remarkable promise to enable high fidelity holographic displays. However, lightweight wearable display devices cannot afford the computation demand and energy consumption for hologram generation due to the limited onboard compute capability and battery life. On the other hand, if the computation is conducted entirely remotely on a cloud server, transmitting lossless hologram data is not only challenging but also result in prohibitively high latency and storage. In this work, by distributing the computation and optimizing the transmission, we propose the first framework that jointly generates and compresses high-quality phase-only holograms. Specifically, our framework asymmetrically separates the hologram generation process into high-compute remote encoding (on the server), and low-compute decoding (on the edge) stages. Our encoding enables light weight latent space data, thus faster and efficient transmission to the edge device. With our framework, we observed a reduction of 76% computation and consequently 83% in energy cost on edge devices, compared to the existing hologram generation methods. Our framework is robust to transmission and decoding errors, and approach high image fidelity for as low as 2 bits-per-pixel, and further reduced average bit-rates and decoding time for holographic videos.",
    "scholar_publication": "ACM Transactions on …, 2022 - par.nsf.gov"
  },
  {
    "paper_id": "pos_241",
    "authors": "Takahito Murakami, Maya Torii, Xanat Vargas Meza, Yoichi Ochiai",
    "title": "Kuchibashi: 3D-printed Tweezers Bioinspired by the New Caledonian Crow’s Beak",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543254",
    "pdf_link": null,
    "abstract": "2 DESIGNMatsui et al.[Matsui et al. 2016] analyzed comparing the characteristics of the NCC beak and genus Corvus. The beak features a length of 4.3 cm from the anterior nasal hinge to the tip of the upper mandible, and the upper mandible is longer than the lower mandible (Fig. 1 d).",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_839",
    "authors": "Ke Ma, Sagnik Das, Zhixin Shu, Dimitris Samaras",
    "title": "Learning From Documents in the Wild to Improve Document Unwarping",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530756",
    "pdf_link": null,
    "abstract": "Document image unwarping is important for document digitization and analysis. The state-of-the-art approach relies on purely synthetic data to train deep networks for unwarping. As a result, the trained networks have generalization limitations when testing on real-world images, often yielding unsatisfying results. In this work, we propose to improve document unwarping performance by incorporating real-world images in training. We collected Document-in-the-Wild (DIW) dataset contains 5000 captured document images with large diversities in content, shape, and capturing environment. We annotate the boundaries of all DIW images and use them for weakly supervised learning. We propose a novel network architecture, PaperEdge, to train with a hybrid of synthetic and real document images. Additionally, we identify and analyze the flaws of popular evaluation metrics, e.g., MS-SSIM and Local Distortion (LD), for document unwarping and propose a more robust and reliable error metric called Aligned Distortion (AD). Training with a combination of synthetic and real-world document images, we demonstrate state-of-the-art performance on popular benchmarks with comprehensive quantitative evaluations and ablation studies. Code and data are available at https://github.com/cvlab-stonybrook/PaperEdge.",
    "scholar_publication": "ACM SIGGRAPH 2022 Conference …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_288",
    "authors": "Qijin She, Ruizhen Hu, Juzhan Xu, Min Liu, Kai Xu, Hui Huang",
    "title": "Learning High-DOF Reaching-and-grasping via Dynamic Representation of Gripper-object Interaction",
    "paper_url": "https://arxiv.org/abs/2204.13998",
    "pdf_link": null,
    "abstract": "We approach the problem of high-DOF reaching-and-grasping via learning joint planning of grasp and motion with deep reinforcement learning. To resolve the sample efficiency issue in learning the high-dimensional and complex control of dexterous grasping, we propose an effective representation of grasping state characterizing the spatial interaction between the gripper and the target object. To represent gripper-object interaction, we adopt Interaction Bisector Surface (IBS) which is the Voronoi diagram between two close by 3D geometric objects and has been successfully applied in characterizing spatial relations between 3D objects. We found that IBS is surprisingly effective as a state representation since it well informs the fine-grained control of each finger with spatial relation against the target object. This novel grasp representation, together with several technical contributions including a fast IBS approximation, a novel vector-based reward and an effective training strategy, facilitate learning a strong control model of high-DOF grasping with good sample efficiency, dynamic adaptability, and cross-category generality. Experiments show that it generates high-quality dexterous grasp for complex shapes with smooth grasping motions.",
    "scholar_publication": "arXiv preprint arXiv:2204.13998, 2022 - arxiv.org"
  },
  {
    "paper_id": "papers_344",
    "authors": "Hsueh-Ti Derek Liu, Francis Williams, Alec Jacobson, Sanja Fidler, Or Litany",
    "title": "Learning Smooth Neural Functions via Lipschitz Regularization",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530713",
    "pdf_link": null,
    "abstract": "Neural implicit fields have recently emerged as a useful representation for 3D shapes. These fields are commonly represented as neural networks which map latent descriptors and 3D coordinates to implicit function values. The latent descriptor of a neural field acts as a deformation handle for the 3D shape it represents. Thus, smoothness with respect to this descriptor is paramount for performing shape-editing operations. In this work, we introduce a novel regularization designed to encourage smooth latent spaces in neural fields by penalizing the upper bound on the field’s Lipschitz constant. Compared with prior Lipschitz regularized networks, ours is computationally fast, can be implemented in four lines of code, and requires minimal hyperparameter tuning for geometric applications. We demonstrate the effectiveness of our approach on shape interpolation and extrapolation as well as partial shape reconstruction from 3D point clouds, showing both qualitative and quantitative improvements over existing state-of-the-art and non-regularized baselines.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_585",
    "authors": "Zhaoming Xie, Sebastian Starke, Hung Yu Ling, Michiel van de Panne",
    "title": "Learning Soccer Juggling Skills With Layer-wise Mixture of Experts",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530735",
    "pdf_link": null,
    "abstract": "Learning physics-based character controllers that can successfully integrate diverse motor skills using a single policy remains a challenging problem. We present a system to learn control policies for multiple soccer juggling skills, based on deep reinforcement learning. We introduce a task-description framework for these skills which facilitates the specification of individual soccer juggling tasks and the transitions between them. Desired motions can be authored using interpolation of crude reference poses or based on motion capture data. We …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_157",
    "authors": "Yotam Nitzan, Kfir Aberman, Orly Liba, Qiurui He, Michal Yarom, Yossi Gandelsman, Inbar Mosseri, Yael Pritch, Daniel Cohen-Or",
    "title": "Learning a Personalized Generative Prior for Face Images",
    "paper_url": "https://dl.acm.org/doi/pdf/10.1145/3532719.3543215",
    "pdf_link": null,
    "abstract": "In recent years, the domain of image editing and enhancement in general, and face editing in particular, has experienced a significant shift. From pixel-level approaches, the field gradually shifted to latent-space methods that essentially interpret editing operators applied in a latent space of a generative model, as explicit image",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_487",
    "authors": "Daniele Reda, Hung Yu Ling, Michiel van de Panne",
    "title": "Learning to Brachiate via Simplified Model Imitation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530728",
    "pdf_link": null,
    "abstract": "Brachiation is the primary form of locomotion for gibbons and siamangs, in which these primates swing from tree limb to tree limb using only their arms. It is challenging to control because of the limited control authority, the required advance planning, and the precision of the required grasps. We present a novel approach to this problem using reinforcement learning, and as demonstrated on a finger-less 14-link planar model that learns to brachiate across challenging handhold sequences. Key to our method is the use of a simplified model, a point mass with a virtual arm, for which we first learn a policy that can brachiate across handhold sequences with a prescribed order. This facilitates the learning of the policy for the full model, for which it provides guidance by providing an overall center-of-mass trajectory to imitate, as well as for the timing of the holds. Lastly, the simplified model can also readily be used for planning suitable sequences of handholds in a given environment. Our results demonstrate brachiation motions with a variety of durations for the flight and hold phases, as well as emergent extra back-and-forth swings when this proves useful. The system is evaluated with a variety of ablations. The method enables future work towards more general 3D brachiation, as well as using simplified model imitation in other settings. For videos, supplementary material and code, visit: https://brachiation-rl.github.io/brachiation.",
    "scholar_publication": "ACM SIGGRAPH 2022 conference …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_149",
    "authors": "Tianxin Tao, Matthew Wilson, Ruiyu Gou, Michiel van de Panne",
    "title": "Learning to Get Up",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530697",
    "pdf_link": null,
    "abstract": "… Then, we show that learning slow getup motions can further improve the naturalness of the motion. Also, we exploit the future pose conditioned policy 𝜋slow to pause the getup motions …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_146",
    "authors": "Zeshi Yang, KangKang Yin, Libin Liu",
    "title": "Learning to Use Chopsticks in Diverse Gripping Styles",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530057",
    "pdf_link": null,
    "abstract": "Learning dexterous manipulation skills is a long-standing challenge in computer graphics and robotics, especially when the task involves complex and delicate interactions between the hands, tools and objects. In this paper, we focus on chopsticks-based object relocation tasks, which are common yet demanding. The key to successful chopsticks skills is steady gripping of the sticks that also supports delicate maneuvers. We automatically discover physically valid chopsticks holding poses by Bayesian Optimization (BO) and Deep Reinforcement Learning (DRL), which works for multiple gripping styles and hand morphologies without the need of example data. Given as input the discovered gripping poses and desired objects to be moved, we build physics-based hand controllers to accomplish relocation tasks in two stages. First, kinematic trajectories are synthesized for the chopsticks and hand in a motion planning stage. The key components of our motion planner include a grasping model to select suitable chopsticks configurations for grasping the object, and a trajectory optimization module to generate collision-free chopsticks trajectories. Then we train physics-based hand controllers through DRL again to track the desired kinematic trajectories produced by the motion planner. We demonstrate the capabilities of our framework by relocating objects of various shapes and sizes, in diverse gripping styles and holding positions for multiple hand morphologies. Our system achieves faster learning speed and better control robustness, when compared to vanilla systems that attempt to learn chopstick-based skills without a gripping pose optimization module and/or without a kinematic motion planner. Our code and models are available at this link.1",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_785",
    "authors": "Iñigo Ezcurdia, Rafael Morales, Marco A. B. Andrade, Asier Marzo",
    "title": "LeviPrint: Contactless Fabrication Using Full Acoustic Manipulation of Elongated Parts",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530752",
    "pdf_link": null,
    "abstract": "LeviPrint is a system for assembling objects in a contactless manner using acoustic levitation. We explore a set of optimum acoustic fields that enables full trapping in position and orientation of elongated objects such as sticks. We then evaluate the capabilities of different ultrasonic levitators to dynamically manipulate these elongated objects. The combination of novel optimization algorithms and levitators enable the manipulation of sticks, beads and droplets to fabricate complex objects. A system prototype composed of a robot arm and a levitator is tested for different fabrication processes. We highlight the reduction of cross-contamination and the capability of building on top of objects from different angles as well as inside closed spaces. We hope that this technique inspires novel fabrication techniques and that reaches fields such as microfabrication of electromechanical components or even in-vivo additive manufacturing.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_415",
    "authors": "Prashanth Chandran, Loïc Ciccone, Markus Gross, Derek Bradley",
    "title": "Local Anatomically Constrained Facial Performance Retargeting",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530114",
    "pdf_link": null,
    "abstract": "Generating realistic facial animation for CG characters and digital doubles is one of the hardest tasks in animation. A typical production workflow involves capturing the performance of a real actor using mo-cap technology, and transferring the captured motion to the target digital character. This process, known as retargeting, has been used for over a decade, and typically relies on either large blendshape rigs that are expensive to create, or direct deformation transfer algorithms that operate on individual geometric elements and are prone to artifacts. We present a new method for high-fidelity offline facial performance retargeting that is neither expensive nor artifact-prone. Our two step method first transfers local expression details to the target, and is followed by a global face surface prediction that uses anatomical constraints in order to stay in the feasible shape space of the target character. Our method also offers artists with familiar blendshape controls to perform fine adjustments to the retargeted animation. As such, our method is ideally suited for the complex task of human-to-human 3D facial performance retargeting, where the quality bar is extremely high in order to avoid the uncanny valley, while also being applicable for more common human-to-creature settings. We demonstrate the superior performance of our method over traditional deformation transfer algorithms, while achieving a quality comparable to current blendshape-based techniques used in production while requiring significantly fewer input shapes at setup time. A detailed user study corroborates the realistic and artifact free animations generated by our method in comparison to existing techniques.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_221",
    "authors": "Pratik Kalshetti, Parag Chaudhuri",
    "title": "Local Scale Adaptation for Augmenting Hand Shape Models",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543246",
    "pdf_link": null,
    "abstract": "The accuracy of hand pose and shape recovery algorithms depends on how closely the geometric hand model resembles the user’s hand. Most existing methods rely on learned shape space, e.g. MANO; but this shape model fails to generalize to unseen hand shapes with large deviations from the training set. We introduce a new hand shape model, aMANO, that augments MANO by introducing local scale adaptation that enables modeling substantially different hand sizes. We use both MANO and aMANO for calibrating the shape to new users from a stream of depth images and observe the improvement of aMANO over MANO. We believe that our new hand shape model is a significant step in improving the robustness and accuracy of existing hand tracking solutions.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_147",
    "authors": "Steve Lesser, Alexey Stomakhin, Gilles Daviet, Joel Wretborn, John Edholm, Noh-hoon Lee, Eston Schweickart, Xiao Zhai, Sean Flynn, Andrew Moffat",
    "title": "Loki: A Unified Multiphysics Simulation Framework for Production",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530058",
    "pdf_link": null,
    "abstract": "We introduce Loki, a new framework for robust simulation of fluid, rigid, and deformable objects with non-compromising fidelity on any single element, and capabilities for coupling and representation transitions across multiple elements. Loki adapts multiple best-in-class solvers into a unified framework driven by a declarative state machine where users declare 'what' is simulated but not 'when,' so an automatic scheduling system takes care of mixing any combination of objects. This leads to intuitive setups for coupled simulations such as hair in the wind or objects transitioning from one representation to another, for example bulk water FLIP particles to SPH spray particles to volumetric mist. We also provide a consistent treatment for components used in several domains, such as unified collision and attachment constraints across 1D, 2D, 3D deforming and rigid objects. Distribution over MPI, custom linear equation solvers, and aggressive application of sparse techniques keep performance within production requirements. We demonstrate a variety of solvers within the framework and their interactions, including FLIPstyle liquids, spatially adaptive volumetric fluids, SPH, MPM, and mesh-based solids, including but not limited to discrete elastic rods, elastons, and FEM with state-of-the-art constitutive models. Our framework has proven powerful and intuitive enough for voluntary artist adoption and has delivered creature and FX simulations for multiple major movie productions in the preceding four years.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_126",
    "authors": "Mohamed Sayed, Robert Cinca, Enrico Costanza, Gabriel Brostow, Mohamed Sayed",
    "title": "LookOut! Interactive Camera Gimbal Controller for Filming Long Takes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3506693",
    "pdf_link": null,
    "abstract": "The job of a camera operator is challenging, and potentially dangerous, when filming long moving camera shots. Broadly, the operator must keep the actors in frame while safely navigating around obstacles and while fulfilling an artistic vision. We propose a unified hardware and software system that distributes some of the camera operator’s burden, freeing the operator up to focus on safety and aesthetics during a take. Our real-time system provides solo operators with end-to-end control so that they can balance on-set responsiveness to action against planned storyboards and framing while looking where they are going. By default, we film without a field monitor. Our LookOut system is built around a lightweight commodity camera gimbal mechanism, with heavy modifications to the controller, which would normally just provide active stabilization. Our control algorithm reacts to speech commands, video, and a premade script. Specifically, our automatic monitoring of the live video feed saves the operator from distractions. In preproduction, an artist uses our graphical user interface (GUI) to design a sequence of high-level camera “behaviors.” Those can be specific, based on a storyboard, or looser objectives, such as “frame both actors.” Then, during filming, a machine-readable script, exported from the GUI, ties together with the sensor readings to drive the gimbal. To validate our algorithm, we compared tracking strategies, interfaces, and hardware protocols and collected impressions from (a) filmmakers who used all aspects of our system and (b) filmmakers who watched footage filmed using LookOut.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_375",
    "authors": "Xifeng Gao, Kui Wu, Zherong Pan",
    "title": "Low-poly Mesh Generation for Building Models",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530716",
    "pdf_link": null,
    "abstract": "As a common practice, game modelers manually craft low-poly meshes for given 3D building models in order to achieve the ideal balance between the small element count and the visual similarity. This can take hours and involve tedious trial and error. We propose a novel and simple algorithm to automate this process by converting high-poly 3D building models into both simple and visually preserving low-poly meshes. Our algorithm has three stages: First, a watertight, self-collision-free visual hull is generated via Boolean intersecting …",
    "scholar_publication": "ACM SIGGRAPH 2022 Conference Proceedings, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_168",
    "authors": "Loïs Paulin, Nicolas Bonneel, David Coeurjolly, JEAN CLAUDE IEHL, Alexander Keller, Victor Ostromoukhov",
    "title": "MatBuilder: Mastering Sampling Uniformity Over Projections",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530063",
    "pdf_link": null,
    "abstract": "Many applications ranging from quasi-Monte Carlo integration over optimal control to neural networks benefit from high-dimensional, highly uniform samples. In the case of computer graphics, and more particularly in rendering, despite the need for uniformity, several sub-problems expose a low-dimensional structure. In this context, mastering sampling uniformity over projections while preserving high-dimensional uniformity has been intrinsically challenging. This difficulty may explain the relatively small number of mathematical constructions for such samplers. We propose a novel approach by showing that uniformity constraints can be expressed as an integer linear program that results in a sampler with the desired properties. As it turns out, complex constraints are easy to describe by means of stratification and sequence properties of digital nets. Formalized using generator matrix determinants, our new MatBuilder software solves the set of constraints by iterating the linear integer program solver in a greedy fashion to compute a problem-specific set of generator matrices that can be used as a drop-in replacement in the popular digital net samplers. The samplers created by MatBuilder achieve the uniformity of classic low discrepancy sequences. More importantly, we demonstrate the benefit of the unprecedented versatility of our constraint approach with respect to low-dimensional problem structure for several applications.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_691",
    "authors": "Paul Guerrero, Miloš Hašan, Kalyan Sunkavalli, Radomír Měch, Tamy Boubekeur, Niloy Mitra",
    "title": "MatFormer: A Generative Model for Procedural Materials",
    "paper_url": "https://arxiv.org/abs/2207.01044",
    "pdf_link": null,
    "abstract": "Procedural material graphs are a compact, parameteric, and resolution-independent representation that are a popular choice for material authoring. However, designing procedural materials requires significant expertise and publicly accessible libraries contain only a few thousand such graphs. We present MatFormer, a generative model that can produce a diverse set of high-quality procedural materials with complex spatial patterns and appearance. While procedural materials can be modeled as directed (operation) graphs, they contain arbitrary numbers of heterogeneous nodes with unstructured, often long-range node connections, and functional constraints on node parameters and connections. MatFormer addresses these challenges with a multi-stage transformer-based model that sequentially generates nodes, node parameters, and edges, while ensuring the semantic validity of the graph. In addition to generation, MatFormer can be used for the auto-completion and exploration of partial material graphs. We qualitatively and quantitatively demonstrate that our method outperforms alternative approaches, in both generated graph and material quality.",
    "scholar_publication": "arXiv preprint arXiv …, 2022 - arxiv.org"
  },
  {
    "paper_id": "pos_243",
    "authors": "Takuro Yonezawa, Nozomi Hayashida, Johannes Przybilla, Yutaro Kyono, Kenta Urano, Nobuo Kawaguchi",
    "title": "MetaPo: A Robotic Meta Portal for Interspace Communication",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543255",
    "pdf_link": null,
    "abstract": "We introduce MetaPo, a mobile robot with spheric display, 360° media I/O and robotic hands for creating a unified model of interspace communication. MetaPo works as a portal between pairs of physical-physical, cyber-cyber and cyber-physical spaces to provide 1) panoramic communication for multiple remote users, and 2) immersive interspace migration with mobility functionality. The paper overviews our concept and first prototype of MetaPo with its hardware and software implementation.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_257",
    "authors": "Navid Ansari, Hans-Peter Seidel, Vahid Babaei",
    "title": "Mixed Integer Neural Inverse Design",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530083",
    "pdf_link": null,
    "abstract": "In computational design and fabrication, neural networks are becoming important surrogates for bulky forward simulations. A long-standing, intertwined question is that of inverse design: how to compute a design that satisfies a desired target performance? Here, we show that the piecewise linear property, very common in everyday neural networks, allows for an inverse design formulation based on mixed-integer linear programming. Our mixed-integer inverse design uncovers globally optimal or near optimal solutions in a principled manner. Furthermore, our method significantly facilitates emerging, but challenging, combinatorial inverse design tasks, such as material selection. For problems where finding the optimal solution is intractable, we develop an efficient yet near-optimal hybrid approach. Eventually, our method is able to find solutions provably robust to possible fabrication perturbations among multiple designs with similar performances. Our code and data are available at https://gitlab.mpi-klsb.mpg.de/nansari/mixed-integer-neural-inverse-design.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_796",
    "authors": "Daoye Wang, Prashanth Chandran, Gaspard Zoss, Derek Bradley, Paulo Gotardo",
    "title": "MoRF: Morphable Radiance Fields for Multiview Neural Head Modeling",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530753",
    "pdf_link": null,
    "abstract": "Recent research work has developed powerful generative models (e.g., StyleGAN2) that can synthesize complete human head images with impressive photorealism, enabling applications such as photorealistically editing real photographs. While these models can be trained on large collections of unposed images, their lack of explicit 3D knowledge makes it difficult to achieve even basic control over 3D viewpoint without unintentionally altering identity. On the other hand, recent Neural Radiance Field (NeRF) methods have already achieved multiview-consistent, photorealistic renderings but they are so far limited to a single facial identity. In this paper, we propose a new Morphable Radiance Field (MoRF) method that extends a NeRF into a generative neural model that can realistically synthesize multiview-consistent images of complete human heads, with variable and controllable identity. MoRF allows for morphing between particular identities, synthesizing arbitrary new identities, or quickly generating a NeRF from few images of a new subject, all while providing realistic and consistent rendering under novel viewpoints. We train MoRF in a supervised fashion by leveraging a high-quality database of multiview portrait images of several people, captured in studio with polarization-based separation of diffuse and specular reflection. Here, we demonstrate how MoRF is a strong new step forwards towards generative NeRFs for 3D neural head modeling.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_156",
    "authors": "Masamune Takano, Yuki Morimoto",
    "title": "Modeling 3D Hair by Outlining Hair Cards",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543214",
    "pdf_link": null,
    "abstract": "We propose an intuitive method for modeling 3DCG character’s hair by inputting sketched lines as the left and right contour lines of a hair strand. Modeling a character’s hairstyle is an important task that affects the character’s appearance. Generally, hair modeling requires many complex tasks. In our method, the user inputs the left and right outlines by sketching them to create hair strand meshes. This enables the user to adjust the details while considering the overall outline of the hairstyle (Fig. 1).",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_822",
    "authors": "Seung-wook Kim, Jaehyung Doh, JungHyun Han",
    "title": "Modeling and Rendering Non-Euclidean Spaces Approximated With Concatenated Polytopes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530186",
    "pdf_link": null,
    "abstract": "A non-Euclidean space is characterized as a manifold with a specific structure that violates Euclid's postulates. This paper proposes to approximate a manifold with polytopes. Based on the scene designer's specification, the polytopes are automatically concatenated and embedded in a higher-dimensional Euclidean space. Then, the scene is navigated and rendered via novel methods tailored to concatenated polytopes. The proof-of-concept implementation and experiments with it show that the proposed methods bring the virtual-world users unusual and fascinating experiences, which cannot be provided in Euclidean-space applications.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_106",
    "authors": "Deok-Kyeong Jang, Soomin Park, Sung-Hee Lee, Deok-Kyeong Jang",
    "title": "Motion Puzzle: Arbitrary Motion Style Transfer by Body Part",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3516429",
    "pdf_link": null,
    "abstract": "This article presents Motion Puzzle, a novel motion style transfer network that advances the state-of-the-art in several important respects. The Motion Puzzle is the first that can control the motion style of individual body parts, allowing for local style editing and significantly increasing the range of stylized motions. Designed to keep the human’s kinematic structure, our framework extracts style features from multiple style motions for different body parts and transfers them locally to the target body parts. Another major advantage is that it can transfer both global and local traits of motion style by integrating the adaptive instance normalization and attention modules while keeping the skeleton topology. Thus, it can capture styles exhibited by dynamic movements, such as flapping and staggering, significantly better than previous work. In addition, our framework allows for arbitrary motion style transfer without datasets with style labeling or motion pairing, making many publicly available motion datasets available for training. Our framework can be easily integrated with motion generation frameworks to create many applications, such as real-time motion transfer. We demonstrate the advantages of our framework with a number of examples and comparisons with previous work.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_549",
    "authors": "Corentin Mercier, Thibault Lescoat, Pierre Roussillon, Tamy Boubekeur, Jean-Marc Thiery",
    "title": "Moving Level-of-detail Surfaces",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530151",
    "pdf_link": null,
    "abstract": "… is to consider a moving level-of-detail of the … moving least squares scheme. We also introduce an adaptive progressive octree refinement scheme, driven by the resulting implicit surface, …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_447",
    "authors": "Thomas Mitchel, Noam Aigerman, Vladimir G. Kim, Michael Kazhdan",
    "title": "Möbius Convolutions for Spherical CNNs",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530724",
    "pdf_link": null,
    "abstract": "Möbius transformations play an important role in both geometry and spherical image processing – they are the group of conformal automorphisms of 2D surfaces and the spherical equivalent of homographies. Here we present a novel, Möbius-equivariant spherical convolution operator which we call Möbius convolution; with it, we develop the foundations for Möbius-equivariant spherical CNNs. Our approach is based on the following observation: to achieve equivariance, we only need to consider the lower-dimensional subgroup which transforms the positions of points as seen in the frames of their neighbors. To efficiently compute Möbius convolutions at scale we derive an approximation of the action of the transformations on spherical filters, allowing us to compute our convolutions in the spectral domain with the fast Spherical Harmonic Transform. The resulting framework is flexible and descriptive, and we demonstrate its utility by achieving promising results in both shape classification and image segmentation tasks.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_231",
    "authors": "Yuwei Li, Longwen Zhang, Zesong Qiu, Yingwenqi Jiang, Nianyi Li, Yuexin Ma, Yuyao Zhang, Lan Xu, Jingyi Yu",
    "title": "NIMBLE: A Non-rigid Hand Model With Bones and Muscles",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530079",
    "pdf_link": null,
    "abstract": "Emerging Metaverse applications demand reliable, accurate, and photorealistic reproductions of human hands to perform sophisticated operations as if in the physical world. While real human hand represents one of the most intricate coordination between bones, muscle, tendon, and skin, state-of-the-art techniques unanimously focus on modeling only the skeleton of the hand. In this paper, we present NIMBLE, a novel parametric hand model that includes the missing key components, bringing 3D hand model to a new level of realism. We first annotate muscles, bones and skins on the recent Magnetic Resonance Imaging hand (MRI-Hand) dataset [Li et al. 2021] and then register a volumetric template hand onto individual poses and subjects within the dataset. NIMBLE consists of 20 bones as triangular meshes, 7 muscle groups as tetrahedral meshes, and a skin mesh. Via iterative shape registration and parameter learning, it further produces shape blend shapes, pose blend shapes, and a joint regressor. We demonstrate applying NIMBLE to modeling, rendering, and visual inference tasks. By enforcing the inner bones and muscles to match anatomic and kinematic rules, NIMBLE can animate 3D hands to new poses at unprecedented realism. To model the appearance of skin, we further construct a photometric HandStage to acquire high-quality textures and normal maps to model wrinkles and palm print. Finally, NIMBLE also benefits learning-based hand pose and shape estimation by either synthesizing rich data or acting directly as a differentiable layer in the inference network.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_438",
    "authors": "Darius Rückert, Rui Li, Yuanhao Wang, Ramzi Idoughi, Wolfgang Heidrich",
    "title": "NeAT: Neural Adaptive Tomography",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530121",
    "pdf_link": null,
    "abstract": "… Overview of our adaptive neural rendering pipeline for tomographic reconstruction. To … -octree intersection, sample the neural volume, decode the neural features, and integrate them by …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_730",
    "authors": "Zhengfei Kuang, Kyle Olszewski, Menglei Chai, Zeng Huang, Panos Achlioptas, Sergey Tulyakov",
    "title": "NeROIC: Neural Rendering of Objects From Online Image Collections",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530177",
    "pdf_link": null,
    "abstract": "We present a novel method to acquire object representations from online image collections, capturing high-quality geometry and material properties of arbitrary objects from photographs with varying cameras, illumination, and backgrounds. This enables various object-centric rendering applications such as novel-view synthesis, relighting, and harmonized background composition from challenging in-the-wild input. Using a multi-stage approach extending neural radiance fields, we first infer the surface geometry and refine the coarsely estimated initial camera parameters, while leveraging coarse foreground object masks to improve the training efficiency and geometry quality. We also introduce a robust normal estimation technique which eliminates the effect of geometric noise while retaining crucial details. Lastly, we extract surface material properties and ambient illumination, represented in spherical harmonics with extensions that handle transient elements, e.g. sharp shadows. The union of these components results in a highly modular and efficient object acquisition framework. Extensive evaluations and comparisons demonstrate the advantages of our approach in capturing high-quality geometry and appearance properties useful for rendering applications.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_155",
    "authors": "Allison Jing, Kunal Gupta, Jeremy McDade, Gun Lee, Mark Billinghurst",
    "title": "Near-gaze Visualisations of Empathic Communication Cues in Mixed Reality Collaboration",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543213",
    "pdf_link": null,
    "abstract": "In this poster, we present a live 360° panoramic-video based empathic Mixed Reality (MR) collaboration system that shares various Near-Gaze non-verbal communication cues including gaze, hand pointing, gesturing, and heart rate visualisations in real-time. The preliminary results indicate that the interface with the partner’s communication cues visualised close to the gaze point allows users to focus without dividing attention to the collaborator’s physical body movements yet still effectively communicate. Shared gaze visualisations coupled with deictic languages are primarily used to affirm joint attention and mutual understanding, while hand pointing and gesturing are used as secondary. Our approach provides a new way to help enable effective remote collaboration through varied empathic communication visualisations and modalities which covers different task properties and spatial setups.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_393",
    "authors": "Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, Noah Snavely",
    "title": "Neural 3D Reconstruction in the Wild",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530718",
    "pdf_link": null,
    "abstract": "We are witnessing an explosion of neural implicit representations in computer vision and graphics. Their applicability has recently expanded beyond tasks such as shape generation and image-based rendering to the fundamental problem of image-based 3D reconstruction. However, existing methods typically assume constrained 3D environments with constant illumination captured by a small set of roughly uniformly distributed cameras. We introduce a new method that enables efficient and accurate surface reconstruction from Internet photo collections in the presence of varying illumination. To achieve this, we propose a hybrid voxel- and surface-guided sampling technique that allows for more efficient ray sampling around surfaces and leads to significant improvements in reconstruction quality. Further, we present a new benchmark and protocol for evaluating reconstruction performance on such in-the-wild scenes. We perform extensive experiments, demonstrating that our approach surpasses both classical and neural reconstruction methods on a wide variety of metrics. Code and data will be made available at https://zju3dv.github.io/neuralrecon-w.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_376",
    "authors": "Zhiqin Chen, Andrea Tagliasacchi, Thomas Funkhouser, Hao Zhang",
    "title": "Neural Dual Contouring",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530108",
    "pdf_link": null,
    "abstract": "We introduce neural dual contouring (NDC), a new data-driven approach to mesh reconstruction based on dual contouring (DC). Like traditional DC, it produces exactly one vertex per …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_520",
    "authors": "Noam Aigerman, Kunal Gupta, Vladimir Kim, Jun Saito, Siddhartha Chaudhuri, Thibault Groueix",
    "title": "Neural Jacobian Fields: Learning Intrinsic Mappings of Arbitrary Meshes",
    "paper_url": "https://arxiv.org/abs/2205.02904",
    "pdf_link": null,
    "abstract": "This paper introduces a framework designed to accurately predict piecewise linear mappings of arbitrary meshes via a neural network, enabling training and evaluating over heterogeneous collections of meshes that do not share a triangulation, as well as producing highly detail-preserving maps whose accuracy exceeds current state of the art. The framework is based on reducing the neural aspect to a prediction of a matrix for a single given point, conditioned on a global shape descriptor. The field of matrices is then projected onto the tangent bundle of the given mesh, and used as candidate jacobians for the predicted map. The map is computed by a standard Poisson solve, implemented as a differentiable layer with cached pre-factorization for efficient training. This construction is agnostic to the triangulation of the input, thereby enabling applications on datasets with varying triangulations. At the same time, by operating in the intrinsic gradient domain of each individual mesh, it allows the framework to predict highly-accurate mappings. We validate these properties by conducting experiments over a broad range of scenarios, from semantic ones such as morphing, registration, and deformation transfer, to optimization-based ones, such as emulating elastic deformations and contact correction, as well as being the first work, to our knowledge, to tackle the task of learning to compute UV parameterizations of arbitrary meshes. The results exhibit the high accuracy of the method as well as its versatility, as it is readily applied to the above scenarios without any changes to the framework.",
    "scholar_publication": "arXiv preprint arXiv …, 2022 - arxiv.org"
  },
  {
    "paper_id": "papers_546",
    "authors": "Jiahui Fan, Beibei Wang, Milos Hasan, Jian Yang, Ling-Qi Yan",
    "title": "Neural Layered BRDFs",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530732",
    "pdf_link": null,
    "abstract": "… Figure 1 Figure 1: We present a neural latent representation for BRDFs and a BRDF layering network based on it. Our method is able to produce closely matching layered results to the …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_621",
    "authors": "Bangbang Yang, Yinda Zhang, Yijin Li, Zhaopeng Cui, Sean Fanello, Hujun Bao, Guofeng Zhang",
    "title": "Neural Rendering in a Room: Amodal 3D Understanding and Free-viewpoint Rendering for the Closed Scene Composed of Pre-Captured Objects",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530163",
    "pdf_link": null,
    "abstract": "We, as human beings, can understand and picture a familiar scene from arbitrary viewpoints given a single image, whereas this is still a grand challenge for computers. We hereby present a novel solution to mimic such human perception capability based on a new paradigm of amodal 3D scene understanding with neural rendering for a closed scene. Specifically, we first learn the prior knowledge of the objects in a closed scene via an offline stage, which facilitates an online stage to understand the room with unseen furniture arrangement. During the online stage, given a panoramic image of the scene in different layouts, we utilize a holistic neural-rendering-based optimization framework to efficiently estimate the correct 3D scene layout and deliver realistic free-viewpoint rendering. In order to handle the domain gap between the offline and online stage, our method exploits compositional neural rendering techniques for data augmentation in the offline training. The experiments on both synthetic and real datasets demonstrate that our two-stage design achieves robust 3D scene understanding and outperforms competing methods by a large margin, and we also show that our realistic free-viewpoint rendering enables various applications, including scene touring and editing. Code and data are available on the project webpage: https://zju3dv.github.io/nr_in_a_room/.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_195",
    "authors": "Sayantan Datta, Derek Nowrouzezahrai, Christoph Schied, Zhao Dong",
    "title": "Neural Shadow Mapping",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530700",
    "pdf_link": null,
    "abstract": "… a neural extension of basic shadow mapping for fast, high quality hard and soft shadows. We compare favorably to fast pre-filtering shadow mapping… -to-train neural shadowing method. …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_206",
    "authors": "Lei Xiao, Salah Nouri, Joel Hegland, Alberto Garcia Garcia, Douglas Lanman",
    "title": "NeuralPassthrough: Learned Real-time View Synthesis for VR",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530701",
    "pdf_link": null,
    "abstract": "Virtual reality (VR) headsets provide an immersive, stereoscopic visual experience, but at the cost of blocking users from directly observing their physical environment. Passthrough techniques are intended to address this limitation by leveraging outward-facing cameras to reconstruct the images that would otherwise be seen by the user without the headset. This is inherently a real-time view synthesis challenge, since passthrough cameras cannot be physically co-located with the user’s eyes. Existing passthrough techniques suffer from distracting reconstruction artifacts, largely due to the lack of accurate depth information (especially for near-field and disoccluded objects), and also exhibit limited image quality (e.g., being low resolution and monochromatic). In this paper, we propose the first learned passthrough method and assess its performance using a custom VR headset that contains a stereo pair of RGB cameras. Through both simulations and experiments, we demonstrate that our learned passthrough method delivers superior image quality compared to state-of-the-art methods, while meeting strict VR requirements for real-time, perspective-correct stereoscopic view synthesis over a wide field of view for desktop-connected headsets.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_786",
    "authors": "Xutong Jin, Sheng Li, Dinesh Manocha, Guoping Wang",
    "title": "NeuralSound: Learning-based Modal Sound Synthesis With Acoustic Transfer",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530184",
    "pdf_link": null,
    "abstract": "We present a novel learning-based modal sound synthesis approach that includes a mixed vibration solver for modal analysis and a radiation network for acoustic transfer. Our mixed vibration solver consists of a 3D sparse convolution network and a Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) module for iterative optimization. Moreover, we highlight the correlation between a standard numerical vibration solver and our network architecture. Our radiation network predicts the Far-Field Acoustic Transfer maps (FFAT Maps) from the surface vibration of the object. The overall running time of our learning-based approach for most new objects is less than one second on a RTX 3080 Ti GPU while maintaining a high sound quality close to the ground truth solved by standard numerical methods. We also evaluate the numerical and perceptual accuracy of our approach on different objects with various shapes and materials.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_748",
    "authors": "Maria Korosteleva, Sung-Hee Lee",
    "title": "NeuralTailor: Reconstructing Sewing Pattern Structures From 3D Point Clouds of Garments",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530179",
    "pdf_link": null,
    "abstract": "The fields of SocialVR, performance capture, and virtual try-on are often faced with a need to faithfully reproduce real garments in the virtual world. One critical task is the disentanglement of the intrinsic garment shape from deformations due to fabric properties, physical forces, and contact with the body. We propose to use a garment sewing pattern, a realistic and compact garment descriptor, to facilitate the intrinsic garment shape estimation. Another major challenge is a high diversity of shapes and designs in the domain. The most common approach for Deep Learning on 3D garments is to build specialized models for individual garments or garment types. We argue that building a unified model for various garment designs has the benefit of generalization to novel garment types, hence covering a larger design domain than individual models would. We introduce NeuralTailor, a novel architecture based on point-level attention for set regression with variable cardinality, and apply it to the task of reconstructing 2D garment sewing patterns from the 3D point cloud garment models. Our experiments show that NeuralTailor successfully reconstructs sewing patterns and generalizes to garment types with pattern topologies unseen during training.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_255",
    "authors": "Tatyana Zaitseva",
    "title": "New Types of Smooth Subdivision Algorithms",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543261",
    "pdf_link": null,
    "abstract": "We suggest a new type of subdivision schemes based on matrix dilation for generating smooth surfaces. At each iteration, the number of the nodes in the mesh is doubled and the direction of their weighted averaging changes. The scheme has a low complexity because of a small number of coefficients (four, five or six). Using the recent techniques related to the notion of joint spectral characteristics of matrices, we find the smoothness of generated surfaces which in some cases is surprisingly better than for classical schemes.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_151",
    "authors": "Filippo Maggioli, Daniele Baieri, Simone Melzi, Emanuele Rodolà",
    "title": "Newton’s Fractals on Surfaces via Bicomplex Algebra",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543211",
    "pdf_link": null,
    "abstract": "2 METHODSince bicomplex functions in the form Math 12 can be expanded with Taylor [Rönn 2001], and the Taylor series in Math 13 converges, we can use the classical proof of the Newton-Raphson method to show that Newton's iteration converges to the root of a function: this allows us to generalize Newton's fractal to bicomplex numbers, and use it to generate 4-dimensional patterns.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_551",
    "authors": "Yiwei Hu, Paul Guerrero, Milos Hasan, Holly Rushmeier, Valentin Deschaintre",
    "title": "Node Graph Optimization Using Differentiable Proxies",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530733",
    "pdf_link": null,
    "abstract": "Graph-based procedural materials are ubiquitous in content production industries. Procedural models allow the creation of photo-realistic materials with parametric control for flexible editing of appearance. However, designing a specific material is a time-consuming process in terms of building a model and fine-tuning parameters. Previous work [Hu et al. 2022; Shi et al. 2020] introduced material graph optimization frameworks for matching target material samples. However, these previous methods were limited to optimizing differentiable …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_323",
    "authors": "Taimoor Tariq, Cara Tursun, Piotr Didyk",
    "title": "Noise-based Enhancement for Foveated Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530101",
    "pdf_link": null,
    "abstract": "Human visual sensitivity to spatial details declines towards the periphery. Novel image synthesis techniques, so-called foveated rendering, exploit this observation and reduce the spatial resolution of synthesized images for the periphery, avoiding the synthesis of high-spatial-frequency details that are costly to generate but not perceived by a viewer. However, contemporary techniques do not make a clear distinction between the range of spatial frequencies that must be reproduced and those that can be omitted. For a given eccentricity, there is a range of frequencies that are detectable but not resolvable. While the accurate reproduction of these frequencies is not required, an observer can detect their absence if completely omitted. We use this observation to improve the performance of existing foveated rendering techniques. We demonstrate that this specific range of frequencies can be efficiently replaced with procedural noise whose parameters are carefully tuned to image content and human perception. Consequently, these frequencies do not have to be synthesized during rendering, allowing more aggressive foveation, and they can be replaced by noise generated in a less expensive post-processing step, leading to improved performance of the rendering system. Our main contribution is a perceptually-inspired technique for deriving the parameters of the noise required for the enhancement and its calibration. The method operates on rendering output and runs at rates exceeding 200 FPS at 4K resolution, making it suitable for integration with real-time foveated rendering systems for VR and AR devices. We validate our results and compare them to the existing contrast enhancement technique in user experiments.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_179",
    "authors": "Diego Royo, Jorge Garcia, Pablo Luesia-Lahoz, Julio Marco, Diego Gutiérrez, Adolfo Muñoz, Adrián Jarabo",
    "title": "Non-line-of-sight Transient Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543223",
    "pdf_link": null,
    "abstract": "Transient imaging methods often analyze time-resolved light transport for applications such as range imaging, reflectance estimation and, especially, non-line-of-sight (NLOS) imaging, which targets the reconstruction of hidden geometry using measurements of indirect diffuse reflections emitted by a laser. Transient rendering is a key tool for developing such new applications. In this work, we introduce a set of simple, yet effective subpath sampling techniques targeting transient light transport simulation in occluded scenes. We analyze the …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_241",
    "authors": "Qing Shuai, Chen Geng, Qi Fang, Sida Peng, Wenhao Shen, Xiaowei Zhou, Hujun Bao",
    "title": "Novel View Synthesis of Human Interactions From Sparse Multi-view Videos",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530704",
    "pdf_link": null,
    "abstract": "This paper presents a novel system for generating free-viewpoint videos of multiple human performers from very sparse RGB cameras. The system reconstructs a layered neural representation of the dynamic multi-person scene from multi-view videos with each layer representing a moving instance or static background. Unlike previous work that requires instance segmentation as input, a novel approach is proposed to decompose the multi-person scene into layers and reconstruct neural representations for each layer in a weakly-supervised manner, yielding both high-quality novel view rendering and accurate instance masks. Camera synchronization error is also addressed in the proposed approach. The experiments demonstrate the better view synthesis quality of the proposed system compared to previous ones and the capability of producing an editable free-viewpoint video of a real soccer game using several asynchronous GoPro cameras. The dataset and code are available at https://github.com/zju3dv/EasyMocap .",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_198",
    "authors": "Dario Lanza, Juan Raúl Padrón-Griffe, Adrian Jarabo, Belen Masia",
    "title": "On the Influence of Dynamic Illumination in the Perception of Translucency",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3548814.3551462",
    "pdf_link": null,
    "abstract": "Translucent materials are ubiquitous in our daily lives, from organic materials such as food, liquids or human skin, to synthetic materials like plastic or rubber. In these materials, light penetrates inside the surface and scatters in the medium before leaving it. While the physical phenomena responsible for translucent appearance are well known, understanding how human observers perceive this type of materials is still an open problem: The appearance of translucent objects is affected by many dimensions beyond the optical properties of the material, including shape and illumination. In this work, we focus on the effect of illumination on the appearance of translucent materials. In particular, we analyze how static and dynamic illumination impact the perception of translucency. Previous studies have shown that changing the illumination conditions results in a constancy failure, specially in media with anisotropic phase functions. We extend this line of work, and analyze whether motion can alleviate such constancy failure. To do that, we run a psychophysical experiment where users need to match the optical density of a reference translucent object under both dynamic and static illumination. Surprisingly, our results suggest that in most cases light motion does not impact the perceived density of the translucent material. Our findings can have implications for material design in predictive rendering and authoring applications.",
    "scholar_publication": "ACM Symposium on Applied Perception …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_110",
    "authors": "Viktorija Paneva, Arthur Fleig, Diego Martínez Plasencia, Timm Faulwasser, Jörg Müller, Viktorija Paneva",
    "title": "OptiTrap: Optimal Trap Trajectories for Acoustic Levitation Displays",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3517746",
    "pdf_link": null,
    "abstract": "Acoustic levitation has recently demonstrated the ability to create volumetric content by trapping and quickly moving particles along reference paths to reveal shapes in mid-air. However, the problem of specifying physically feasible trap trajectories to display desired shapes remains unsolved. Even if only the final shape is of interest to the content creator, the trap trajectories need to determine where and when the traps need to be, for the particle to reveal the intended shape. We propose OptiTrap, the first structured numerical approach to compute trap trajectories for acoustic levitation displays. Our approach generates trap trajectories that are physically feasible and nearly time-optimal, and reveal generic mid-air shapes, given only a reference path (i.e., a shape with no time information). We provide a multi-dimensional model of the acoustic forces around a trap to model the trap-particle system dynamics and compute optimal trap trajectories by formulating and solving a non-linear path following problem. We formulate our approach and evaluate it, demonstrating how OptiTrap consistently produces feasible and nearly optimal paths, with increases in size, frequency, and accuracy of the shapes rendered, allowing us to demonstrate larger and more complex shapes than ever shown to date.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_143",
    "authors": "Shiqi Chen, Huajun Feng, Dexin Pan, Zhihai Xu, Qi Li, Yueting Chen, Shiqi Chen",
    "title": "Optical Aberration Correction in Postprocessing Using Imaging Simulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3474088",
    "pdf_link": null,
    "abstract": "As the popularity of mobile photography continues to grow, considerable effort is being invested in the reconstruction of degraded images. Due to the spatial variation in optical aberrations, which cannot be avoided during the lens design process, recent commercial cameras have shifted some of these correction tasks from optical design to postprocessing systems. However, without engaging with the optical parameters, these systems only achieve limited correction for aberrations. In this work, we propose a practical method for recovering the degradation caused by optical aberrations. Specifically, we establish an imaging simulation system based on our proposed optical point spread function model. Given the optical parameters of the camera, it generates the imaging results of these specific devices. To perform the restoration, we design a spatial-adaptive network model on synthetic data pairs generated by the imaging simulation system, eliminating the overhead of capturing training data by a large amount of shooting and registration. Moreover, we comprehensively evaluate the proposed method in simulations and experimentally with a customized digital-single-lens-reflex camera lens and HUAWEI HONOR 20, respectively. The experiments demonstrate that our solution successfully removes spatially variant blur and color dispersion. When compared with the state-of-the-art deblur methods, the proposed approach achieves better results with a lower computational overhead. Moreover, the reconstruction technique does not introduce artificial texture and is convenient to transfer to current commercial cameras. Project Page: https://github.com/TanGeeGo/ImagingSimulation.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_124",
    "authors": "Marco Livesu, Luca Pitzalis, Gianmarco Cherchi, Gianmarco Cherchi",
    "title": "Optimal Dual Schemes for Adaptive Grid Based Hexmeshing",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3494456",
    "pdf_link": null,
    "abstract": "Hexahedral meshes are a ubiquitous domain for the numerical resolution of partial differential equations. Computing a pure hexahedral mesh from an adaptively refined grid is a prominent approach to automatic hexmeshing, and requires the ability to restore the all hex property around the hanging nodes that arise at the interface between cells having different size. The most advanced tools to accomplish this task are based on mesh dualization. These approaches use topological schemes to regularize the valence of inner …",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_122",
    "authors": "Filippo Andrea Fanni, Fabio Pellacini, Riccardo Scateni, Andrea Giachetti, Filippo Andrea Fanni",
    "title": "PAVEL: Decorative Patterns With Packed Volumetric Elements",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3502802",
    "pdf_link": null,
    "abstract": "Many real-world hand-crafted objects are decorated with elements that are packed onto the object’s surface and deformed to cover it as much as possible. Examples are artisanal ceramics and metal jewelry. Inspired by these objects, we present a method to enrich surfaces with packed volumetric decorations. Our algorithm works by first determining the locations in which to add the decorative elements and then removing the non-physical overlap between them while preserving the decoration volume. For the placement, we support several strategies depending on the desired overall motif. To remove the overlap, we use an approach based on implicit deformable models creating the qualitative effect of plastic warping while avoiding expensive and hard-to-control physical simulations. Our decorative elements can be used to enhance virtual surfaces, as well as 3D-printed pieces, by assembling the decorations onto real surfaces to obtain tangible reproductions.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_135",
    "authors": "Chems-Eddine Himeur, Thibault Lejemble, Thomas Pellegrini, Mathias Paulin, Loic Barthe, Nicolas Mellado, Chems-Eddine Himeur",
    "title": "PCEDNet: A Lightweight Neural Network for Fast and Interactive Edge Detection in 3D Point Clouds",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3481804",
    "pdf_link": null,
    "abstract": "In recent years, Convolutional Neural Networks (CNN) have proven to be efficient analysis tools for processing point clouds, e.g., for reconstruction, segmentation, and classification. In this article, we focus on the classification of edges in point clouds, where both edges and their surrounding are described. We propose a new parameterization adding to each point a set of differential information on its surrounding shape reconstructed at different scales. These parameters, stored in a Scale-Space Matrix (SSM), provide a well-suited information from which an adequate neural network can learn the description of edges and use it to efficiently detect them in acquired point clouds. After successfully applying a multi-scale CNN on SSMs for the efficient classification of edges and their neighborhood, we propose a new lightweight neural network architecture outperforming the CNN in learning time, processing time, and classification capabilities. Our architecture is compact, requires small learning sets, is very fast to train, and classifies millions of points in seconds.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_847",
    "authors": "Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim Salimans, David Fleet, Mohammad Norouzi",
    "title": "Palette: Image-to-image Diffusion Models",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530757",
    "pdf_link": null,
    "abstract": "… Despite these results, it is not clear whether diffusion models rival GANs in offering a … the general applicability of Palette, our implementation of image-to-image diffusion models, to a …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_254",
    "authors": "Shao Yu Shen, Brigham Okano, Sebastian Dille, Yagiz Aksoy",
    "title": "Parallax Background Texture Generation",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543260",
    "pdf_link": null,
    "abstract": "… To ease the next processes and increase the visual quality of the resulting texture, we apply … texture generation example with the input segment (top) and the generated texture (bottom). …",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_188",
    "authors": "Lei Lan, Guanqun Ma, Yin Yang, Changxi Zheng, Minchen Li, Chenfanfu Jiang",
    "title": "Penetration-free Projective Dynamics on the GPU",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530069",
    "pdf_link": null,
    "abstract": "We present a GPU algorithm for deformable simulation. Our method offers good computational efficiency and penetration-free guarantee at the same time, which are not common with existing techniques. The main idea is an algorithmic integration of projective dynamics (PD) and incremental potential contact (IPC). PD is a position-based simulation framework, favored for its robust convergence and convenient implementation. We show that PD can be employed to handle the variational optimization with the interior point method e.g., IPC. While conceptually straightforward, this requires a dedicated rework over the collision resolution and the iteration modality to avoid incorrect collision projection with improved numerical convergence. IPC exploits a barrier-based formulation, which yields an infinitely large penalty when the constraint is on the verge of being violated. This mechanism guarantees intersection-free trajectories of deformable bodies during the simulation, as long as they are apart at the rest configuration. On the downside, IPC brings a large amount of nonlinearity to the system, making PD slower to converge. To mitigate this issue, we propose a novel GPU algorithm named A-Jacobi for faster linear solve at the global step of PD. A-Jacobi is based on Jacobi iteration, but it better harvests the computation capacity on modern GPUs by lumping several Jacobi steps into a single iteration. In addition, we also re-design the CCD root finding procedure by using a new minimum-gradient Newton algorithm. Those saved time budgets allow more iterations to accommodate stiff IPC barriers so that the result is both realistic and collision-free. Putting together, our algorithm simulates complicated models of both solids and shells on the GPU at an interactive rate or even in real time.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_403",
    "authors": "Johannes Lang, Miguel A. Nacenta",
    "title": "Perception of Letter Glyph Parameters for InfoTypography",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530111",
    "pdf_link": null,
    "abstract": "The advent of variable font technologies---where typographic parameters such as weight, x-height and slant are easily adjusted across a range---enables encoding ordinal, interval or ratio data into text that is still readable. This is potentially valuable to represent additional information in text labels in visualizations (e.g., font weight can indicate city size in a geographical visualization) or in text itself (e.g., the intended reading speed of a sentence can be encoded with the font width). However, we do not know how different parameters, which are complex variations of shape, are perceived by the human visual system. Without this information it is difficult to select appropriate parameters and mapping functions that maximize perception of differences within the parameter range. We provide an empirical characterization of seven typographical parameters of Latin fonts in terms of absolute perception and just noticeable differences (JNDs) to help visualization designers to choose typographic parameters for visualizations that contain text, as well as support typographers and type designers when selecting which levels of these parameters to implement to achieve differentiability between normal text, emphasized text and different headings.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_116",
    "authors": "Vassillen Chizhov, Iliyan Georgiev, Karol Myszkowski, Gurprit Singh, Vassillen Chizhov",
    "title": "Perceptual Error Optimization for Monte Carlo Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3504002",
    "pdf_link": null,
    "abstract": "Synthesizing realistic images involves computing high-dimensional light-transport integrals. In practice, these integrals are numerically estimated via Monte Carlo integration. The error of this estimation manifests itself as conspicuous aliasing or noise. To ameliorate such artifacts and improve image fidelity, we propose a perception-oriented framework to optimize the error of Monte Carlo rendering. We leverage models based on human perception from the halftoning literature. The result is an optimization problem whose solution distributes the error as visually pleasing blue noise in image space. To find solutions, we present a set of algorithms that provide varying trade-offs between quality and speed, showing substantial improvements over prior state of the art. We perform evaluations using quantitative and error metrics and provide extensive supplemental material to demonstrate the perceptual improvements achieved by our methods.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_193",
    "authors": "Phillip Guan, Olivier Mercier, Michael Shvartsman, Douglas Lanman",
    "title": "Perceptual Requirements for Eye-tracked Distortion Correction in VR",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530699",
    "pdf_link": null,
    "abstract": "We present a virtual reality display system simulator that accurately reproduces gaze-contingent distortions created by any viewing optic. The simulator hardware supports rapid prototyping by presenting stereoscopic distortions on a high-speed television paired with shutter glasses, eliminating the need to fabricate physical optics. We further introduce light field portals as an efficient and general-purpose representation for VR optics, enabling real-time emulation using our simulator. This platform is used to conduct the first user study of perceptual requirements for eye-tracked optical distortion correction. Because our hardware platform facilitates consistent head and eye movements, it enables direct comparison of these requirements across observers, optical designs, and scene content. We conclude by introducing a simple binocular distortion metric, built using light field portals, which agrees with key trends identified in the user study and lays a foundation for the design of perceptually-based distortion metrics and correction schemes.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_279",
    "authors": "Ruizhen Hu, Xiangyu Su, Xiangkai Chen, Oliver van Kaick, Hui Huang",
    "title": "Photo-to-shape Material Transfer for Diverse Structures",
    "paper_url": "http://people.scs.carleton.ca/~olivervankaick/pubs/TMT.pdf",
    "pdf_link": null,
    "abstract": "Most applications of computer graphics require 3D shapes with materials, since the geometry of 3D shapes alone does not fully convey the appearance of an object to a human. Shapes with materials are",
    "scholar_publication": "ACM Trans …, 2022 - people.scs.carleton.ca"
  },
  {
    "paper_id": "paperstog_137",
    "authors": "Shilin Zhu, Zexiang Xu, Tiancheng Sun, Alexandr Kuznetsov, Mark Meyer, Henrik Wann Jensen, Hao Su, Ravi Ramamoorthi, Shilin Zhu",
    "title": "Photon-driven Neural Reconstruction for Path Guiding",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3476828",
    "pdf_link": null,
    "abstract": "Although Monte Carlo path tracing is a simple and effective algorithm to synthesize photo-realistic images, it is often very slow to converge to noise-free results when involving complex global illumination. One of the most successful variance-reduction techniques is path guiding, which can learn better distributions for importance sampling to reduce pixel noise. However, previous methods require a large number of path samples to achieve reliable path guiding. We present a novel neural path guiding approach that can reconstruct high-quality sampling distributions for path guiding from a sparse set of samples, using an offline trained neural network. We leverage photons traced from light sources as the primary input for sampling density reconstruction, which is effective for challenging scenes with strong global illumination. To fully make use of our deep neural network, we partition the scene space into an adaptive hierarchical grid, in which we apply our network to reconstruct high-quality sampling distributions for any local region in the scene. This allows for effective path guiding for arbitrary path bounce at any location in path tracing. We demonstrate that our photon-driven neural path guiding approach can generalize to diverse testing scenes, often achieving better rendering results than previous path guiding approaches and opening up interesting future directions.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_672",
    "authors": "Mengyu Chu, Lingjie Liu, Quan Zheng, Erik Franz, Hans-Peter Seidel, Christian Theobalt, Rhaleb Zayer",
    "title": "Physics Informed Neural Fields for Smoke Reconstruction With Sparse Data",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530169",
    "pdf_link": null,
    "abstract": "High-fidelity reconstruction of dynamic fluids from sparse multiview RGB videos remains a formidable challenge, due to the complexity of the underlying physics as well as the severe occlusion and complex lighting in the captured data. Existing solutions either assume knowledge of obstacles and lighting, or only focus on simple fluid scenes without obstacles or complex lighting, and thus are unsuitable for real-world scenes with unknown lighting conditions or arbitrary obstacles. We present the first method to reconstruct dynamic fluid phenomena by leveraging the governing physics (ie, Navier -Stokes equations) in an end-to-end optimization from a mere set of sparse video frames without taking lighting conditions, geometry information, or boundary conditions as input. Our method provides a continuous spatio-temporal scene representation using neural networks as the ansatz of density and velocity solution functions for fluids as well as the radiance field for static objects. With a hybrid architecture that separates static and dynamic contents apart, fluid interactions with static obstacles are reconstructed for the first time without additional geometry input or human labeling. By augmenting time-varying neural radiance fields with physics-informed deep learning, our method benefits from the supervision of images and physical priors. Our progressively growing model with regularization further disentangles the density-color ambiguity in the radiance field, which allows for a more robust optimization from the given input of sparse views. A pretrained density-to-velocity fluid model is leveraged in addition as the data prior to avoid suboptimal velocity solutions which underestimate vorticity but trivially fulfill physical equations. Our method exhibits high-quality results with relaxed constraints and strong flexibility on a representative set of synthetic and real flow captures. Code and sample tests are at https://people.mpi-inf.mpg.de/~mchu/projects/PI-NeRF/.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_180",
    "authors": "Yongwoo Lee, Jehee Lee",
    "title": "Physics-based Character Control Using Conditional GAIL",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543224",
    "pdf_link": null,
    "abstract": "The goal of our research is to control a physics-based character that learns several dynamic motor skills using conditional Generative adversarial imitation learning(GAIL). We present a network-based learning algorithm that learns various motor skills and changing motions between the motor skills from disparate motion clips. The overall framework for our controller is composed of a control policy which generates a character’s behavior, and a discriminator which induces the policy to produce proper motions from a user’s commands. The discriminator and the policy take outputs from each other as input and improve each performance through an adversarial training process. Using this system, when a user commands a specific motion to the character, the character can design a motion plan to perform the motion from the current pose. We demonstrated the effectiveness of our approach through examples with an interactive character that learns various dynamics motor skills and follows a user command in the physics simulation.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_177",
    "authors": "Jungdam Won Won, Deepak Gopinath, Jessica Hodgins",
    "title": "Physics-based Character Controllers Using Conditional VAEs",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530067",
    "pdf_link": null,
    "abstract": "High-quality motion capture datasets are now publicly available, and researchers have used them to create kinematics-based controllers that can generate plausible and diverse human motions without conditioning on specific goals (i.e., a task-agnostic generative model). In this paper, we present an algorithm to build such controllers for physically simulated characters having many degrees of freedom. Our physics-based controllers are learned by using conditional VAEs, which can perform a variety of behaviors that are similar to motions in the training dataset. The controllers are robust enough to generate more than a few minutes of motion without conditioning on specific goals and to allow many complex downstream tasks to be solved efficiently. To show the effectiveness of our method, we demonstrate controllers learned from several different motion capture databases and use them to solve a number of downstream tasks that are challenging to learn controllers that generate natural-looking motions from scratch. We also perform ablation studies to demonstrate the importance of the elements of the algorithm. Code and data for this paper are available at: https://github.com/facebookresearch/PhysicsVAE",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_151",
    "authors": "Michael B. Nielsen, Robert Bridson, Morten Bojsen-Hansen, Konstantinos Stamatelos, Michael B. Nielsen, Robert Bridson",
    "title": "Physics-based Combustion Simulation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3526213",
    "pdf_link": null,
    "abstract": "… We model the combustion as infinitely fast chemistry and … In combination, these models enable us to simulate deflagration … production to some of the physics-based models we propose. …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_319",
    "authors": "Emilie Yu, Rahul Arora, J. Andreas Bærentzen, Karan Singh, Adrien Bousseau",
    "title": "Piecewise-smooth Surface Fitting Onto Unstructured 3D Sketches",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530100",
    "pdf_link": null,
    "abstract": "We propose a method to transform unstructured 3D sketches into piecewise smooth surfaces that preserve sketched geometric features. Immersive 3D drawing and sketch-based 3D modeling applications increasingly produce imperfect and unstructured collections of 3D strokes as design output. These 3D sketches are readily perceived as piecewise smooth surfaces by viewers, but are poorly handled by existing 3D surface techniques tailored to well-connected curve networks or sparse point sets. Our algorithm is aligned with human tendency to imagine the strokes as a small set of simple smooth surfaces joined along stroke boundaries. Starting with an initial proxy surface, we iteratively segment the surface into smooth patches joined sharply along some strokes, and optimize these patches to fit surrounding strokes. Our evaluation is fourfold: we demonstrate the impact of various algorithmic parameters, we evaluate our method on synthetic sketches with known ground truth surfaces, we compare to prior art, and we show compelling results on more than 50 designs from a diverse set of 3D sketch sources.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_405",
    "authors": "Beibei Wang, Wenhua Jin, Jiahui Fan, Nicolas Holzschuch, Jian Yang, Ling-Qi Yan",
    "title": "Position-free Multiple-bounce Computations for Smith Microfacet BSDFs",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530112",
    "pdf_link": null,
    "abstract": "Bidirectional Scattering Distribution Functions (BSDFs) encode how a material reflects or transmits the incoming light. The most commonly used model is the microfacet BSDF. It computes the material response from the microgeometry of the surface assuming a single bounce on specular microfacets. The original model ignores multiple bounces on the microgeometry, resulting in an energy loss, especially for rough materials. In this paper, we present a new method to compute the multiple bounces inside the microgeometry, eliminating this energy loss. Our method relies on a position-free formulation of multiple bounces inside the microgeometry. We use an explicit mathematical definition of the path space that describes single and multiple bounces in a uniform way. We then study the behavior of light on the different vertices and segments in the path space, leading to a reciprocal multiple-bounce description of BSDFs. Furthermore, we present practical, unbiased Monte Carlo estimators to compute multiple scattering. Our method is less noisy than existing algorithms for computing multiple scattering. It is almost noise-free with a very-low sampling rate, from 2 to 4 samples per pixel (spp).",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_338",
    "authors": "Junqiu Zhu, Sizhe Zhao, Lu Wang, Yanning Xu, Ling-Qi Yan",
    "title": "Practical Level-of-detail Aggregation of Fur Appearance",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530105",
    "pdf_link": null,
    "abstract": "Fur appearance rendering is crucial for the realism of computer generated imagery, but is also a challenge in computer graphics for many years. Much effort has been made to accurately simulate the multiple-scattered light transport among fur fibers, but the computation cost is still very high, since the number of fur fibers is usually extremely large. In this paper, we aim at reducing the number of fur fibers while preserving realistic fur appearance. We present an aggregated fur appearance model, using one thick cylinder to accurately describe the aggregated optical behavior of a bunch of fur fibers, including the multiple scattering of light among them. Then, to acquire the parameters of our aggregated model, we use a lightweight neural network to map individual fur fiber's optical properties to those in our aggregated model. Finally, we come up with a practical heuristic that guides the simplification process of fur dynamically at different bounces of the light, leading to a practical level-of-detail rendering scheme. Our method achieves nearly the same results as the ground truth, but performs 3.8×-13.5× faster.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_316",
    "authors": "Xiaoyu Pan, Jiaming Mai, Xinwei Jiang, Dongxue Tang, Jingxiang Li, Tianjia Shao, Kun Zhou, Xiaogang Jin, Dinesh Manocha",
    "title": "Predicting Loose-fitting Garment Deformations Using Bone-driven Motion Networks",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530709",
    "pdf_link": null,
    "abstract": "We present a learning algorithm that uses bone-driven motion networks to predict the deformation of loose-fitting garment meshes at interactive rates. Given a garment, we generate a simulation database and extract virtual bones from simulated mesh sequences using skin decomposition. At runtime, we separately compute low- and high-frequency deformations in a sequential manner. The low-frequency deformations are predicted by transferring body motions to virtual bones’ motions, and the high-frequency deformations are estimated leveraging the global information of virtual bones’ motions and local information extracted from low-frequency meshes. In addition, our method can estimate garment deformations caused by variations of the simulation parameters (e.g., fabric’s bending stiffness) using an RBF kernel ensembling trained networks for different sets of simulation parameters. Through extensive comparisons, we show that our method outperforms state-of-the-art methods in terms of prediction accuracy of mesh deformations by about 20% in RMSE and 10% in Hausdorff distance and STED. The code and data are available at https://github.com/non-void/VirtualBones.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_242",
    "authors": "Maria Larsson, Takashi Ijiri, Hironori Yoshida, Johannes A. J. Huber, Magnus Fredriksson, Olof Broman, Takeo Igarashi",
    "title": "Procedural Texturing of Solid Wood With Knots",
    "paper_url": "https://www.researchgate.net/profile/Maria-Larsson-5/publication/360311826_Procedural_Texturing_of_Solid_Wood_with_Knots/links/626f74f1c42af62fe2e64f19/Procedural-Texturing-of-Solid-Wood-with-Knots.pdf",
    "pdf_link": null,
    "abstract": "Knots are commonly seen on wooden surfaces, including structural building members, wall panelling, flooring, and table tops. Knots are caused by branches growing out from the stem of the tree, which leave traces inside the wood. They cause complex distortions to the otherwise relatively straight stem grain, giving rise to distinctive annual ring patterns. Depending on the direction in which the knot faces the surface, its appearance changes from a circular spot to a curved cone (Fig. 2). Moreover, during the lifetime of a tree, a branch might die, which affects the shape of the knot and its impact on the stem grain. Knots are particularly characteristic of softwood, which is wood from conifer trees (eg, pine and spruce). Such trees typically have many branches growing out from their main stem, giving rise to dense knot patterns in the wood texture. Nonetheless, hardwoods (eg, oak) often have knots in their textures as well. The level set method was successfully applied to model annual ring patterns by simulating the gradual expansion of trees [Kratt",
    "scholar_publication": "ACM Trans …, 2022 - researchgate.net"
  },
  {
    "paper_id": "paperstog_125",
    "authors": "Till Niese, Soren Pirk, Matthias Albrecht, Bedrich Benes, Oliver Deussen, Oliver Deussen",
    "title": "Procedural Urban Forestry",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3502220",
    "pdf_link": null,
    "abstract": "The placement of vegetation plays a central role in the realism of virtual scenes. We introduce procedural placement models (PPMs) for vegetation in urban layouts. PPMs are …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_227",
    "authors": "Shir Rorberg, Michal Lev, Shenhav Lev, Yoav Sterman, Mirela Ben Chen",
    "title": "Programmable Eclairs",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543251",
    "pdf_link": null,
    "abstract": "… (5) Finally, We bake the eclair. During baking the dough expands and pushes the 2D auxetic pattern of … Different regions of the shape expand at different rates, thus shaping the eclair. …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_132",
    "authors": "Wooje Chang, Yeeun Shin, Yeon Soo Kim, Woohun Lee",
    "title": "ProjecString: Turning an Everyday String Curtain Into an Interactive Projection Display",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543203",
    "pdf_link": null,
    "abstract": "We present ProjecString, a touch-sensitive string curtain projection display that encourages novel interactions via touching, grasping, and seeing and walking through the display. We embed capacitive-sensing conductive chains into an everyday string curtain, turning it into both a space divider and an interactive display. This novel take on transforming an everyday object into an interactive projection surface with a unique translucent property creates novel interactions that are both immersive and isolating.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_194",
    "authors": "Kuan-Wei Tseng, Jing-Yuan Huang, Yang-Shen Chen, Chu-Song Chen, Yi-Ping Hung",
    "title": "Pseudo-3D Scene Modeling for Virtual Reality Using Stylized Novel View Synthesis",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543232",
    "pdf_link": null,
    "abstract": "Stylized Novel View Synthesis is an emerging technique that combines style transfer and view synthesis. However, none of the existing works explore their applications in Virtual Reality (VR). This work devises a novel application for stylized novel view synthesis. We propose to replace actual 3D scene models or 360 images with stylized stereoscopic images for the areas outside the major play area but are still visible to the user. User study results reveal that users can feel 3D sense and tell them from plane texture. Codes and other materials are available at: kuan-wei-tseng.github.io/ArtNV",
    "scholar_publication": "Acm siggraph 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_743",
    "authors": "Zhize Zhou, Qing Shuai, Yize Wang, Qi Fang, Xiaopeng Ji, Fashuai Li, Hujun Bao, Xiaowei Zhou",
    "title": "QuickPose: Real-time Multi-view Multi-person Pose Estimation in Crowded Scenes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530746",
    "pdf_link": null,
    "abstract": "This work proposes a real-time algorithm for reconstructing 3D human poses in crowded scenes from multiple calibrated views. The key challenge of this problem is to efficiently match 2D observations across multiple views. Previous methods perform multi-view matching either at the full-body level, which is sensitive to 2D pose estimation error, or at the part level, which ignores 2D constraints between different types of body parts in the same view. Instead, our approach reasons about all plausible skeleton proposals during multi-view matching, where each skeleton may consist of an arbitrary number of parts instead of being a whole body or a single part. To this end, we formulate the multi-view matching problem as mode seeking in the space of skeleton proposals and develop an efficient algorithm named QuickPose to solve the problem, which enables real-time motion capture in crowded scenes. Experiments show that the proposed algorithm achieves the state-of-the-art performance in terms of both speed and accuracy on public datasets.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_685",
    "authors": "Sadjad Fouladi, Brennan Shacklett, Fait Poms, Arjun Arora, Alex Ozdemir, Deepti Raghavan, Pat Hanrahan, Kayvon Fatahalian, Keith Winstein",
    "title": "R2E2: Low-latency Path Tracing of Terabyte-scale Scenes Using Thousands of Cloud CPUs",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530171",
    "pdf_link": null,
    "abstract": "In this paper we explore the viability of path tracing massive scenes using a \"supercomputer\" constructed on-the-fly from thousands of small, serverless cloud computing nodes. We present R2E2 (Really Elastic Ray Engine) a scene decomposition-based parallel renderer that rapidly acquires thousands of cloud CPU cores, loads scene geometry from a pre-built scene BVH into the aggregate memory of these nodes in parallel, and performs full path traced global illumination using an inter-node messaging service designed for communicating ray data. To balance ray tracing work across many nodes, R2E2 adopts a service-oriented design that statically replicates geometry and texture data from frequently traversed scene regions onto multiple nodes based on estimates of load, and dynamically assigns ray tracing work to lightly loaded nodes holding the required data. We port pbrt's ray-scene intersection components to the R2E2 architecture, and demonstrate that scenes with up to a terabyte of geometry and texture data (where as little as 1/250th of the scene can fit on any one node) can be path traced at 4K resolution, in tens of seconds using thousands of tiny serverless nodes on the AWS Lambda platform.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_223",
    "authors": "Kevin Roice, George Alex Koulieris",
    "title": "RHapTor: Rendering Haptic Torques for Virtual Reality",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543248",
    "pdf_link": null,
    "abstract": "Figure 1: The RHapTor device (left). An example gyroscopic torque, τg, generated by head rotation while disks spin (middle). User exploration profile in the xz plane, for a virtual beach environment with and without resistive torque rendering, with t-values describing the difference in means between each pair of univariate distributions (right).",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_326",
    "authors": "Amir Belder, Gal Yefet, Ran Ben-Itzhak, Ayellet Tal",
    "title": "Random Walks for Adversarial Meshes",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530710",
    "pdf_link": null,
    "abstract": "A polygonal mesh is the most-commonly used representation of surfaces in computer graphics. Therefore, it is not surprising that a number of mesh classification networks have recently been proposed. However, while adversarial attacks are wildly researched in 2D, the field of adversarial meshes is under explored. This paper proposes a novel, unified, and general adversarial attack, which leads to misclassification of several state-of-the-art mesh classification neural networks. Our attack approach is black-box, i.e. it has access only to the network’s predictions, but not to the network’s full architecture or gradients. The key idea is to train a network to imitate a given classification network. This is done by utilizing random walks along the mesh surface, which gather geometric information. These walks provide insight onto the regions of the mesh that are important for the correct prediction of the given classification network. These mesh regions are then modified more than other regions in order to attack the network in a manner that is barely visible to the naked eye.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_293",
    "authors": "Joon Hyub Lee, Hanbit Kim, Seok-Hyung Bae",
    "title": "Rapid Design of Articulated Objects",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530092",
    "pdf_link": null,
    "abstract": "Designing articulated objects is challenging because, unlike with static objects, it requires complex decisions to be made regarding the form, parts, rig, poses, and motion. We present a novel 3D sketching system for rapidly authoring concepts of articulated objects for the early stages of design, when designers make such decisions. Compared to existing CAD software, which focuses on slowly but elaborately producing models consisting of precise surfaces and volumes, our system focuses on quickly but roughly producing models …",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_281",
    "authors": "Animesh Karnewar, Tobias Ritschel, Oliver Wang, Niloy Mitra",
    "title": "ReLU Fields: The Little Non-linearity That Could",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530707",
    "pdf_link": null,
    "abstract": "In many recent works, multi-layer perceptions (MLPs) have been shown to be suitable for modeling complex spatially-varying functions including images and 3D scenes. Although the MLPs are able to represent complex scenes with unprecedented quality and memory footprint, this expressive power of the MLPs, however, comes at the cost of long training and inference times. On the other hand, bilinear/trilinear interpolation on regular grid-based representations can give fast training and inference times, but cannot match the quality of MLPs without requiring significant additional memory. Hence, in this work, we investigate what is the smallest change to grid-based representations that allows for retaining the high fidelity result of MLPs while enabling fast reconstruction and rendering times. We introduce a surprisingly simple change that achieves this task – simply allowing a fixed non-linearity (ReLU) on interpolated grid values. When combined with coarse-to-fine optimization, we show that such an approach becomes competitive with the state-of-the-art. We report results on radiance fields, and occupancy fields, and compare against multiple existing alternatives. Code and data for the paper are available at https://geometry.cs.ucl.ac.uk/projects/2022/relu_fields.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_284",
    "authors": "Xiangjun Tang, He Wang, Bo Hu, Xu Gong, Ruifan Yi, Qilong Kou, Xiaogang Jin",
    "title": "Real-time Controllable Motion Transition for Characters",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530090",
    "pdf_link": null,
    "abstract": "Real-time in-between motion generation is universally required in games and highly desirable in existing animation pipelines. Its core challenge lies in the need to satisfy three critical conditions simultaneously: quality, controllability and speed, which renders any methods that need offline computation (or post-processing) or cannot incorporate (often unpredictable) user control undesirable. To this end, we propose a new real-time transition method to address the aforementioned challenges. Our approach consists of two key components: motion manifold and conditional transitioning. The former learns the important low-level motion features and their dynamics; while the latter synthesizes transitions conditioned on a target frame and the desired transition duration. We first learn a motion manifold that explicitly models the intrinsic transition stochasticity in human motions via a multi-modal mapping mechanism. Then, during generation, we design a transition model which is essentially a sampling strategy to sample from the learned manifold, based on the target frame and the aimed transition duration. We validate our method on different datasets in tasks where no post-processing or offline computation is allowed. Through exhaustive evaluation and comparison, we show that our method is able to generate high-quality motions measured under multiple metrics. Our method is also robust under various target frames (with extreme cases).",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_213",
    "authors": "Young-Woo Kim, Duksu Kim",
    "title": "Real-time Lens Distortion Algorithm on Embedded GPU Systems",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543241",
    "pdf_link": null,
    "abstract": "The lens distortion is essential for displaying VR contents on a head-mounted display (HMD) with a distorted display surface. We propose a novel lens distortion algorithm on an embedded GPU system. To minimize the memory access overhead, we propose a compressed form of a lookup table. We also utilize the integrated memory architecture of the edge GPU system (e.g., NVIDIA’s Jetson devices) to reduce data communication overhead between host and device. As a result, our method shows up to 1.72-times higher performance than prior lookup table-based lens distortion approaches while it consumes up to 28.93% less power. Finally, our algorithm achieved real-time performance for high-resolution images on edge GPU systems (e.g., 94 FPS for 8K image on Jetson NX). These results demonstrate the benefits of our approach from the perspectives of both performance and energy.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_352",
    "authors": "Xi Deng, Fujun Luan, Bruce Walter, Kavita Bala, Steve Marschner",
    "title": "Reconstructing Translucent Objects Using Differentiable Rendering",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530714",
    "pdf_link": null,
    "abstract": "Inverse rendering is a powerful approach to modeling objects from photographs, and we extend previous techniques to handle translucent materials that exhibit subsurface scattering. Representing translucency using a heterogeneous bidirectional scattering-surface reflectance distribution function (BSSRDF), we extend the framework of path-space differentiable rendering to accommodate both surface and subsurface reflection. This introduces new types of paths requiring new methods for sampling moving discontinuities in material space that arise from visibility and moving geometry. We use this differentiable rendering method in an end-to-end approach that jointly recovers heterogeneous translucent materials (represented by a BSSRDF) and detailed geometry of an object (represented by a mesh) from a sparse set of measured 2D images in a coarse-to-fine framework incorporating Laplacian preconditioning for the geometry. To efficiently optimize our models in the presence of the Monte Carlo noise introduced by the BSSRDF integral, we introduce a dual-buffer method for evaluating the L2 image loss. This efficiently avoids potential bias in gradient estimation due to the correlation of estimates for image pixels and their derivatives and enables correct convergence of the optimizer even when using low sample counts in the renderer. We validate our derivatives by comparing against finite differences and demonstrate the effectiveness of our technique by comparing inverse-rendering performance with previous methods. We show superior reconstruction quality on a set of synthetic and real-world translucent objects as compared to previous methods that model only surface reflection.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_231",
    "authors": "Manos Kamarianakis, Ilias Chrysovergis, Mike Kentros, George Papagiannakis",
    "title": "Recording and Replaying Psychomotor User Actions in VR",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543253",
    "pdf_link": null,
    "abstract": "Nowadays, session recording and playback of a single or multiuser VR session has become an increasingly market-required asset. The need for effective VR recording and replaying (VRRR) is especially highlighted in virtual training applications, as replaying user actions can serve as an additional and powerful educational tool. Despite the effort, achieving VRRR is a task not natively undertaken by modern game engines and therefore most VR applications do not include such a feature by default. Current bibliography contains numerous studies of how the VR record and replay features can enhance the learning impact that VR educational-oriented applications provide, by mainly measuring the performance of users [Lahanas et al. 2015]. Usually, the data are captured in video format [Zia et al. 2016] and a post process of this high-dimensional data is required to obtain any further analysis. Since video data is not sufficient for reasons we explain in Section 2, our approach is close to [Kloiber et al. 2020], where user’s motion were analysed by recording their hands and head trajectories. Current ongoing research also explores the proper methods and data structures that must be employed to achieve realtime logging while keeping the required data storage manageable and allowing effective replay.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_300",
    "authors": "Corentin Salaun, Adrien Gruson, Binh-Son Hua, Toshiya Hachisuka, Gurprit Singh",
    "title": "Regression-based Monte Carlo Integration",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530095",
    "pdf_link": null,
    "abstract": "Monte Carlo integration is typically interpreted as an estimator of the expected value using stochastic samples. There exists an alternative interpretation in calculus where Monte Carlo integration can be seen as estimating a constant function---from the stochastic evaluations of the integrand---that integrates to the original integral. The integral mean value theorem states that this constant function should be the mean (or expectation) of the integrand. Since both interpretations result in the same estimator, little attention has been devoted to the calculus-oriented interpretation. We show that the calculus-oriented interpretation actually implies the possibility of using a more complex function than a constant one to construct a more efficient estimator for Monte Carlo integration. We build a new estimator based on this interpretation and relate our estimator to control variates with least-squares regression on the stochastic samples of the integrand. Unlike prior work, our resulting estimator is provably better than or equal to the conventional Monte Carlo estimator. To demonstrate the strength of our approach, we introduce a practical estimator that can act as a simple drop-in replacement for conventional Monte Carlo integration. We experimentally validate our framework on various light transport integrals. The code is available at https://github.com/iribis/regressionmc.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_765",
    "authors": "Weizhen Huang, Sebastian Merzbach, Clara Callenberg, Doekele Stavenga, Matthias Hullin",
    "title": "Rendering Iridescent Rock Dove Neck Feathers",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530749",
    "pdf_link": null,
    "abstract": "Bird feathers exhibit fascinating reflectance, which is governed by fiber-like structures. Unlike hair and fur, the feather geometric structures follow intricate hierarchical patterns that span many orders of magnitude in scale. At the smallest scales, fiber elements have strongly non-cylindrical cross-sections and are often complemented by regular nanostructures, causing rich structural color. Therefore, past attempts to render feathers using fiber- or texture-based appearance models missed characteristic aspects of the visual appearance. We introduce a new feather modeling and rendering framework, which abstracts the microscopic geometry and reflectance into a microfacet-like BSDF. The R, TRT and T lobes, also known from hair and fur, here account for specular reflection off the cortex, diffuse reflection off the medulla, and transmission due to barbule spacing, respectively. Our BSDF, which does not require precomputation or storage, can be efficiently importance-sampled and readily integrated into rendering pipelines that represent feather geometry down to the barb level. We verify our approach using a BSDF-capturing setup for small biological structures, as well as against calibrated photographs of rock dove neck feathers.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_421",
    "authors": "Alexandr Kuznetsov, Fujun Luan, Krishna Mullia, Zexiang Xu, Xuezheng Wang, Milos Hasan, Ravi Ramamoorthi",
    "title": "Rendering Neural Materials on Curved Surfaces",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530721",
    "pdf_link": null,
    "abstract": "Neural material reflectance representations address some limitations of traditional analytic BRDFs with parameter textures; they can theoretically represent any material data, whether a complex synthetic microgeometry with displacements, shadows and inter-reflections, or real measured reflectance. However, they still approximate the material on an infinite plane, which prevents them from correctly handling silhouette and parallax effects for viewing directions close to grazing. The goal of this paper is to design a neural material representation capable of correctly handling such silhouette effects. We extend the neural network query to take surface curvature information as input, while the query output is extended to return a transparency value in addition to reflectance. We train the new neural representation on synthetic data that contains queries spanning a variety of surface curvatures. We show an ability to accurately represent complex silhouette behavior that would traditionally require more expensive and less flexible techniques, such as on-the-fly geometry displacement or ray marching.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_140",
    "authors": "Shintaro Fuji, Syuhei Sato, Kei Iwasaki, Yoshinori Dobashi, Shangce Gao, Zheng Tang",
    "title": "Rendering of Scratched Transparent Materials Using Precomputed SV-BSDFs",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543207",
    "pdf_link": null,
    "abstract": "Recently, many methods have been proposed to realistically render various materials. The realism of the synthetic images can be improved by rendering small-scale details on the surfaces of 3D objects. We focus on the efficient rendering of the scratches on the transparent objects. Although a fast rendering method using precomputed 2D BRDFs for a scratched material has been proposed, the method is limited to the opaque materials such as metals. We extend this method to the transparent objects. On the surface of the transparent object, rays are split into specular reflections and refractions. We therefore precompute Bidirectional Scattering Distribution Functions (BSDFs). We use a 2D ray tracer as in the previous method to accelerate the precomputation. We show several examples to demonstrate the effectiveness of our method.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_149",
    "authors": "Shlomi Steinberg, Ling-Qi Yan, Shlomi Steinberg",
    "title": "Rendering of Subjective Speckle Formed by Rough Statistical Surfaces",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3472293",
    "pdf_link": null,
    "abstract": "Tremendous effort has been extended by the computer graphics community to advance the level of realism of material appearance reproduction by incorporating increasingly more advanced techniques. We are now able to re-enact the complicated interplay between light and microscopic surface features—scratches, bumps and other imperfections—in a visually convincing fashion. However, diffractive patterns arise even when no explicitly defined features are present: Any random surface will act as a diffracting aperture and its statistics heavily influence the statistics of the diffracted wave fields. Nonetheless, the problem of rendering diffraction effects induced by surfaces that are defined purely statistically remains wholly unexplored. We present a thorough derivation, from core optical principles, of the intensity of the scattered fields that arise when a natural, partially coherent light source illuminates a random surface. We follow with a probability theory analysis of the statistics of those fields and present our rendering algorithm. All of our derivations are formally proven and verified numerically as well. Our method is the first to render diffraction effects produced by a surface described statistically only, and bridges the theoretical gap between contemporary surface modelling and rendering.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_171",
    "authors": "Sheng-Yu Wang, David Bau, Jun-Yan Zhu",
    "title": "Rewriting Geometric Rules of a GAN",
    "paper_url": "https://www.academia.edu/download/98531300/3528223.pdf",
    "pdf_link": null,
    "abstract": "… reach of GAN inversion; and given extremely few user inputs, it is difficult to adapt a GAN to the … to rewrite the geometric rules. Moreover, by a simple linear combination of edited model’s …",
    "scholar_publication": "ACM Trans. Graph., 2022 - academia.edu"
  },
  {
    "paper_id": "papers_724",
    "authors": "Xingyi Du, Qingnan Zhou, Nathan Carr, Tao Ju",
    "title": "Robust Computation of Implicit Surface Networks for Piecewise Linear Functions",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530176",
    "pdf_link": null,
    "abstract": "Implicit surface networks, such as arrangements of implicit surfaces and materials interfaces, are used for modeling piecewise smooth or partitioned shapes. However, accurate and numerically robust algorithms for discretizing either structure on a grid are still lacking. We present a unified approach for computing both types of surface networks for piecewise linear functions defined on a tetrahedral grid. Both algorithms are guaranteed to produce a correct combinatorial structure for any number of functions. Our main contribution is an exact and efficient method for partitioning a tetrahedron using the level sets of linear functions defined by barycentric interpolation. To further improve performance, we designed look-up tables to speed up processing of tetrahedra involving few functions and introduced an efficient algorithm for identifying nested 3D regions.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_347",
    "authors": "Thu Nguyen-Phuoc, Feng Liu, Lei Xiao",
    "title": "SNeRF: Stylized Neural Implicit Representations for 3D Scenes",
    "paper_url": "",
    "pdf_link": null,
    "abstract": null,
    "scholar_publication": null
  },
  {
    "paper_id": "papers_263",
    "authors": "Amir Hertz, Or Perel, Raja Giryes, Olga Sorkine-Hornung, Daniel Cohen-Or",
    "title": "SPAGHETTI: Editing Implicit Shapes Through Part Aware Generation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530084",
    "pdf_link": null,
    "abstract": "Neural implicit fields are quickly emerging as an attractive representation for learning based techniques. However, adopting them for 3D shape modeling and editing is challenging. We introduce a method for Editing Implicit Shapes Through Part Aware GeneraTion, permuted in short as SPAGHETTI. Our architecture allows for manipulation of implicit shapes by means of transforming, interpolating and combining shape segments together, without requiring explicit part supervision. SPAGHETTI disentangles shape part representation into extrinsic and intrinsic geometric information. This characteristic enables a generative framework with part-level control. The modeling capabilities of SPAGHETTI are demonstrated using an interactive graphical interface, where users can directly edit neural implicit shapes. Our code, editing user interface demo and pre-trained models are available at github.com/amirhertz/spaghetti.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_783",
    "authors": "Fujia Su, Sheng Li, Guoping Wang",
    "title": "SPCBPT: Subspace-based Probabilistic Connections for Bidirectional Path Tracing",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530183",
    "pdf_link": null,
    "abstract": "Bidirectional path tracing (BDPT) can be accelerated by selecting appropriate light sub-paths for connection. However, existing algorithms need to perform frequent distribution reconstruction and have expensive overhead. We present a novel approach, SPCBPT, for probabilistic connections that constructs the light selection distribution in sub-path space. Our approach bins the sub-paths into multiple subspaces and keeps the sub-paths in the same subspace of low discrepancy, wherein the light sub-paths can be selected by a subspace-based two-stage sampling method, i.e., first sampling the light subspace and then resampling the light sub-paths within this subspace. The subspace-based distribution is free of reconstruction and provides efficient light selection at a very low cost. We also propose a method that considers the Multiple Importance Sampling (MIS) term in the light selection and thus obtain an MIS-aware distribution that can minimize the upper bound of variance of the combined estimator. Prior methods typically omit this MIS weights term. We evaluate our algorithm using various benchmarks, and the results show that our approach has superior performance and can significantly reduce the noise compared with the state-of-the-art method.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_214",
    "authors": "Snehal Padhye, David Messinger, James Ferwerda",
    "title": "SVBRDF Estimation Using a Normal Sorting Technique",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543242",
    "pdf_link": null,
    "abstract": "Spatially varying bi-directional reflectance distribution functions (SVBRDFs) play an important role in appearance modeling of realworld objects. Automatic capture of these features is highly desirable, and there has been a lot of research on creating practical and lightweight setups for SVBRDF acquisition [Francken et al. 2009][Ferwerda 2018]. Structured light techniques have been widely used for 3D modeling of objects [Geng 2011]. Capturing SVBRDFs using structured light is challenging, which is often the main limitation in using it for modeling the complete appearance of objects. Baek et al.[Baek et al. 2018] used polarimetric images with the structured light setup to measure surface roughness and Rushmeier et al.[Rushmeier et al. 2015] used multiple pairs of cameras and projectors with high spatial frequency patterns to estimate SVBRDFs.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_559",
    "authors": "Xiuchao Wu, Jiamin Xu, Zihan Zhu, Hujun Bao, Qixing Huang, James Tompkin, Weiwei Xu",
    "title": "Scalable Neural Indoor Scene Rendering",
    "paper_url": "https://par.nsf.gov/servlets/purl/10388892",
    "pdf_link": null,
    "abstract": "Reconstructing real-world 3D scenes and rendering them photorealistically at interactive rates has long been desired in visual computing. Given captured images and reconstructed scene geometry, many image-based rendering (IBR) techniques can synthesize realistic renderings at novel views to enable free-viewpoint navigation [Hedman et al. 2018, 2016; Xu et al. 2021]. Past methods have required high input sample rates or high-quality geometry to avoid ghosting or tearing artifacts within rendered images. Recently, neural methods have gained popularity in IBR due to their capability to synthesize realistic novel views with viewdependent effects. For instance, NeRF [Mildenhall et al. 2020] optimizes multi-layer perceptron neural networks (MLPs) to output volume radiance and density by rendering views via volume integration along rays. Applying NeRF to model large scenes requires large MLPs to maintain detailed appearance, and requires long rendering times as we must sample 3D points along cast rays and pass them to an MLP to obtain volume radiance and density. Further, given sparse inputs in which view-dependent highlights do not consistently appear, this model fails to reproduce reflections and highlights in reconstructions.A common strategy to accelerate neural rendering is to trade memory for time. For example, one approach is to explore sparse voxel grids to cache or bake different outputs of the MLP. Examples include deep radiance maps [Garbin et al. 2021], spherical harmonic coefficients [Yu et al. 2021a], and the combination of RGB color, volume density, and features [Hedman et al. 2021]. While these approaches efficiently speed up rendering, memory costs are still high for large 3D scenes, which can be a bottleneck in training that limits scene detail or scale. In KiloNerf [Reiser et al. 2021], thousands of tiny MLPs represent the scene to avoid a high memory footprint. However, this method needs to train a single large-capacity MLP as a teacher to begin training tiny MLPs, which increases training time and hinders its application to large scenes. In summary, applying neural techniques to large scenes remains a technical challenge. We propose a neural scene rendering method for static indoor scenes that is scalable in both training and rendering. Given an initial reconstructed proxy geometry (the global mesh), we partition the 3D space into tiles each with MLPs to avoid training a single largecapacity MLP. Based on this tile-based neural scene representation, we make two key improvements to achieve a scalable solution:",
    "scholar_publication": "ACM transactions on …, 2022 - par.nsf.gov"
  },
  {
    "paper_id": "pos_202",
    "authors": "Weizhen Huang, Matthias B. Hullin, Johannes Hanika",
    "title": "Scattering From Elliptical Hair Fibers Based on Microfacet Theory",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543236",
    "pdf_link": null,
    "abstract": "Almost all hair and fiber scattering models in computer graphics today are based on separable bidirectional curve scattering distribution function (BCSDF) proposed by [Marschner et al. 2003], including the most recent works that model elliptical hair fibers [Benamira and Pattanaik 2021; Khungurn and Marschner 2017]; they separate the scattering function into a longitudinal function M (θ) and an azimuthal function N (φ), which is mathematically convenient, but not physically correct, hence fails to capture the glinty appearance of real hair in the forward scattering direction. We introduce an alternative scattering model for elliptical hair [Huang et al. 2022]. We consider the hair fiber as a homogeneous dielectric cylinder with a rough surface modeled as microfacets [Heitz 2014], and perform the usual radiometric analysis as by",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_108",
    "authors": "Karima Ma, Michael Gharbi, Andrew Adams, Shoaib Kamil, Tzu-Mao Li, Connelly Barnes, Jonathan Ragan-Kelley, Karima Ma",
    "title": "Searching for Fast Demosaicking Algorithms",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3508461",
    "pdf_link": null,
    "abstract": "We present a method to automatically synthesize efficient, high-quality demosaicking algorithms, across a range of computational budgets, given a loss function and training data. It performs a multi-objective, discrete-continuous optimization which simultaneously solves for the program structure and parameters that best tradeoff computational cost and image quality. We design the method to exploit domain-specific structure for search efficiency. We apply it to several tasks, including demosaicking both Bayer and Fuji X-Trans color filter patterns, as well as joint demosaicking and super-resolution. In a few days on 8 GPUs, it produces a family of algorithms that significantly improves image quality relative to the prior state-of-the-art across a range of computational budgets from 10 s to 1000 s of operations per pixel (1 dB–3 dB higher quality at the same cost, or 8.5–200× higher throughput at same or better quality). The resulting programs combine features of both classical and deep learning-based demosaicking algorithms into more efficient hybrid combinations, which are bandwidth-efficient and vectorizable by construction. Finally, our method automatically schedules and compiles all generated programs into optimized SIMD code for modern processors.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_801",
    "authors": "Zheng Shi, Yuval Bahat, Seung-Hwan Baek, Qiang Fu, Hadi Amata, Xiao Li, Praneeth Chakravarthula, Wolfgang Heidrich, Felix Heide",
    "title": "Seeing Through Obstructions With Diffractive Cloaking",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530185",
    "pdf_link": null,
    "abstract": "Unwanted camera obstruction can severely degrade captured images, including both scene occluders near the camera and partial occlusions of the camera cover glass. Such occlusions can cause catastrophic failures for various scene understanding tasks such as semantic segmentation, object detection, and depth estimation. Existing camera arrays capture multiple redundant views of a scene to see around thin occlusions. Such multi-camera systems effectively form a large synthetic aperture, which can suppress nearby occluders with a large defocus blur, but significantly increase the overall form factor of the imaging setup. In this work, we propose a monocular single-shot imaging approach that optically cloaks obstructions by emulating a large array. Instead of relying on different camera views, we learn a diffractive optical element (DOE) that performs depth-dependent optical encoding, scattering nearby occlusions while allowing paraxial wavefronts to be focused. We computationally reconstruct unobstructed images from these superposed measurements with a neural network that is trained jointly with the optical layer of the proposed imaging system. We assess the proposed method in simulation and with an experimental prototype, validating that the proposed computational camera is capable of recovering occluded scene information in the presence of severe camera obstruction.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_139",
    "authors": "Gal Metzer, Rana Hanocka, Raja Giryes, Daniel Cohen-Or, Gal Metzer",
    "title": "Self-Sampling for Neural Point Cloud Consolidation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3470645",
    "pdf_link": null,
    "abstract": "We introduce a novel technique for neural point cloud consolidation which learns from only the input point cloud. Unlike other point up-sampling methods which analyze shapes via local patches, in this work, we learn from global subsets. We repeatedly self-sample the input point cloud with global subsets that are used to train a deep neural network. Specifically, we define source and target subsets according to the desired consolidation criteria (e.g., generating sharp points or points in sparse regions). The network learns a mapping from source to target subsets, and implicitly learns to consolidate the point cloud. During inference, the network is fed with random subsets of points from the input, which it displaces to synthesize a consolidated point set. We leverage the inductive bias of neural networks to eliminate noise and outliers, a notoriously difficult problem in point cloud consolidation. The shared weights of the network are optimized over the entire shape, learning non-local statistics and exploiting the recurrence of local-scale geometries. Specifically, the network encodes the distribution of the underlying shape surface within a fixed set of local kernels, which results in the best explanation of the underlying shape surface. We demonstrate the ability to consolidate point sets from a variety of shapes, while eliminating outliers and noise.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_513",
    "authors": "Jonghee Back, Binh-Son Hua, Toshiya Hachisuka, Bochang Moon",
    "title": "Self-Supervised Post-Correction for Monte Carlo Denoising",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530730",
    "pdf_link": null,
    "abstract": "Using a network trained by a large dataset is becoming popular for denoising Monte Carlo rendering. Such a denoising approach based on supervised learning is currently considered the best approach in terms of quality. Nevertheless, this approach may fail when the image to be rendered (i.e., the test data) has very different characteristics than the images included in the training dataset. A pre-trained network may not properly denoise such an image since it is unseen data from a supervised learning perspective. To address this fundamental issue, we introduce a post-processing network that improves the performance of supervised learning denoisers. The key idea behind our approach is to train this post-processing network with self-supervised learning. In contrast to supervised learning, our self-supervised model does not need a reference image in its training process. We can thus use a noisy test image and self-correct the model on the fly to improve denoising performance. Our main contribution is a self-supervised loss that can guide the post-correction network to optimize its parameters without relying on the reference. Our work is the first to apply this self-supervised learning concept in denoising Monte Carlo rendered estimates. We demonstrate that our post-correction framework can boost supervised denoising via our self-supervised optimization. Our implementation is available at https://github.com/CGLab-GIST/self-supervised-post-corr.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_178",
    "authors": "Yunzhe Liu, Rinon Gal, Amit H. Bermano, Baoquan Chen, Daniel Cohen-Or",
    "title": "Self-conditioned Generative Adversarial Networks for Image Editing",
    "paper_url": "https://arxiv.org/abs/2202.04040",
    "pdf_link": null,
    "abstract": "Generative Adversarial Networks (GANs) are susceptible to bias, learned from either the unbalanced data, or through mode collapse. The networks focus on the core of the data distribution, leaving the tails - or the edges of the distribution - behind. We argue that this bias is responsible not only for fairness concerns, but that it plays a key role in the collapse of latent-traversal editing methods when deviating away from the distribution's core. Building on this observation, we outline a method for mitigating generative bias through a self-conditioning process, where distances in the latent-space of a pre-trained generator are used to provide initial labels for the data. By fine-tuning the generator on a re-sampled distribution drawn from these self-labeled data, we force the generator to better contend with rare semantic attributes and enable more realistic generation of these properties. We compare our models to a wide range of latent editing methods, and show that by alleviating the bias they achieve finer semantic control and better identity preservation through a wider range of transformations. Our code and models will be available at https://github.com/yzliu567/sc-gan",
    "scholar_publication": "arXiv preprint arXiv …, 2022 - arxiv.org"
  },
  {
    "paper_id": "papers_289",
    "authors": "Ron Mokady, Omer Tov, Michal Yarom, Oran Lang, Inbar Mosseri, Tali Dekel, Daniel Cohen-Or, Michal Irani",
    "title": "Self-distilled StyleGAN: Towards Generation From Internet Photos",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530708",
    "pdf_link": null,
    "abstract": "StyleGAN is known to produce high-fidelity images, while also offering unprecedented semantic editing. However, these fascinating abilities have been demonstrated only on a limited set of datasets, which are usually structurally aligned and well curated. In this paper, we show how StyleGAN can be adapted to work on raw uncurated images collected from the Internet. Such image collections impose two main challenges to StyleGAN: they contain many outlier images, and are characterized by a multi-modal distribution. Training StyleGAN on such raw image collections results in degraded image synthesis quality. To meet these challenges, we proposed a StyleGAN-based self-distillation approach, which consists of two main components: (i) A generative-based self-filtering of the dataset to eliminate outlier images, in order to generate an adequate training set, and (ii) Perceptual clustering of the generated images to detect the inherent data modalities, which are then employed to improve StyleGAN’s “truncation trick” in the image synthesis process. The presented technique enables the generation of high-quality images, while minimizing the loss in diversity of the data. Through qualitative and quantitative evaluation, we demonstrate the power of our approach to new challenging and diverse domains collected from the Internet. New datasets and pre-trained models are provided in our project website https://self-distilled-stylegan.github.io/.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_539",
    "authors": "Tiancheng Zhi, Bowei Chen, Ivaylo Boyadzhiev, Sing Bing Kang, Martial Hebert, Srinivasa G. Narasimhan",
    "title": "Semantically Supervised Appearance Decomposition for Virtual Staging From a Single Panorama",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530148",
    "pdf_link": null,
    "abstract": "We describe a novel approach to decompose a single panorama of an empty indoor environment into four appearance components: specular, direct sunlight, diffuse and diffuse ambient without direct sunlight. Our system is weakly supervised by automatically generated semantic maps (with floor, wall, ceiling, lamp, window and door labels) that have shown success on perspective views and are trained for panoramas using transfer learning without any further annotations. A GAN-based approach supervised by coarse information obtained from the semantic map extracts specular reflection and direct sunlight regions on the floor and walls. These lighting effects are removed via a similar GAN-based approach and a semantic-aware inpainting step. The appearance decomposition enables multiple applications including sun direction estimation, virtual furniture insertion, floor material replacement, and sun direction change, providing an effective tool for virtual home staging. We demonstrate the effectiveness of our approach on a large and recently released dataset of panoramas of empty homes.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_426",
    "authors": "Yuchi Huo, Shi Li, Yazhen Yuan, Xu Chen, Rui Wang, Wenting Zheng, Hai Lin, Hujun Bao",
    "title": "ShaderTransformer: Predicting Shader Quality via One-shot Embedding for Fast Simplification",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530722",
    "pdf_link": null,
    "abstract": "Given specific scene configurations and target functions, automatic shader simplification searches for the best simplified shader variant from an optimization space with many candidates. Although various speedup methods have been proposed, there is still a costly render-and-evaluate process to obtain variant’s performance and quality, especially when the scene changes. In this paper, we present a deep learning-based framework for predicting a shader’s simplification space, where the shader’s variants can be embedded into a metric space all at once for efficient quality evaluation. The novel framework allows the one-shot embedding of a space rather than a single instance. In addition, the simplification errors can be interpreted by mutual attention between shader fragments, presenting an informative focus-aware simplification framework that can assist experts in optimizing the codes. The results show that the new framework achieves significant speedup compared with existing search approaches. The focus-aware simplification framework reveals a new possibility of interpreting shaders for various applications.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_471",
    "authors": "Mostafa Morsy Abdelkader Morsy, Alan Brunton, Philipp Urban",
    "title": "Shape Dithering for 3D Printing",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530129",
    "pdf_link": null,
    "abstract": "… affect the fatigue behavior of printed parts. We use implicit shape dithering, displacing the part's … leverage to optimize a 3D blue-noise mask to generate the anisotropic dither signal. As a …",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_230",
    "authors": "Anyi Rao, Linning Xu, Dahua Lin",
    "title": "Shoot360: Normal View Video Creation From City Panorama Footage",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530702",
    "pdf_link": null,
    "abstract": "We present Shoot360, a system that efficiently generates multi-shot normal view videos with desired content presentation and various cinematic styles, given a collection of 360 video recordings on different environments. The core of our system is a three-step decision process: 1) It firstly semantically analyzes the contents of interest from each panorama environment based on shot units, and produces a guidance that specifies the semantic focus and movement type of its output shot according to the user specification on content presentation and cinematic styles. 2) Based on the obtained guidance, it generates video candidates for each shot with shot-level control parameters for view projections following the filming rules. 3) The system further aggregates the projected normal view shots with the imposed local and global constraints, which incorporates the external knowledge learned from exemplar videos and professional filming rules. Extensive experiments verify the effectiveness of our system design, and we conclude with promising extensions for applying it to more generalized scenarios.",
    "scholar_publication": "ACM SIGGRAPH 2022 conference proceedings, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_103",
    "authors": "Linxu Fan, Floyd Chitalu, Taku Komura, Floyd Chitalu",
    "title": "Simulating Brittle Fracture With Material Points",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3522573",
    "pdf_link": null,
    "abstract": "Large-scale topological changes play a key role in capturing the fine debris of fracturing virtual brittle material. Real-world, tough brittle fractures have dynamic branching behaviour but numerical simulation of this phenomena is notoriously challenging. In order to robustly capture these visual characteristics, we simulate brittle fracture by combining elastodynamic continuum mechanical models with rigid-body methods: A continuum damage mechanics (CDM) problem is solved, following rigid-body impact, to simulate crack propagation by tracking a damage field. We combine the result of this elastostatic continuum model with a novel technique to approximate cracks as a non-manifold mid-surface, which enables accurate and robust modelling of material fragment volumes to compliment fast-and-rigid shatter effects. For enhanced realism, we add fracture detail, incorporating particle damage-time to inform localised perturbation of the crack surface with artistic control. We evaluate our method with numerous examples and comparisons, showing that it produces a breadth of brittle material fracture effects and with low simulation resolution to require much less time compared to fully elastodynamic simulations.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_523",
    "authors": "Xuwen Chen, Xingyu Ni, Bo Zhu, Bin Wang, Baoquan Chen",
    "title": "Simulation and Optimization of Magnetoelastic Thin Shells",
    "paper_url": "https://xw-c.github.io/publications/sig22MagThinShells-lowres.pdf",
    "pdf_link": null,
    "abstract": "Magnetic substance simulation has received much attention in the computer graphics and computational physics field over the past years. These simulations range from magnetic rigid bodies [Kim and Han 2020; Kim et al. 2018; Thomaszewski et al. 2008], elastic solids [Wang et al. 2020a; Yan et al. 2021; Zhao et al. 2019], ferrofluid [Huang et al. 2019; Huang and Michels 2020; Ishikawa et al. 2013; Ni et al. 2020], and to viscoelastic materials [Sun et al. 2021]. The most visually appealing process underpinning these magnetic-related phenomena rests in the complex interactions between a (time-varying) magnetic field and non-linear solid/fluid material properties. Despite the inspirational breakthroughs that have taken place in the field of magnetic object simulations, the modeling of magnetic thin shells remains as an unexplored problem due to the many difficulties that come along with simulating the dynamic elasto-magnetic coupling process of a thin object. In particular, there exists no effective continuum mechanics model to characterize the magnetic-induced elastic behaviors on a thin shell, not to mention a robust numerical scheme to discretize and differentiate the mechanics model on complex thin geometries.Thin-shell objects, such as wrinkled cloth [Bridson et al. 2003; Chen et al. 2021; Guo et al. 2018; Sperl et al. 2020], fractured sheets [Busaryev et al. 2013; Manteaux et al. 2015; Pfaff et al. 2014; Zhu et al. 2015], crumpled paper [Chen et al. 2018; Dudte et al. 2016;",
    "scholar_publication": "ACM Trans. Graph., 2022 - xw-c.github.io"
  },
  {
    "paper_id": "papers_813",
    "authors": "Yuxuan Han, Ruicheng Wang, Jiaolong Yang",
    "title": "Single-view View Synthesis in the Wild With Learned Adaptive Multiplane Images",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530755",
    "pdf_link": null,
    "abstract": "This paper deals with the challenging task of synthesizing novel views for in-the-wild photographs. Existing methods have shown promising results leveraging monocular depth estimation and color inpainting with layered depth representations. However, these methods still have limited capability to handle scenes with complex 3D geometry. We propose a new method based on the multiplane image (MPI) representation. To accommodate diverse scene layouts in the wild and tackle the difficulty in producing high-dimensional MPI contents, we design a network structure that consists of two novel modules, one for plane depth adjustment and another for depth-aware color prediction. The former adjusts the initial plane positions using the RGBD context feature and an attention mechanism. Given adjusted depth values, the latter predicts the color and density for each plane separately with proper inter-plane interactions achieved via a feature masking strategy. To train our method, we construct large-scale stereo training data using only unconstrained single-view image collections by a simple yet effective warp-back strategy. The experiments on both synthetic and real datasets demonstrate that our trained model works remarkably well and achieves state-of-the-art results.",
    "scholar_publication": "ACM SIGGRAPH 2022 Conference …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_145",
    "authors": "J. Andreas Bærentzen, Eva Rotenberg, J. Andreas Bærentzen",
    "title": "Skeletonization via Local Separators",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3459233",
    "pdf_link": null,
    "abstract": "… skeleton computation that differs from previous algorithms by being based on the notion of local separators… For a simple 2D graph (left), we find the local separators shown as identically …",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_340",
    "authors": "Kirill Brodt, Mikhail Bessmeltsev",
    "title": "Sketch2Pose: Estimating a 3D Character Pose From a Bitmap Sketch",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530106",
    "pdf_link": null,
    "abstract": "Artists frequently capture character poses via raster sketches, then use these drawings as a reference while posing a 3D character in a specialized 3D software --- a time-consuming process, requiring specialized 3D training and mental effort. We tackle this challenge by proposing the first system for automatically inferring a 3D character pose from a single bitmap sketch, producing poses consistent with viewer expectations. Algorithmically interpreting bitmap sketches is challenging, as they contain significantly distorted proportions and foreshortening. We address this by predicting three key elements of a drawing, necessary to disambiguate the drawn poses: 2D bone tangents, self-contacts, and bone foreshortening. These elements are then leveraged in an optimization inferring the 3D character pose consistent with the artist's intent. Our optimization balances cues derived from artistic literature and perception research to compensate for distorted character proportions. We demonstrate a gallery of results on sketches of numerous styles. We validate our method via numerical evaluations, user studies, and comparisons to manually posed characters and previous work. Code and data for our paper are available at http://www-labs.iro.umontreal.ca/bmpix/sketch2pose/.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_134",
    "authors": "Anpei Chen, Ruiyang Liu, Ling Xie, Zhang Chen, Hao Su, Jingyi Yu, Ruiyang Liu",
    "title": "SofGAN: A Portrait Image Generator With Dynamic Styling",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3470848",
    "pdf_link": null,
    "abstract": "Recently, Generative Adversarial Networks (GANs) have been widely used for portrait image generation. However, in the latent space learned by GANs, different attributes, such as pose, shape, and texture style, are generally entangled, making the explicit control of specific attributes difficult. To address this issue, we propose a SofGAN image generator to decouple the latent space of portraits into two subspaces: a geometry space and a texture space. The latent codes sampled from the two subspaces are fed to two network branches separately, one to generate the 3D geometry of portraits with canonical pose, and the other to generate textures. The aligned 3D geometries also come with semantic part segmentation, encoded as a semantic occupancy field (SOF). The SOF allows the rendering of consistent 2D semantic segmentation maps at arbitrary views, which are then fused with the generated texturemaps and stylized to a portrait photo using our semantic instance-wise module. Through extensive experiments, we show that our system can generate high-quality portrait images with independently controllable geometry and texture attributes. The method also generalizes well in various applications, such as appearance-consistent facial animation and dynamic styling.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_209",
    "authors": "Inseung Hwang, Daniel S. Jeon, Adolfo Muñoz, Diego Gutierrez, Xin Tong, Min H. Kim",
    "title": "Sparse Ellipsometry: Portable Acquisition of Polarimetric SVBRDF and Shape With Unstructured Flash Photography",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530075",
    "pdf_link": null,
    "abstract": "Ellipsometry techniques allow to measure polarization information of materials, requiring precise rotations of optical components with different configurations of lights and sensors. This results in cumbersome capture devices, carefully calibrated in lab conditions, and in very long acquisition times, usually in the order of a few days per object. Recent techniques allow to capture polarimetric spatially-varying reflectance information, but limited to a single view, or to cover all view directions, but limited to spherical objects made of a single homogeneous material. We present sparse ellipsometry, a portable polarimetric acquisition method that captures both polarimetric SVBRDF and 3D shape simultaneously. Our handheld device consists of off-the-shelf, fixed optical components. Instead of days, the total acquisition time varies between twenty and thirty minutes per object. We develop a complete polarimetric SVBRDF model that includes diffuse and specular components, as well as single scattering, and devise a novel polarimetric inverse rendering algorithm with data augmentation of specular reflection samples via generative modeling. Our results show a strong agreement with a recent ground-truth dataset of captured polarimetric BRDFs of real-world objects.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_105",
    "authors": "Philipp Herholz, Xuan Tang, Teseo Schneider, Shoaib Kamil, Daniele Panozzo, Olga Sorkine-Hornung, Philipp Herholz",
    "title": "Sparsity-specific Code Optimization Using Expression Trees",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3520484",
    "pdf_link": null,
    "abstract": "We introduce a code generator that converts unoptimized C++ code operating on sparse data into vectorized and parallel CPU or GPU kernels. Our approach unrolls the computation into a massive expression graph, performs redundant expression elimination, grouping, and then generates an architecture-specific kernel to solve the same problem, assuming that the sparsity pattern is fixed, which is a common scenario in many applications in computer graphics and scientific computing. We show that our approach scales to large problems and can achieve speedups of two orders of magnitude on CPUs and three orders of magnitude on GPUs, compared to a set of manually optimized CPU baselines. To demonstrate the practical applicability of our approach, we employ it to optimize popular algorithms with applications to physical simulation and interactive mesh deformation.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_220",
    "authors": "Mana Fukasawa, Yu Nakayama",
    "title": "Spatial Augmented Reality Assistance System With Accelerometer and Projection Mapping at Cleaning Activities",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543245",
    "pdf_link": null,
    "abstract": "Projection mapping is a technological process where digital images are projected onto a physical surface using a video projector [Raskar et al. 2001]. It is one of the promising solutions of Spatial Augmented Reality (SAR) for well-being. Projection-based work supporting systems were investigated on an assembly sequence [Rodriguez et al.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_568",
    "authors": "Nicholas Sharp, Alec Jacobson",
    "title": "Spelunking the Deep: Guaranteed Queries on General Neural Implicit Surfaces via Range Analysis",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530155",
    "pdf_link": null,
    "abstract": "Neural implicit representations, which encode a surface as the level set of a neural network applied to spatial coordinates, have proven to be remarkably effective for optimizing, compressing, and generating 3D geometry. Although these representations are easy to fit, it is not clear how to best evaluate geometric queries on the shape, such as intersecting against a ray or finding a closest point. The predominant approach is to encourage the network to have a signed distance property. However, this property typically holds only approximately, leading to robustness issues, and holds only at the conclusion of training, inhibiting the use of queries in loss functions. Instead, this work presents a new approach to perform queries directly on general neural implicit functions for a wide range of existing architectures. Our key tool is the application of range analysis to neural networks, using automatic arithmetic rules to bound the output of a network over a region; we conduct a study of range analysis on neural networks, and identify variants of affine arithmetic which are highly effective. We use the resulting bounds to develop geometric queries including ray casting, intersection testing, constructing spatial hierarchies, fast mesh extraction, closest-point evaluation, evaluating bulk properties, and more. Our queries can be efficiently evaluated on GPUs, and offer concrete accuracy guarantees even on randomly-initialized networks, enabling their use in training objectives and beyond. We also show a preliminary application to inverse rendering.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_138",
    "authors": "Valerie Gaveau",
    "title": "Sphere: A Novel Approach to 3D and Active Sound Localization",
    "paper_url": "https://www.biorxiv.org/content/10.1101/2020.03.19.998906.abstract",
    "pdf_link": null,
    "abstract": "… through active listening behavior, exploring the auditory … novel approach to sound localization in 3D named SPHERE (… these elements (controlled positioning of a real sound source and …",
    "scholar_publication": "bioRxiv, 2020 - biorxiv.org"
  },
  {
    "paper_id": "papers_328",
    "authors": "William Neveu, Ivan Puhachov, Bernhard Thomaszewski, Mikhail Bessmeltsev",
    "title": "Stability-aware Simplification of Curve Networks",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530711",
    "pdf_link": null,
    "abstract": "Designing curve networks for fabrication requires simultaneous consideration of structural stability, cost effectiveness, and visual appeal—complex, interrelated objectives that make manual design a difficult and tedious task. We present a novel method for fabrication-aware simplification of curve networks, algorithmically selecting a stable subset of given 3D curves. While traditionally stability is measured as magnitude of deformation induced by a set of pre-defined loads, predicting applied forces for common day objects can be challenging. Instead, we directly optimize for minimal deformation under the worst-case load. Our technical contribution is a novel formulation of 3D curve network simplification for worst-case stability, leading to a mixed-integer semi-definite programming problem (MI-SDP). We show that while solving MI-SDP directly is infeasible, a physical insight suggests an efficient greedy approximation algorithm. We demonstrate the potential of our approach on a variety of curve network designs and validate its effectiveness compared to simpler alternatives using numerical experiments.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_136",
    "authors": "Mari Shiina, Naoki Hashimoto",
    "title": "Stereoscopic Transparent Display Visible With Naked Eye",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543205",
    "pdf_link": null,
    "abstract": "In this study, we propose a stereoscopic transparent display that can be viewed with the naked eye. Existing methods for generating realistic high-quality stereoscopic images require wearable devices and the presence of a display, which degrades the sense of presence. Our method increases the sense of presence by making the stereoscopic images blend into the surrounding environment.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_234",
    "authors": "Hideki Todo, Kunihiko Kobayashi, Jin Katsuragi, Haruna Shimotahira, Shizuo Kaji, Yonghao Yue",
    "title": "Stroke Transfer: Example-based Synthesis of Animatable Stroke Styles",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530703",
    "pdf_link": null,
    "abstract": "We present stroke transfer, an example-based synthesis method of brushstrokes for animated scenes under changes in viewpoint, lighting conditions, and object shapes. We introduce stroke field for guiding the generation of strokes, consisting of spatially varying attributes of strokes, namely, their orientations, lengths, widths, and colors. Strokes are synthesized as the integral curves of the stroke field. In essence, we separate elements that constitute the artistic stroke into style-specific transferable elements and instance-intrinsic ones. To generate the stroke field, we first compute a set of vector fields that reflect the instance-intrinsic elements and then combine them using style-specific weight functions learned from exemplars, with the weights computed in a proxy feature space shared among a variety of objects. The rendered animation using our method captures time-varying viewpoint, lighting conditions, and object shapes, as well as the artistic style given in the form of exemplars.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_148",
    "authors": "Daniel Berio, Paul Asente, Jose Echevarria, Frederic Fol Leymarie, Daniel Berio",
    "title": "StrokeStyles: Stroke-based Segmentation and Stylization of Fonts",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3505246",
    "pdf_link": null,
    "abstract": "We develop a method to automatically segment a font’s glyphs into a set of overlapping and intersecting strokes with the aim of generating artistic stylizations. The segmentation method relies on a geometric analysis of the glyph’s outline, its interior, and the surrounding areas and is grounded in perceptually informed principles and measures. Our method does not require training data or templates and applies to glyphs in a large variety of input languages, writing systems, and styles. It uses the medial axis, curvilinear shape features that specify convex and concave outline parts, links that connect concavities, and seven junction types. We show that the resulting decomposition in strokes can be used to create variations, stylizations, and animations in different artistic or design-oriented styles while remaining recognizably similar to the input font.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_152",
    "authors": "Omer Kafri, Or Patashnik, Yuval Alaluf, Daniel Cohen-Or, Omer Kafri",
    "title": "StyleFusion: Disentangling Spatial Segments in StyleGAN-generated Images",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3527168",
    "pdf_link": null,
    "abstract": "We present StyleFusion, a new mapping architecture for StyleGAN, which takes as input a number of latent codes and fuses them into a single style code. Inserting the resulting style code into a pre-trained StyleGAN generator results in a single harmonized image in which each semantic region is controlled by one of the input latent codes. Effectively, StyleFusion yields a disentangled representation of the image, providing fine-grained control over each region of the generated image. Moreover, to help facilitate global control over the generated image, a special input latent code is incorporated into the fused representation. StyleFusion operates in a hierarchical manner, where each level is tasked with learning to disentangle a pair of image regions (e.g., the car body and wheels). The resulting learned disentanglement allows one to modify both local, fine-grained semantics (e.g., facial features) as well as more global features (e.g., pose and background), providing improved flexibility in the synthesis process. As a natural extension, StyleFusion allows one to perform semantically-aware cross-image mixing of regions that are not necessarily aligned. Finally, we demonstrate how StyleFusion can be paired with existing editing techniques to more faithfully constrain the edit to the user’s region of interest. Code is available at: https://github.com/OmerKafri/StyleFusion.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_628",
    "authors": "Rinon Gal, Or Patashnik, Haggai Maron, Amit Bermano, Gal Chechik, Daniel Cohen-Or",
    "title": "StyleGAN-NADA: CLIP-guided Domain Adaptation of Image Generators",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530164",
    "pdf_link": null,
    "abstract": "Can a generative model be trained to produce images from a specific domain, guided only by a text prompt, without seeing any image? In other words: can an image generator be trained \"blindly\"? Leveraging the semantic power of large scale Contrastive-Language-Image-Pre-training (CLIP) models, we present a text-driven method that allows shifting a generative model to new domains, without having to collect even a single image. We show that through natural language prompts and a few minutes of training, our method can adapt a generator across a multitude of domains characterized by diverse styles and shapes. Notably, many of these modifications would be difficult or infeasible to reach with existing methods. We conduct an extensive set of experiments across a wide range of domains. These demonstrate the effectiveness of our approach, and show that our models preserve the latent-space structure that makes generative models appealing for downstream tasks. Code and videos available at: stylegan-nada.github.io/",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_634",
    "authors": "Axel Sauer, Katja Schwarz, Andreas Geiger",
    "title": "StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530738",
    "pdf_link": null,
    "abstract": "Computer graphics has experienced a recent surge of data-centric approaches for photorealistic and controllable content creation. StyleGAN in particular sets new standards for generative modeling regarding image quality and controllability. However, StyleGAN’s performance severely degrades on large unstructured datasets such as ImageNet. StyleGAN was designed for controllability; hence, prior works suspect its restrictive design to be unsuitable for diverse datasets. In contrast, we find the main limiting factor to be the current training strategy. Following the recently introduced Projected GAN paradigm, we leverage powerful neural network priors and a progressive growing strategy to successfully train the latest StyleGAN3 generator on ImageNet. Our final model, StyleGAN-XL, sets a new state-of-the-art on large-scale image synthesis and is the first to generate images at a resolution of 10242 at such a dataset scale. We demonstrate that this model can invert and edit images beyond the narrow domain of portraits or specific object classes. Code, models, and supplementary videos can be found at https://sites.google.com/view/stylegan-xl/ .",
    "scholar_publication": "ACM SIGGRAPH 2022 conference …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_121",
    "authors": "Shi-min Hu, Zheng-Ning Liu, Meng-Hao Guo, Jun-Xiong Cai, Jiahui Huang, Tai-Jiang Mu, Ralph R. Martin, Zheng-Ning Liu",
    "title": "Subdivision Based Convolutional Networks",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3506694",
    "pdf_link": null,
    "abstract": "… Based on subdivision sequence connectivity, our approach offers a more general and standard convolution … Experimentally, we find this simple convolutional network provides sufficient …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_442",
    "authors": "Felix Hähnlein, Yulia Gryaditskaya, Alla Sheffer, Adrien Bousseau",
    "title": "Symmetry-driven 3D Reconstruction From Concept Sketches",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530723",
    "pdf_link": null,
    "abstract": "Concept sketches, ubiquitously used in industrial design, are inherently imprecise yet highly effective at communicating 3D shape to human observers. We present a new symmetry-driven algorithm for recovering designer-intended 3D geometry from concept sketches. We observe that most concept sketches of human-made shapes are structured around locally symmetric building blocks, defined by triplets of orthogonal symmetry planes. We identify potential building blocks using a combination of 2D symmetries and drawing order. We reconstruct each such building block by leveraging a combination of perceptual cues and observations about designer drawing choices. We cast this reconstruction as an integer programming problem where we seek to identify, among the large set of candidate symmetry correspondences formed by approximate pen strokes, the subset that results in the most symmetric and well-connected shape. We demonstrate the robustness of our approach by reconstructing 82 sketches, which exhibit significant over-sketching, inaccurate perspective, partial symmetry, and other imperfections. In a comparative study, participants judged our results as superior to the state-of-the-art by a ratio of 2:1.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_110",
    "authors": "Ruofan Liu, Erwin Wu, Chen-Chieh Liao, Hayato Nishioka, Shinichi Furuya, Hideki Koike",
    "title": "Synchronized Hand Difference Visualization for Piano Learning",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543196",
    "pdf_link": null,
    "abstract": "When learning a dexterous skill such as playing the piano, people commonly watch videos of a teacher. However, this conventional way has some downsides such as limited information to be retrieved and less intuitive instructions. We propose a virtual training system by visualizing differences between hands to provide intuitive feedback for skill acquisition. After synchronizing the data, two visual cues are proposed including a hand-overlay manner and a two-keyboards visualization. A pilot study confirm the superiority of the proposed methods over conventional video-viewing.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_104",
    "authors": "Florian Cyril Stutz, Tim Felle Olsen, Jeroen Peter Groen, Tuan Nguyen Trung, Niels Aage, Ole Sigmund, Justin Solomon, Andreas Bærentzen, Tim Felle Olsen",
    "title": "Synthesis of Frame Field-aligned Multi-laminar Structures",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3516522",
    "pdf_link": null,
    "abstract": "In the field of topology optimization, the homogenization approach has been revived as an important alternative to the established, density-based methods. Homogenization can represent microstructures at length scales decoupled from the resolution of the computational grid. The optimal microstructure for a single load case is an orthogonal rank-3 laminate. Initially, we investigate where singularities occur in orthogonal rank-3 laminates and show that the laminar parts of the structures we seek are unaffected by the singularities …",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_120",
    "authors": "Haikuan Zhu, Juan Cao, Yanyang Xiao, Zhonggui Chen, Zichun Zhong, Yongjie Jessica Zhang, Zichun Zhong",
    "title": "TCB-spline-based Image Vectorization",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3513132",
    "pdf_link": null,
    "abstract": "… We explore these properties of TCB-splines and apply them to vector image representation. … our TCB-spline-based representation and the proposed raster image vectorization algorithm …",
    "scholar_publication": "… Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_140",
    "authors": "Zhi-Chao Dong, Wenming Wu, Zeng-Hao Xu, Qi Sun, Guan-Jie Yuan, Ligang Liu, Xiao-Ming Fu, Qi Sun",
    "title": "Tailored Reality: Perception-aware Scene Restructuring for Adaptive VR Navigation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3470847",
    "pdf_link": null,
    "abstract": "In virtual reality (VR), the virtual scenes are pre-designed by creators. Our physical surroundings, however, comprise significantly varied sizes, layouts, and components. To bridge the gap and further enable natural navigation, recent solutions have been proposed to redirect users or recreate the virtual content. However, they suffer from either interrupted experience or distorted appearances. We present a novel VR-oriented algorithm that automatically restructures a given virtual scene for a user’s physical environment. Different from the previous methods, we introduce neither interrupted walking experience nor curved appearances. Instead, a perception-aware function optimizes our retargeting technique to preserve the fidelity of the virtual scene that appears in VR head-mounted displays. Besides geometric and topological properties, it emphasizes the unique first-person view perceptual factors in VR, such as dynamic visibility and objectwise relationships. We conduct both analytical experiments and subjective studies. The results demonstrate our system’s versatile capability and practicability for natural navigation in VR: It reduces the virtual space by 40% without statistical loss of perceptual identicality.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_334",
    "authors": "Yuming Jiang, Shuai Yang, Haonan Qiu, Wayne Wu, Chen Change Loy, Ziwei Liu",
    "title": "Text2Human: Text-driven Controllable Human Image Generation",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530104",
    "pdf_link": null,
    "abstract": "Generating high-quality and diverse human images is an important yet challenging task in vision and graphics. However, existing generative models often fall short under the high diversity of clothing shapes and textures. Furthermore, the generation process is even desired to be intuitively controllable for layman users. In this work, we present a text-driven controllable framework, Text2Human, for a high-quality and diverse human generation. We synthesize full-body human images starting from a given human pose with two dedicated steps. 1) With some texts describing the shapes of clothes, the given human pose is first translated to a human parsing map. 2) The final human image is then generated by providing the system with more attributes about the textures of clothes. Specifically, to model the diversity of clothing textures, we build a hierarchical texture-aware codebook that stores multi-scale neural representations for each type of texture. The codebook at the coarse level includes the structural representations of textures, while the codebook at the fine level focuses on the details of textures. To make use of the learned hierarchical codebook to synthesize desired images, a diffusion-based transformer sampler with mixture of experts is firstly employed to sample indices from the coarsest level of the codebook, which then is used to predict the indices of the codebook at finer levels. The predicted indices at different levels are translated to human images by the decoder learned accompanied with hierarchical codebooks. The use of mixture-of-experts allows for the generated image conditioned on the fine-grained text input. The prediction for finer level indices refines the quality of clothing textures. Extensive quantitative and qualitative evaluations demonstrate that our proposed Text2Human framework can generate more diverse and realistic human images compared to state-of-the-art methods. Our project page is https://yumingj.github.io/projects/Text2Human.html. Code and pretrained models are available at https://github.com/yumingj/Text2Human.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_130",
    "authors": "Jungeon Kim, Hyomin Kim, Hyeonseo Nam, Jaesik Park, Seungyong Lee, Jungeon Kim",
    "title": "TextureMe: High-quality Textured Scene Reconstruction in Real Time",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3503926",
    "pdf_link": null,
    "abstract": "Three-dimensional (3D) reconstruction using an RGB-D camera has been widely adopted for realistic content creation. However, high-quality texture mapping onto the reconstructed geometry is often treated as an offline step that should run after geometric reconstruction. In this article, we propose TextureMe, a novel approach that jointly recovers 3D surface geometry and high-quality texture in real time. The key idea is to create triangular texture patches that correspond to zero-crossing triangles of truncated signed distance function (TSDF) progressively in a global texture atlas. Our approach integrates color details into the texture patches in parallel with the depth map integration to a TSDF. It also actively updates a pool of texture patches to adapt TSDF changes and minimizes misalignment artifacts that occur due to camera drift and image distortion. Our global texture atlas representation is fully compatible with conventional texture mapping. As a result, our approach produces high-quality textures without utilizing additional texture map optimization, mesh parameterization, or heavy post-processing. High-quality scenes produced by our real-time approach are even comparable to the results from state-of-the-art methods that run offline.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_141",
    "authors": "Ahmad Nasikun, Klaus Hildebrandt, Ahmad Nasikun",
    "title": "The Hierarchical Subspace Iteration Method for Laplace-Beltrami Eigenproblems",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3495208",
    "pdf_link": null,
    "abstract": "Sparse eigenproblems are important for various applications in computer graphics. The spectrum and eigenfunctions of the Laplace–Beltrami operator, for example, are fundamental for methods in shape analysis and mesh processing. The Subspace Iteration Method is a robust solver for these problems. In practice, however, Lanczos schemes are often faster. In this article, we introduce the Hierarchical Subspace Iteration Method (HSIM), a novel solver for sparse eigenproblems that operates on a hierarchy of nested vector spaces. The hierarchy is constructed such that on the coarsest space all eigenpairs can be computed with a dense eigensolver. HSIM uses these eigenpairs as initialization and iterates from coarse to fine over the hierarchy. On each level, subspace iterations, initialized with the solution from the previous level, are used to approximate the eigenpairs. This approach substantially reduces the number of iterations needed on the finest grid compared to the non-hierarchical Subspace Iteration Method. Our experiments show that HSIM can solve Laplace–Beltrami eigenproblems on meshes faster than state-of-the-art methods based on Lanczos iterations, preconditioned conjugate gradients, and subspace iterations.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_172",
    "authors": "Ziyin Qu, Minchen Li, Fernando de Goes, Chenfanfu Jiang",
    "title": "The Power Particle-in-Cell Method",
    "paper_url": "https://par.nsf.gov/biblio/10358323",
    "pdf_link": null,
    "abstract": "… ) method and the Affine Particle-In-Cell (APIC) method with volume preservation and robustness to varying particle-per-cell ratio, while retaining low numerical dissipation, conserving …",
    "scholar_publication": "ACM Transactions on Graphics, 2022 - par.nsf.gov"
  },
  {
    "paper_id": "paperstog_147",
    "authors": "Xin Chen, Anqi Pang, Wei Yang, Peihao Wang, Lan Xu, Jingyi Yu, Jingyi Yu, Xin Chen",
    "title": "TightCap: 3D Human Shape Capture With Clothing Tightness Field",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3478518",
    "pdf_link": null,
    "abstract": "In this article, we present TightCap, a data-driven scheme to capture both the human shape and dressed garments accurately with only a single three-dimensional (3D) human scan, which enables numerous applications such as virtual try-on, biometrics, and body evaluation. To break the severe variations of the human poses and garments, we propose to model the clothing tightness field—the displacements from the garments to the human shape implicitly in the global UV texturing domain. To this end, we utilize an enhanced statistical human template and an effective multi-stage alignment scheme to map the 3D scan into a hybrid 2D geometry image. Based on this 2D representation, we propose a novel framework to predict clothing tightness field via a novel tightness formulation, as well as an effective optimization scheme to further reconstruct multi-layer human shape and garments under various clothing categories and human postures. We further propose a new clothing tightness dataset of human scans with a large variety of clothing styles, poses, and corresponding ground-truth human shapes to stimulate further research. Extensive experiments demonstrate the effectiveness of our TightCap to achieve the high-quality human shape and dressed garments reconstruction, as well as the further applications for clothing segmentation, retargeting, and animation.",
    "scholar_publication": "ACM Transactions on …, 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_578",
    "authors": "Suyeon Choi, Manu Gopakumar, Yifan Peng, Jonghyun Kim, Matthew O'Toole, Gordon Wetzstein",
    "title": "Time-multiplexed Neural Holography: A Flexible Framework for Holographic Near-eye Displays With Fast Heavily Quantized Spatial Light Modulators",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530734",
    "pdf_link": null,
    "abstract": "Holographic near-eye displays offer unprecedented capabilities for virtual and augmented reality systems, including perceptually important focus cues. Although artificial intelligence–driven algorithms for computer-generated holography (CGH) have recently made much progress in improving the image quality and synthesis efficiency of holograms, these algorithms are not directly applicable to emerging phase-only spatial light modulators (SLM) that are extremely fast but offer phase control with very limited precision. The speed of these SLMs offers time multiplexing capabilities, essentially enabling partially-coherent holographic display modes. Here we report advances in camera-calibrated wave propagation models for these types of holographic near-eye displays and we develop a CGH framework that robustly optimizes the heavily quantized phase patterns of fast SLMs. Our framework is flexible in supporting runtime supervision with different types of content, including 2D and 2.5D RGBD images, 3D focal stacks, and 4D light fields. Using our framework, we demonstrate state-of-the-art results for all of these scenarios in simulation and experiment.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_541",
    "authors": "Xianzhong Fang, Mathieu Desbrun, Hujun Bao, Jin Huang",
    "title": "TopoCut: Fast and Robust Planar Cutting of Arbitrary Domains",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530149",
    "pdf_link": null,
    "abstract": "Given a complex three-dimensional domain delimited by a closed and non-degenerate input triangle mesh without any self-intersection, a common geometry processing task consists in cutting up the domain into cells through a set of planar cuts, creating a \"cut-cell mesh\", i.e., a volumetric decomposition of the domain amenable to visualization (e.g., exploded views), animation (e.g., virtual surgery), or simulation (finite volume computations). A large number of methods have proposed either efficient or robust solutions, sometimes restricting the cuts to form a regular or adaptive grid for simplicity; yet, none can guarantee both properties, severely limiting their usefulness in practice. At the core of the difficulty is the determination of topological relationships among large numbers of vertices, edges, faces and cells in order to assemble a proper cut-cell mesh: while exact geometric computations provide a robust solution to this issue, their high computational cost has prompted a number of faster solutions based on, e.g., local floating-point angle sorting to significantly accelerate the process --- but losing robustness in doing so. In this paper, we introduce a new approach to planar cutting of 3D domains that substitutes topological inference for numerical ordering through a novel mesh data structure, and revert to exact numerical evaluations only in the few rare cases where it is strictly necessary. We show that our novel concept of topological cuts exploits the inherent structure of cut-cell mesh generation to save computational time while still guaranteeing exactness for, and robustness to, arbitrary cuts and surface geometry. We demonstrate the superiority of our approach over state-of-the-art methods on almost 10,000 meshes with a wide range of geometric and topological complexity. We also provide an open source implementation.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_431",
    "authors": "Shlomi Steinberg, Pradeep Sen, Ling-Qi Yan",
    "title": "Towards Practical Physical-optics Rendering",
    "paper_url": "https://search.proquest.com/openview/ad3dbd625f5a6efcf3a0bac0b4446afe/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "pdf_link": null,
    "abstract": "Today's rendering and light transport frameworks are formulated strictly under the context of ray optics. However, many applications often call for taking the wave nature of light into consideration. This has been historically challenging, mainly because wave-optical descriptors of light are neither linear nor local, frustrating the applications of classical rendering and path-tracing techniques. Today, such path-tracing techniques power most of the complex computer-generated content in films and movies, however wave solvers …",
    "scholar_publication": "2023 - search.proquest.com"
  },
  {
    "paper_id": "papers_469",
    "authors": "Alejandro Rodríguez, Gabriel Cirio",
    "title": "True Seams: Modeling Seams in Digital Garments",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530128",
    "pdf_link": null,
    "abstract": "Seams play a fundamental role in the way a garment looks, fits, feels and behaves. Seams can have very different shapes and mechanical properties depending on how fabric is overlapped, folded and stitched together, with garment designers often choosing specific seam and stitch type combinations depending on the appearance and behavior they want for the garment. Yet, virtually all 3D CAD tools for fashion and visual effects ignore most of the visual and mechanical complexity of seams, and just treat them as joint edges, their simplest possible form, drastically limiting the fidelity of digital garments. In this paper, we present a method that models seams following their true, real-life construction. Each seam brings together and overlaps the fabric pieces to be sewn, folds the fabric according to the type of seam, and stitches the resulting assembly following the type of stitch. To avoid dealing with the complexities of folding in 3D space, we cast the problem into a sequence of simpler 2D problems where we can easily shape the seam and produce a result free of self-intersections, before lifting the folded geometry back to 3D space. We run a series of constrained optimizations to enforce spatial properties in these 2D settings, allowing us to treat asymmetric seams, gatherings and overlapping construction orders. Using a variety of common seams and stitches, we show how our approach substantially improves the visual appearance of full garments, for a better and more predictive digital replica.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_176",
    "authors": "Nipun Jindal, Pranay Kumar",
    "title": "Typefaces Structural Transformations Regularized Using Differential Evolution for Personalized Visual Accessibility",
    "paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3532719.3543222",
    "pdf_link": null,
    "abstract": "… transformation by providing candidate points and utilizing differential evolution with a typeface … GlyphWidth, StemWidth to ensure the output typeface is still legible. Our research enables …",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_283",
    "authors": "Yingying Ren, Uday Kusupati, Julian Panetta, Florin Isvoranu, Davide Pellis, Tian Chen, Mark Pauly",
    "title": "Umbrella Meshes: Elastic Mechanisms for Freeform Shape Deployment",
    "paper_url": "https://infoscience.epfl.ch/bitstreams/d8a02b1d-807b-4e7c-b17b-badc231d8996/download",
    "pdf_link": null,
    "abstract": "Deployable structures are widely used in industrial and consumer products, medical devices, aerospace applications, and civil installations [Molinari et al. 2011; Tang et al. 2017]. The ability to transform between different geometric states offers unique advantages such as compact storage and transport, simpler fabrication or assembly, and multi-functionality. Examples of deployable structures include temporary shelters, satellites, space-based solar panels [Chen et al. 2019], heart stents [Tomita et al. 2015], inflatable buildings, robotic surgical tools, and scissor lifts [Randall et al. 2012]. Rigid linkage mechanisms are one important class of deployable structures. Typically composed of rigid elements connected via rotational joints, such transformable assemblies can be modeled and optimized based on kinematic analysis [McCarthy and Soh 2010]. One iconic example is the Hoberman sphere that continuously transforms between compact and extended spherical states (Figure 2a). Compared to rigid linkage mechanisms, bending-active deployable structures have a richer shape space and offer additional functionalities. For example, deployable gridshells can assume a variety of curved shapes by allowing the individual beams to bend and twist in addition to pivoting around the connecting joints (see Figure 2b). Within this context, we propose a new deployable material system that combines the advantages of rigid linkage mechanisms and elastic beams to enable a wide variety of freeform shapes. Our work is inspired by a classical every-day deployable object, the umbrella. Most umbrellas use a compliant linkage structure to expand a fabric to the desired covering surface when deployed. We call our structures umbrella meshes as they are composed of regular arrangements of parameterized cells, each consisting of an umbrella-like mechanism (Figure 3).The key feature of umbrella meshes is that neighboring umbrella cells are geometrically incompatible when deployed to their expanded configurations. Although each cell covers the same area footprint in the undeployed state, the differing cell heights cause this area to expand by different amounts during deployment. Umbrella elements are thus forced to deform out-of-plane to accommodate the kinematic incompatibilities with their neighbors. Importantly, the undeployed state has no such incompatibility and so is free of residual stresses. This ensures easy assembly and enables direct fabrication with single-piece 3D printing.",
    "scholar_publication": "ACM Trans …, 2022 - infoscience.epfl.ch"
  },
  {
    "paper_id": "papers_197",
    "authors": "Merlin Nimier-David, Thomas Müller, Alexander Keller, Wenzel Jakob",
    "title": "Unbiased Inverse Volume Rendering With Differential Trackers",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530073",
    "pdf_link": null,
    "abstract": "Volumetric representations are popular in inverse rendering because they have a simple parameterization, are smoothly varying, and transparently handle topology changes. However, incorporating the full volumetric transport of light is costly and challenging, often leading practitioners to implement simplified models, such as purely emissive and absorbing volumes with \"baked\" lighting. One such challenge is the efficient estimation of the gradients of the volume's appearance with respect to its scattering and absorption parameters. We show that the straightforward approach---differentiating a volumetric free-flight sampler---can lead to biased and high-variance gradients, hindering optimization. Instead, we propose using a new sampling strategy: differential ratio tracking, which is unbiased, yields low-variance gradients, and runs in linear time. Differential ratio tracking combines ratio tracking and reservoir sampling to estimate gradients by sampling distances proportional to the unweighted transmittance rather than the usual extinction-weighted transmittance. In addition, we observe local minima when optimizing scattering parameters to reproduce dense volumes or surfaces. We show that these local minima can be overcome by bootstrapping the optimization from nonphysical emissive volumes that are easily optimized.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_610",
    "authors": "Zackary Misso, Benedikt Bitterli, Iliyan Georgiev, Wojciech Jarosz",
    "title": "Unbiased and Consistent Rendering Using Biased Estimators",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530160",
    "pdf_link": null,
    "abstract": "We introduce a general framework for transforming biased estimators into unbiased and consistent estimators for the same quantity. We show how several existing unbiased and consistent estimation strategies in rendering are special cases of this framework, and are part of a broader debiasing principle. We provide a recipe for constructing estimators using our generalized framework and demonstrate its applicability by developing novel unbiased forms of transmittance estimation, photon mapping, and finite differences.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_254",
    "authors": "Purvi Goel, Doug L. James",
    "title": "Unified Many-worlds Browsing of Arbitrary Physics-based Animations",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530082",
    "pdf_link": null,
    "abstract": "Manually tuning physics-based animation parameters to explore a simulation outcome space or achieve desired motion outcomes can be notoriously tedious. This problem has motivated many sophisticated and specialized optimization-based methods for fine-grained (keyframe) control, each of which are typically limited to specific animation phenomena, usually complicated, and, unfortunately, not widely used. In this paper, we propose Unified Many-Worlds Browsing (UMWB), a practical method for sample-level control and exploration of physics-based animations. Our approach supports browsing of large simulation ensembles of arbitrary animation phenomena by using a unified volumetric WORLDPACK representation based on spatiotemporally compressed voxel data associated with geometric occupancy and other low-fidelity animation state. Beyond memory reduction, the WORLDPACK representation also enables unified query support for interactive browsing: it provides fast evaluation of approximate spatiotemporal queries, such as occupancy tests that find ensemble samples (\"worlds\") where material is either IN or NOT IN a user-specified spacetime region. WORLDPACKS also support real-time hardware-accelerated voxel rendering by exploiting the spatially hierarchical and temporal RLE raster data structure. Our UMWB implementation supports interactive browsing (and offline refinement) of ensembles containing thousands of simulation samples, and fast spatiotemporal queries and ranking. We show UMWB results using a wide variety of physics-based animation phenomena---not just JELL-O®.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_673",
    "authors": "Xianghao Xu, Yifan Ruan, Srinath Sridhar, Daniel Ritchie",
    "title": "Unsupervised Kinematic Motion Detection for Part-segmented 3D Shape Collections",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530742",
    "pdf_link": null,
    "abstract": "3D models of manufactured objects are important for populating virtual worlds and for synthetic data generation for vision and robotics. To be most useful, such objects should be articulated: their parts should move when interacted with. While articulated object datasets exist, creating them is labor-intensive. Learning-based prediction of part motions can help, but all existing methods require annotated training data. In this paper, we present an unsupervised approach for discovering articulated motions in a part-segmented 3D shape collection. Our approach is based on a concept we call category closure: any valid articulation of an object’s parts should keep the object in the same semantic category (e.g. a chair stays a chair). We operationalize this concept with an algorithm that optimizes a shape’s part motion parameters such that it can transform into other shapes in the collection. We evaluate our approach by using it to re-discover part motions from the PartNet-Mobility dataset. For almost all shape categories, our method’s predicted motion parameters have low error with respect to ground truth annotations, outperforming two supervised motion prediction methods.",
    "scholar_publication": "ACM SIGGRAPH 2022 Conference …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_144",
    "authors": "Lei Chu, Hao Pan, Wenping Wang, Hao Pan",
    "title": "Unsupervised Shape Completion via Deep Prior in the Neural Tangent Kernel Perspective",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3459234",
    "pdf_link": null,
    "abstract": "We present a novel approach for completing and reconstructing 3D shapes from incomplete scanned data by using deep neural networks. Rather than being trained on supervised completion tasks and applied on a testing shape, the network is optimized from scratch on the single testing shape to fully adapt to the shape and complete the missing data using contextual guidance from the known regions. The ability to complete missing data by an untrained neural network is usually referred to as the deep prior. In this article, we interpret the deep prior from a neural tangent kernel (NTK) perspective and show that the completed shape patches by the trained CNN are naturally similar to existing patches, as they are proximate in the kernel feature space induced by NTK. The interpretation allows us to design more efficient network structures and learning mechanisms for the shape completion and reconstruction task. Being more aware of structural regularities than both traditional and other unsupervised learning-based reconstruction methods, our approach completes large missing regions with plausible shapes and complements supervised learning-based methods that use database priors by requiring no extra training dataset and showing flexible adaptation to a particular shape instance.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_503",
    "authors": "Michael Tao, Christopher Batty, Mirela Ben-Chen, Eugene Fiume, David Levin",
    "title": "VEMPIC: Particle-in-polyhedron Fluid Simulation for Intricate Solid Boundaries",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530138",
    "pdf_link": null,
    "abstract": "The comprehensive visual modeling of fluid motion has historically been a challenging task, due in no small part to the difficulties inherent in geometries that are non-manifold, open, or thin. Modern geometric cut-cell mesh generators have been shown to produce, both robustly and quickly, workable volumetric elements in the presence of these problematic geometries, and the resulting volumetric representation would seem to offer an ideal infrastructure with which to perform fluid simulations. However, cut-cell mesh elements are general polyhedra that often contain holes and are non-convex; it is therefore difficult to construct the explicit function spaces required to employ standard functional discretizations, such as the Finite Element Method. The Virtual Element Method (VEM) has recently emerged as a functional discretization that successfully operates with complex polyhedral elements through a weak formulation of its function spaces. We present a novel cut-cell fluid simulation framework that exactly represents boundary geometry during the simulation. Our approach enables, for the first time, detailed fluid simulation with \"in-the-wild\" obstacles, including ones that contain non-manifold parts, self-intersections, and extremely thin features. Our key technical contribution is the generalization of the Particle-In-Cell fluid simulation methodology to arbitrary polyhedra using VEM. Coupled with a robust cut-cell generation scheme, this produces a fluid simulation algorithm that can operate on previously infeasible geometries without requiring any additional mesh modification or repair.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_483",
    "authors": "Towaki Takikawa, Alex Evans, Jonathan Tremblay, Thomas Müller, Morgan McGuire, Alec Jacobson, Sanja Fidler",
    "title": "Variable Bitrate Neural Fields",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530727",
    "pdf_link": null,
    "abstract": "… (static bitrate), in contrast to our work where we aim to achieve variable bitrate via streaming … We will first give a background on signal compression and neural fields to provide an …",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_502",
    "authors": "Astrid Bunge, Philipp Herholz, Olga Sorkine-Hornung, Mario Botsch, Michael Kazhdan",
    "title": "Variational Quadratic Shape Functions for Polygons and Polyhedra",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530137",
    "pdf_link": null,
    "abstract": "Solving partial differential equations (PDEs) on geometric domains is an important component of computer graphics, geometry processing, and many other fields. Typically, the given discrete mesh is the geometric representation and should not be altered for simulation purposes. Hence, accurately solving PDEs on general meshes is a central goal and has been considered for various differential operators over the last years. While it is known that using higher-order basis functions on simplicial meshes can substantially improve accuracy and convergence, extending these benefits to general surface or volume tessellations in an efficient fashion remains an open problem. Our work proposes variationally optimized piecewise quadratic shape functions for polygons and polyhedra, which generalize quadratic P2 elements, exactly reproduce them on simplices, and inherit their beneficial numerical properties. To mitigate the associated cost of increased computation time, particularly for volumetric meshes, we introduce a custom two-level multigrid solver which significantly improves computational performance.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_193",
    "authors": "Gregg Perkins, Santiago Echeverry",
    "title": "Virtual Production in Action: A Creative Implementation of Expanded Cinematography and Narratives",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543231",
    "pdf_link": null,
    "abstract": "Virtual Production fulfills George Lucas's early dream of having an engulfing “space-opera in the sky” (1). Epic Games’ focus on realistic interactive 3D game environments using Unreal Engine, revolutionized the field of film-making, by replacing rear film projections with large format, curved, high resolution, immersive LED video screens, allowing backdrops to adapt in real time to the narrative needs of each scene by tracking the movement of the camera. Cinematographers and Art Directors are adapting to the challenges of virtual and real lighting and props, recruiting animators and new media developers who create, usually in very little time, virtual and real props, and metahuman actors and characters, enhancing the production value, optimizing and reducing costs in unparalleled ways. This poster presents the results of the first Virtual Production class offered by the Film Animation and New Media Department at the University of Tampa. In a very short time span, students working in interdisciplinary teams have seen the possibilities of these new technologies for science fiction, fantasy and experimental films that otherwise would have been impossible to create with very limited student budgets.",
    "scholar_publication": "ACM SIGGRAPH 2022 Posters, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_782",
    "authors": "Feitong Tan, Sean Fanello, Abhimitra Meka, Sergio Orts-Escolano, Danhang Tang, Rohit Pandey, Jonathan Taylor, Ping Tan, Yinda Zhang",
    "title": "VoLux-GAN: A Generative Model for 3D Face Synthesis With HDRI Relighting",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528233.3530751",
    "pdf_link": null,
    "abstract": "We propose VoLux-GAN, a generative framework to synthesize 3D-aware faces with convincing relighting. Our main contribution is a volumetric HDRI relighting method that can efficiently accumulate albedo, diffuse and specular lighting contributions along each 3D ray for any desired HDR environmental map. Additionally, we show the importance of supervising the image decomposition process using multiple discriminators. In particular, we propose a data augmentation technique that leverages recent advances in single image portrait relighting to enforce consistent geometry, albedo, diffuse and specular components. Multiple experiments and comparisons with other generative frameworks show how our model is a step forward towards photorealistic relightable 3D generative models. Code and pre-trained models are available at: https://github.com/google/volux-gan.",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_443",
    "authors": "Hendrik Brückler, David Bommes, Marcel Campen",
    "title": "Volume Parametrization Quantization for Hexahedral Meshing",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530123",
    "pdf_link": null,
    "abstract": "Developments in the field of parametrization-based quad mesh generation on surfaces have been impactful over the past decade. In this context, an important advance has been the replacement of error-prone rounding in the generation of integer-grid maps, by robust quantization methods. In parallel, parametrization-based hex mesh generation for volumes has been advanced. In this volumetric context, however, the state-of-the-art still relies on fragile rounding, not rarely producing defective meshes, especially when targeting a coarse mesh resolution. We present a method to robustly quantize volume parametrizations, i.e., to determine guaranteed valid choices of integers for 3D integer-grid maps. Inspired by the 2D case, we base our construction on a non-conforming cell decomposition of the volume, a 3D analogue of a T-mesh. In particular, we leverage the motorcycle complex, a recent generalization of the motorcycle graph, for this purpose. Integer values are expressed in a differential manner on the edges of this complex, enabling the efficient formulation of the conditions required to strictly prevent forcing the map into degeneration. Applying our method in the context of hexahedral meshing, we demonstrate that hexahedral meshes can be generated with significantly improved flexibility.",
    "scholar_publication": "ACM Transactions on Graphics …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_488",
    "authors": "Jiahui Sun, Wenming Wu, Ligang Liu, Wenjie Min, Gaofeng Zhang, Liping Zheng",
    "title": "WallPlan: Synthesizing Floorplans by Learning to Generate Wall Graphs",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530135",
    "pdf_link": null,
    "abstract": "Floorplan generation has drawn widespread interest in the community. Recent learning-based methods for generating realistic floorplans have made significant progress while a complex heuristic post-processing is still necessary to obtain desired results. In this paper, we propose a novel wall-oriented method, called WallPlan, for automatically and efficiently generating plausible floorplans from various design constraints. We pioneer the representation of the floorplan as a wall graph with room labels and consider the floorplan generation as a graph generation. Given the boundary as input, we first initialize the boundary with windows predicted by WinNet. Then a graph generation network GraphNet and semantics prediction network LabelNet are coupled to generate the wall graph progressively by imitating graph traversal. WallPlan can be applied for practical architectural designs, especially the wall-based constraints. We conduct ablation experiments, qualitative evaluations, quantitative comparisons, and perceptual studies to evaluate our method's feasibility, efficacy, and versatility. Intensive experiments demonstrate our method requires no post-processing, producing higher quality floorplans than state-of-the-art techniques.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "papers_827",
    "authors": "Hanxiao Shen, Leyi Zhu, Ryan Capouellez, Daniele Panozzo, Marcel Campen, Denis Zorin",
    "title": "Which Cross Fields Can Be Quadrangulated? Global Parameterization From Prescribed Holonomy Signatures",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530187",
    "pdf_link": null,
    "abstract": "We describe a method for the generation of seamless surface parametrizations with guaranteed local injectivity and full control over holonomy. Previous methods guarantee only one of the two. Local injectivity is required to enable these parametrizations' use in applications such as surface quadrangulation and spline construction. Holonomy control is crucial to enable guidance or prescription of the parametrization's isocurves based on directional information, in particular from cross-fields or feature curves, and more generally to constrain the parametrization topologically. To this end we investigate the relation between cross-field topology and seamless parametrization topology. Leveraging previous results on locally injective parametrization and combining them with insights on this relation in terms of holonomy, we propose an algorithm that meets these requirements. A key component relies on the insight that arbitrary surface cut graphs, as required for global parametrization, can be homeomorphically modified to assume almost any set of turning numbers with respect to a given target cross-field.",
    "scholar_publication": "ACM Transactions on …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "pos_124",
    "authors": "Akihiro Kiuchi, Taishi Eguchi, Jun Rekimoto, Manabu Tsukada, Hiroshi Esaki",
    "title": "ZIGEN: A Windowing System Enabling Multitasking Among 3D and 2D Applications in Immersive Environments",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3532719.3543200",
    "pdf_link": null,
    "abstract": "Windowing systems are an integral part of the modern desktop environment. Thanks to them, we are able to use multiple graphical user interface (GUI) applications from different developers simultaneously on a single display. They not only display multiple applications as overlapping windows, but also abstract input events such as keyboard and mouse events, and define the concept of focus which is the destination of these events, so that input events are transferred only to the application intended by the user. Furthermore, they define protocols such as drag-and-drop so that data can be passed between applications even if they are developed by",
    "scholar_publication": "ACM SIGGRAPH 2022 …, 2022 - dl.acm.org"
  },
  {
    "paper_id": "paperstog_119",
    "authors": "Giacomo Nazzaro, Enrico Puppo, Fabio Pellacini, Enrico Puppo",
    "title": "geoTangle: Interactive Design of Geodesic Tangle Patterns on Surfaces",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3487909",
    "pdf_link": null,
    "abstract": "Tangles are complex patterns, which are often used to decorate the surface of real-world artisanal objects. They consist of arrangements of simple shapes organized into nested hierarchies, obtained by recursively splitting regions to add progressively finer details. In this article, we show that 3D digital shapes can be decorated with tangles by working interactively in the intrinsic metric of the surface. Our tangles are generated by the recursive application of only four operators, which are derived from tracing the isolines or the integral curves of geodesics fields generated from selected seeds on the surface. Based on this formulation, we present an interactive application that lets designers model complex recursive patterns directly on the object surface without relying on parametrization. We reach interactive speed on meshes of a few million triangles by relying on an efficient approximate graph-based geodesic solver.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2021 - dl.acm.org"
  },
  {
    "paper_id": "papers_416",
    "authors": "Rafal K. Mantiuk, Maliha Ashraf, Alexandre Chapiro",
    "title": "stelaCSF — A Unified Model of Contrast Sensitivity as the Function of Spatio-temporal Frequency, Eccentricity Luminance, and Area",
    "paper_url": "https://dl.acm.org/doi/abs/10.1145/3528223.3530115",
    "pdf_link": null,
    "abstract": "A contrast sensitivity function, or CSF, is a cornerstone of many visual models. It explains whether a contrast pattern is visible to the human eye. The existing CSFs typically account for a subset of relevant dimensions describing a stimulus, limiting the use of such functions to either static or foveal content but not both. In this paper, we propose a unified CSF, stelaCSF, which accounts for all major dimensions of the stimulus: spatial and temporal frequency, eccentricity, luminance, and area. To model the 5-dimensional space of contrast sensitivity, we combined data from 11 papers, each of which studied a subset of this space. While previously proposed CSFs were fitted to a single dataset, stelaCSF can predict the data from all these studies using the same set of parameters. The predictions are accurate in the entire domain, including low frequencies. In addition, stelaCSF relies on psychophysical models and experimental evidence to explain the major interactions between the 5 dimensions of the CSF. We demonstrate the utility of our new CSF in a flicker detection metric and in foveated rendering.",
    "scholar_publication": "ACM Transactions on Graphics (TOG), 2022 - dl.acm.org"
  }
]